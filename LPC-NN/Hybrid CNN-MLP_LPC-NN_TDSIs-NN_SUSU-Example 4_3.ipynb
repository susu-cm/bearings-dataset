{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file includes implementation of methods used in our paper in Example С on SUSU dataset:\n",
    "### 1- HybridCNN+MLP \n",
    "### 2- LPC-NN \n",
    "### 3- TDSIs-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HybridCNN+MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z8mK8ge2tRek"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "import imageio\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import savez_compressed\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD9ZDA-no5Rd",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-BK83NRkuSbO"
   },
   "outputs": [],
   "source": [
    "def results(history, model, testX, testY):\n",
    "  plt.rc('axes',edgecolor='k')\n",
    "  plt.rc('axes',linewidth='1')\n",
    "  plt.rcParams['figure.dpi'] = 100\n",
    "  dataset_labels=np.array(['Normal','Inner', 'Outer', 'Ball', 'Comb'])\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs_range = range(len(history.history['loss']))\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  plt.subplot(121, facecolor='w')\n",
    "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(122, facecolor='w')\n",
    "  plt.plot(epochs_range, loss, label='Training Loss')\n",
    "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "  test_loss, test_acc = model.evaluate(testX, testY, verbose=2)\n",
    "\n",
    "  # Confusion Matrix\n",
    "  predictions = model.predict(testX)\n",
    "  confusion = confusion_matrix(np.argmax(testY, axis=1), \n",
    "                              np.argmax(predictions, axis=1))\n",
    "  print('CONFUSION MATRIX\\n', confusion, '\\n\\n')\n",
    "  # normalize confustion matrix [0 1]\n",
    "  # confusion = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "  df_cm = pd.DataFrame(confusion, \n",
    "                       dataset_labels, \n",
    "                       dataset_labels)\n",
    "  sn.set(font_scale=1.2) # for label size\n",
    "  plt.figure(figsize=(4,4))\n",
    "  sn.heatmap(df_cm, \n",
    "             annot=True, \n",
    "             annot_kws={\"size\": 10},\n",
    "             fmt = \"d\",\n",
    "             linewidths=.5,\n",
    "             cmap=\"YlGnBu\") \n",
    "  plt.title(str(model.name))\n",
    "  plt.ylabel(\"True Label\")\n",
    "  plt.xlabel(\"Predicted Label\")\n",
    "  plt.show()\n",
    "\n",
    "  print('CLASSIFICATION REPORT\\n',\n",
    "        classification_report(np.argmax(testY, axis=1), \n",
    "                              np.argmax(predictions, axis=1), \n",
    "                              target_names=dataset_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BJxoi3Tv4Z9g"
   },
   "outputs": [],
   "source": [
    "def progress(value, max=100):\n",
    "  # Progress Bar\n",
    "    return HTML(\"\"\"\n",
    "        <progress\n",
    "            value='{value}'\n",
    "            max='{max}',\n",
    "            style='width: 50%'\n",
    "        >\n",
    "            {value}\n",
    "        </progress>\n",
    "    \"\"\".format(value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SL6hlRQnoabl"
   },
   "outputs": [],
   "source": [
    "def load_signals_attributes(input_path, display=False):\n",
    "  print('[INFO] Loading…\\n')\n",
    "  cols = [\"N1\", \"N2\", \"class\"]\n",
    "  df = pd.read_csv(input_path, sep=\" \", header=None, names=cols)\n",
    "  print('[INFO] Attributes loaded successfully!\\n')\n",
    "  if display == True:\n",
    "    df.head()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IFhkV4cxqdeU"
   },
   "outputs": [],
   "source": [
    "def load_signals_images(input_path):\n",
    "  print(os.listdir(input_path))\n",
    "  print('[INFO] Sorting files in directory...\\n')\n",
    "  path = input_path+\"/*.png\"\n",
    "  directory = sorted(glob.glob(path), key=len) \n",
    "  directory = sorted(glob.glob(path), \n",
    "                    key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "  def get_key(fp):\n",
    "      filename = os.path.splitext(os.path.basename(fp))[0]\n",
    "      int_part = filename.split()[0]\n",
    "      return int(int_part)\n",
    "  directory = sorted(glob.glob(path), \n",
    "                    key=get_key)\n",
    "\n",
    "  print('[INFO] Loading images in matrices...\\n')\n",
    "  Im = []\n",
    "  bar = display(progress(0, len(directory)), display_id=True) # Progress Bar\n",
    "  counter = 0\n",
    "  for image_path in directory:\n",
    "    img = imageio.imread(image_path)\n",
    "    Im.append(img)\n",
    "    counter += 1\n",
    "    bar.update(progress(counter, len(directory))) # Update Progress\n",
    "  # Масштабируем  \n",
    "  Im = np.array(Im)/255.0\n",
    "  print(\"[INFO] Dataset loaded\")\n",
    "  return Im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgAwpeHXj2cu",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPje5-McV47_"
   },
   "source": [
    "### Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z-ABvShmKriO"
   },
   "outputs": [],
   "source": [
    "data_root_Train='D:\\\\Mohammad paper\\\\LPC-NN\\\\to_submit_Trans_on_Ins_Meas\\\\CORRECTED\\\\data\\\\hilbert\\\\imagesTrain'\n",
    "data_root_Test='D:\\\\Mohammad paper\\\\LPC-NN\\\\to_submit_Trans_on_Ins_Meas\\\\CORRECTED\\\\data\\\\hilbert\\\\imagesTest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWqoqV1VhVlQ",
    "outputId": "2bc6295b-e8ff-445b-d887-37bcf2ee7aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading…\n",
      "\n",
      "[INFO] Attributes loaded successfully!\n",
      "\n",
      "[INFO] Loading…\n",
      "\n",
      "[INFO] Attributes loaded successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attr_Train = load_signals_attributes(data_root_Train+\"/TxtInfo_Train.txt\")\n",
    "attr_Test = load_signals_attributes(data_root_Test+\"/TxtInfo_Test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vgj141hX1aah"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.png', '10.png', '100.png', '1000.png', '1001.png', '1002.png', '1003.png', '1004.png', '1005.png', '1006.png', '1007.png', '1008.png', '1009.png', '101.png', '1010.png', '1011.png', '1012.png', '1013.png', '1014.png', '1015.png', '1016.png', '1017.png', '1018.png', '1019.png', '102.png', '1020.png', '1021.png', '1022.png', '1023.png', '1024.png', '1025.png', '1026.png', '1027.png', '1028.png', '1029.png', '103.png', '1030.png', '1031.png', '1032.png', '1033.png', '1034.png', '1035.png', '1036.png', '1037.png', '1038.png', '1039.png', '104.png', '1040.png', '1041.png', '1042.png', '1043.png', '1044.png', '1045.png', '1046.png', '1047.png', '1048.png', '1049.png', '105.png', '1050.png', '1051.png', '1052.png', '1053.png', '1054.png', '1055.png', '1056.png', '1057.png', '1058.png', '1059.png', '106.png', '1060.png', '1061.png', '1062.png', '1063.png', '1064.png', '1065.png', '1066.png', '1067.png', '1068.png', '1069.png', '107.png', '1070.png', '1071.png', '1072.png', '1073.png', '1074.png', '1075.png', '1076.png', '1077.png', '1078.png', '1079.png', '108.png', '1080.png', '1081.png', '1082.png', '1083.png', '1084.png', '1085.png', '1086.png', '1087.png', '1088.png', '1089.png', '109.png', '1090.png', '1091.png', '1092.png', '1093.png', '1094.png', '1095.png', '1096.png', '1097.png', '1098.png', '1099.png', '11.png', '110.png', '1100.png', '1101.png', '1102.png', '1103.png', '1104.png', '1105.png', '1106.png', '1107.png', '1108.png', '1109.png', '111.png', '1110.png', '1111.png', '1112.png', '1113.png', '1114.png', '1115.png', '1116.png', '1117.png', '1118.png', '1119.png', '112.png', '1120.png', '1121.png', '1122.png', '1123.png', '1124.png', '1125.png', '1126.png', '1127.png', '1128.png', '1129.png', '113.png', '1130.png', '1131.png', '1132.png', '1133.png', '1134.png', '1135.png', '1136.png', '1137.png', '1138.png', '1139.png', '114.png', '1140.png', '1141.png', '1142.png', '1143.png', '1144.png', '1145.png', '1146.png', '1147.png', '1148.png', '1149.png', '115.png', '1150.png', '1151.png', '1152.png', '1153.png', '1154.png', '1155.png', '1156.png', '1157.png', '1158.png', '1159.png', '116.png', '1160.png', '1161.png', '1162.png', '1163.png', '1164.png', '1165.png', '1166.png', '1167.png', '1168.png', '1169.png', '117.png', '1170.png', '1171.png', '1172.png', '1173.png', '1174.png', '1175.png', '1176.png', '1177.png', '1178.png', '1179.png', '118.png', '1180.png', '1181.png', '1182.png', '1183.png', '1184.png', '1185.png', '1186.png', '1187.png', '1188.png', '1189.png', '119.png', '1190.png', '1191.png', '1192.png', '1193.png', '1194.png', '1195.png', '1196.png', '1197.png', '1198.png', '1199.png', '12.png', '120.png', '1200.png', '1201.png', '1202.png', '1203.png', '1204.png', '1205.png', '1206.png', '1207.png', '1208.png', '1209.png', '121.png', '1210.png', '1211.png', '1212.png', '1213.png', '1214.png', '1215.png', '1216.png', '1217.png', '1218.png', '1219.png', '122.png', '1220.png', '1221.png', '1222.png', '1223.png', '1224.png', '1225.png', '1226.png', '1227.png', '1228.png', '1229.png', '123.png', '1230.png', '1231.png', '1232.png', '1233.png', '1234.png', '1235.png', '1236.png', '1237.png', '1238.png', '1239.png', '124.png', '1240.png', '1241.png', '1242.png', '1243.png', '1244.png', '1245.png', '1246.png', '1247.png', '1248.png', '1249.png', '125.png', '1250.png', '1251.png', '1252.png', '1253.png', '1254.png', '1255.png', '1256.png', '1257.png', '1258.png', '1259.png', '126.png', '1260.png', '1261.png', '1262.png', '1263.png', '1264.png', '1265.png', '1266.png', '1267.png', '1268.png', '1269.png', '127.png', '1270.png', '1271.png', '1272.png', '1273.png', '1274.png', '1275.png', '1276.png', '1277.png', '1278.png', '1279.png', '128.png', '1280.png', '1281.png', '1282.png', '1283.png', '1284.png', '1285.png', '1286.png', '1287.png', '1288.png', '1289.png', '129.png', '1290.png', '1291.png', '1292.png', '1293.png', '1294.png', '1295.png', '1296.png', '1297.png', '1298.png', '1299.png', '13.png', '130.png', '1300.png', '1301.png', '1302.png', '1303.png', '1304.png', '1305.png', '1306.png', '1307.png', '1308.png', '1309.png', '131.png', '1310.png', '1311.png', '1312.png', '1313.png', '1314.png', '1315.png', '1316.png', '1317.png', '1318.png', '1319.png', '132.png', '1320.png', '1321.png', '1322.png', '1323.png', '1324.png', '1325.png', '1326.png', '1327.png', '1328.png', '1329.png', '133.png', '1330.png', '1331.png', '1332.png', '1333.png', '1334.png', '1335.png', '1336.png', '1337.png', '1338.png', '1339.png', '134.png', '1340.png', '1341.png', '1342.png', '1343.png', '1344.png', '1345.png', '1346.png', '1347.png', '1348.png', '1349.png', '135.png', '1350.png', '1351.png', '1352.png', '1353.png', '1354.png', '1355.png', '1356.png', '1357.png', '1358.png', '1359.png', '136.png', '1360.png', '1361.png', '1362.png', '1363.png', '1364.png', '1365.png', '1366.png', '1367.png', '1368.png', '1369.png', '137.png', '1370.png', '1371.png', '1372.png', '1373.png', '1374.png', '1375.png', '1376.png', '1377.png', '1378.png', '1379.png', '138.png', '1380.png', '1381.png', '1382.png', '1383.png', '1384.png', '1385.png', '1386.png', '1387.png', '1388.png', '1389.png', '139.png', '1390.png', '1391.png', '1392.png', '1393.png', '1394.png', '1395.png', '1396.png', '1397.png', '1398.png', '1399.png', '14.png', '140.png', '1400.png', '1401.png', '1402.png', '1403.png', '1404.png', '1405.png', '1406.png', '1407.png', '1408.png', '1409.png', '141.png', '1410.png', '1411.png', '1412.png', '1413.png', '1414.png', '1415.png', '1416.png', '1417.png', '1418.png', '1419.png', '142.png', '1420.png', '1421.png', '1422.png', '1423.png', '1424.png', '1425.png', '1426.png', '1427.png', '1428.png', '1429.png', '143.png', '1430.png', '1431.png', '1432.png', '1433.png', '1434.png', '1435.png', '1436.png', '1437.png', '1438.png', '1439.png', '144.png', '1440.png', '1441.png', '1442.png', '1443.png', '1444.png', '1445.png', '1446.png', '1447.png', '1448.png', '1449.png', '145.png', '1450.png', '1451.png', '1452.png', '1453.png', '1454.png', '1455.png', '1456.png', '1457.png', '1458.png', '1459.png', '146.png', '1460.png', '1461.png', '1462.png', '1463.png', '1464.png', '1465.png', '1466.png', '1467.png', '1468.png', '1469.png', '147.png', '1470.png', '1471.png', '1472.png', '1473.png', '1474.png', '1475.png', '1476.png', '1477.png', '1478.png', '1479.png', '148.png', '1480.png', '1481.png', '1482.png', '1483.png', '1484.png', '1485.png', '1486.png', '1487.png', '1488.png', '1489.png', '149.png', '1490.png', '1491.png', '1492.png', '1493.png', '1494.png', '1495.png', '1496.png', '1497.png', '1498.png', '1499.png', '15.png', '150.png', '1500.png', '1501.png', '1502.png', '1503.png', '1504.png', '1505.png', '1506.png', '1507.png', '1508.png', '1509.png', '151.png', '1510.png', '1511.png', '1512.png', '1513.png', '1514.png', '1515.png', '1516.png', '1517.png', '1518.png', '1519.png', '152.png', '1520.png', '1521.png', '1522.png', '1523.png', '1524.png', '1525.png', '1526.png', '1527.png', '1528.png', '1529.png', '153.png', '1530.png', '1531.png', '1532.png', '1533.png', '1534.png', '1535.png', '1536.png', '1537.png', '1538.png', '1539.png', '154.png', '1540.png', '1541.png', '1542.png', '1543.png', '1544.png', '1545.png', '1546.png', '1547.png', '1548.png', '1549.png', '155.png', '1550.png', '1551.png', '1552.png', '1553.png', '1554.png', '1555.png', '1556.png', '1557.png', '1558.png', '1559.png', '156.png', '1560.png', '1561.png', '1562.png', '1563.png', '1564.png', '1565.png', '1566.png', '1567.png', '1568.png', '1569.png', '157.png', '1570.png', '1571.png', '1572.png', '1573.png', '1574.png', '1575.png', '1576.png', '1577.png', '1578.png', '1579.png', '158.png', '1580.png', '1581.png', '1582.png', '1583.png', '1584.png', '1585.png', '1586.png', '1587.png', '1588.png', '1589.png', '159.png', '1590.png', '1591.png', '1592.png', '1593.png', '1594.png', '1595.png', '1596.png', '1597.png', '1598.png', '1599.png', '16.png', '160.png', '1600.png', '1601.png', '1602.png', '1603.png', '1604.png', '1605.png', '1606.png', '1607.png', '1608.png', '1609.png', '161.png', '1610.png', '1611.png', '1612.png', '1613.png', '1614.png', '1615.png', '1616.png', '1617.png', '1618.png', '1619.png', '162.png', '1620.png', '1621.png', '1622.png', '1623.png', '1624.png', '1625.png', '1626.png', '1627.png', '1628.png', '1629.png', '163.png', '1630.png', '1631.png', '1632.png', '1633.png', '1634.png', '1635.png', '1636.png', '1637.png', '1638.png', '1639.png', '164.png', '1640.png', '1641.png', '1642.png', '1643.png', '1644.png', '1645.png', '1646.png', '1647.png', '1648.png', '1649.png', '165.png', '1650.png', '1651.png', '1652.png', '1653.png', '1654.png', '1655.png', '1656.png', '1657.png', '1658.png', '1659.png', '166.png', '1660.png', '1661.png', '1662.png', '1663.png', '1664.png', '1665.png', '1666.png', '1667.png', '1668.png', '1669.png', '167.png', '1670.png', '1671.png', '1672.png', '1673.png', '1674.png', '1675.png', '1676.png', '1677.png', '1678.png', '1679.png', '168.png', '1680.png', '1681.png', '1682.png', '1683.png', '1684.png', '1685.png', '1686.png', '1687.png', '1688.png', '1689.png', '169.png', '1690.png', '1691.png', '1692.png', '1693.png', '1694.png', '1695.png', '1696.png', '1697.png', '1698.png', '1699.png', '17.png', '170.png', '1700.png', '1701.png', '1702.png', '1703.png', '1704.png', '1705.png', '1706.png', '1707.png', '1708.png', '1709.png', '171.png', '1710.png', '1711.png', '1712.png', '1713.png', '1714.png', '1715.png', '1716.png', '1717.png', '1718.png', '1719.png', '172.png', '1720.png', '1721.png', '1722.png', '1723.png', '1724.png', '1725.png', '1726.png', '1727.png', '1728.png', '1729.png', '173.png', '1730.png', '1731.png', '1732.png', '1733.png', '1734.png', '1735.png', '1736.png', '1737.png', '1738.png', '1739.png', '174.png', '1740.png', '1741.png', '1742.png', '1743.png', '1744.png', '1745.png', '1746.png', '1747.png', '1748.png', '1749.png', '175.png', '1750.png', '1751.png', '1752.png', '1753.png', '1754.png', '1755.png', '1756.png', '1757.png', '1758.png', '1759.png', '176.png', '1760.png', '1761.png', '1762.png', '1763.png', '1764.png', '1765.png', '1766.png', '1767.png', '1768.png', '1769.png', '177.png', '1770.png', '1771.png', '1772.png', '1773.png', '1774.png', '1775.png', '1776.png', '1777.png', '1778.png', '1779.png', '178.png', '1780.png', '1781.png', '1782.png', '1783.png', '1784.png', '1785.png', '1786.png', '1787.png', '1788.png', '1789.png', '179.png', '1790.png', '1791.png', '1792.png', '1793.png', '1794.png', '1795.png', '1796.png', '1797.png', '1798.png', '1799.png', '18.png', '180.png', '1800.png', '1801.png', '1802.png', '1803.png', '1804.png', '1805.png', '1806.png', '1807.png', '1808.png', '1809.png', '181.png', '1810.png', '1811.png', '1812.png', '1813.png', '1814.png', '1815.png', '1816.png', '1817.png', '1818.png', '1819.png', '182.png', '1820.png', '1821.png', '1822.png', '1823.png', '1824.png', '1825.png', '1826.png', '1827.png', '1828.png', '1829.png', '183.png', '1830.png', '1831.png', '1832.png', '1833.png', '1834.png', '1835.png', '1836.png', '1837.png', '1838.png', '1839.png', '184.png', '1840.png', '1841.png', '1842.png', '1843.png', '1844.png', '1845.png', '1846.png', '1847.png', '1848.png', '1849.png', '185.png', '1850.png', '1851.png', '1852.png', '1853.png', '1854.png', '1855.png', '1856.png', '1857.png', '1858.png', '1859.png', '186.png', '1860.png', '1861.png', '1862.png', '1863.png', '1864.png', '1865.png', '1866.png', '1867.png', '1868.png', '1869.png', '187.png', '1870.png', '1871.png', '1872.png', '1873.png', '1874.png', '1875.png', '1876.png', '1877.png', '1878.png', '1879.png', '188.png', '1880.png', '1881.png', '1882.png', '1883.png', '1884.png', '1885.png', '1886.png', '1887.png', '1888.png', '1889.png', '189.png', '1890.png', '1891.png', '1892.png', '1893.png', '1894.png', '1895.png', '1896.png', '1897.png', '1898.png', '1899.png', '19.png', '190.png', '1900.png', '1901.png', '1902.png', '1903.png', '1904.png', '1905.png', '1906.png', '1907.png', '1908.png', '1909.png', '191.png', '1910.png', '1911.png', '1912.png', '1913.png', '1914.png', '1915.png', '1916.png', '1917.png', '1918.png', '1919.png', '192.png', '1920.png', '1921.png', '1922.png', '1923.png', '1924.png', '1925.png', '1926.png', '1927.png', '1928.png', '1929.png', '193.png', '1930.png', '1931.png', '1932.png', '1933.png', '1934.png', '1935.png', '1936.png', '1937.png', '1938.png', '1939.png', '194.png', '1940.png', '1941.png', '1942.png', '1943.png', '1944.png', '1945.png', '1946.png', '1947.png', '1948.png', '1949.png', '195.png', '1950.png', '1951.png', '1952.png', '1953.png', '1954.png', '1955.png', '1956.png', '1957.png', '1958.png', '1959.png', '196.png', '1960.png', '1961.png', '1962.png', '1963.png', '1964.png', '1965.png', '1966.png', '1967.png', '1968.png', '1969.png', '197.png', '1970.png', '1971.png', '1972.png', '1973.png', '1974.png', '1975.png', '1976.png', '1977.png', '1978.png', '1979.png', '198.png', '1980.png', '1981.png', '1982.png', '1983.png', '1984.png', '1985.png', '1986.png', '1987.png', '1988.png', '1989.png', '199.png', '1990.png', '1991.png', '1992.png', '1993.png', '1994.png', '1995.png', '1996.png', '1997.png', '1998.png', '1999.png', '2.png', '20.png', '200.png', '2000.png', '2001.png', '2002.png', '2003.png', '2004.png', '2005.png', '2006.png', '2007.png', '2008.png', '2009.png', '201.png', '2010.png', '2011.png', '2012.png', '2013.png', '2014.png', '2015.png', '2016.png', '2017.png', '2018.png', '2019.png', '202.png', '2020.png', '2021.png', '2022.png', '2023.png', '2024.png', '2025.png', '2026.png', '2027.png', '2028.png', '2029.png', '203.png', '2030.png', '2031.png', '2032.png', '2033.png', '2034.png', '2035.png', '2036.png', '2037.png', '2038.png', '2039.png', '204.png', '2040.png', '2041.png', '2042.png', '2043.png', '2044.png', '2045.png', '2046.png', '2047.png', '2048.png', '2049.png', '205.png', '2050.png', '2051.png', '2052.png', '2053.png', '2054.png', '2055.png', '2056.png', '2057.png', '2058.png', '2059.png', '206.png', '2060.png', '2061.png', '2062.png', '2063.png', '2064.png', '2065.png', '2066.png', '2067.png', '2068.png', '2069.png', '207.png', '2070.png', '2071.png', '2072.png', '2073.png', '2074.png', '2075.png', '2076.png', '2077.png', '2078.png', '2079.png', '208.png', '2080.png', '2081.png', '2082.png', '2083.png', '2084.png', '2085.png', '2086.png', '2087.png', '2088.png', '2089.png', '209.png', '2090.png', '2091.png', '2092.png', '2093.png', '2094.png', '2095.png', '2096.png', '2097.png', '2098.png', '2099.png', '21.png', '210.png', '2100.png', '2101.png', '2102.png', '2103.png', '2104.png', '2105.png', '2106.png', '2107.png', '2108.png', '2109.png', '211.png', '2110.png', '2111.png', '2112.png', '2113.png', '2114.png', '2115.png', '2116.png', '2117.png', '2118.png', '2119.png', '212.png', '2120.png', '2121.png', '2122.png', '2123.png', '2124.png', '2125.png', '2126.png', '2127.png', '2128.png', '2129.png', '213.png', '2130.png', '2131.png', '2132.png', '2133.png', '2134.png', '2135.png', '2136.png', '2137.png', '2138.png', '2139.png', '214.png', '2140.png', '2141.png', '2142.png', '2143.png', '2144.png', '2145.png', '2146.png', '2147.png', '2148.png', '2149.png', '215.png', '2150.png', '2151.png', '2152.png', '2153.png', '2154.png', '2155.png', '216.png', '217.png', '218.png', '219.png', '22.png', '220.png', '221.png', '222.png', '223.png', '224.png', '225.png', '226.png', '227.png', '228.png', '229.png', '23.png', '230.png', '231.png', '232.png', '233.png', '234.png', '235.png', '236.png', '237.png', '238.png', '239.png', '24.png', '240.png', '241.png', '242.png', '243.png', '244.png', '245.png', '246.png', '247.png', '248.png', '249.png', '25.png', '250.png', '251.png', '252.png', '253.png', '254.png', '255.png', '256.png', '257.png', '258.png', '259.png', '26.png', '260.png', '261.png', '262.png', '263.png', '264.png', '265.png', '266.png', '267.png', '268.png', '269.png', '27.png', '270.png', '271.png', '272.png', '273.png', '274.png', '275.png', '276.png', '277.png', '278.png', '279.png', '28.png', '280.png', '281.png', '282.png', '283.png', '284.png', '285.png', '286.png', '287.png', '288.png', '289.png', '29.png', '290.png', '291.png', '292.png', '293.png', '294.png', '295.png', '296.png', '297.png', '298.png', '299.png', '3.png', '30.png', '300.png', '301.png', '302.png', '303.png', '304.png', '305.png', '306.png', '307.png', '308.png', '309.png', '31.png', '310.png', '311.png', '312.png', '313.png', '314.png', '315.png', '316.png', '317.png', '318.png', '319.png', '32.png', '320.png', '321.png', '322.png', '323.png', '324.png', '325.png', '326.png', '327.png', '328.png', '329.png', '33.png', '330.png', '331.png', '332.png', '333.png', '334.png', '335.png', '336.png', '337.png', '338.png', '339.png', '34.png', '340.png', '341.png', '342.png', '343.png', '344.png', '345.png', '346.png', '347.png', '348.png', '349.png', '35.png', '350.png', '351.png', '352.png', '353.png', '354.png', '355.png', '356.png', '357.png', '358.png', '359.png', '36.png', '360.png', '361.png', '362.png', '363.png', '364.png', '365.png', '366.png', '367.png', '368.png', '369.png', '37.png', '370.png', '371.png', '372.png', '373.png', '374.png', '375.png', '376.png', '377.png', '378.png', '379.png', '38.png', '380.png', '381.png', '382.png', '383.png', '384.png', '385.png', '386.png', '387.png', '388.png', '389.png', '39.png', '390.png', '391.png', '392.png', '393.png', '394.png', '395.png', '396.png', '397.png', '398.png', '399.png', '4.png', '40.png', '400.png', '401.png', '402.png', '403.png', '404.png', '405.png', '406.png', '407.png', '408.png', '409.png', '41.png', '410.png', '411.png', '412.png', '413.png', '414.png', '415.png', '416.png', '417.png', '418.png', '419.png', '42.png', '420.png', '421.png', '422.png', '423.png', '424.png', '425.png', '426.png', '427.png', '428.png', '429.png', '43.png', '430.png', '431.png', '432.png', '433.png', '434.png', '435.png', '436.png', '437.png', '438.png', '439.png', '44.png', '440.png', '441.png', '442.png', '443.png', '444.png', '445.png', '446.png', '447.png', '448.png', '449.png', '45.png', '450.png', '451.png', '452.png', '453.png', '454.png', '455.png', '456.png', '457.png', '458.png', '459.png', '46.png', '460.png', '461.png', '462.png', '463.png', '464.png', '465.png', '466.png', '467.png', '468.png', '469.png', '47.png', '470.png', '471.png', '472.png', '473.png', '474.png', '475.png', '476.png', '477.png', '478.png', '479.png', '48.png', '480.png', '481.png', '482.png', '483.png', '484.png', '485.png', '486.png', '487.png', '488.png', '489.png', '49.png', '490.png', '491.png', '492.png', '493.png', '494.png', '495.png', '496.png', '497.png', '498.png', '499.png', '5.png', '50.png', '500.png', '501.png', '502.png', '503.png', '504.png', '505.png', '506.png', '507.png', '508.png', '509.png', '51.png', '510.png', '511.png', '512.png', '513.png', '514.png', '515.png', '516.png', '517.png', '518.png', '519.png', '52.png', '520.png', '521.png', '522.png', '523.png', '524.png', '525.png', '526.png', '527.png', '528.png', '529.png', '53.png', '530.png', '531.png', '532.png', '533.png', '534.png', '535.png', '536.png', '537.png', '538.png', '539.png', '54.png', '540.png', '541.png', '542.png', '543.png', '544.png', '545.png', '546.png', '547.png', '548.png', '549.png', '55.png', '550.png', '551.png', '552.png', '553.png', '554.png', '555.png', '556.png', '557.png', '558.png', '559.png', '56.png', '560.png', '561.png', '562.png', '563.png', '564.png', '565.png', '566.png', '567.png', '568.png', '569.png', '57.png', '570.png', '571.png', '572.png', '573.png', '574.png', '575.png', '576.png', '577.png', '578.png', '579.png', '58.png', '580.png', '581.png', '582.png', '583.png', '584.png', '585.png', '586.png', '587.png', '588.png', '589.png', '59.png', '590.png', '591.png', '592.png', '593.png', '594.png', '595.png', '596.png', '597.png', '598.png', '599.png', '6.png', '60.png', '600.png', '601.png', '602.png', '603.png', '604.png', '605.png', '606.png', '607.png', '608.png', '609.png', '61.png', '610.png', '611.png', '612.png', '613.png', '614.png', '615.png', '616.png', '617.png', '618.png', '619.png', '62.png', '620.png', '621.png', '622.png', '623.png', '624.png', '625.png', '626.png', '627.png', '628.png', '629.png', '63.png', '630.png', '631.png', '632.png', '633.png', '634.png', '635.png', '636.png', '637.png', '638.png', '639.png', '64.png', '640.png', '641.png', '642.png', '643.png', '644.png', '645.png', '646.png', '647.png', '648.png', '649.png', '65.png', '650.png', '651.png', '652.png', '653.png', '654.png', '655.png', '656.png', '657.png', '658.png', '659.png', '66.png', '660.png', '661.png', '662.png', '663.png', '664.png', '665.png', '666.png', '667.png', '668.png', '669.png', '67.png', '670.png', '671.png', '672.png', '673.png', '674.png', '675.png', '676.png', '677.png', '678.png', '679.png', '68.png', '680.png', '681.png', '682.png', '683.png', '684.png', '685.png', '686.png', '687.png', '688.png', '689.png', '69.png', '690.png', '691.png', '692.png', '693.png', '694.png', '695.png', '696.png', '697.png', '698.png', '699.png', '7.png', '70.png', '700.png', '701.png', '702.png', '703.png', '704.png', '705.png', '706.png', '707.png', '708.png', '709.png', '71.png', '710.png', '711.png', '712.png', '713.png', '714.png', '715.png', '716.png', '717.png', '718.png', '719.png', '72.png', '720.png', '721.png', '722.png', '723.png', '724.png', '725.png', '726.png', '727.png', '728.png', '729.png', '73.png', '730.png', '731.png', '732.png', '733.png', '734.png', '735.png', '736.png', '737.png', '738.png', '739.png', '74.png', '740.png', '741.png', '742.png', '743.png', '744.png', '745.png', '746.png', '747.png', '748.png', '749.png', '75.png', '750.png', '751.png', '752.png', '753.png', '754.png', '755.png', '756.png', '757.png', '758.png', '759.png', '76.png', '760.png', '761.png', '762.png', '763.png', '764.png', '765.png', '766.png', '767.png', '768.png', '769.png', '77.png', '770.png', '771.png', '772.png', '773.png', '774.png', '775.png', '776.png', '777.png', '778.png', '779.png', '78.png', '780.png', '781.png', '782.png', '783.png', '784.png', '785.png', '786.png', '787.png', '788.png', '789.png', '79.png', '790.png', '791.png', '792.png', '793.png', '794.png', '795.png', '796.png', '797.png', '798.png', '799.png', '8.png', '80.png', '800.png', '801.png', '802.png', '803.png', '804.png', '805.png', '806.png', '807.png', '808.png', '809.png', '81.png', '810.png', '811.png', '812.png', '813.png', '814.png', '815.png', '816.png', '817.png', '818.png', '819.png', '82.png', '820.png', '821.png', '822.png', '823.png', '824.png', '825.png', '826.png', '827.png', '828.png', '829.png', '83.png', '830.png', '831.png', '832.png', '833.png', '834.png', '835.png', '836.png', '837.png', '838.png', '839.png', '84.png', '840.png', '841.png', '842.png', '843.png', '844.png', '845.png', '846.png', '847.png', '848.png', '849.png', '85.png', '850.png', '851.png', '852.png', '853.png', '854.png', '855.png', '856.png', '857.png', '858.png', '859.png', '86.png', '860.png', '861.png', '862.png', '863.png', '864.png', '865.png', '866.png', '867.png', '868.png', '869.png', '87.png', '870.png', '871.png', '872.png', '873.png', '874.png', '875.png', '876.png', '877.png', '878.png', '879.png', '88.png', '880.png', '881.png', '882.png', '883.png', '884.png', '885.png', '886.png', '887.png', '888.png', '889.png', '89.png', '890.png', '891.png', '892.png', '893.png', '894.png', '895.png', '896.png', '897.png', '898.png', '899.png', '9.png', '90.png', '900.png', '901.png', '902.png', '903.png', '904.png', '905.png', '906.png', '907.png', '908.png', '909.png', '91.png', '910.png', '911.png', '912.png', '913.png', '914.png', '915.png', '916.png', '917.png', '918.png', '919.png', '92.png', '920.png', '921.png', '922.png', '923.png', '924.png', '925.png', '926.png', '927.png', '928.png', '929.png', '93.png', '930.png', '931.png', '932.png', '933.png', '934.png', '935.png', '936.png', '937.png', '938.png', '939.png', '94.png', '940.png', '941.png', '942.png', '943.png', '944.png', '945.png', '946.png', '947.png', '948.png', '949.png', '95.png', '950.png', '951.png', '952.png', '953.png', '954.png', '955.png', '956.png', '957.png', '958.png', '959.png', '96.png', '960.png', '961.png', '962.png', '963.png', '964.png', '965.png', '966.png', '967.png', '968.png', '969.png', '97.png', '970.png', '971.png', '972.png', '973.png', '974.png', '975.png', '976.png', '977.png', '978.png', '979.png', '98.png', '980.png', '981.png', '982.png', '983.png', '984.png', '985.png', '986.png', '987.png', '988.png', '989.png', '99.png', '990.png', '991.png', '992.png', '993.png', '994.png', '995.png', '996.png', '997.png', '998.png', '999.png', 'TxtInfo_train.txt']\n",
      "[INFO] Sorting files in directory...\n",
      "\n",
      "[INFO] Loading images in matrices...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='2155'\n",
       "            max='2155',\n",
       "            style='width: 50%'\n",
       "        >\n",
       "            2155\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset loaded\n",
      "['1.png', '10.png', '100.png', '101.png', '102.png', '103.png', '104.png', '105.png', '106.png', '107.png', '108.png', '109.png', '11.png', '110.png', '111.png', '112.png', '113.png', '114.png', '115.png', '116.png', '117.png', '118.png', '119.png', '12.png', '120.png', '121.png', '122.png', '123.png', '124.png', '125.png', '126.png', '127.png', '128.png', '129.png', '13.png', '130.png', '131.png', '132.png', '133.png', '134.png', '135.png', '136.png', '137.png', '138.png', '139.png', '14.png', '140.png', '141.png', '142.png', '143.png', '144.png', '145.png', '146.png', '147.png', '148.png', '149.png', '15.png', '150.png', '151.png', '152.png', '153.png', '154.png', '155.png', '156.png', '157.png', '158.png', '159.png', '16.png', '160.png', '161.png', '162.png', '163.png', '164.png', '165.png', '166.png', '167.png', '168.png', '169.png', '17.png', '170.png', '171.png', '172.png', '173.png', '174.png', '175.png', '176.png', '177.png', '178.png', '179.png', '18.png', '180.png', '181.png', '182.png', '183.png', '184.png', '185.png', '186.png', '187.png', '188.png', '189.png', '19.png', '190.png', '191.png', '192.png', '193.png', '194.png', '195.png', '196.png', '197.png', '198.png', '199.png', '2.png', '20.png', '200.png', '201.png', '202.png', '203.png', '204.png', '205.png', '206.png', '207.png', '208.png', '209.png', '21.png', '210.png', '211.png', '212.png', '213.png', '214.png', '215.png', '216.png', '217.png', '218.png', '219.png', '22.png', '220.png', '221.png', '222.png', '223.png', '224.png', '225.png', '226.png', '227.png', '228.png', '229.png', '23.png', '230.png', '231.png', '232.png', '233.png', '234.png', '235.png', '236.png', '237.png', '238.png', '239.png', '24.png', '240.png', '241.png', '242.png', '243.png', '244.png', '245.png', '246.png', '247.png', '248.png', '249.png', '25.png', '250.png', '251.png', '252.png', '253.png', '254.png', '255.png', '256.png', '257.png', '258.png', '259.png', '26.png', '260.png', '261.png', '262.png', '263.png', '264.png', '265.png', '266.png', '267.png', '268.png', '269.png', '27.png', '270.png', '271.png', '272.png', '273.png', '274.png', '275.png', '276.png', '277.png', '278.png', '279.png', '28.png', '280.png', '281.png', '282.png', '283.png', '284.png', '285.png', '286.png', '287.png', '288.png', '289.png', '29.png', '290.png', '291.png', '292.png', '293.png', '294.png', '295.png', '296.png', '297.png', '298.png', '299.png', '3.png', '30.png', '300.png', '301.png', '302.png', '303.png', '304.png', '305.png', '306.png', '307.png', '308.png', '309.png', '31.png', '310.png', '311.png', '312.png', '313.png', '314.png', '315.png', '316.png', '317.png', '318.png', '319.png', '32.png', '320.png', '321.png', '322.png', '323.png', '324.png', '325.png', '326.png', '327.png', '328.png', '329.png', '33.png', '330.png', '331.png', '332.png', '333.png', '334.png', '335.png', '336.png', '337.png', '338.png', '339.png', '34.png', '340.png', '341.png', '342.png', '343.png', '344.png', '345.png', '346.png', '347.png', '348.png', '349.png', '35.png', '350.png', '351.png', '352.png', '353.png', '354.png', '355.png', '356.png', '357.png', '358.png', '359.png', '36.png', '360.png', '361.png', '362.png', '363.png', '364.png', '365.png', '366.png', '367.png', '368.png', '369.png', '37.png', '370.png', '371.png', '372.png', '373.png', '374.png', '375.png', '376.png', '377.png', '378.png', '379.png', '38.png', '380.png', '381.png', '382.png', '383.png', '384.png', '385.png', '386.png', '387.png', '388.png', '389.png', '39.png', '390.png', '391.png', '392.png', '393.png', '394.png', '395.png', '396.png', '397.png', '398.png', '399.png', '4.png', '40.png', '400.png', '401.png', '402.png', '403.png', '404.png', '405.png', '406.png', '407.png', '408.png', '409.png', '41.png', '410.png', '411.png', '412.png', '413.png', '414.png', '415.png', '416.png', '417.png', '418.png', '419.png', '42.png', '420.png', '421.png', '422.png', '423.png', '424.png', '425.png', '426.png', '427.png', '428.png', '429.png', '43.png', '430.png', '431.png', '432.png', '433.png', '434.png', '435.png', '436.png', '437.png', '438.png', '439.png', '44.png', '440.png', '441.png', '442.png', '443.png', '444.png', '445.png', '446.png', '447.png', '448.png', '449.png', '45.png', '450.png', '451.png', '452.png', '453.png', '454.png', '455.png', '456.png', '457.png', '458.png', '459.png', '46.png', '460.png', '461.png', '462.png', '463.png', '464.png', '465.png', '466.png', '467.png', '468.png', '469.png', '47.png', '470.png', '471.png', '472.png', '473.png', '474.png', '475.png', '476.png', '477.png', '478.png', '479.png', '48.png', '480.png', '481.png', '482.png', '483.png', '484.png', '485.png', '486.png', '487.png', '488.png', '489.png', '49.png', '490.png', '491.png', '492.png', '493.png', '494.png', '495.png', '496.png', '497.png', '498.png', '499.png', '5.png', '50.png', '500.png', '501.png', '502.png', '503.png', '504.png', '505.png', '506.png', '507.png', '508.png', '509.png', '51.png', '510.png', '511.png', '512.png', '513.png', '514.png', '515.png', '516.png', '517.png', '518.png', '519.png', '52.png', '520.png', '521.png', '522.png', '523.png', '524.png', '525.png', '526.png', '527.png', '528.png', '529.png', '53.png', '530.png', '531.png', '532.png', '533.png', '534.png', '535.png', '536.png', '537.png', '538.png', '539.png', '54.png', '540.png', '541.png', '542.png', '543.png', '544.png', '545.png', '546.png', '547.png', '548.png', '549.png', '55.png', '550.png', '551.png', '552.png', '553.png', '554.png', '555.png', '556.png', '557.png', '558.png', '559.png', '56.png', '560.png', '561.png', '562.png', '563.png', '564.png', '565.png', '566.png', '567.png', '568.png', '569.png', '57.png', '570.png', '571.png', '572.png', '573.png', '574.png', '575.png', '576.png', '577.png', '578.png', '579.png', '58.png', '580.png', '581.png', '582.png', '583.png', '584.png', '585.png', '586.png', '587.png', '588.png', '589.png', '59.png', '590.png', '591.png', '592.png', '593.png', '594.png', '595.png', '596.png', '597.png', '598.png', '599.png', '6.png', '60.png', '600.png', '601.png', '602.png', '603.png', '604.png', '605.png', '606.png', '607.png', '608.png', '609.png', '61.png', '610.png', '611.png', '612.png', '613.png', '614.png', '615.png', '616.png', '617.png', '618.png', '619.png', '62.png', '620.png', '621.png', '622.png', '623.png', '624.png', '625.png', '626.png', '627.png', '628.png', '629.png', '63.png', '630.png', '631.png', '632.png', '633.png', '634.png', '635.png', '636.png', '637.png', '638.png', '639.png', '64.png', '640.png', '641.png', '642.png', '643.png', '644.png', '645.png', '646.png', '647.png', '648.png', '649.png', '65.png', '650.png', '651.png', '652.png', '653.png', '654.png', '655.png', '656.png', '657.png', '658.png', '659.png', '66.png', '660.png', '661.png', '662.png', '663.png', '664.png', '665.png', '666.png', '667.png', '668.png', '669.png', '67.png', '670.png', '671.png', '672.png', '673.png', '674.png', '675.png', '676.png', '677.png', '678.png', '679.png', '68.png', '680.png', '681.png', '682.png', '683.png', '684.png', '685.png', '686.png', '687.png', '688.png', '689.png', '69.png', '690.png', '691.png', '692.png', '693.png', '694.png', '695.png', '696.png', '697.png', '698.png', '699.png', '7.png', '70.png', '700.png', '701.png', '702.png', '703.png', '704.png', '705.png', '706.png', '707.png', '708.png', '709.png', '71.png', '710.png', '711.png', '712.png', '713.png', '714.png', '715.png', '716.png', '717.png', '718.png', '719.png', '72.png', '720.png', '721.png', '722.png', '723.png', '724.png', '725.png', '726.png', '727.png', '728.png', '729.png', '73.png', '730.png', '731.png', '732.png', '733.png', '734.png', '735.png', '736.png', '737.png', '738.png', '739.png', '74.png', '740.png', '741.png', '742.png', '743.png', '744.png', '745.png', '746.png', '747.png', '748.png', '749.png', '75.png', '750.png', '751.png', '752.png', '753.png', '754.png', '755.png', '756.png', '757.png', '758.png', '759.png', '76.png', '760.png', '761.png', '762.png', '763.png', '764.png', '765.png', '766.png', '767.png', '768.png', '769.png', '77.png', '770.png', '771.png', '772.png', '773.png', '774.png', '775.png', '776.png', '777.png', '778.png', '779.png', '78.png', '780.png', '781.png', '782.png', '783.png', '784.png', '785.png', '786.png', '787.png', '788.png', '789.png', '79.png', '790.png', '791.png', '792.png', '793.png', '794.png', '795.png', '796.png', '797.png', '798.png', '799.png', '8.png', '80.png', '800.png', '801.png', '802.png', '803.png', '804.png', '805.png', '806.png', '807.png', '808.png', '809.png', '81.png', '810.png', '811.png', '812.png', '813.png', '814.png', '815.png', '816.png', '817.png', '818.png', '819.png', '82.png', '820.png', '821.png', '822.png', '823.png', '824.png', '825.png', '826.png', '827.png', '828.png', '829.png', '83.png', '830.png', '831.png', '832.png', '833.png', '834.png', '835.png', '836.png', '837.png', '838.png', '839.png', '84.png', '840.png', '841.png', '842.png', '843.png', '844.png', '845.png', '846.png', '847.png', '848.png', '849.png', '85.png', '850.png', '851.png', '852.png', '853.png', '854.png', '855.png', '856.png', '857.png', '858.png', '859.png', '86.png', '860.png', '861.png', '862.png', '863.png', '864.png', '865.png', '866.png', '867.png', '868.png', '869.png', '87.png', '870.png', '871.png', '872.png', '873.png', '874.png', '875.png', '876.png', '877.png', '878.png', '879.png', '88.png', '880.png', '881.png', '882.png', '883.png', '884.png', '885.png', '886.png', '887.png', '888.png', '889.png', '89.png', '890.png', '891.png', '892.png', '893.png', '894.png', '895.png', '896.png', '897.png', '898.png', '899.png', '9.png', '90.png', '900.png', '901.png', '902.png', '903.png', '904.png', '905.png', '906.png', '907.png', '908.png', '909.png', '91.png', '910.png', '911.png', '912.png', '913.png', '914.png', '915.png', '916.png', '917.png', '918.png', '919.png', '92.png', '920.png', '93.png', '94.png', '95.png', '96.png', '97.png', '98.png', '99.png', 'TxtInfo_Test.txt']\n",
      "[INFO] Sorting files in directory...\n",
      "\n",
      "[INFO] Loading images in matrices...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='841'\n",
       "            max='920',\n",
       "            style='width: 50%'\n",
       "        >\n",
       "            841\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_Train = load_signals_images(data_root_Train) # сырые картинки, которые будут нормализованы (нужно больше времени)\n",
    "images_Test = load_signals_images(data_root_Test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z37lrFeJV-hH",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLzMbbFmdIIC",
    "outputId": "2e68dbc9-39b0-4d77-af3c-32a6bc16fbd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1939, 3)\n",
      "(216, 3)\n",
      "(920, 3)\n",
      "(1939, 32, 32, 3)\n",
      "(216, 32, 32, 3)\n",
      "(920, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testAttrX=attr_Test\n",
    "testImagesX=images_Test\n",
    "\n",
    "AttrX=attr_Train\n",
    "ImagesX=images_Train\n",
    "\n",
    "split = train_test_split(AttrX, ImagesX, test_size=0.1, random_state=42)\n",
    "(trainAttrX,validAttrX, trainImagesX, validImagesX) = split\n",
    "\n",
    "trainAttrX\n",
    "\n",
    "continuous = [\"N1\", \"N2\"]\n",
    "\n",
    "# Normalizing data to be the interval [0 1]\n",
    "cs = MinMaxScaler()\n",
    "trainAttrXnorm = cs.fit_transform(trainAttrX[continuous])\n",
    "validAttrXnorm = cs.fit_transform(validAttrX[continuous])\n",
    "testAttrXnorm = cs.transform(testAttrX[continuous])\n",
    "\n",
    "zipBinarizer = LabelBinarizer().fit(attr_Train[\"class\"])\n",
    "trainY = zipBinarizer.transform(trainAttrX[\"class\"])\n",
    "validY = zipBinarizer.transform(validAttrX[\"class\"])\n",
    "\n",
    "zipBinarizer = LabelBinarizer().fit(attr_Test[\"class\"])\n",
    "testY = zipBinarizer.transform(testAttrX[\"class\"])\n",
    "\n",
    "print(trainAttrX.shape)\n",
    "print(validAttrX.shape)\n",
    "print(testAttrX.shape)\n",
    "print(trainImagesX.shape)\n",
    "print(validImagesX.shape)\n",
    "print(testImagesX.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress=False):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(16, input_dim=dim, activation=\"relu\"))\n",
    "\tmodel.add(Dense(8, activation=\"relu\"))\n",
    "\n",
    "\tif regress:\n",
    "\t\tmodel.add(Dense(5))\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "\t# initialize the input shape and channel dimension, assuming\n",
    "\t# TensorFlow/channels-last ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\n",
    "\t# define the model input\n",
    "\tinputs = Input(shape=inputShape)\n",
    "\n",
    "\t# loop over the number of filters\n",
    "\tfor (i, f) in enumerate(filters):\n",
    "\t\t# if this is the first CONV layer then set the input\n",
    "\t\t# appropriately\n",
    "\t\tif i == 0:\n",
    "\t\t\tx = inputs\n",
    "\n",
    "\t\t# CONV => RELU => BN => POOL\n",
    "\t\tx = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "\t\tx = Activation(\"relu\")(x)\n",
    "\t\tx = BatchNormalization(axis=chanDim)(x)\n",
    "\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "\n",
    "\t# flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "\tx = Flatten()(x)\n",
    "\tx = Dense(16)(x)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\tx = BatchNormalization(axis=chanDim)(x)\n",
    "\tx = Dropout(0.5)(x) \n",
    "\n",
    "\t# apply another FC layer, this one to match the number of nodes\n",
    "\t# coming out of the MLP\n",
    "\tx = Dense(8)(x)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\n",
    "\t# check to see if the regression node should be added\n",
    "\tif regress:\n",
    "\t\tx = Dense(5)(x)\n",
    "\n",
    "\t# construct the CNN\n",
    "\tmodel = Model(inputs, x)\n",
    "\n",
    "\t# return the CNN\n",
    "\treturn model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZyvMufRwevK",
    "tags": []
   },
   "source": [
    "## Hybrid CNN + MLP_10 runs for average values of accuracy and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfpAJwWAKHxA",
    "outputId": "d698ad9a-2a31-4e3e-dc4f-45a6c895d5da",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "Model: \"Hybrid_CNN_MLP\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 16)   448         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32, 32, 16)   0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 16)  64          ['activation_15[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 16)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 32)   4640        ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 32)   0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 32)  128         ['activation_16[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 8, 8, 32)    0           ['batch_normalization_13[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 64)     18496       ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 64)     0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['activation_17[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 4, 4, 64)    0           ['batch_normalization_14[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 1024)         0           ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 16)           16400       ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16)           0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16)          64          ['activation_18[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_20_input (InputLayer)    [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16)           0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 16)           48          ['dense_20_input[0][0]']         \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 8)            136         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 8)            136         ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 8)            0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16)           0           ['dense_21[0][0]',               \n",
      "                                                                  'activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 8)            136         ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 5)            45          ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,997\n",
      "Trainable params: 40,741\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "print('[INFO] Creating Hybrid CNN+MLP...')\n",
    "mlp = create_mlp(trainAttrXnorm.shape[1], regress=False)\n",
    "cnn = create_cnn(32, 32, 3, regress=False) \n",
    "\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "x = Dense(8, activation=\"relu\")(combinedInput)\n",
    "x = Dense(5)(x)\n",
    "\n",
    "checkpoint_path='hybrid1.h5'\n",
    "\n",
    "keras_callbacks   = [\n",
    "      EarlyStopping(monitor='val_accuracy', patience=10, verbose=1),\n",
    "      ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "]\n",
    "\n",
    "model_mixed = Model(inputs=[mlp.input, cnn.input], \n",
    "                    outputs=x, \n",
    "                    name=\"Hybrid_CNN_MLP\")\n",
    "\n",
    "print('[INFO] Compiling model...')\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-3 / 200)\n",
    "model_mixed.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model_mixed.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 14ms/step - loss: 1.7059 - accuracy: 0.2785 - val_loss: 1.5936 - val_accuracy: 0.1944\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.4771 - accuracy: 0.3755 - val_loss: 1.5763 - val_accuracy: 0.2731\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.3817 - accuracy: 0.4327 - val_loss: 1.5193 - val_accuracy: 0.3565\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.3197 - accuracy: 0.4487 - val_loss: 1.4311 - val_accuracy: 0.3889\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2657 - accuracy: 0.4992 - val_loss: 1.2665 - val_accuracy: 0.6250\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.1880 - accuracy: 0.5585 - val_loss: 1.1113 - val_accuracy: 0.7083\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1403 - accuracy: 0.6075 - val_loss: 1.0091 - val_accuracy: 0.7500\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0869 - accuracy: 0.6364 - val_loss: 0.8866 - val_accuracy: 0.7731\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0373 - accuracy: 0.6710 - val_loss: 0.8489 - val_accuracy: 0.8009\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.9735 - accuracy: 0.7071 - val_loss: 0.8003 - val_accuracy: 0.8333\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.9423 - accuracy: 0.7339 - val_loss: 0.7669 - val_accuracy: 0.8056\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.8953 - accuracy: 0.7390 - val_loss: 0.7318 - val_accuracy: 0.8056\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.8500 - accuracy: 0.7669 - val_loss: 0.6922 - val_accuracy: 0.8194\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.8085 - accuracy: 0.7705 - val_loss: 0.6594 - val_accuracy: 0.8194\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.7717 - accuracy: 0.7932 - val_loss: 0.6101 - val_accuracy: 0.8519\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7442 - accuracy: 0.8123 - val_loss: 0.5958 - val_accuracy: 0.8750\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7005 - accuracy: 0.8308 - val_loss: 0.5510 - val_accuracy: 0.8981\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.6755 - accuracy: 0.8448 - val_loss: 0.5320 - val_accuracy: 0.8981\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.6373 - accuracy: 0.8530 - val_loss: 0.4955 - val_accuracy: 0.9167\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.6203 - accuracy: 0.8685 - val_loss: 0.5074 - val_accuracy: 0.9259\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.8809 - val_loss: 0.4585 - val_accuracy: 0.9352\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.5494 - accuracy: 0.8891 - val_loss: 0.4217 - val_accuracy: 0.9398\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.5353 - accuracy: 0.8850 - val_loss: 0.4020 - val_accuracy: 0.9213\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.5078 - accuracy: 0.8948 - val_loss: 0.3912 - val_accuracy: 0.9259\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.4904 - accuracy: 0.8953 - val_loss: 0.3916 - val_accuracy: 0.9074\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.4516 - accuracy: 0.9061 - val_loss: 0.3581 - val_accuracy: 0.9306\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.4287 - accuracy: 0.9180 - val_loss: 0.3432 - val_accuracy: 0.9398\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4096 - accuracy: 0.9139 - val_loss: 0.3049 - val_accuracy: 0.9537\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3901 - accuracy: 0.9206 - val_loss: 0.3171 - val_accuracy: 0.9398\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3810 - accuracy: 0.9170 - val_loss: 0.2982 - val_accuracy: 0.9398\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3504 - accuracy: 0.9278 - val_loss: 0.2767 - val_accuracy: 0.9537\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3297 - accuracy: 0.9278 - val_loss: 0.2663 - val_accuracy: 0.9537\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3253 - accuracy: 0.9268 - val_loss: 0.3222 - val_accuracy: 0.9167\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3128 - accuracy: 0.9232 - val_loss: 0.2681 - val_accuracy: 0.9491\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2931 - accuracy: 0.9360 - val_loss: 0.2187 - val_accuracy: 0.9537\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2663 - accuracy: 0.9443 - val_loss: 0.2396 - val_accuracy: 0.9444\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2696 - accuracy: 0.9366 - val_loss: 0.2336 - val_accuracy: 0.9398\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2467 - accuracy: 0.9391 - val_loss: 0.2163 - val_accuracy: 0.9398\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2383 - accuracy: 0.9479 - val_loss: 0.1732 - val_accuracy: 0.9583\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2361 - accuracy: 0.9428 - val_loss: 0.1632 - val_accuracy: 0.9537\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2309 - accuracy: 0.9417 - val_loss: 0.1669 - val_accuracy: 0.9676\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2070 - accuracy: 0.9546 - val_loss: 0.1889 - val_accuracy: 0.9537\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2094 - accuracy: 0.9536 - val_loss: 0.1551 - val_accuracy: 0.9676\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2081 - accuracy: 0.9428 - val_loss: 0.1697 - val_accuracy: 0.9630\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1822 - accuracy: 0.9587 - val_loss: 0.2052 - val_accuracy: 0.9352\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1928 - accuracy: 0.9469 - val_loss: 0.1619 - val_accuracy: 0.9583\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1686 - accuracy: 0.9608 - val_loss: 0.1642 - val_accuracy: 0.9537\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1766 - accuracy: 0.9484 - val_loss: 0.1728 - val_accuracy: 0.9537\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1762 - accuracy: 0.9526 - val_loss: 0.1839 - val_accuracy: 0.9444\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1486 - accuracy: 0.9618 - val_loss: 0.2161 - val_accuracy: 0.9352\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9572 - val_loss: 0.2166 - val_accuracy: 0.9444\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9551 - val_loss: 0.1739 - val_accuracy: 0.9444\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1284 - accuracy: 0.9680 - val_loss: 0.1274 - val_accuracy: 0.9583\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1319 - accuracy: 0.9649 - val_loss: 0.1465 - val_accuracy: 0.9583\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1489 - accuracy: 0.9582 - val_loss: 0.1220 - val_accuracy: 0.9676\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1233 - accuracy: 0.9706 - val_loss: 0.1432 - val_accuracy: 0.9583\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1450 - accuracy: 0.9634 - val_loss: 0.1684 - val_accuracy: 0.9630\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1311 - accuracy: 0.9649 - val_loss: 0.0998 - val_accuracy: 0.9722\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.1338 - accuracy: 0.9639 - val_loss: 0.1192 - val_accuracy: 0.9583\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.1121 - accuracy: 0.9711 - val_loss: 0.1568 - val_accuracy: 0.9491\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1118 - accuracy: 0.9696 - val_loss: 0.1220 - val_accuracy: 0.9630\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0969 - accuracy: 0.9773 - val_loss: 0.1516 - val_accuracy: 0.9630\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1001 - accuracy: 0.9747 - val_loss: 0.1222 - val_accuracy: 0.9676\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1075 - accuracy: 0.9685 - val_loss: 0.1388 - val_accuracy: 0.9583\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1080 - accuracy: 0.9716 - val_loss: 0.1628 - val_accuracy: 0.9491\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0991 - accuracy: 0.9768 - val_loss: 0.1126 - val_accuracy: 0.9630\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1029 - accuracy: 0.9696 - val_loss: 0.1534 - val_accuracy: 0.9676\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0977 - accuracy: 0.9789 - val_loss: 0.1303 - val_accuracy: 0.9676\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0887 - accuracy: 0.9732 - val_loss: 0.1584 - val_accuracy: 0.9676\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0910 - accuracy: 0.9706 - val_loss: 0.0907 - val_accuracy: 0.9676\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0935 - accuracy: 0.9737 - val_loss: 0.1415 - val_accuracy: 0.9722\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0796 - accuracy: 0.9809 - val_loss: 0.1327 - val_accuracy: 0.9583\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0878 - accuracy: 0.9778 - val_loss: 0.1783 - val_accuracy: 0.9491\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0747 - accuracy: 0.9804 - val_loss: 0.1512 - val_accuracy: 0.9491\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0786 - accuracy: 0.9799 - val_loss: 0.1147 - val_accuracy: 0.9676\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.9763 - val_loss: 0.1089 - val_accuracy: 0.9630\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0743 - accuracy: 0.9804 - val_loss: 0.0604 - val_accuracy: 0.9815\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.0711 - accuracy: 0.9809 - val_loss: 0.0713 - val_accuracy: 0.9815\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0597 - accuracy: 0.9850 - val_loss: 0.0833 - val_accuracy: 0.9722\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0681 - accuracy: 0.9825 - val_loss: 0.0895 - val_accuracy: 0.9769\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0727 - accuracy: 0.9804 - val_loss: 0.0739 - val_accuracy: 0.9815\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0711 - accuracy: 0.9799 - val_loss: 0.1013 - val_accuracy: 0.9769\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0688 - accuracy: 0.9814 - val_loss: 0.1041 - val_accuracy: 0.9630\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0686 - accuracy: 0.9825 - val_loss: 0.1110 - val_accuracy: 0.9722\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0634 - accuracy: 0.9840 - val_loss: 0.0678 - val_accuracy: 0.9861\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.0683 - accuracy: 0.9825 - val_loss: 0.1312 - val_accuracy: 0.9583\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0627 - accuracy: 0.9825 - val_loss: 0.0676 - val_accuracy: 0.9769\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0613 - accuracy: 0.9825 - val_loss: 0.0769 - val_accuracy: 0.9769\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0659 - accuracy: 0.9835 - val_loss: 0.0608 - val_accuracy: 0.9861\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0568 - accuracy: 0.9850 - val_loss: 0.0824 - val_accuracy: 0.9815\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0636 - accuracy: 0.9799 - val_loss: 0.1198 - val_accuracy: 0.9676\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0450 - accuracy: 0.9881 - val_loss: 0.1137 - val_accuracy: 0.9722\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0522 - accuracy: 0.9892 - val_loss: 0.1149 - val_accuracy: 0.9676\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0596 - accuracy: 0.9825 - val_loss: 0.0766 - val_accuracy: 0.9769\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0499 - accuracy: 0.9866 - val_loss: 0.0614 - val_accuracy: 0.9861\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0504 - accuracy: 0.9871 - val_loss: 0.0977 - val_accuracy: 0.9676\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0520 - accuracy: 0.9871 - val_loss: 0.0812 - val_accuracy: 0.9769\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0637 - accuracy: 0.9825 - val_loss: 0.1327 - val_accuracy: 0.9630\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0459 - accuracy: 0.9892 - val_loss: 0.1212 - val_accuracy: 0.9630\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0489 - accuracy: 0.9856 - val_loss: 0.1041 - val_accuracy: 0.9630\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0493 - accuracy: 0.9892 - val_loss: 0.1944 - val_accuracy: 0.9491\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 0.0924 - val_accuracy: 0.9676\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0568 - accuracy: 0.9861 - val_loss: 0.0881 - val_accuracy: 0.9815\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0538 - accuracy: 0.9856 - val_loss: 0.1018 - val_accuracy: 0.9676\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0503 - accuracy: 0.9866 - val_loss: 0.1110 - val_accuracy: 0.9676\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0445 - accuracy: 0.9897 - val_loss: 0.1143 - val_accuracy: 0.9630\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0333 - accuracy: 0.9923 - val_loss: 0.0596 - val_accuracy: 0.9815\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0364 - accuracy: 0.9897 - val_loss: 0.0903 - val_accuracy: 0.9722\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.1435 - val_accuracy: 0.9630\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0398 - accuracy: 0.9897 - val_loss: 0.0776 - val_accuracy: 0.9769\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0463 - accuracy: 0.9866 - val_loss: 0.0840 - val_accuracy: 0.9769\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0431 - accuracy: 0.9850 - val_loss: 0.1047 - val_accuracy: 0.9722\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0412 - accuracy: 0.9907 - val_loss: 0.0620 - val_accuracy: 0.9769\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 0.0896 - val_accuracy: 0.9722\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0376 - accuracy: 0.9897 - val_loss: 0.0825 - val_accuracy: 0.9769\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0471 - accuracy: 0.9861 - val_loss: 0.0976 - val_accuracy: 0.9676\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0301 - accuracy: 0.9933 - val_loss: 0.2137 - val_accuracy: 0.9398\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 0.1194 - val_accuracy: 0.9676\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0433 - accuracy: 0.9856 - val_loss: 0.0769 - val_accuracy: 0.9722\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0372 - accuracy: 0.9917 - val_loss: 0.0813 - val_accuracy: 0.9769\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 0.1356 - val_accuracy: 0.9676\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0366 - accuracy: 0.9856 - val_loss: 0.1222 - val_accuracy: 0.9537\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.0922 - val_accuracy: 0.9722\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0298 - accuracy: 0.9943 - val_loss: 0.0695 - val_accuracy: 0.9722\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.1043 - val_accuracy: 0.9769\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.1070 - val_accuracy: 0.9722\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.1000 - val_accuracy: 0.9676\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0482 - accuracy: 0.9892 - val_loss: 0.0876 - val_accuracy: 0.9722\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0465 - accuracy: 0.9876 - val_loss: 0.1302 - val_accuracy: 0.9676\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.1004 - val_accuracy: 0.9769\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.0794 - val_accuracy: 0.9769\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0409 - accuracy: 0.9887 - val_loss: 0.1278 - val_accuracy: 0.9722\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0394 - accuracy: 0.9856 - val_loss: 0.2016 - val_accuracy: 0.9444\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0250 - accuracy: 0.9964 - val_loss: 0.0898 - val_accuracy: 0.9676\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 0.0782 - val_accuracy: 0.9676\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0293 - accuracy: 0.9928 - val_loss: 0.1143 - val_accuracy: 0.9630\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.1034 - val_accuracy: 0.9722\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.1271 - val_accuracy: 0.9676\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0260 - accuracy: 0.9938 - val_loss: 0.1077 - val_accuracy: 0.9722\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0816 - val_accuracy: 0.9815\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0243 - accuracy: 0.9943 - val_loss: 0.0581 - val_accuracy: 0.9861\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.1810 - val_accuracy: 0.9537\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 0.0764 - val_accuracy: 0.9815\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.1025 - val_accuracy: 0.9630\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0211 - accuracy: 0.9954 - val_loss: 0.1471 - val_accuracy: 0.9676\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.0993 - val_accuracy: 0.9769\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.0659 - val_accuracy: 0.9815\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0204 - accuracy: 0.9959 - val_loss: 0.0675 - val_accuracy: 0.9815\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.0351 - val_accuracy: 0.9907\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.1295 - val_accuracy: 0.9676\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.0834 - val_accuracy: 0.9861\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0275 - accuracy: 0.9928 - val_loss: 0.0576 - val_accuracy: 0.9815\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0303 - accuracy: 0.9892 - val_loss: 0.1423 - val_accuracy: 0.9583\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0446 - accuracy: 0.9866 - val_loss: 0.1096 - val_accuracy: 0.9676\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0459 - accuracy: 0.9840 - val_loss: 0.1245 - val_accuracy: 0.9676\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.0775 - val_accuracy: 0.9769\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 0.0769 - val_accuracy: 0.9769\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0298 - accuracy: 0.9892 - val_loss: 0.0695 - val_accuracy: 0.9769\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.1000 - val_accuracy: 0.9769\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0982 - val_accuracy: 0.9769\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 0.9938 - val_loss: 0.0706 - val_accuracy: 0.9815\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0790 - val_accuracy: 0.9815\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.0978 - val_accuracy: 0.9676\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 0.2295 - val_accuracy: 0.9398\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0225 - accuracy: 0.9959 - val_loss: 0.0707 - val_accuracy: 0.9769\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.0584 - val_accuracy: 0.9861\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0552 - accuracy: 0.9845 - val_loss: 0.1269 - val_accuracy: 0.9722\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.1124 - val_accuracy: 0.9722\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.1485 - val_accuracy: 0.9583\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.1213 - val_accuracy: 0.9676\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.0829 - val_accuracy: 0.9815\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.1632 - val_accuracy: 0.9630\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.0815 - val_accuracy: 0.9769\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.1004 - val_accuracy: 0.9676\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.0928 - val_accuracy: 0.9769\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.1203 - val_accuracy: 0.9676\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9769\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.1186 - val_accuracy: 0.9676\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0419 - val_accuracy: 0.9861\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.0574 - val_accuracy: 0.9815\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.0581 - val_accuracy: 0.9722\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0504 - val_accuracy: 0.9861\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.1143 - val_accuracy: 0.9676\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0202 - accuracy: 0.9964 - val_loss: 0.1214 - val_accuracy: 0.9676\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.0567 - val_accuracy: 0.9769\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0638 - val_accuracy: 0.9815\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0922 - val_accuracy: 0.9769\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.0946 - val_accuracy: 0.9769\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.1317 - val_accuracy: 0.9676\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.0667 - val_accuracy: 0.9769\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0636 - val_accuracy: 0.9815\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.0725 - val_accuracy: 0.9769\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0575 - val_accuracy: 0.9861\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0870 - val_accuracy: 0.9676\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0715 - val_accuracy: 0.9769\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.1069 - val_accuracy: 0.9583\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0957 - val_accuracy: 0.9722\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.1052 - val_accuracy: 0.9722\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 0.1380 - val_accuracy: 0.9722\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.1466 - val_accuracy: 0.9676\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.1498 - val_accuracy: 0.9630\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.1145 - val_accuracy: 0.9722\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.1857 - val_accuracy: 0.9583\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.1531 - val_accuracy: 0.9583\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 0.1251 - val_accuracy: 0.9630\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0224 - accuracy: 0.9917 - val_loss: 0.1563 - val_accuracy: 0.9583\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0718 - val_accuracy: 0.9815\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.1441 - val_accuracy: 0.9722\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0312 - accuracy: 0.9917 - val_loss: 0.1145 - val_accuracy: 0.9815\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9815\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 0.0962 - val_accuracy: 0.9815\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.1009 - val_accuracy: 0.9769\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.1043 - val_accuracy: 0.9769\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1000 - val_accuracy: 0.9769\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.1019 - val_accuracy: 0.9722\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.1402 - val_accuracy: 0.9630\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.0703 - val_accuracy: 0.9769\n",
      "Epoch 219/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0873 - val_accuracy: 0.9769\n",
      "Epoch 220/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0745 - val_accuracy: 0.9815\n",
      "Epoch 221/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1109 - val_accuracy: 0.9815\n",
      "Epoch 222/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0707 - val_accuracy: 0.9769\n",
      "Epoch 223/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.1610 - val_accuracy: 0.9583\n",
      "Epoch 224/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.1424 - val_accuracy: 0.9722\n",
      "Epoch 225/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0724 - val_accuracy: 0.9861\n",
      "Epoch 226/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1246 - val_accuracy: 0.9769\n",
      "Epoch 227/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.1019 - val_accuracy: 0.9815\n",
      "Epoch 228/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0660 - val_accuracy: 0.9769\n",
      "Epoch 229/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0629 - val_accuracy: 0.9815\n",
      "Epoch 230/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0796 - val_accuracy: 0.9815\n",
      "Epoch 231/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.1038 - val_accuracy: 0.9769\n",
      "Epoch 232/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.1011 - val_accuracy: 0.9722\n",
      "Epoch 233/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0818 - val_accuracy: 0.9861\n",
      "Epoch 234/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.0985 - val_accuracy: 0.9676\n",
      "Epoch 235/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.1407 - val_accuracy: 0.9676\n",
      "Epoch 236/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.1488 - val_accuracy: 0.9676\n",
      "Epoch 237/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0549 - val_accuracy: 0.9907\n",
      "Epoch 238/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.0936 - val_accuracy: 0.9722\n",
      "Epoch 239/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0852 - val_accuracy: 0.9769\n",
      "Epoch 240/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.1438 - val_accuracy: 0.9769\n",
      "Epoch 241/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1179 - val_accuracy: 0.9583\n",
      "Epoch 242/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.0783 - val_accuracy: 0.9815\n",
      "Epoch 243/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0716 - val_accuracy: 0.9815\n",
      "Epoch 244/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1141 - val_accuracy: 0.9769\n",
      "Epoch 245/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.1171 - val_accuracy: 0.9676\n",
      "Epoch 246/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0806 - val_accuracy: 0.9861\n",
      "Epoch 247/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.1165 - val_accuracy: 0.9722\n",
      "Epoch 248/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.1789 - val_accuracy: 0.9630\n",
      "Epoch 249/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 0.0851 - val_accuracy: 0.9769\n",
      "Epoch 250/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.0992 - val_accuracy: 0.9769\n",
      "Epoch 250: early stopping\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9685\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 3s 16ms/step - loss: 1.5435 - accuracy: 0.3388 - val_loss: 1.6788 - val_accuracy: 0.2222\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.3905 - accuracy: 0.4363 - val_loss: 1.6639 - val_accuracy: 0.2176\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.2791 - accuracy: 0.5235 - val_loss: 1.6663 - val_accuracy: 0.1806\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.2268 - accuracy: 0.5627 - val_loss: 1.4763 - val_accuracy: 0.3426\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.1629 - accuracy: 0.6163 - val_loss: 1.2166 - val_accuracy: 0.5324\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0935 - accuracy: 0.6498 - val_loss: 1.0387 - val_accuracy: 0.7269\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0378 - accuracy: 0.6674 - val_loss: 0.9121 - val_accuracy: 0.8194\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0067 - accuracy: 0.6844 - val_loss: 0.8558 - val_accuracy: 0.8241\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.9451 - accuracy: 0.6988 - val_loss: 0.7591 - val_accuracy: 0.8194\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.8906 - accuracy: 0.7437 - val_loss: 0.7100 - val_accuracy: 0.8380\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.8349 - accuracy: 0.7396 - val_loss: 0.6657 - val_accuracy: 0.8380\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.8088 - accuracy: 0.7653 - val_loss: 0.6169 - val_accuracy: 0.8241\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7542 - accuracy: 0.7746 - val_loss: 0.6001 - val_accuracy: 0.8287\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7086 - accuracy: 0.8179 - val_loss: 0.5343 - val_accuracy: 0.8657\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.6612 - accuracy: 0.8375 - val_loss: 0.5174 - val_accuracy: 0.8796\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.6398 - accuracy: 0.8551 - val_loss: 0.4731 - val_accuracy: 0.9074\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5860 - accuracy: 0.8726 - val_loss: 0.4546 - val_accuracy: 0.8935\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.5557 - accuracy: 0.8943 - val_loss: 0.4067 - val_accuracy: 0.9352\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5134 - accuracy: 0.8907 - val_loss: 0.3966 - val_accuracy: 0.9213\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.4886 - accuracy: 0.8938 - val_loss: 0.3593 - val_accuracy: 0.9259\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.4562 - accuracy: 0.9092 - val_loss: 0.3432 - val_accuracy: 0.9352\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.4503 - accuracy: 0.9051 - val_loss: 0.3150 - val_accuracy: 0.9398\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.4257 - accuracy: 0.9092 - val_loss: 0.3240 - val_accuracy: 0.9167\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.3764 - accuracy: 0.9206 - val_loss: 0.2816 - val_accuracy: 0.9444\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.3663 - accuracy: 0.9309 - val_loss: 0.2586 - val_accuracy: 0.9444\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.3367 - accuracy: 0.9263 - val_loss: 0.2504 - val_accuracy: 0.9398\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.3289 - accuracy: 0.9304 - val_loss: 0.2526 - val_accuracy: 0.9398\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2918 - accuracy: 0.9376 - val_loss: 0.2490 - val_accuracy: 0.9306\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.2843 - accuracy: 0.9345 - val_loss: 0.2143 - val_accuracy: 0.9537\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2852 - accuracy: 0.9288 - val_loss: 0.2080 - val_accuracy: 0.9444\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2561 - accuracy: 0.9438 - val_loss: 0.2144 - val_accuracy: 0.9537\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.2577 - accuracy: 0.9350 - val_loss: 0.1838 - val_accuracy: 0.9630\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2339 - accuracy: 0.9500 - val_loss: 0.1892 - val_accuracy: 0.9491\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2278 - accuracy: 0.9433 - val_loss: 0.1890 - val_accuracy: 0.9537\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2161 - accuracy: 0.9500 - val_loss: 0.2101 - val_accuracy: 0.9259\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2097 - accuracy: 0.9474 - val_loss: 0.1849 - val_accuracy: 0.9491\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2012 - accuracy: 0.9510 - val_loss: 0.1654 - val_accuracy: 0.9537\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1923 - accuracy: 0.9515 - val_loss: 0.1928 - val_accuracy: 0.9491\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1835 - accuracy: 0.9562 - val_loss: 0.1642 - val_accuracy: 0.9537\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1724 - accuracy: 0.9639 - val_loss: 0.1636 - val_accuracy: 0.9537\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.1491 - accuracy: 0.9665 - val_loss: 0.1521 - val_accuracy: 0.9676\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1466 - accuracy: 0.9593 - val_loss: 0.1504 - val_accuracy: 0.9583\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1677 - accuracy: 0.9541 - val_loss: 0.1474 - val_accuracy: 0.9537\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1490 - accuracy: 0.9624 - val_loss: 0.1455 - val_accuracy: 0.9583\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1377 - accuracy: 0.9706 - val_loss: 0.1374 - val_accuracy: 0.9583\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1336 - accuracy: 0.9654 - val_loss: 0.1383 - val_accuracy: 0.9583\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1277 - accuracy: 0.9649 - val_loss: 0.1839 - val_accuracy: 0.9537\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1226 - accuracy: 0.9691 - val_loss: 0.1577 - val_accuracy: 0.9537\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1260 - accuracy: 0.9680 - val_loss: 0.1586 - val_accuracy: 0.9444\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1122 - accuracy: 0.9701 - val_loss: 0.1228 - val_accuracy: 0.9676\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1183 - accuracy: 0.9701 - val_loss: 0.1593 - val_accuracy: 0.9491\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1175 - accuracy: 0.9701 - val_loss: 0.1371 - val_accuracy: 0.9630\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1077 - accuracy: 0.9732 - val_loss: 0.1465 - val_accuracy: 0.9537\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1108 - accuracy: 0.9716 - val_loss: 0.1744 - val_accuracy: 0.9444\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1005 - accuracy: 0.9727 - val_loss: 0.1441 - val_accuracy: 0.9583\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0933 - accuracy: 0.9742 - val_loss: 0.1598 - val_accuracy: 0.9491\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1019 - accuracy: 0.9716 - val_loss: 0.1605 - val_accuracy: 0.9491\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0779 - accuracy: 0.9819 - val_loss: 0.1435 - val_accuracy: 0.9537\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0848 - accuracy: 0.9768 - val_loss: 0.1262 - val_accuracy: 0.9491\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0809 - accuracy: 0.9783 - val_loss: 0.2002 - val_accuracy: 0.9398\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0817 - accuracy: 0.9768 - val_loss: 0.1833 - val_accuracy: 0.9444\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1025 - accuracy: 0.9696 - val_loss: 0.1391 - val_accuracy: 0.9630\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0685 - accuracy: 0.9809 - val_loss: 0.1572 - val_accuracy: 0.9491\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0749 - accuracy: 0.9835 - val_loss: 0.1350 - val_accuracy: 0.9537\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0770 - accuracy: 0.9783 - val_loss: 0.1446 - val_accuracy: 0.9583\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0824 - accuracy: 0.9778 - val_loss: 0.1581 - val_accuracy: 0.9491\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0698 - accuracy: 0.9819 - val_loss: 0.1427 - val_accuracy: 0.9537\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0674 - accuracy: 0.9789 - val_loss: 0.1531 - val_accuracy: 0.9491\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0703 - accuracy: 0.9835 - val_loss: 0.1868 - val_accuracy: 0.9491\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0861 - accuracy: 0.9722 - val_loss: 0.1720 - val_accuracy: 0.9537\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0697 - accuracy: 0.9819 - val_loss: 0.1686 - val_accuracy: 0.9630\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0607 - accuracy: 0.9845 - val_loss: 0.1418 - val_accuracy: 0.9537\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0748 - accuracy: 0.9732 - val_loss: 0.1211 - val_accuracy: 0.9583\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0699 - accuracy: 0.9783 - val_loss: 0.1427 - val_accuracy: 0.9444\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0591 - accuracy: 0.9830 - val_loss: 0.1229 - val_accuracy: 0.9630\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0615 - accuracy: 0.9835 - val_loss: 0.1062 - val_accuracy: 0.9630\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0656 - accuracy: 0.9783 - val_loss: 0.1669 - val_accuracy: 0.9583\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0546 - accuracy: 0.9845 - val_loss: 0.1374 - val_accuracy: 0.9537\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0529 - accuracy: 0.9861 - val_loss: 0.1346 - val_accuracy: 0.9537\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0502 - accuracy: 0.9871 - val_loss: 0.1288 - val_accuracy: 0.9630\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0483 - accuracy: 0.9871 - val_loss: 0.1669 - val_accuracy: 0.9537\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0610 - accuracy: 0.9850 - val_loss: 0.1758 - val_accuracy: 0.9537\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0513 - accuracy: 0.9871 - val_loss: 0.1211 - val_accuracy: 0.9583\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0440 - accuracy: 0.9881 - val_loss: 0.1159 - val_accuracy: 0.9583\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0503 - accuracy: 0.9856 - val_loss: 0.1524 - val_accuracy: 0.9444\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 0.1245 - val_accuracy: 0.9583\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.1068 - val_accuracy: 0.9583\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 0.1063 - val_accuracy: 0.9676\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0370 - accuracy: 0.9907 - val_loss: 0.1742 - val_accuracy: 0.9583\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0415 - accuracy: 0.9887 - val_loss: 0.1224 - val_accuracy: 0.9676\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0462 - accuracy: 0.9881 - val_loss: 0.1680 - val_accuracy: 0.9583\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0561 - accuracy: 0.9819 - val_loss: 0.3407 - val_accuracy: 0.8796\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0433 - accuracy: 0.9892 - val_loss: 0.1177 - val_accuracy: 0.9630\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0392 - accuracy: 0.9902 - val_loss: 0.1576 - val_accuracy: 0.9676\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0448 - accuracy: 0.9881 - val_loss: 0.1308 - val_accuracy: 0.9537\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0390 - accuracy: 0.9902 - val_loss: 0.1237 - val_accuracy: 0.9491\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0400 - accuracy: 0.9876 - val_loss: 0.1519 - val_accuracy: 0.9491\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0362 - accuracy: 0.9917 - val_loss: 0.1438 - val_accuracy: 0.9676\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0417 - accuracy: 0.9907 - val_loss: 0.1881 - val_accuracy: 0.9398\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.1382 - val_accuracy: 0.9537\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.1422 - val_accuracy: 0.9537\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.1586 - val_accuracy: 0.9583\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0399 - accuracy: 0.9856 - val_loss: 0.1349 - val_accuracy: 0.9537\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.1345 - val_accuracy: 0.9583\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.1037 - val_accuracy: 0.9583\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0344 - accuracy: 0.9907 - val_loss: 0.1576 - val_accuracy: 0.9676\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0443 - accuracy: 0.9876 - val_loss: 0.1045 - val_accuracy: 0.9630\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0439 - accuracy: 0.9887 - val_loss: 0.1732 - val_accuracy: 0.9676\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.1105 - val_accuracy: 0.9630\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.1763 - val_accuracy: 0.9491\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0296 - accuracy: 0.9928 - val_loss: 0.1152 - val_accuracy: 0.9630\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0320 - accuracy: 0.9907 - val_loss: 0.0952 - val_accuracy: 0.9676\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.1006 - val_accuracy: 0.9676\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.1032 - val_accuracy: 0.9676\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 0.0884 - val_accuracy: 0.9676\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.1644 - val_accuracy: 0.9537\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.1459 - val_accuracy: 0.9444\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0208 - accuracy: 0.9964 - val_loss: 0.1808 - val_accuracy: 0.9491\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.1410 - val_accuracy: 0.9491\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.1564 - val_accuracy: 0.9630\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.1498 - val_accuracy: 0.9630\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.0260 - accuracy: 0.9954 - val_loss: 0.0997 - val_accuracy: 0.9815\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 0.1258 - val_accuracy: 0.9676\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0391 - accuracy: 0.9897 - val_loss: 0.1422 - val_accuracy: 0.9630\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.1343 - val_accuracy: 0.9676\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.1449 - val_accuracy: 0.9583\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0265 - accuracy: 0.9907 - val_loss: 0.1465 - val_accuracy: 0.9676\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.1588 - val_accuracy: 0.9769\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.1016 - val_accuracy: 0.9722\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 0.1461 - val_accuracy: 0.9583\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0470 - accuracy: 0.9830 - val_loss: 0.1415 - val_accuracy: 0.9583\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0263 - accuracy: 0.9943 - val_loss: 0.1410 - val_accuracy: 0.9676\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0221 - accuracy: 0.9954 - val_loss: 0.1768 - val_accuracy: 0.9352\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.1947 - val_accuracy: 0.9537\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0329 - accuracy: 0.9881 - val_loss: 0.2458 - val_accuracy: 0.9352\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0248 - accuracy: 0.9943 - val_loss: 0.1230 - val_accuracy: 0.9769\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.1327 - val_accuracy: 0.9676\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.1698 - val_accuracy: 0.9537\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.1497 - val_accuracy: 0.9537\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 0.1448 - val_accuracy: 0.9676\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.9959 - val_loss: 0.1805 - val_accuracy: 0.9583\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.1291 - val_accuracy: 0.9722\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.3060 - val_accuracy: 0.9398\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.1588 - val_accuracy: 0.9630\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.1431 - val_accuracy: 0.9537\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0289 - accuracy: 0.9881 - val_loss: 0.1004 - val_accuracy: 0.9769\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 0.1300 - val_accuracy: 0.9630\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0372 - accuracy: 0.9902 - val_loss: 0.1392 - val_accuracy: 0.9537\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.1278 - val_accuracy: 0.9722\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.1313 - val_accuracy: 0.9583\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.1386 - val_accuracy: 0.9583\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.1847 - val_accuracy: 0.9630\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.1474 - val_accuracy: 0.9583\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.1831 - val_accuracy: 0.9676\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.2020 - val_accuracy: 0.9676\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.1318 - val_accuracy: 0.9676\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1294 - val_accuracy: 0.9722\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0222 - accuracy: 0.9943 - val_loss: 0.1232 - val_accuracy: 0.9769\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.1389 - val_accuracy: 0.9722\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.1370 - val_accuracy: 0.9676\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.1290 - val_accuracy: 0.9630\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.9959 - val_loss: 0.1342 - val_accuracy: 0.9722\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.1568 - val_accuracy: 0.9676\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0152 - accuracy: 0.9985 - val_loss: 0.1427 - val_accuracy: 0.9676\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.1881 - val_accuracy: 0.9537\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.1635 - val_accuracy: 0.9398\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.1552 - val_accuracy: 0.9630\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.1710 - val_accuracy: 0.9630\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.1539 - val_accuracy: 0.9491\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.1154 - val_accuracy: 0.9722\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.1163 - val_accuracy: 0.9769\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.1481 - val_accuracy: 0.9583\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0181 - accuracy: 0.9923 - val_loss: 0.1938 - val_accuracy: 0.9583\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.1628 - val_accuracy: 0.9583\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.1757 - val_accuracy: 0.9676\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1273 - val_accuracy: 0.9769\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.1157 - val_accuracy: 0.9769\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: 0.1778 - val_accuracy: 0.9583\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.1258 - val_accuracy: 0.9769\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 0.1463 - val_accuracy: 0.9769\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.1151 - val_accuracy: 0.9722\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0221 - accuracy: 0.9907 - val_loss: 0.1302 - val_accuracy: 0.9769\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.1346 - val_accuracy: 0.9630\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.1517 - val_accuracy: 0.9630\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.1102 - val_accuracy: 0.9769\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.1752 - val_accuracy: 0.9676\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.1791 - val_accuracy: 0.9630\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.1364 - val_accuracy: 0.9630\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.1460 - val_accuracy: 0.9722\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.1847 - val_accuracy: 0.9630\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.1881 - val_accuracy: 0.9769\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.1204 - val_accuracy: 0.9676\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.1116 - val_accuracy: 0.9769\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0863 - val_accuracy: 0.9815\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.1082 - val_accuracy: 0.9722\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.1035 - val_accuracy: 0.9861\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.1375 - val_accuracy: 0.9676\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.1088 - val_accuracy: 0.9815\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.1158 - val_accuracy: 0.9815\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.1374 - val_accuracy: 0.9583\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.1837 - val_accuracy: 0.9583\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.1087 - val_accuracy: 0.9815\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.1150 - val_accuracy: 0.9537\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.1523 - val_accuracy: 0.9722\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1089 - val_accuracy: 0.9769\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1526 - val_accuracy: 0.9676\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0963 - val_accuracy: 0.9769\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.1372 - val_accuracy: 0.9722\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.1147 - val_accuracy: 0.9722\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.1229 - val_accuracy: 0.9583\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0425 - accuracy: 0.9856 - val_loss: 0.1391 - val_accuracy: 0.9630\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0676 - val_accuracy: 0.9676\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.0884 - val_accuracy: 0.9769\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0973 - val_accuracy: 0.9769\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0147 - accuracy: 0.9933 - val_loss: 0.1163 - val_accuracy: 0.9676\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.1508 - val_accuracy: 0.9537\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.1257 - val_accuracy: 0.9676\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.1005 - val_accuracy: 0.9769\n",
      "Epoch 219/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.1012 - val_accuracy: 0.9676\n",
      "Epoch 220/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.1439 - val_accuracy: 0.9630\n",
      "Epoch 221/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.1340 - val_accuracy: 0.9630\n",
      "Epoch 222/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1154 - val_accuracy: 0.9676\n",
      "Epoch 223/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.1068 - val_accuracy: 0.9630\n",
      "Epoch 224/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1391 - val_accuracy: 0.9630\n",
      "Epoch 225/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.2903 - val_accuracy: 0.9398\n",
      "Epoch 226/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.1293 - val_accuracy: 0.9630\n",
      "Epoch 227/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.1302 - val_accuracy: 0.9583\n",
      "Epoch 228/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.1085 - val_accuracy: 0.9769\n",
      "Epoch 229/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.1811 - val_accuracy: 0.9583\n",
      "Epoch 230/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.1178 - val_accuracy: 0.9676\n",
      "Epoch 231/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.1507 - val_accuracy: 0.9630\n",
      "Epoch 232/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.1561 - val_accuracy: 0.9583\n",
      "Epoch 233/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.1350 - val_accuracy: 0.9583\n",
      "Epoch 234/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.1307 - val_accuracy: 0.9722\n",
      "Epoch 235/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.1296 - val_accuracy: 0.9537\n",
      "Epoch 236/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.1208 - val_accuracy: 0.9676\n",
      "Epoch 237/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 0.3473 - val_accuracy: 0.9167\n",
      "Epoch 238/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1655 - val_accuracy: 0.9676\n",
      "Epoch 239/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.1419 - val_accuracy: 0.9722\n",
      "Epoch 240/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.1756 - val_accuracy: 0.9676\n",
      "Epoch 241/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1090 - val_accuracy: 0.9722\n",
      "Epoch 242/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.1101 - val_accuracy: 0.9722\n",
      "Epoch 243/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1306 - val_accuracy: 0.9630\n",
      "Epoch 244/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.1745 - val_accuracy: 0.9630\n",
      "Epoch 245/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.1507 - val_accuracy: 0.9722\n",
      "Epoch 246/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.1333 - val_accuracy: 0.9676\n",
      "Epoch 247/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.1838 - val_accuracy: 0.9444\n",
      "Epoch 248/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.1393 - val_accuracy: 0.9676\n",
      "Epoch 249/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.1589 - val_accuracy: 0.9676\n",
      "Epoch 250/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.1188 - val_accuracy: 0.9676\n",
      "Epoch 251/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.1770 - val_accuracy: 0.9583\n",
      "Epoch 252/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.1210 - val_accuracy: 0.9722\n",
      "Epoch 253/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.1555 - val_accuracy: 0.9676\n",
      "Epoch 254/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0085 - accuracy: 0.9964 - val_loss: 0.1469 - val_accuracy: 0.9676\n",
      "Epoch 255/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.1206 - val_accuracy: 0.9676\n",
      "Epoch 256/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.1300 - val_accuracy: 0.9630\n",
      "Epoch 257/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.1122 - val_accuracy: 0.9676\n",
      "Epoch 258/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.1016 - val_accuracy: 0.9769\n",
      "Epoch 259/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.1315 - val_accuracy: 0.9630\n",
      "Epoch 260/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.1121 - val_accuracy: 0.9676\n",
      "Epoch 261/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.1142 - val_accuracy: 0.9722\n",
      "Epoch 262/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.1285 - val_accuracy: 0.9676\n",
      "Epoch 263/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.1584 - val_accuracy: 0.9630\n",
      "Epoch 264/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.1139 - val_accuracy: 0.9722\n",
      "Epoch 265/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.1600 - val_accuracy: 0.9722\n",
      "Epoch 266/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9722\n",
      "Epoch 267/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.1402 - val_accuracy: 0.9630\n",
      "Epoch 268/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.1330 - val_accuracy: 0.9676\n",
      "Epoch 269/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.2146 - val_accuracy: 0.9491\n",
      "Epoch 270/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.1058 - val_accuracy: 0.9630\n",
      "Epoch 271/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.2095 - val_accuracy: 0.9676\n",
      "Epoch 272/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.1905 - val_accuracy: 0.9537\n",
      "Epoch 273/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.1980 - val_accuracy: 0.9352\n",
      "Epoch 274/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0860 - val_accuracy: 0.9722\n",
      "Epoch 275/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9769\n",
      "Epoch 276/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.1350 - val_accuracy: 0.9676\n",
      "Epoch 277/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0705 - val_accuracy: 0.9769\n",
      "Epoch 278/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1344 - val_accuracy: 0.9722\n",
      "Epoch 279/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.1740 - val_accuracy: 0.9676\n",
      "Epoch 280/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1657 - val_accuracy: 0.9722\n",
      "Epoch 281/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.1392 - val_accuracy: 0.9676\n",
      "Epoch 282/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1226 - val_accuracy: 0.9676\n",
      "Epoch 283/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.1025 - val_accuracy: 0.9769\n",
      "Epoch 284/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.1292 - val_accuracy: 0.9676\n",
      "Epoch 285/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.1329 - val_accuracy: 0.9676\n",
      "Epoch 286/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0953 - val_accuracy: 0.9630\n",
      "Epoch 287/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.1670 - val_accuracy: 0.9537\n",
      "Epoch 288/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1213 - val_accuracy: 0.9769\n",
      "Epoch 289/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1124 - val_accuracy: 0.9630\n",
      "Epoch 290/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.1093 - val_accuracy: 0.9583\n",
      "Epoch 291/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.1745 - val_accuracy: 0.9722\n",
      "Epoch 292/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1494 - val_accuracy: 0.9630\n",
      "Epoch 293/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0995 - val_accuracy: 0.9676\n",
      "Epoch 294/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.1763 - val_accuracy: 0.9491\n",
      "Epoch 295/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1663 - val_accuracy: 0.9676\n",
      "Epoch 296/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.1182 - val_accuracy: 0.9630\n",
      "Epoch 296: early stopping\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1607 - accuracy: 0.9511\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 14ms/step - loss: 1.7092 - accuracy: 0.2300 - val_loss: 1.7077 - val_accuracy: 0.1991\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.4804 - accuracy: 0.3337 - val_loss: 1.6702 - val_accuracy: 0.1991\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.3852 - accuracy: 0.4131 - val_loss: 1.5998 - val_accuracy: 0.2037\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.3212 - accuracy: 0.4595 - val_loss: 1.4784 - val_accuracy: 0.4074\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.2509 - accuracy: 0.5286 - val_loss: 1.2795 - val_accuracy: 0.6204\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.2050 - accuracy: 0.5658 - val_loss: 1.1393 - val_accuracy: 0.6620\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.1543 - accuracy: 0.6111 - val_loss: 1.0109 - val_accuracy: 0.7269\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.0893 - accuracy: 0.6400 - val_loss: 0.9432 - val_accuracy: 0.7361\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.0584 - accuracy: 0.6591 - val_loss: 0.8697 - val_accuracy: 0.7731\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.0023 - accuracy: 0.6704 - val_loss: 0.8483 - val_accuracy: 0.7454\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.9500 - accuracy: 0.6875 - val_loss: 0.7736 - val_accuracy: 0.7546\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.9054 - accuracy: 0.6957 - val_loss: 0.7784 - val_accuracy: 0.7593\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.8613 - accuracy: 0.7200 - val_loss: 0.7133 - val_accuracy: 0.7639\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.8285 - accuracy: 0.7174 - val_loss: 0.6913 - val_accuracy: 0.7824\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.8105 - accuracy: 0.7189 - val_loss: 0.6365 - val_accuracy: 0.7917\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7679 - accuracy: 0.7370 - val_loss: 0.6276 - val_accuracy: 0.8148\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7395 - accuracy: 0.7468 - val_loss: 0.5814 - val_accuracy: 0.8241\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7085 - accuracy: 0.7576 - val_loss: 0.5606 - val_accuracy: 0.8472\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.7000 - accuracy: 0.7586 - val_loss: 0.5416 - val_accuracy: 0.8426\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.6593 - accuracy: 0.7751 - val_loss: 0.5105 - val_accuracy: 0.8565\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.6264 - accuracy: 0.7978 - val_loss: 0.4781 - val_accuracy: 0.8611\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.6132 - accuracy: 0.8030 - val_loss: 0.4625 - val_accuracy: 0.8796\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5919 - accuracy: 0.8164 - val_loss: 0.4416 - val_accuracy: 0.8843\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5590 - accuracy: 0.8329 - val_loss: 0.4136 - val_accuracy: 0.9074\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5522 - accuracy: 0.8504 - val_loss: 0.3918 - val_accuracy: 0.9028\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5341 - accuracy: 0.8561 - val_loss: 0.3887 - val_accuracy: 0.9028\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5041 - accuracy: 0.8773 - val_loss: 0.3832 - val_accuracy: 0.9167\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5061 - accuracy: 0.8695 - val_loss: 0.3495 - val_accuracy: 0.9213\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4571 - accuracy: 0.8896 - val_loss: 0.3649 - val_accuracy: 0.9167\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4489 - accuracy: 0.9005 - val_loss: 0.3513 - val_accuracy: 0.9120\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.4105 - accuracy: 0.9092 - val_loss: 0.3122 - val_accuracy: 0.9306\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.4039 - accuracy: 0.9072 - val_loss: 0.2869 - val_accuracy: 0.9398\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3874 - accuracy: 0.9175 - val_loss: 0.2551 - val_accuracy: 0.9398\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3634 - accuracy: 0.9185 - val_loss: 0.2663 - val_accuracy: 0.9352\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3535 - accuracy: 0.9226 - val_loss: 0.2791 - val_accuracy: 0.9306\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3374 - accuracy: 0.9247 - val_loss: 0.2554 - val_accuracy: 0.9259\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3123 - accuracy: 0.9304 - val_loss: 0.2475 - val_accuracy: 0.9352\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3087 - accuracy: 0.9309 - val_loss: 0.2498 - val_accuracy: 0.9306\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2946 - accuracy: 0.9345 - val_loss: 0.2393 - val_accuracy: 0.9213\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2734 - accuracy: 0.9464 - val_loss: 0.1929 - val_accuracy: 0.9398\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2648 - accuracy: 0.9360 - val_loss: 0.2216 - val_accuracy: 0.9259\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.2504 - accuracy: 0.9479 - val_loss: 0.1713 - val_accuracy: 0.9537\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2158 - accuracy: 0.9551 - val_loss: 0.1742 - val_accuracy: 0.9537\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2381 - accuracy: 0.9428 - val_loss: 0.2109 - val_accuracy: 0.9398\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2174 - accuracy: 0.9479 - val_loss: 0.1933 - val_accuracy: 0.9259\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2102 - accuracy: 0.9479 - val_loss: 0.1493 - val_accuracy: 0.9630\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1863 - accuracy: 0.9593 - val_loss: 0.1824 - val_accuracy: 0.9491\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1802 - accuracy: 0.9618 - val_loss: 0.1731 - val_accuracy: 0.9444\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1879 - accuracy: 0.9562 - val_loss: 0.1642 - val_accuracy: 0.9444\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1659 - accuracy: 0.9536 - val_loss: 0.1798 - val_accuracy: 0.9537\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1795 - accuracy: 0.9608 - val_loss: 0.1401 - val_accuracy: 0.9444\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1620 - accuracy: 0.9660 - val_loss: 0.1321 - val_accuracy: 0.9537\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1460 - accuracy: 0.9660 - val_loss: 0.1435 - val_accuracy: 0.9583\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1492 - accuracy: 0.9649 - val_loss: 0.1330 - val_accuracy: 0.9491\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1385 - accuracy: 0.9680 - val_loss: 0.1364 - val_accuracy: 0.9491\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1267 - accuracy: 0.9737 - val_loss: 0.1341 - val_accuracy: 0.9306\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1352 - accuracy: 0.9685 - val_loss: 0.1117 - val_accuracy: 0.9537\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1314 - accuracy: 0.9701 - val_loss: 0.0920 - val_accuracy: 0.9769\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1357 - accuracy: 0.9685 - val_loss: 0.1126 - val_accuracy: 0.9630\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1381 - accuracy: 0.9654 - val_loss: 0.1386 - val_accuracy: 0.9444\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1383 - accuracy: 0.9639 - val_loss: 0.1697 - val_accuracy: 0.9398\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1141 - accuracy: 0.9763 - val_loss: 0.0989 - val_accuracy: 0.9630\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1270 - accuracy: 0.9716 - val_loss: 0.1404 - val_accuracy: 0.9491\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1156 - accuracy: 0.9727 - val_loss: 0.0980 - val_accuracy: 0.9676\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1033 - accuracy: 0.9773 - val_loss: 0.1219 - val_accuracy: 0.9398\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1124 - accuracy: 0.9716 - val_loss: 0.1305 - val_accuracy: 0.9444\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9768 - val_loss: 0.1073 - val_accuracy: 0.9583\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9732 - val_loss: 0.1226 - val_accuracy: 0.9491\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0974 - accuracy: 0.9794 - val_loss: 0.0968 - val_accuracy: 0.9630\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0935 - accuracy: 0.9783 - val_loss: 0.1695 - val_accuracy: 0.9352\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1069 - accuracy: 0.9742 - val_loss: 0.1369 - val_accuracy: 0.9491\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1173 - accuracy: 0.9660 - val_loss: 0.0939 - val_accuracy: 0.9676\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0819 - accuracy: 0.9819 - val_loss: 0.1034 - val_accuracy: 0.9583\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1059 - accuracy: 0.9742 - val_loss: 0.1066 - val_accuracy: 0.9537\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0862 - accuracy: 0.9799 - val_loss: 0.0973 - val_accuracy: 0.9630\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0879 - accuracy: 0.9783 - val_loss: 0.1568 - val_accuracy: 0.9491\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0799 - accuracy: 0.9814 - val_loss: 0.1456 - val_accuracy: 0.9491\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0701 - accuracy: 0.9856 - val_loss: 0.0917 - val_accuracy: 0.9630\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0749 - accuracy: 0.9809 - val_loss: 0.1014 - val_accuracy: 0.9630\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0662 - accuracy: 0.9897 - val_loss: 0.1037 - val_accuracy: 0.9630\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0729 - accuracy: 0.9804 - val_loss: 0.1332 - val_accuracy: 0.9537\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0628 - accuracy: 0.9871 - val_loss: 0.1205 - val_accuracy: 0.9583\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0667 - accuracy: 0.9850 - val_loss: 0.0722 - val_accuracy: 0.9722\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0625 - accuracy: 0.9835 - val_loss: 0.0750 - val_accuracy: 0.9722\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0643 - accuracy: 0.9866 - val_loss: 0.1168 - val_accuracy: 0.9583\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0701 - accuracy: 0.9825 - val_loss: 0.0799 - val_accuracy: 0.9722\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0731 - accuracy: 0.9830 - val_loss: 0.0976 - val_accuracy: 0.9630\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0656 - accuracy: 0.9830 - val_loss: 0.0679 - val_accuracy: 0.9815\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0520 - accuracy: 0.9917 - val_loss: 0.0980 - val_accuracy: 0.9722\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0599 - accuracy: 0.9861 - val_loss: 0.0854 - val_accuracy: 0.9769\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0570 - accuracy: 0.9876 - val_loss: 0.0691 - val_accuracy: 0.9722\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0562 - accuracy: 0.9876 - val_loss: 0.1012 - val_accuracy: 0.9537\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0563 - accuracy: 0.9887 - val_loss: 0.0784 - val_accuracy: 0.9815\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0648 - accuracy: 0.9840 - val_loss: 0.1174 - val_accuracy: 0.9630\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0474 - accuracy: 0.9897 - val_loss: 0.1453 - val_accuracy: 0.9491\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0490 - accuracy: 0.9907 - val_loss: 0.0847 - val_accuracy: 0.9676\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.0884 - val_accuracy: 0.9676\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.0890 - val_accuracy: 0.9676\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0444 - accuracy: 0.9876 - val_loss: 0.0819 - val_accuracy: 0.9630\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0357 - accuracy: 0.9917 - val_loss: 0.1049 - val_accuracy: 0.9676\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0419 - accuracy: 0.9907 - val_loss: 0.0896 - val_accuracy: 0.9722\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0420 - accuracy: 0.9917 - val_loss: 0.2427 - val_accuracy: 0.9259\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0532 - accuracy: 0.9835 - val_loss: 0.0805 - val_accuracy: 0.9815\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0455 - accuracy: 0.9917 - val_loss: 0.0977 - val_accuracy: 0.9676\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0428 - accuracy: 0.9907 - val_loss: 0.0980 - val_accuracy: 0.9722\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.0963 - val_accuracy: 0.9722\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0436 - accuracy: 0.9881 - val_loss: 0.1120 - val_accuracy: 0.9676\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0410 - accuracy: 0.9928 - val_loss: 0.0715 - val_accuracy: 0.9722\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0486 - accuracy: 0.9881 - val_loss: 0.1646 - val_accuracy: 0.9491\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0416 - accuracy: 0.9887 - val_loss: 0.1094 - val_accuracy: 0.9583\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0396 - accuracy: 0.9912 - val_loss: 0.0941 - val_accuracy: 0.9722\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.1243 - val_accuracy: 0.9583\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0582 - accuracy: 0.9830 - val_loss: 0.0834 - val_accuracy: 0.9722\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0514 - accuracy: 0.9871 - val_loss: 0.1125 - val_accuracy: 0.9676\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.1285 - val_accuracy: 0.9537\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0507 - accuracy: 0.9876 - val_loss: 0.1029 - val_accuracy: 0.9769\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0401 - accuracy: 0.9912 - val_loss: 0.1027 - val_accuracy: 0.9722\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0802 - val_accuracy: 0.9861\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0348 - accuracy: 0.9928 - val_loss: 0.0706 - val_accuracy: 0.9815\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.0732 - val_accuracy: 0.9676\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 0.0877 - val_accuracy: 0.9722\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.0697 - val_accuracy: 0.9769\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 0.1297 - val_accuracy: 0.9630\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.0814 - val_accuracy: 0.9722\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0330 - accuracy: 0.9917 - val_loss: 0.0957 - val_accuracy: 0.9722\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0325 - accuracy: 0.9923 - val_loss: 0.0844 - val_accuracy: 0.9722\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0232 - accuracy: 0.9954 - val_loss: 0.0613 - val_accuracy: 0.9815\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.0588 - val_accuracy: 0.9861\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0246 - accuracy: 0.9964 - val_loss: 0.0768 - val_accuracy: 0.9722\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.1104 - val_accuracy: 0.9630\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.1129 - val_accuracy: 0.9583\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0841 - val_accuracy: 0.9676\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0867 - val_accuracy: 0.9676\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.1137 - val_accuracy: 0.9676\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0391 - accuracy: 0.9887 - val_loss: 0.0776 - val_accuracy: 0.9722\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.0807 - val_accuracy: 0.9769\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.0967 - val_accuracy: 0.9630\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0242 - accuracy: 0.9943 - val_loss: 0.0845 - val_accuracy: 0.9676\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0246 - accuracy: 0.9943 - val_loss: 0.0730 - val_accuracy: 0.9676\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.0987 - val_accuracy: 0.9630\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.0914 - val_accuracy: 0.9722\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.1218 - val_accuracy: 0.9630\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 0.0825 - val_accuracy: 0.9676\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0670 - val_accuracy: 0.9815\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.2138 - val_accuracy: 0.9491\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0334 - accuracy: 0.9876 - val_loss: 0.0834 - val_accuracy: 0.9769\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0350 - accuracy: 0.9881 - val_loss: 0.0762 - val_accuracy: 0.9861\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.1087 - val_accuracy: 0.9676\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.1108 - val_accuracy: 0.9630\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0921 - val_accuracy: 0.9769\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.0639 - val_accuracy: 0.9861\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0661 - val_accuracy: 0.9861\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.1093 - val_accuracy: 0.9722\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.0823 - val_accuracy: 0.9676\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0731 - val_accuracy: 0.9769\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.1369 - val_accuracy: 0.9676\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.0786 - val_accuracy: 0.9769\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.1573 - val_accuracy: 0.9583\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0297 - accuracy: 0.9923 - val_loss: 0.0963 - val_accuracy: 0.9676\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.1534 - val_accuracy: 0.9491\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 0.1020 - val_accuracy: 0.9583\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.9959 - val_loss: 0.0728 - val_accuracy: 0.9722\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.0728 - val_accuracy: 0.9815\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0859 - val_accuracy: 0.9676\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0932 - val_accuracy: 0.9630\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.0710 - val_accuracy: 0.9722\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.1144 - val_accuracy: 0.9630\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.0866 - val_accuracy: 0.9815\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.0774 - val_accuracy: 0.9769\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0594 - val_accuracy: 0.9815\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.0781 - val_accuracy: 0.9722\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0123 - accuracy: 0.9990 - val_loss: 0.0752 - val_accuracy: 0.9630\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.1244 - val_accuracy: 0.9583\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1279 - val_accuracy: 0.9676\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.1688 - val_accuracy: 0.9491\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.1575 - val_accuracy: 0.9491\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0193 - accuracy: 0.9964 - val_loss: 0.0821 - val_accuracy: 0.9815\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.1130 - val_accuracy: 0.9583\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1105 - val_accuracy: 0.9630\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0845 - val_accuracy: 0.9676\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.2882 - val_accuracy: 0.9120\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.0959 - val_accuracy: 0.9583\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.1252 - val_accuracy: 0.9537\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.0926 - val_accuracy: 0.9630\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.1104 - val_accuracy: 0.9630\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.1640 - val_accuracy: 0.9537\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.1258 - val_accuracy: 0.9583\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.1057 - val_accuracy: 0.9537\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.1748 - val_accuracy: 0.9491\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0979 - val_accuracy: 0.9630\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0994 - val_accuracy: 0.9630\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.1082 - val_accuracy: 0.9630\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.1434 - val_accuracy: 0.9630\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.1095 - val_accuracy: 0.9630\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.1322 - val_accuracy: 0.9630\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.3053 - val_accuracy: 0.9259\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1229 - val_accuracy: 0.9722\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1388 - val_accuracy: 0.9583\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.1153 - val_accuracy: 0.9583\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.2206 - val_accuracy: 0.9444\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.1067 - val_accuracy: 0.9537\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.1306 - val_accuracy: 0.9583\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.1414 - val_accuracy: 0.9491\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.1514 - val_accuracy: 0.9583\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.1284 - val_accuracy: 0.9630\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.0709 - val_accuracy: 0.9722\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.1099 - val_accuracy: 0.9630\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.1450 - val_accuracy: 0.9676\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.1712 - val_accuracy: 0.9537\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1145 - val_accuracy: 0.9722\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1138 - val_accuracy: 0.9722\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0934 - val_accuracy: 0.9815\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.0978 - val_accuracy: 0.9676\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.1845 - val_accuracy: 0.9583\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 0.0655 - val_accuracy: 0.9861\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.1121 - val_accuracy: 0.9630\n",
      "Epoch 218: early stopping\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.9457\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 14ms/step - loss: 1.5207 - accuracy: 0.3105 - val_loss: 1.6014 - val_accuracy: 0.4213\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.3421 - accuracy: 0.4420 - val_loss: 1.5961 - val_accuracy: 0.2685\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2235 - accuracy: 0.5255 - val_loss: 1.5074 - val_accuracy: 0.3333\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.1249 - accuracy: 0.6070 - val_loss: 1.3292 - val_accuracy: 0.5046\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0496 - accuracy: 0.6937 - val_loss: 1.0675 - val_accuracy: 0.7083\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0031 - accuracy: 0.7231 - val_loss: 0.8897 - val_accuracy: 0.8519\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.9059 - accuracy: 0.7958 - val_loss: 0.7887 - val_accuracy: 0.8333\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.8620 - accuracy: 0.8112 - val_loss: 0.7034 - val_accuracy: 0.8843\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8066 - accuracy: 0.8159 - val_loss: 0.6577 - val_accuracy: 0.8889\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7370 - accuracy: 0.8437 - val_loss: 0.6123 - val_accuracy: 0.8889\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.6944 - accuracy: 0.8484 - val_loss: 0.5739 - val_accuracy: 0.8935\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.6624 - accuracy: 0.8602 - val_loss: 0.5181 - val_accuracy: 0.9028\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.6087 - accuracy: 0.8783 - val_loss: 0.4831 - val_accuracy: 0.9213\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5775 - accuracy: 0.8747 - val_loss: 0.4500 - val_accuracy: 0.9167\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5346 - accuracy: 0.8855 - val_loss: 0.3962 - val_accuracy: 0.9213\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5204 - accuracy: 0.8855 - val_loss: 0.3772 - val_accuracy: 0.9306\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4608 - accuracy: 0.9046 - val_loss: 0.3548 - val_accuracy: 0.9398\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4717 - accuracy: 0.8932 - val_loss: 0.3298 - val_accuracy: 0.9398\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4199 - accuracy: 0.9139 - val_loss: 0.3459 - val_accuracy: 0.9259\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4050 - accuracy: 0.9175 - val_loss: 0.2845 - val_accuracy: 0.9352\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3714 - accuracy: 0.9190 - val_loss: 0.2628 - val_accuracy: 0.9444\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3673 - accuracy: 0.9165 - val_loss: 0.2309 - val_accuracy: 0.9444\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3293 - accuracy: 0.9293 - val_loss: 0.2374 - val_accuracy: 0.9630\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3168 - accuracy: 0.9360 - val_loss: 0.2267 - val_accuracy: 0.9398\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2992 - accuracy: 0.9288 - val_loss: 0.2055 - val_accuracy: 0.9583\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2675 - accuracy: 0.9448 - val_loss: 0.2016 - val_accuracy: 0.9630\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2682 - accuracy: 0.9438 - val_loss: 0.1997 - val_accuracy: 0.9537\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2591 - accuracy: 0.9474 - val_loss: 0.1936 - val_accuracy: 0.9537\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2356 - accuracy: 0.9500 - val_loss: 0.1776 - val_accuracy: 0.9630\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2460 - accuracy: 0.9371 - val_loss: 0.1908 - val_accuracy: 0.9398\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2082 - accuracy: 0.9556 - val_loss: 0.1821 - val_accuracy: 0.9398\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2175 - accuracy: 0.9479 - val_loss: 0.1967 - val_accuracy: 0.9583\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1909 - accuracy: 0.9587 - val_loss: 0.1664 - val_accuracy: 0.9444\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1743 - accuracy: 0.9649 - val_loss: 0.1557 - val_accuracy: 0.9630\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1820 - accuracy: 0.9593 - val_loss: 0.1728 - val_accuracy: 0.9491\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1696 - accuracy: 0.9629 - val_loss: 0.1769 - val_accuracy: 0.9398\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1599 - accuracy: 0.9644 - val_loss: 0.1478 - val_accuracy: 0.9491\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1462 - accuracy: 0.9634 - val_loss: 0.1960 - val_accuracy: 0.9352\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1409 - accuracy: 0.9691 - val_loss: 0.1434 - val_accuracy: 0.9583\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1426 - accuracy: 0.9660 - val_loss: 0.1465 - val_accuracy: 0.9583\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1271 - accuracy: 0.9737 - val_loss: 0.1372 - val_accuracy: 0.9583\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1196 - accuracy: 0.9737 - val_loss: 0.1412 - val_accuracy: 0.9676\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1257 - accuracy: 0.9691 - val_loss: 0.1618 - val_accuracy: 0.9491\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1167 - accuracy: 0.9752 - val_loss: 0.2179 - val_accuracy: 0.9306\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1169 - accuracy: 0.9747 - val_loss: 0.1286 - val_accuracy: 0.9676\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0991 - accuracy: 0.9794 - val_loss: 0.1398 - val_accuracy: 0.9676\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1091 - accuracy: 0.9763 - val_loss: 0.1366 - val_accuracy: 0.9722\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1084 - accuracy: 0.9706 - val_loss: 0.1394 - val_accuracy: 0.9537\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0964 - accuracy: 0.9752 - val_loss: 0.1463 - val_accuracy: 0.9537\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0905 - accuracy: 0.9819 - val_loss: 0.1417 - val_accuracy: 0.9537\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0934 - accuracy: 0.9778 - val_loss: 0.1450 - val_accuracy: 0.9537\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0767 - accuracy: 0.9840 - val_loss: 0.1577 - val_accuracy: 0.9444\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0849 - accuracy: 0.9778 - val_loss: 0.1759 - val_accuracy: 0.9306\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0827 - accuracy: 0.9773 - val_loss: 0.1842 - val_accuracy: 0.9398\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0719 - accuracy: 0.9830 - val_loss: 0.1365 - val_accuracy: 0.9583\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0835 - accuracy: 0.9809 - val_loss: 0.1448 - val_accuracy: 0.9537\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0692 - accuracy: 0.9835 - val_loss: 0.1426 - val_accuracy: 0.9583\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0698 - accuracy: 0.9825 - val_loss: 0.1431 - val_accuracy: 0.9583\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0567 - accuracy: 0.9897 - val_loss: 0.1429 - val_accuracy: 0.9583\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0624 - accuracy: 0.9840 - val_loss: 0.1389 - val_accuracy: 0.9630\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0681 - accuracy: 0.9830 - val_loss: 0.1295 - val_accuracy: 0.9537\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0677 - accuracy: 0.9840 - val_loss: 0.1490 - val_accuracy: 0.9537\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0579 - accuracy: 0.9856 - val_loss: 0.1160 - val_accuracy: 0.9676\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0634 - accuracy: 0.9825 - val_loss: 0.1259 - val_accuracy: 0.9722\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0563 - accuracy: 0.9861 - val_loss: 0.1388 - val_accuracy: 0.9630\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0654 - accuracy: 0.9830 - val_loss: 0.1266 - val_accuracy: 0.9630\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0609 - accuracy: 0.9845 - val_loss: 0.1347 - val_accuracy: 0.9583\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0558 - accuracy: 0.9819 - val_loss: 0.1535 - val_accuracy: 0.9583\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0532 - accuracy: 0.9856 - val_loss: 0.1276 - val_accuracy: 0.9630\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0549 - accuracy: 0.9866 - val_loss: 0.1956 - val_accuracy: 0.9444\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0449 - accuracy: 0.9928 - val_loss: 0.1240 - val_accuracy: 0.9676\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0559 - accuracy: 0.9845 - val_loss: 0.1390 - val_accuracy: 0.9630\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0493 - accuracy: 0.9887 - val_loss: 0.1557 - val_accuracy: 0.9444\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0434 - accuracy: 0.9902 - val_loss: 0.1267 - val_accuracy: 0.9722\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0388 - accuracy: 0.9938 - val_loss: 0.1297 - val_accuracy: 0.9722\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0460 - accuracy: 0.9881 - val_loss: 0.1560 - val_accuracy: 0.9537\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 0.1988 - val_accuracy: 0.9306\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 0.1388 - val_accuracy: 0.9630\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0466 - accuracy: 0.9840 - val_loss: 0.1654 - val_accuracy: 0.9537\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0389 - accuracy: 0.9902 - val_loss: 0.1570 - val_accuracy: 0.9583\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0455 - accuracy: 0.9892 - val_loss: 0.2529 - val_accuracy: 0.9306\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0443 - accuracy: 0.9907 - val_loss: 0.1788 - val_accuracy: 0.9537\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0428 - accuracy: 0.9907 - val_loss: 0.1712 - val_accuracy: 0.9398\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0298 - accuracy: 0.9954 - val_loss: 0.1733 - val_accuracy: 0.9444\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0424 - accuracy: 0.9871 - val_loss: 0.2088 - val_accuracy: 0.9537\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.1463 - val_accuracy: 0.9676\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0344 - accuracy: 0.9917 - val_loss: 0.1723 - val_accuracy: 0.9398\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0385 - accuracy: 0.9871 - val_loss: 0.2052 - val_accuracy: 0.9352\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0405 - accuracy: 0.9902 - val_loss: 0.1429 - val_accuracy: 0.9630\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 0.1737 - val_accuracy: 0.9537\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.1746 - val_accuracy: 0.9491\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0349 - accuracy: 0.9917 - val_loss: 0.1997 - val_accuracy: 0.9398\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0328 - accuracy: 0.9917 - val_loss: 0.1719 - val_accuracy: 0.9630\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0233 - accuracy: 0.9959 - val_loss: 0.1289 - val_accuracy: 0.9676\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 0.1376 - val_accuracy: 0.9630\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0413 - accuracy: 0.9881 - val_loss: 0.1444 - val_accuracy: 0.9583\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0328 - accuracy: 0.9923 - val_loss: 0.2644 - val_accuracy: 0.9306\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 0.1415 - val_accuracy: 0.9537\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 0.1427 - val_accuracy: 0.9583\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.1533 - val_accuracy: 0.9583\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.1481 - val_accuracy: 0.9583\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0266 - accuracy: 0.9943 - val_loss: 0.2041 - val_accuracy: 0.9537\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0372 - accuracy: 0.9887 - val_loss: 0.1559 - val_accuracy: 0.9491\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0242 - accuracy: 0.9948 - val_loss: 0.1425 - val_accuracy: 0.9583\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0230 - accuracy: 0.9943 - val_loss: 0.1925 - val_accuracy: 0.9398\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 0.1405 - val_accuracy: 0.9676\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0210 - accuracy: 0.9974 - val_loss: 0.1826 - val_accuracy: 0.9583\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0200 - accuracy: 0.9954 - val_loss: 0.1835 - val_accuracy: 0.9537\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.1801 - val_accuracy: 0.9583\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.1725 - val_accuracy: 0.9583\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 0.1401 - val_accuracy: 0.9583\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.1807 - val_accuracy: 0.9537\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.2098 - val_accuracy: 0.9491\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.1503 - val_accuracy: 0.9583\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.1372 - val_accuracy: 0.9722\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.1631 - val_accuracy: 0.9583\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.1672 - val_accuracy: 0.9630\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0217 - accuracy: 0.9969 - val_loss: 0.1443 - val_accuracy: 0.9583\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.1454 - val_accuracy: 0.9630\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0249 - accuracy: 0.9902 - val_loss: 0.1625 - val_accuracy: 0.9630\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.2057 - val_accuracy: 0.9444\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.1403 - val_accuracy: 0.9676\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.1938 - val_accuracy: 0.9398\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.1376 - val_accuracy: 0.9583\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0184 - accuracy: 0.9959 - val_loss: 0.1329 - val_accuracy: 0.9630\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.1292 - val_accuracy: 0.9630\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 0.1711 - val_accuracy: 0.9491\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.1629 - val_accuracy: 0.9630\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.1544 - val_accuracy: 0.9630\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.1521 - val_accuracy: 0.9583\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 0.1619 - val_accuracy: 0.9537\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.1497 - val_accuracy: 0.9630\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.2173 - val_accuracy: 0.9491\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.1802 - val_accuracy: 0.9537\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.1759 - val_accuracy: 0.9583\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.2018 - val_accuracy: 0.9444\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0222 - accuracy: 0.9943 - val_loss: 0.1799 - val_accuracy: 0.9630\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.1475 - val_accuracy: 0.9583\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0202 - accuracy: 0.9959 - val_loss: 0.1820 - val_accuracy: 0.9630\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.1301 - val_accuracy: 0.9537\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.1590 - val_accuracy: 0.9630\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0177 - accuracy: 0.9959 - val_loss: 0.1415 - val_accuracy: 0.9630\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0223 - accuracy: 0.9948 - val_loss: 0.1462 - val_accuracy: 0.9537\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.1254 - val_accuracy: 0.9583\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 0.1555 - val_accuracy: 0.9630\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.1270 - val_accuracy: 0.9630\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.1381 - val_accuracy: 0.9630\n",
      "Epoch 147: early stopping\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9609\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 3s 16ms/step - loss: 1.6575 - accuracy: 0.2140 - val_loss: 1.5924 - val_accuracy: 0.1944\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.4878 - accuracy: 0.2120 - val_loss: 1.5767 - val_accuracy: 0.1944\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.4217 - accuracy: 0.2249 - val_loss: 1.5362 - val_accuracy: 0.1991\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.3689 - accuracy: 0.2378 - val_loss: 1.4391 - val_accuracy: 0.2083\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.3378 - accuracy: 0.2579 - val_loss: 1.3400 - val_accuracy: 0.2917\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.3087 - accuracy: 0.3038 - val_loss: 1.2758 - val_accuracy: 0.3333\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.2955 - accuracy: 0.3259 - val_loss: 1.2334 - val_accuracy: 0.4259\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.2708 - accuracy: 0.3760 - val_loss: 1.1976 - val_accuracy: 0.4815\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.2365 - accuracy: 0.4430 - val_loss: 1.1708 - val_accuracy: 0.5463\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.2025 - accuracy: 0.5028 - val_loss: 1.1348 - val_accuracy: 0.6157\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.1689 - accuracy: 0.5554 - val_loss: 1.1023 - val_accuracy: 0.6759\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.1407 - accuracy: 0.6194 - val_loss: 1.0742 - val_accuracy: 0.7546\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.1059 - accuracy: 0.6225 - val_loss: 1.0390 - val_accuracy: 0.7639\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0789 - accuracy: 0.6534 - val_loss: 0.9958 - val_accuracy: 0.7639\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 1.0366 - accuracy: 0.6859 - val_loss: 0.9623 - val_accuracy: 0.7917\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0135 - accuracy: 0.6973 - val_loss: 0.9199 - val_accuracy: 0.7639\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.9699 - accuracy: 0.7169 - val_loss: 0.8912 - val_accuracy: 0.7963\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.9354 - accuracy: 0.7334 - val_loss: 0.8428 - val_accuracy: 0.7778\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.8885 - accuracy: 0.7385 - val_loss: 0.8070 - val_accuracy: 0.7824\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.8694 - accuracy: 0.7406 - val_loss: 0.7826 - val_accuracy: 0.7778\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.8244 - accuracy: 0.7581 - val_loss: 0.7543 - val_accuracy: 0.7917\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.7937 - accuracy: 0.7679 - val_loss: 0.7218 - val_accuracy: 0.7824\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.7675 - accuracy: 0.7767 - val_loss: 0.6930 - val_accuracy: 0.8009\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.7392 - accuracy: 0.7824 - val_loss: 0.6392 - val_accuracy: 0.8194\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.6979 - accuracy: 0.7963 - val_loss: 0.6234 - val_accuracy: 0.8148\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.6852 - accuracy: 0.8092 - val_loss: 0.5955 - val_accuracy: 0.8380\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.6524 - accuracy: 0.8257 - val_loss: 0.5539 - val_accuracy: 0.8333\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.6026 - accuracy: 0.8489 - val_loss: 0.5246 - val_accuracy: 0.8611\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5719 - accuracy: 0.8757 - val_loss: 0.5122 - val_accuracy: 0.8565\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.5557 - accuracy: 0.8618 - val_loss: 0.4938 - val_accuracy: 0.8704\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.5371 - accuracy: 0.8752 - val_loss: 0.4551 - val_accuracy: 0.8935\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.4978 - accuracy: 0.9036 - val_loss: 0.4178 - val_accuracy: 0.8981\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.4570 - accuracy: 0.9092 - val_loss: 0.4023 - val_accuracy: 0.8843\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.4200 - accuracy: 0.9190 - val_loss: 0.3502 - val_accuracy: 0.9213\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.4078 - accuracy: 0.9237 - val_loss: 0.3263 - val_accuracy: 0.9352\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.3737 - accuracy: 0.9299 - val_loss: 0.3531 - val_accuracy: 0.8843\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.3535 - accuracy: 0.9366 - val_loss: 0.2907 - val_accuracy: 0.9167\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.3392 - accuracy: 0.9288 - val_loss: 0.2725 - val_accuracy: 0.9398\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2999 - accuracy: 0.9417 - val_loss: 0.2608 - val_accuracy: 0.9352\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.3043 - accuracy: 0.9391 - val_loss: 0.2447 - val_accuracy: 0.9352\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.2638 - accuracy: 0.9479 - val_loss: 0.2379 - val_accuracy: 0.9259\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.2812 - accuracy: 0.9340 - val_loss: 0.2239 - val_accuracy: 0.9444\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.2492 - accuracy: 0.9484 - val_loss: 0.1949 - val_accuracy: 0.9491\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.2350 - accuracy: 0.9515 - val_loss: 0.1745 - val_accuracy: 0.9630\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.2087 - accuracy: 0.9582 - val_loss: 0.2021 - val_accuracy: 0.9352\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.2132 - accuracy: 0.9541 - val_loss: 0.1767 - val_accuracy: 0.9537\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1963 - accuracy: 0.9613 - val_loss: 0.1886 - val_accuracy: 0.9398\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1902 - accuracy: 0.9618 - val_loss: 0.1828 - val_accuracy: 0.9491\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1656 - accuracy: 0.9680 - val_loss: 0.1576 - val_accuracy: 0.9537\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1671 - accuracy: 0.9685 - val_loss: 0.1778 - val_accuracy: 0.9398\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1663 - accuracy: 0.9613 - val_loss: 0.1616 - val_accuracy: 0.9491\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1538 - accuracy: 0.9618 - val_loss: 0.1550 - val_accuracy: 0.9491\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1560 - accuracy: 0.9618 - val_loss: 0.1359 - val_accuracy: 0.9537\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1467 - accuracy: 0.9670 - val_loss: 0.1340 - val_accuracy: 0.9676\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1355 - accuracy: 0.9706 - val_loss: 0.1704 - val_accuracy: 0.9444\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1453 - accuracy: 0.9696 - val_loss: 0.1377 - val_accuracy: 0.9444\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1308 - accuracy: 0.9685 - val_loss: 0.1311 - val_accuracy: 0.9583\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1207 - accuracy: 0.9783 - val_loss: 0.1263 - val_accuracy: 0.9630\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1118 - accuracy: 0.9768 - val_loss: 0.1078 - val_accuracy: 0.9769\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1124 - accuracy: 0.9711 - val_loss: 0.1337 - val_accuracy: 0.9630\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1116 - accuracy: 0.9737 - val_loss: 0.1274 - val_accuracy: 0.9537\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1156 - accuracy: 0.9706 - val_loss: 0.1011 - val_accuracy: 0.9722\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0984 - accuracy: 0.9794 - val_loss: 0.1146 - val_accuracy: 0.9676\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0879 - accuracy: 0.9830 - val_loss: 0.1188 - val_accuracy: 0.9583\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1030 - accuracy: 0.9783 - val_loss: 0.1192 - val_accuracy: 0.9537\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0872 - accuracy: 0.9809 - val_loss: 0.1314 - val_accuracy: 0.9491\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0754 - accuracy: 0.9881 - val_loss: 0.1314 - val_accuracy: 0.9537\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0829 - accuracy: 0.9814 - val_loss: 0.1264 - val_accuracy: 0.9583\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0786 - accuracy: 0.9835 - val_loss: 0.1084 - val_accuracy: 0.9630\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.1048 - accuracy: 0.9732 - val_loss: 0.1050 - val_accuracy: 0.9722\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0971 - accuracy: 0.9737 - val_loss: 0.1278 - val_accuracy: 0.9537\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0669 - accuracy: 0.9856 - val_loss: 0.1004 - val_accuracy: 0.9676\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0725 - accuracy: 0.9825 - val_loss: 0.0964 - val_accuracy: 0.9722\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0679 - accuracy: 0.9871 - val_loss: 0.1030 - val_accuracy: 0.9722\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0667 - accuracy: 0.9825 - val_loss: 0.1045 - val_accuracy: 0.9676\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0726 - accuracy: 0.9835 - val_loss: 0.1672 - val_accuracy: 0.9491\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0675 - accuracy: 0.9819 - val_loss: 0.0912 - val_accuracy: 0.9769\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0759 - accuracy: 0.9840 - val_loss: 0.1046 - val_accuracy: 0.9583\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0584 - accuracy: 0.9887 - val_loss: 0.0767 - val_accuracy: 0.9722\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0520 - accuracy: 0.9892 - val_loss: 0.0719 - val_accuracy: 0.9722\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0525 - accuracy: 0.9887 - val_loss: 0.1158 - val_accuracy: 0.9583\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0573 - accuracy: 0.9861 - val_loss: 0.0851 - val_accuracy: 0.9676\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0648 - accuracy: 0.9830 - val_loss: 0.1043 - val_accuracy: 0.9676\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0556 - accuracy: 0.9881 - val_loss: 0.0831 - val_accuracy: 0.9769\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0544 - accuracy: 0.9871 - val_loss: 0.0897 - val_accuracy: 0.9722\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0484 - accuracy: 0.9897 - val_loss: 0.1046 - val_accuracy: 0.9630\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0436 - accuracy: 0.9902 - val_loss: 0.0986 - val_accuracy: 0.9722\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0533 - accuracy: 0.9892 - val_loss: 0.1148 - val_accuracy: 0.9722\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0442 - accuracy: 0.9923 - val_loss: 0.1286 - val_accuracy: 0.9352\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0418 - accuracy: 0.9907 - val_loss: 0.1137 - val_accuracy: 0.9722\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0606 - accuracy: 0.9856 - val_loss: 0.0784 - val_accuracy: 0.9676\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0479 - accuracy: 0.9892 - val_loss: 0.0990 - val_accuracy: 0.9583\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0389 - accuracy: 0.9907 - val_loss: 0.1403 - val_accuracy: 0.9583\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9881 - val_loss: 0.1102 - val_accuracy: 0.9630\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.0455 - accuracy: 0.9881 - val_loss: 0.0745 - val_accuracy: 0.9815\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0360 - accuracy: 0.9928 - val_loss: 0.0605 - val_accuracy: 0.9676\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.1178 - val_accuracy: 0.9676\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0390 - accuracy: 0.9917 - val_loss: 0.0783 - val_accuracy: 0.9769\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0540 - accuracy: 0.9830 - val_loss: 0.1612 - val_accuracy: 0.9537\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0339 - accuracy: 0.9943 - val_loss: 0.0733 - val_accuracy: 0.9676\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.0827 - val_accuracy: 0.9722\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0417 - accuracy: 0.9907 - val_loss: 0.0926 - val_accuracy: 0.9630\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0410 - accuracy: 0.9881 - val_loss: 0.1559 - val_accuracy: 0.9583\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0291 - accuracy: 0.9943 - val_loss: 0.2354 - val_accuracy: 0.9398\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.1000 - val_accuracy: 0.9537\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.1333 - val_accuracy: 0.9537\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.1063 - val_accuracy: 0.9630\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0364 - accuracy: 0.9917 - val_loss: 0.0684 - val_accuracy: 0.9769\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0312 - accuracy: 0.9938 - val_loss: 0.0864 - val_accuracy: 0.9676\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.0753 - val_accuracy: 0.9769\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0290 - accuracy: 0.9948 - val_loss: 0.0713 - val_accuracy: 0.9815\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0312 - accuracy: 0.9923 - val_loss: 0.0810 - val_accuracy: 0.9676\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.1093 - val_accuracy: 0.9537\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.1208 - val_accuracy: 0.9676\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0334 - accuracy: 0.9923 - val_loss: 0.0891 - val_accuracy: 0.9815\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0282 - accuracy: 0.9938 - val_loss: 0.0867 - val_accuracy: 0.9630\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.1350 - val_accuracy: 0.9583\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0289 - accuracy: 0.9938 - val_loss: 0.0851 - val_accuracy: 0.9722\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.1228 - val_accuracy: 0.9722\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0199 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9722\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.0705 - val_accuracy: 0.9815\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.0827 - val_accuracy: 0.9722\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0343 - accuracy: 0.9933 - val_loss: 0.1044 - val_accuracy: 0.9722\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.1283 - val_accuracy: 0.9583\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.1132 - val_accuracy: 0.9722\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.0741 - val_accuracy: 0.9722\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.0812 - val_accuracy: 0.9676\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0361 - accuracy: 0.9871 - val_loss: 0.0753 - val_accuracy: 0.9722\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.0781 - val_accuracy: 0.9815\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.0735 - val_accuracy: 0.9815\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0849 - val_accuracy: 0.9722\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0974 - val_accuracy: 0.9722\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0851 - val_accuracy: 0.9769\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.0829 - val_accuracy: 0.9676\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 15ms/step - loss: 0.0148 - accuracy: 0.9985 - val_loss: 0.0673 - val_accuracy: 0.9861\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9815\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0216 - accuracy: 0.9959 - val_loss: 0.0694 - val_accuracy: 0.9815\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0989 - val_accuracy: 0.9630\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.0826 - val_accuracy: 0.9769\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.1000 - val_accuracy: 0.9769\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0197 - accuracy: 0.9959 - val_loss: 0.0755 - val_accuracy: 0.9769\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.0864 - val_accuracy: 0.9769\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.0475 - val_accuracy: 0.9676\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0742 - val_accuracy: 0.9722\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0835 - val_accuracy: 0.9769\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0365 - accuracy: 0.9917 - val_loss: 0.1170 - val_accuracy: 0.9630\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0665 - val_accuracy: 0.9722\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.1052 - val_accuracy: 0.9676\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0698 - val_accuracy: 0.9815\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.0787 - val_accuracy: 0.9769\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 0.0981 - val_accuracy: 0.9722\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0200 - accuracy: 0.9959 - val_loss: 0.1104 - val_accuracy: 0.9769\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.1086 - val_accuracy: 0.9630\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.0806 - val_accuracy: 0.9815\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.0729 - val_accuracy: 0.9769\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 0.1128 - val_accuracy: 0.9769\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.0935 - val_accuracy: 0.9722\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0779 - val_accuracy: 0.9769\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0635 - val_accuracy: 0.9815\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.0810 - val_accuracy: 0.9815\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.0827 - val_accuracy: 0.9815\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.0627 - val_accuracy: 0.9815\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.0921 - val_accuracy: 0.9676\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0797 - val_accuracy: 0.9722\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0212 - accuracy: 0.9943 - val_loss: 0.0870 - val_accuracy: 0.9676\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0847 - val_accuracy: 0.9722\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.1074 - val_accuracy: 0.9722\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0744 - val_accuracy: 0.9861\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0098 - accuracy: 0.9990 - val_loss: 0.0743 - val_accuracy: 0.9722\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0783 - val_accuracy: 0.9769\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0618 - val_accuracy: 0.9769\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9815\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 0.0667 - val_accuracy: 0.9815\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0821 - val_accuracy: 0.9769\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0952 - val_accuracy: 0.9769\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0484 - val_accuracy: 0.9769\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.3069 - val_accuracy: 0.9398\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.0559 - val_accuracy: 0.9815\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0659 - val_accuracy: 0.9815\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.0953 - val_accuracy: 0.9815\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.1054 - val_accuracy: 0.9722\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.0999 - val_accuracy: 0.9676\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0148 - accuracy: 0.9943 - val_loss: 0.0681 - val_accuracy: 0.9861\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0949 - val_accuracy: 0.9676\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0819 - val_accuracy: 0.9815\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1441 - val_accuracy: 0.9537\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0801 - val_accuracy: 0.9815\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1020 - val_accuracy: 0.9769\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0871 - val_accuracy: 0.9769\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.1008 - val_accuracy: 0.9769\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0562 - val_accuracy: 0.9769\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0589 - val_accuracy: 0.9769\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.1040 - val_accuracy: 0.9769\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0601 - val_accuracy: 0.9769\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.0622 - val_accuracy: 0.9769\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.1675 - val_accuracy: 0.9537\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0777 - val_accuracy: 0.9769\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0741 - val_accuracy: 0.9815\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0713 - val_accuracy: 0.9815\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.0848 - val_accuracy: 0.9722\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.1271 - val_accuracy: 0.9722\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0165 - accuracy: 0.9928 - val_loss: 0.0642 - val_accuracy: 0.9769\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.1314 - val_accuracy: 0.9583\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.1070 - val_accuracy: 0.9583\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.1395 - val_accuracy: 0.9583\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9676\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.1226 - val_accuracy: 0.9722\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.1080 - val_accuracy: 0.9722\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.1040 - val_accuracy: 0.9630\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9815\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.1165 - val_accuracy: 0.9630\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0996 - val_accuracy: 0.9676\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.1082 - val_accuracy: 0.9722\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.1309 - val_accuracy: 0.9630\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0278 - accuracy: 0.9892 - val_loss: 0.1655 - val_accuracy: 0.9630\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0206 - accuracy: 0.9959 - val_loss: 0.1244 - val_accuracy: 0.9722\n",
      "Epoch 219/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.1084 - val_accuracy: 0.9815\n",
      "Epoch 220/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.1096 - val_accuracy: 0.9769\n",
      "Epoch 221/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0980 - val_accuracy: 0.9676\n",
      "Epoch 222/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.1112 - val_accuracy: 0.9676\n",
      "Epoch 223/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9676\n",
      "Epoch 224/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.0960 - val_accuracy: 0.9722\n",
      "Epoch 225/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.0622 - val_accuracy: 0.9815\n",
      "Epoch 226/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.0535 - val_accuracy: 0.9722\n",
      "Epoch 227/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.0661 - val_accuracy: 0.9769\n",
      "Epoch 228/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0762 - val_accuracy: 0.9815\n",
      "Epoch 229/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.1051 - val_accuracy: 0.9722\n",
      "Epoch 230/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0441 - val_accuracy: 0.9722\n",
      "Epoch 231/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.0767 - val_accuracy: 0.9769\n",
      "Epoch 232/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0827 - val_accuracy: 0.9722\n",
      "Epoch 233/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0935 - val_accuracy: 0.9630\n",
      "Epoch 234/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.0943 - val_accuracy: 0.9722\n",
      "Epoch 235/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 0.0732 - val_accuracy: 0.9815\n",
      "Epoch 236/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0548 - val_accuracy: 0.9769\n",
      "Epoch 236: early stopping\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9696\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 14ms/step - loss: 1.5067 - accuracy: 0.3445 - val_loss: 1.6172 - val_accuracy: 0.2222\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.3474 - accuracy: 0.4332 - val_loss: 1.6584 - val_accuracy: 0.2222\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2529 - accuracy: 0.5095 - val_loss: 1.5577 - val_accuracy: 0.2731\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.1703 - accuracy: 0.5931 - val_loss: 1.3218 - val_accuracy: 0.3796\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.0873 - accuracy: 0.6658 - val_loss: 1.0630 - val_accuracy: 0.6528\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.0240 - accuracy: 0.7035 - val_loss: 0.9376 - val_accuracy: 0.7546\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.9871 - accuracy: 0.7071 - val_loss: 0.8187 - val_accuracy: 0.8009\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.9050 - accuracy: 0.7478 - val_loss: 0.7639 - val_accuracy: 0.8287\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.8309 - accuracy: 0.7844 - val_loss: 0.7262 - val_accuracy: 0.8519\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7845 - accuracy: 0.7983 - val_loss: 0.6262 - val_accuracy: 0.8704\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7285 - accuracy: 0.8123 - val_loss: 0.5831 - val_accuracy: 0.8472\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.6849 - accuracy: 0.8370 - val_loss: 0.5096 - val_accuracy: 0.9167\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.6404 - accuracy: 0.8427 - val_loss: 0.4771 - val_accuracy: 0.8843\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5897 - accuracy: 0.8602 - val_loss: 0.4682 - val_accuracy: 0.9028\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5631 - accuracy: 0.8628 - val_loss: 0.3902 - val_accuracy: 0.9352\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5073 - accuracy: 0.8840 - val_loss: 0.3375 - val_accuracy: 0.9444\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4817 - accuracy: 0.8798 - val_loss: 0.3311 - val_accuracy: 0.9306\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4445 - accuracy: 0.8943 - val_loss: 0.3025 - val_accuracy: 0.9352\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4387 - accuracy: 0.8912 - val_loss: 0.2661 - val_accuracy: 0.9537\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4062 - accuracy: 0.8927 - val_loss: 0.2736 - val_accuracy: 0.9306\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3729 - accuracy: 0.9092 - val_loss: 0.2310 - val_accuracy: 0.9491\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3561 - accuracy: 0.9067 - val_loss: 0.2400 - val_accuracy: 0.9306\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3075 - accuracy: 0.9247 - val_loss: 0.2058 - val_accuracy: 0.9491\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.3068 - accuracy: 0.9237 - val_loss: 0.1895 - val_accuracy: 0.9630\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3064 - accuracy: 0.9159 - val_loss: 0.1907 - val_accuracy: 0.9537\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2677 - accuracy: 0.9330 - val_loss: 0.1797 - val_accuracy: 0.9630\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2607 - accuracy: 0.9350 - val_loss: 0.1570 - val_accuracy: 0.9630\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2454 - accuracy: 0.9381 - val_loss: 0.1757 - val_accuracy: 0.9444\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2460 - accuracy: 0.9371 - val_loss: 0.1576 - val_accuracy: 0.9583\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2175 - accuracy: 0.9458 - val_loss: 0.1533 - val_accuracy: 0.9583\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2143 - accuracy: 0.9479 - val_loss: 0.1456 - val_accuracy: 0.9630\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2039 - accuracy: 0.9464 - val_loss: 0.2213 - val_accuracy: 0.9120\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2027 - accuracy: 0.9417 - val_loss: 0.1359 - val_accuracy: 0.9722\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1844 - accuracy: 0.9515 - val_loss: 0.1600 - val_accuracy: 0.9537\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1673 - accuracy: 0.9598 - val_loss: 0.1096 - val_accuracy: 0.9769\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1716 - accuracy: 0.9567 - val_loss: 0.1287 - val_accuracy: 0.9722\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1637 - accuracy: 0.9587 - val_loss: 0.1124 - val_accuracy: 0.9630\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1711 - accuracy: 0.9458 - val_loss: 0.1679 - val_accuracy: 0.9352\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1442 - accuracy: 0.9608 - val_loss: 0.1117 - val_accuracy: 0.9722\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1456 - accuracy: 0.9670 - val_loss: 0.1596 - val_accuracy: 0.9398\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1446 - accuracy: 0.9587 - val_loss: 0.1067 - val_accuracy: 0.9769\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1258 - accuracy: 0.9696 - val_loss: 0.1223 - val_accuracy: 0.9491\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1409 - accuracy: 0.9603 - val_loss: 0.1119 - val_accuracy: 0.9583\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1561 - accuracy: 0.9536 - val_loss: 0.1160 - val_accuracy: 0.9676\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1251 - accuracy: 0.9665 - val_loss: 0.1199 - val_accuracy: 0.9630\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1337 - accuracy: 0.9613 - val_loss: 0.1049 - val_accuracy: 0.9722\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1150 - accuracy: 0.9691 - val_loss: 0.1367 - val_accuracy: 0.9583\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1044 - accuracy: 0.9727 - val_loss: 0.1077 - val_accuracy: 0.9676\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0961 - accuracy: 0.9752 - val_loss: 0.1088 - val_accuracy: 0.9769\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1212 - accuracy: 0.9660 - val_loss: 0.0972 - val_accuracy: 0.9676\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1177 - accuracy: 0.9629 - val_loss: 0.1052 - val_accuracy: 0.9722\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0953 - accuracy: 0.9701 - val_loss: 0.0961 - val_accuracy: 0.9769\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0999 - accuracy: 0.9706 - val_loss: 0.1005 - val_accuracy: 0.9676\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0911 - accuracy: 0.9752 - val_loss: 0.0884 - val_accuracy: 0.9815\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1006 - accuracy: 0.9675 - val_loss: 0.1410 - val_accuracy: 0.9537\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0774 - accuracy: 0.9773 - val_loss: 0.1115 - val_accuracy: 0.9630\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0826 - accuracy: 0.9799 - val_loss: 0.1089 - val_accuracy: 0.9630\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0722 - accuracy: 0.9814 - val_loss: 0.1107 - val_accuracy: 0.9769\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0796 - accuracy: 0.9794 - val_loss: 0.0989 - val_accuracy: 0.9769\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0731 - accuracy: 0.9778 - val_loss: 0.0935 - val_accuracy: 0.9769\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0809 - accuracy: 0.9778 - val_loss: 0.0949 - val_accuracy: 0.9769\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0848 - accuracy: 0.9701 - val_loss: 0.0881 - val_accuracy: 0.9769\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0655 - accuracy: 0.9814 - val_loss: 0.0818 - val_accuracy: 0.9815\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0747 - accuracy: 0.9814 - val_loss: 0.1179 - val_accuracy: 0.9676\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0579 - accuracy: 0.9861 - val_loss: 0.1006 - val_accuracy: 0.9722\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0469 - accuracy: 0.9902 - val_loss: 0.0834 - val_accuracy: 0.9815\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0625 - accuracy: 0.9856 - val_loss: 0.0879 - val_accuracy: 0.9815\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0714 - accuracy: 0.9783 - val_loss: 0.0825 - val_accuracy: 0.9722\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0607 - accuracy: 0.9814 - val_loss: 0.0860 - val_accuracy: 0.9769\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.1454 - val_accuracy: 0.9537\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0715 - accuracy: 0.9768 - val_loss: 0.0823 - val_accuracy: 0.9815\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0486 - accuracy: 0.9871 - val_loss: 0.1236 - val_accuracy: 0.9583\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0493 - accuracy: 0.9881 - val_loss: 0.1298 - val_accuracy: 0.9583\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0603 - accuracy: 0.9819 - val_loss: 0.1011 - val_accuracy: 0.9769\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 0.0984 - val_accuracy: 0.9722\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0530 - accuracy: 0.9876 - val_loss: 0.0998 - val_accuracy: 0.9722\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0489 - accuracy: 0.9866 - val_loss: 0.0923 - val_accuracy: 0.9769\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0471 - accuracy: 0.9881 - val_loss: 0.0684 - val_accuracy: 0.9722\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0388 - accuracy: 0.9907 - val_loss: 0.0770 - val_accuracy: 0.9815\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0448 - accuracy: 0.9902 - val_loss: 0.1095 - val_accuracy: 0.9722\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.1236 - val_accuracy: 0.9722\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 0.1071 - val_accuracy: 0.9769\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0465 - accuracy: 0.9866 - val_loss: 0.1063 - val_accuracy: 0.9676\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0420 - accuracy: 0.9876 - val_loss: 0.0753 - val_accuracy: 0.9769\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0479 - accuracy: 0.9881 - val_loss: 0.0825 - val_accuracy: 0.9769\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0392 - accuracy: 0.9892 - val_loss: 0.1219 - val_accuracy: 0.9630\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0505 - accuracy: 0.9840 - val_loss: 0.1228 - val_accuracy: 0.9722\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0412 - accuracy: 0.9897 - val_loss: 0.0904 - val_accuracy: 0.9815\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 0.0817 - val_accuracy: 0.9769\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0370 - accuracy: 0.9892 - val_loss: 0.1083 - val_accuracy: 0.9815\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0351 - accuracy: 0.9917 - val_loss: 0.1005 - val_accuracy: 0.9676\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.1220 - val_accuracy: 0.9630\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.0860 - val_accuracy: 0.9815\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0478 - accuracy: 0.9856 - val_loss: 0.1220 - val_accuracy: 0.9722\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0318 - accuracy: 0.9933 - val_loss: 0.1320 - val_accuracy: 0.9630\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0525 - accuracy: 0.9830 - val_loss: 0.0914 - val_accuracy: 0.9630\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.1194 - val_accuracy: 0.9676\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0328 - accuracy: 0.9907 - val_loss: 0.0944 - val_accuracy: 0.9815\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.0699 - val_accuracy: 0.9769\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.0928 - val_accuracy: 0.9769\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0866 - val_accuracy: 0.9815\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0289 - accuracy: 0.9917 - val_loss: 0.1184 - val_accuracy: 0.9676\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.1105 - val_accuracy: 0.9769\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0401 - accuracy: 0.9876 - val_loss: 0.2707 - val_accuracy: 0.9167\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.0884 - val_accuracy: 0.9861\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0901 - val_accuracy: 0.9861\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.2441 - val_accuracy: 0.9306\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0396 - accuracy: 0.9907 - val_loss: 0.1099 - val_accuracy: 0.9676\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0377 - accuracy: 0.9871 - val_loss: 0.0843 - val_accuracy: 0.9769\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0283 - accuracy: 0.9928 - val_loss: 0.0955 - val_accuracy: 0.9769\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0711 - val_accuracy: 0.9815\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.0885 - val_accuracy: 0.9861\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.1035 - val_accuracy: 0.9815\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0224 - accuracy: 0.9948 - val_loss: 0.1054 - val_accuracy: 0.9815\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0241 - accuracy: 0.9943 - val_loss: 0.1205 - val_accuracy: 0.9722\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.0870 - val_accuracy: 0.9769\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 0.0891 - val_accuracy: 0.9769\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 0.1005 - val_accuracy: 0.9769\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0991 - val_accuracy: 0.9722\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0253 - accuracy: 0.9948 - val_loss: 0.1682 - val_accuracy: 0.9444\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0216 - accuracy: 0.9954 - val_loss: 0.1010 - val_accuracy: 0.9815\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 0.1405 - val_accuracy: 0.9583\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0719 - val_accuracy: 0.9815\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0839 - val_accuracy: 0.9722\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.1348 - val_accuracy: 0.9676\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0329 - accuracy: 0.9892 - val_loss: 0.1041 - val_accuracy: 0.9630\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.1126 - val_accuracy: 0.9815\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0980 - val_accuracy: 0.9815\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.1300 - val_accuracy: 0.9676\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0236 - accuracy: 0.9954 - val_loss: 0.0973 - val_accuracy: 0.9722\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0879 - val_accuracy: 0.9815\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0224 - accuracy: 0.9943 - val_loss: 0.1634 - val_accuracy: 0.9583\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 0.1947 - val_accuracy: 0.9583\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0279 - accuracy: 0.9907 - val_loss: 0.0925 - val_accuracy: 0.9769\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.1191 - val_accuracy: 0.9722\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.0854 - val_accuracy: 0.9676\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0254 - accuracy: 0.9902 - val_loss: 0.0768 - val_accuracy: 0.9722\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.1308 - val_accuracy: 0.9583\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0987 - val_accuracy: 0.9769\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0378 - accuracy: 0.9902 - val_loss: 0.1559 - val_accuracy: 0.9630\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0210 - accuracy: 0.9959 - val_loss: 0.1076 - val_accuracy: 0.9722\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.1342 - val_accuracy: 0.9722\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.1025 - val_accuracy: 0.9722\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.1075 - val_accuracy: 0.9676\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.2610 - val_accuracy: 0.9352\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.1107 - val_accuracy: 0.9769\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.1963 - val_accuracy: 0.9491\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.1591 - val_accuracy: 0.9676\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.1727 - val_accuracy: 0.9537\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.1734 - val_accuracy: 0.9583\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.1884 - val_accuracy: 0.9583\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.1301 - val_accuracy: 0.9630\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.1430 - val_accuracy: 0.9583\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.1194 - val_accuracy: 0.9769\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.0930 - val_accuracy: 0.9769\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.1209 - val_accuracy: 0.9769\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.1411 - val_accuracy: 0.9722\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.1165 - val_accuracy: 0.9722\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.1233 - val_accuracy: 0.9722\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0857 - val_accuracy: 0.9815\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.1292 - val_accuracy: 0.9722\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.2139 - val_accuracy: 0.9537\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.1027 - val_accuracy: 0.9769\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.1198 - val_accuracy: 0.9769\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.1155 - val_accuracy: 0.9815\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.1342 - val_accuracy: 0.9676\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.1222 - val_accuracy: 0.9722\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.1711 - val_accuracy: 0.9583\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.1529 - val_accuracy: 0.9769\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.1213 - val_accuracy: 0.9769\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.1255 - val_accuracy: 0.9722\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.0816 - val_accuracy: 0.9722\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.1094 - val_accuracy: 0.9722\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.1116 - val_accuracy: 0.9722\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0253 - accuracy: 0.9943 - val_loss: 0.0524 - val_accuracy: 0.9907\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0790 - val_accuracy: 0.9769\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0870 - val_accuracy: 0.9815\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.1058 - val_accuracy: 0.9722\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.0942 - val_accuracy: 0.9769\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.1080 - val_accuracy: 0.9769\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1158 - val_accuracy: 0.9722\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.1674 - val_accuracy: 0.9630\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.1113 - val_accuracy: 0.9676\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.1118 - val_accuracy: 0.9722\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.1329 - val_accuracy: 0.9722\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.1333 - val_accuracy: 0.9491\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.1346 - val_accuracy: 0.9676\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0231 - accuracy: 0.9943 - val_loss: 0.1638 - val_accuracy: 0.9676\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.1576 - val_accuracy: 0.9537\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.1156 - val_accuracy: 0.9722\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 0.1366 - val_accuracy: 0.9676\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0152 - accuracy: 0.9933 - val_loss: 0.1070 - val_accuracy: 0.9815\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.1404 - val_accuracy: 0.9676\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0221 - accuracy: 0.9943 - val_loss: 0.1087 - val_accuracy: 0.9676\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.1291 - val_accuracy: 0.9676\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 0.1677 - val_accuracy: 0.9630\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0156 - accuracy: 0.9938 - val_loss: 0.0837 - val_accuracy: 0.9769\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0587 - val_accuracy: 0.9861\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.1043 - val_accuracy: 0.9815\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.1091 - val_accuracy: 0.9769\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.1231 - val_accuracy: 0.9722\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 0.1429 - val_accuracy: 0.9722\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.1696 - val_accuracy: 0.9630\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.1195 - val_accuracy: 0.9722\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1960 - val_accuracy: 0.9444\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.1530 - val_accuracy: 0.9676\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1474 - val_accuracy: 0.9676\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0164 - accuracy: 0.9938 - val_loss: 0.1364 - val_accuracy: 0.9722\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.1278 - val_accuracy: 0.9722\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.1129 - val_accuracy: 0.9769\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.1423 - val_accuracy: 0.9630\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.1003 - val_accuracy: 0.9769\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1173 - val_accuracy: 0.9769\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.2589 - val_accuracy: 0.9491\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.1321 - val_accuracy: 0.9769\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.1054 - val_accuracy: 0.9722\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.1326 - val_accuracy: 0.9769\n",
      "Epoch 219/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0975 - val_accuracy: 0.9815\n",
      "Epoch 220/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0135 - accuracy: 0.9938 - val_loss: 0.0944 - val_accuracy: 0.9861\n",
      "Epoch 221/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.1106 - val_accuracy: 0.9815\n",
      "Epoch 222/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0861 - val_accuracy: 0.9861\n",
      "Epoch 223/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.1356 - val_accuracy: 0.9676\n",
      "Epoch 224/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1113 - val_accuracy: 0.9769\n",
      "Epoch 225/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.1155 - val_accuracy: 0.9722\n",
      "Epoch 226/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.1252 - val_accuracy: 0.9769\n",
      "Epoch 227/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.1147 - val_accuracy: 0.9722\n",
      "Epoch 228/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0896 - val_accuracy: 0.9815\n",
      "Epoch 229/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0800 - val_accuracy: 0.9815\n",
      "Epoch 230/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 0.1915 - val_accuracy: 0.9676\n",
      "Epoch 231/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.1997 - val_accuracy: 0.9491\n",
      "Epoch 232/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.1556 - val_accuracy: 0.9583\n",
      "Epoch 233/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.1000 - val_accuracy: 0.9769\n",
      "Epoch 234/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0982 - val_accuracy: 0.9769\n",
      "Epoch 235/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0798 - val_accuracy: 0.9815\n",
      "Epoch 236/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0826 - val_accuracy: 0.9815\n",
      "Epoch 237/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.1191 - val_accuracy: 0.9722\n",
      "Epoch 238/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.1065 - val_accuracy: 0.9815\n",
      "Epoch 239/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1438 - val_accuracy: 0.9722\n",
      "Epoch 240/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1551 - val_accuracy: 0.9630\n",
      "Epoch 241/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0830 - val_accuracy: 0.9815\n",
      "Epoch 242/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0927 - val_accuracy: 0.9861\n",
      "Epoch 243/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.1057 - val_accuracy: 0.9769\n",
      "Epoch 244/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.1458 - val_accuracy: 0.9722\n",
      "Epoch 245/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.1980 - val_accuracy: 0.9583\n",
      "Epoch 246/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.1889 - val_accuracy: 0.9630\n",
      "Epoch 247/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.1353 - val_accuracy: 0.9722\n",
      "Epoch 248/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.1358 - val_accuracy: 0.9769\n",
      "Epoch 249/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.2812 - val_accuracy: 0.9213\n",
      "Epoch 250/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.2199 - val_accuracy: 0.9537\n",
      "Epoch 251/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.1009 - val_accuracy: 0.9769\n",
      "Epoch 252/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.1187 - val_accuracy: 0.9722\n",
      "Epoch 253/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.1345 - val_accuracy: 0.9676\n",
      "Epoch 254/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.1742 - val_accuracy: 0.9537\n",
      "Epoch 255/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1257 - val_accuracy: 0.9676\n",
      "Epoch 256/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.1097 - val_accuracy: 0.9815\n",
      "Epoch 257/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1199 - val_accuracy: 0.9676\n",
      "Epoch 258/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.1121 - val_accuracy: 0.9676\n",
      "Epoch 259/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1078 - val_accuracy: 0.9722\n",
      "Epoch 260/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.1141 - val_accuracy: 0.9769\n",
      "Epoch 261/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1224 - val_accuracy: 0.9676\n",
      "Epoch 262/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1032 - val_accuracy: 0.9815\n",
      "Epoch 263/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.2052 - val_accuracy: 0.9583\n",
      "Epoch 264/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.1258 - val_accuracy: 0.9722\n",
      "Epoch 265/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.1124 - val_accuracy: 0.9722\n",
      "Epoch 266/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.1396 - val_accuracy: 0.9676\n",
      "Epoch 267/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.1150 - val_accuracy: 0.9769\n",
      "Epoch 268/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.1855 - val_accuracy: 0.9630\n",
      "Epoch 269/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.1264 - val_accuracy: 0.9769\n",
      "Epoch 270/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1117 - val_accuracy: 0.9722\n",
      "Epoch 271/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1053 - val_accuracy: 0.9815\n",
      "Epoch 272/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0088 - accuracy: 0.9959 - val_loss: 0.1027 - val_accuracy: 0.9769\n",
      "Epoch 273/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.1280 - val_accuracy: 0.9769\n",
      "Epoch 274/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.1190 - val_accuracy: 0.9722\n",
      "Epoch 275/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.1821 - val_accuracy: 0.9630\n",
      "Epoch 275: early stopping\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9511\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 12ms/step - loss: 1.5485 - accuracy: 0.3141 - val_loss: 1.6631 - val_accuracy: 0.2222\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.4175 - accuracy: 0.3713 - val_loss: 2.0473 - val_accuracy: 0.2222\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.3362 - accuracy: 0.4110 - val_loss: 2.2128 - val_accuracy: 0.2222\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.2523 - accuracy: 0.4342 - val_loss: 1.9247 - val_accuracy: 0.2361\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.1984 - accuracy: 0.4636 - val_loss: 1.4996 - val_accuracy: 0.3472\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.1429 - accuracy: 0.5013 - val_loss: 1.1383 - val_accuracy: 0.5417\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0979 - accuracy: 0.5224 - val_loss: 1.0140 - val_accuracy: 0.6343\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0485 - accuracy: 0.5735 - val_loss: 0.9606 - val_accuracy: 0.6759\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0234 - accuracy: 0.5993 - val_loss: 0.9231 - val_accuracy: 0.6991\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.9874 - accuracy: 0.6612 - val_loss: 0.8905 - val_accuracy: 0.7130\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.9538 - accuracy: 0.6792 - val_loss: 0.8578 - val_accuracy: 0.7315\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.9397 - accuracy: 0.6978 - val_loss: 0.8303 - val_accuracy: 0.7593\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.8769 - accuracy: 0.7127 - val_loss: 0.7898 - val_accuracy: 0.7593\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8585 - accuracy: 0.7256 - val_loss: 0.7593 - val_accuracy: 0.8056\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8354 - accuracy: 0.7334 - val_loss: 0.7221 - val_accuracy: 0.8102\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7839 - accuracy: 0.7576 - val_loss: 0.6933 - val_accuracy: 0.8241\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.7711 - accuracy: 0.7571 - val_loss: 0.6577 - val_accuracy: 0.8241\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.7274 - accuracy: 0.7844 - val_loss: 0.6476 - val_accuracy: 0.7963\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7010 - accuracy: 0.7788 - val_loss: 0.6097 - val_accuracy: 0.8333\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.6719 - accuracy: 0.7963 - val_loss: 0.6089 - val_accuracy: 0.8009\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.6504 - accuracy: 0.8102 - val_loss: 0.5631 - val_accuracy: 0.8796\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.6179 - accuracy: 0.8133 - val_loss: 0.5310 - val_accuracy: 0.8843\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.5991 - accuracy: 0.8174 - val_loss: 0.5027 - val_accuracy: 0.8796\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.5905 - accuracy: 0.8216 - val_loss: 0.4967 - val_accuracy: 0.8750\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5590 - accuracy: 0.8360 - val_loss: 0.4764 - val_accuracy: 0.8981\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5253 - accuracy: 0.8623 - val_loss: 0.4393 - val_accuracy: 0.9167\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.5280 - accuracy: 0.8654 - val_loss: 0.4434 - val_accuracy: 0.8796\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.4818 - accuracy: 0.8721 - val_loss: 0.4091 - val_accuracy: 0.9167\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4685 - accuracy: 0.8809 - val_loss: 0.3751 - val_accuracy: 0.9352\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4516 - accuracy: 0.8860 - val_loss: 0.3770 - val_accuracy: 0.9398\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.4492 - accuracy: 0.8881 - val_loss: 0.3688 - val_accuracy: 0.9074\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.4044 - accuracy: 0.9097 - val_loss: 0.3894 - val_accuracy: 0.9028\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3970 - accuracy: 0.9092 - val_loss: 0.3578 - val_accuracy: 0.9074\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3795 - accuracy: 0.9211 - val_loss: 0.3119 - val_accuracy: 0.9444\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3631 - accuracy: 0.9185 - val_loss: 0.2718 - val_accuracy: 0.9398\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3406 - accuracy: 0.9293 - val_loss: 0.2716 - val_accuracy: 0.9537\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3152 - accuracy: 0.9469 - val_loss: 0.2348 - val_accuracy: 0.9537\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.3120 - accuracy: 0.9366 - val_loss: 0.3621 - val_accuracy: 0.8889\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2861 - accuracy: 0.9443 - val_loss: 0.2823 - val_accuracy: 0.9306\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2688 - accuracy: 0.9489 - val_loss: 0.2324 - val_accuracy: 0.9491\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2508 - accuracy: 0.9464 - val_loss: 0.1971 - val_accuracy: 0.9537\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2535 - accuracy: 0.9438 - val_loss: 0.1807 - val_accuracy: 0.9537\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2350 - accuracy: 0.9515 - val_loss: 0.2021 - val_accuracy: 0.9537\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2096 - accuracy: 0.9618 - val_loss: 0.1727 - val_accuracy: 0.9537\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9500 - val_loss: 0.1732 - val_accuracy: 0.9537\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1860 - accuracy: 0.9670 - val_loss: 0.1595 - val_accuracy: 0.9630\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1837 - accuracy: 0.9598 - val_loss: 0.1603 - val_accuracy: 0.9537\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1763 - accuracy: 0.9629 - val_loss: 0.1844 - val_accuracy: 0.9398\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1708 - accuracy: 0.9649 - val_loss: 0.2489 - val_accuracy: 0.9306\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1660 - accuracy: 0.9660 - val_loss: 0.1238 - val_accuracy: 0.9583\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1630 - accuracy: 0.9644 - val_loss: 0.1682 - val_accuracy: 0.9491\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1545 - accuracy: 0.9629 - val_loss: 0.1470 - val_accuracy: 0.9537\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1448 - accuracy: 0.9644 - val_loss: 0.1032 - val_accuracy: 0.9583\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1502 - accuracy: 0.9624 - val_loss: 0.1348 - val_accuracy: 0.9583\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1205 - accuracy: 0.9763 - val_loss: 0.1822 - val_accuracy: 0.9491\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1237 - accuracy: 0.9752 - val_loss: 0.2259 - val_accuracy: 0.9306\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1299 - accuracy: 0.9716 - val_loss: 0.1462 - val_accuracy: 0.9537\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1198 - accuracy: 0.9742 - val_loss: 0.1324 - val_accuracy: 0.9583\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1257 - accuracy: 0.9685 - val_loss: 0.1048 - val_accuracy: 0.9583\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0969 - accuracy: 0.9840 - val_loss: 0.0837 - val_accuracy: 0.9583\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1001 - accuracy: 0.9799 - val_loss: 0.1018 - val_accuracy: 0.9676\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0894 - accuracy: 0.9804 - val_loss: 0.1522 - val_accuracy: 0.9630\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0991 - accuracy: 0.9809 - val_loss: 0.0858 - val_accuracy: 0.9630\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0858 - accuracy: 0.9825 - val_loss: 0.1088 - val_accuracy: 0.9630\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0926 - accuracy: 0.9778 - val_loss: 0.1084 - val_accuracy: 0.9676\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0812 - accuracy: 0.9814 - val_loss: 0.1440 - val_accuracy: 0.9537\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0847 - accuracy: 0.9794 - val_loss: 0.1395 - val_accuracy: 0.9537\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0929 - accuracy: 0.9747 - val_loss: 0.1371 - val_accuracy: 0.9630\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0705 - accuracy: 0.9856 - val_loss: 0.1048 - val_accuracy: 0.9630\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0627 - accuracy: 0.9871 - val_loss: 0.1015 - val_accuracy: 0.9630\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0670 - accuracy: 0.9866 - val_loss: 0.1114 - val_accuracy: 0.9583\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0693 - accuracy: 0.9830 - val_loss: 0.0881 - val_accuracy: 0.9630\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0725 - accuracy: 0.9814 - val_loss: 0.0902 - val_accuracy: 0.9676\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.1041 - val_accuracy: 0.9630\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0746 - accuracy: 0.9845 - val_loss: 0.0822 - val_accuracy: 0.9722\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0609 - accuracy: 0.9876 - val_loss: 0.1029 - val_accuracy: 0.9630\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0646 - accuracy: 0.9850 - val_loss: 0.0815 - val_accuracy: 0.9676\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0607 - accuracy: 0.9856 - val_loss: 0.0770 - val_accuracy: 0.9630\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0636 - accuracy: 0.9830 - val_loss: 0.1100 - val_accuracy: 0.9630\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0537 - accuracy: 0.9897 - val_loss: 0.0717 - val_accuracy: 0.9722\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0551 - accuracy: 0.9881 - val_loss: 0.0829 - val_accuracy: 0.9722\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0638 - accuracy: 0.9845 - val_loss: 0.0920 - val_accuracy: 0.9630\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0532 - accuracy: 0.9861 - val_loss: 0.0863 - val_accuracy: 0.9583\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0481 - accuracy: 0.9897 - val_loss: 0.1428 - val_accuracy: 0.9583\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0485 - accuracy: 0.9887 - val_loss: 0.1944 - val_accuracy: 0.9444\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.0927 - val_accuracy: 0.9583\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0429 - accuracy: 0.9912 - val_loss: 0.0816 - val_accuracy: 0.9630\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0551 - accuracy: 0.9845 - val_loss: 0.1090 - val_accuracy: 0.9630\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 0.0894 - val_accuracy: 0.9630\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0524 - accuracy: 0.9892 - val_loss: 0.1546 - val_accuracy: 0.9491\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0394 - accuracy: 0.9938 - val_loss: 0.1189 - val_accuracy: 0.9537\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 0.1109 - val_accuracy: 0.9583\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0373 - accuracy: 0.9923 - val_loss: 0.1257 - val_accuracy: 0.9676\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0455 - accuracy: 0.9840 - val_loss: 0.1691 - val_accuracy: 0.9491\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0417 - accuracy: 0.9892 - val_loss: 0.0388 - val_accuracy: 0.9861\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0335 - accuracy: 0.9933 - val_loss: 0.1327 - val_accuracy: 0.9583\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 0.0576 - val_accuracy: 0.9769\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0464 - accuracy: 0.9871 - val_loss: 0.1409 - val_accuracy: 0.9537\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.1062 - val_accuracy: 0.9630\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0363 - accuracy: 0.9938 - val_loss: 0.0573 - val_accuracy: 0.9769\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 0.0822 - val_accuracy: 0.9676\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 0.3092 - val_accuracy: 0.9259\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.1361 - val_accuracy: 0.9630\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0883 - val_accuracy: 0.9630\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0537 - accuracy: 0.9825 - val_loss: 0.1710 - val_accuracy: 0.9537\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0335 - accuracy: 0.9907 - val_loss: 0.0616 - val_accuracy: 0.9630\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0277 - accuracy: 0.9954 - val_loss: 0.1645 - val_accuracy: 0.9537\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 0.0645 - val_accuracy: 0.9722\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0400 - accuracy: 0.9876 - val_loss: 0.0522 - val_accuracy: 0.9722\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.0468 - val_accuracy: 0.9815\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0294 - accuracy: 0.9938 - val_loss: 0.1111 - val_accuracy: 0.9630\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 0.0948 - val_accuracy: 0.9676\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.0681 - val_accuracy: 0.9769\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0348 - accuracy: 0.9907 - val_loss: 0.0860 - val_accuracy: 0.9630\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.0685 - val_accuracy: 0.9722\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 0.1305 - val_accuracy: 0.9537\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0237 - accuracy: 0.9954 - val_loss: 0.1381 - val_accuracy: 0.9583\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 0.1414 - val_accuracy: 0.9630\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.1029 - val_accuracy: 0.9583\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.1114 - val_accuracy: 0.9630\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.1876 - val_accuracy: 0.9491\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 0.0506 - val_accuracy: 0.9815\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.0981 - val_accuracy: 0.9676\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0233 - accuracy: 0.9959 - val_loss: 0.1111 - val_accuracy: 0.9630\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.1888 - val_accuracy: 0.9491\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0275 - accuracy: 0.9933 - val_loss: 0.0759 - val_accuracy: 0.9722\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0979 - val_accuracy: 0.9722\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0955 - val_accuracy: 0.9676\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0838 - val_accuracy: 0.9676\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.0524 - val_accuracy: 0.9769\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0204 - accuracy: 0.9959 - val_loss: 0.1200 - val_accuracy: 0.9630\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0241 - accuracy: 0.9943 - val_loss: 0.0964 - val_accuracy: 0.9676\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0297 - accuracy: 0.9938 - val_loss: 0.0828 - val_accuracy: 0.9722\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.1951 - val_accuracy: 0.9676\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.0798 - val_accuracy: 0.9630\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0987 - val_accuracy: 0.9583\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.1194 - val_accuracy: 0.9630\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.0781 - val_accuracy: 0.9861\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.0506 - val_accuracy: 0.9815\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0309 - accuracy: 0.9907 - val_loss: 0.3501 - val_accuracy: 0.9259\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9676\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0794 - val_accuracy: 0.9769\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 0.1132 - val_accuracy: 0.9676\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 0.0731 - val_accuracy: 0.9676\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0224 - accuracy: 0.9964 - val_loss: 0.1072 - val_accuracy: 0.9676\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0546 - val_accuracy: 0.9815\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0682 - val_accuracy: 0.9583\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.0824 - val_accuracy: 0.9630\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.0755 - val_accuracy: 0.9676\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.1478 - val_accuracy: 0.9583\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.0498 - val_accuracy: 0.9861\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.1315 - val_accuracy: 0.9630\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0915 - val_accuracy: 0.9676\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0684 - val_accuracy: 0.9722\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0730 - val_accuracy: 0.9722\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.0575 - val_accuracy: 0.9769\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.1210 - val_accuracy: 0.9630\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 0.1382 - val_accuracy: 0.9630\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.0666 - val_accuracy: 0.9769\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0892 - val_accuracy: 0.9722\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.1674 - val_accuracy: 0.9537\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.2786 - val_accuracy: 0.9537\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0776 - val_accuracy: 0.9722\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0891 - val_accuracy: 0.9722\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.1103 - val_accuracy: 0.9676\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.1013 - val_accuracy: 0.9769\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0718 - val_accuracy: 0.9722\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0255 - accuracy: 0.9907 - val_loss: 0.1349 - val_accuracy: 0.9583\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.1146 - val_accuracy: 0.9630\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0247 - accuracy: 0.9948 - val_loss: 0.0612 - val_accuracy: 0.9861\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0214 - accuracy: 0.9954 - val_loss: 0.0642 - val_accuracy: 0.9815\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.1084 - val_accuracy: 0.9722\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 0.1862 - val_accuracy: 0.9444\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.0687 - val_accuracy: 0.9722\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.0512 - val_accuracy: 0.9769\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0818 - val_accuracy: 0.9722\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.0560 - val_accuracy: 0.9769\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.0698 - val_accuracy: 0.9769\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.1605 - val_accuracy: 0.9630\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.1002 - val_accuracy: 0.9722\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0704 - val_accuracy: 0.9769\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9722\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0454 - val_accuracy: 0.9861\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.1546 - val_accuracy: 0.9676\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.0803 - val_accuracy: 0.9630\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.1235 - val_accuracy: 0.9630\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0562 - val_accuracy: 0.9630\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0908 - val_accuracy: 0.9676\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.0970 - val_accuracy: 0.9630\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9722\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.1122 - val_accuracy: 0.9630\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0659 - val_accuracy: 0.9676\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.0942 - val_accuracy: 0.9676\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1469 - val_accuracy: 0.9537\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.1170 - val_accuracy: 0.9676\n",
      "Epoch 195: early stopping\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1651 - accuracy: 0.9565\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 15ms/step - loss: 1.4511 - accuracy: 0.3749 - val_loss: 1.5872 - val_accuracy: 0.4583\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.3550 - accuracy: 0.4533 - val_loss: 1.5213 - val_accuracy: 0.5046\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.2840 - accuracy: 0.5266 - val_loss: 1.4414 - val_accuracy: 0.5185\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.2192 - accuracy: 0.5843 - val_loss: 1.3269 - val_accuracy: 0.5417\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.1700 - accuracy: 0.6013 - val_loss: 1.1792 - val_accuracy: 0.6528\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.1119 - accuracy: 0.6498 - val_loss: 1.0642 - val_accuracy: 0.6852\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0765 - accuracy: 0.6576 - val_loss: 0.9909 - val_accuracy: 0.7222\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 1.0242 - accuracy: 0.6756 - val_loss: 0.9151 - val_accuracy: 0.7685\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.9595 - accuracy: 0.6978 - val_loss: 0.8547 - val_accuracy: 0.7685\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.9121 - accuracy: 0.7076 - val_loss: 0.7939 - val_accuracy: 0.7963\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.8538 - accuracy: 0.7365 - val_loss: 0.7609 - val_accuracy: 0.7639\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.8130 - accuracy: 0.7457 - val_loss: 0.7161 - val_accuracy: 0.7824\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7783 - accuracy: 0.7483 - val_loss: 0.6409 - val_accuracy: 0.7917\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7320 - accuracy: 0.7736 - val_loss: 0.6607 - val_accuracy: 0.8009\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.7148 - accuracy: 0.7674 - val_loss: 0.5612 - val_accuracy: 0.8380\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.6620 - accuracy: 0.7911 - val_loss: 0.5174 - val_accuracy: 0.8241\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.6267 - accuracy: 0.8056 - val_loss: 0.4830 - val_accuracy: 0.8519\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5728 - accuracy: 0.8314 - val_loss: 0.4538 - val_accuracy: 0.9028\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.5361 - accuracy: 0.8638 - val_loss: 0.4140 - val_accuracy: 0.9213\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.5192 - accuracy: 0.8623 - val_loss: 0.3717 - val_accuracy: 0.9444\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4898 - accuracy: 0.8809 - val_loss: 0.3289 - val_accuracy: 0.9398\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4313 - accuracy: 0.9046 - val_loss: 0.3445 - val_accuracy: 0.9444\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.4206 - accuracy: 0.9005 - val_loss: 0.2815 - val_accuracy: 0.9491\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.3843 - accuracy: 0.9108 - val_loss: 0.2854 - val_accuracy: 0.9583\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3626 - accuracy: 0.9170 - val_loss: 0.2432 - val_accuracy: 0.9583\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.3423 - accuracy: 0.9257 - val_loss: 0.2465 - val_accuracy: 0.9630\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3240 - accuracy: 0.9232 - val_loss: 0.2108 - val_accuracy: 0.9630\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3076 - accuracy: 0.9283 - val_loss: 0.2106 - val_accuracy: 0.9630\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2982 - accuracy: 0.9355 - val_loss: 0.2111 - val_accuracy: 0.9398\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2673 - accuracy: 0.9474 - val_loss: 0.1937 - val_accuracy: 0.9583\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.2570 - accuracy: 0.9355 - val_loss: 0.1674 - val_accuracy: 0.9722\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2623 - accuracy: 0.9330 - val_loss: 0.1706 - val_accuracy: 0.9722\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2161 - accuracy: 0.9541 - val_loss: 0.1611 - val_accuracy: 0.9676\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2470 - accuracy: 0.9355 - val_loss: 0.1705 - val_accuracy: 0.9630\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2096 - accuracy: 0.9562 - val_loss: 0.1439 - val_accuracy: 0.9722\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.2055 - accuracy: 0.9541 - val_loss: 0.1396 - val_accuracy: 0.9722\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1984 - accuracy: 0.9577 - val_loss: 0.1377 - val_accuracy: 0.9769\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1956 - accuracy: 0.9577 - val_loss: 0.1177 - val_accuracy: 0.9815\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1879 - accuracy: 0.9577 - val_loss: 0.1317 - val_accuracy: 0.9676\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1741 - accuracy: 0.9598 - val_loss: 0.1290 - val_accuracy: 0.9722\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1466 - accuracy: 0.9701 - val_loss: 0.1312 - val_accuracy: 0.9491\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1632 - accuracy: 0.9587 - val_loss: 0.1206 - val_accuracy: 0.9722\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1538 - accuracy: 0.9618 - val_loss: 0.1017 - val_accuracy: 0.9815\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1421 - accuracy: 0.9696 - val_loss: 0.1075 - val_accuracy: 0.9769\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1233 - accuracy: 0.9747 - val_loss: 0.1139 - val_accuracy: 0.9676\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1358 - accuracy: 0.9675 - val_loss: 0.0940 - val_accuracy: 0.9815\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1247 - accuracy: 0.9696 - val_loss: 0.1318 - val_accuracy: 0.9537\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1513 - accuracy: 0.9644 - val_loss: 0.1090 - val_accuracy: 0.9722\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1117 - accuracy: 0.9747 - val_loss: 0.0815 - val_accuracy: 0.9815\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.1250 - accuracy: 0.9701 - val_loss: 0.0814 - val_accuracy: 0.9815\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0982 - accuracy: 0.9804 - val_loss: 0.0683 - val_accuracy: 0.9861\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1138 - accuracy: 0.9722 - val_loss: 0.1246 - val_accuracy: 0.9583\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0929 - accuracy: 0.9794 - val_loss: 0.0807 - val_accuracy: 0.9815\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0937 - accuracy: 0.9758 - val_loss: 0.1125 - val_accuracy: 0.9676\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0886 - accuracy: 0.9825 - val_loss: 0.0898 - val_accuracy: 0.9769\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0961 - accuracy: 0.9799 - val_loss: 0.0997 - val_accuracy: 0.9769\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0842 - accuracy: 0.9799 - val_loss: 0.0913 - val_accuracy: 0.9769\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0791 - accuracy: 0.9825 - val_loss: 0.0806 - val_accuracy: 0.9769\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0674 - accuracy: 0.9871 - val_loss: 0.1142 - val_accuracy: 0.9722\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0783 - accuracy: 0.9799 - val_loss: 0.0772 - val_accuracy: 0.9815\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0740 - accuracy: 0.9814 - val_loss: 0.1753 - val_accuracy: 0.9398\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0779 - accuracy: 0.9794 - val_loss: 0.1581 - val_accuracy: 0.9444\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0722 - accuracy: 0.9830 - val_loss: 0.0754 - val_accuracy: 0.9861\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0725 - accuracy: 0.9845 - val_loss: 0.0778 - val_accuracy: 0.9861\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0654 - accuracy: 0.9876 - val_loss: 0.1159 - val_accuracy: 0.9722\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0646 - accuracy: 0.9876 - val_loss: 0.1339 - val_accuracy: 0.9583\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0688 - accuracy: 0.9856 - val_loss: 0.0919 - val_accuracy: 0.9815\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0756 - accuracy: 0.9809 - val_loss: 0.0982 - val_accuracy: 0.9815\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0656 - accuracy: 0.9840 - val_loss: 0.0924 - val_accuracy: 0.9769\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0632 - accuracy: 0.9814 - val_loss: 0.1152 - val_accuracy: 0.9722\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0580 - accuracy: 0.9876 - val_loss: 0.0990 - val_accuracy: 0.9815\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.0801 - val_accuracy: 0.9861\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0601 - accuracy: 0.9845 - val_loss: 0.0801 - val_accuracy: 0.9769\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0726 - accuracy: 0.9794 - val_loss: 0.1522 - val_accuracy: 0.9630\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0598 - accuracy: 0.9825 - val_loss: 0.0856 - val_accuracy: 0.9769\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0471 - accuracy: 0.9907 - val_loss: 0.0929 - val_accuracy: 0.9769\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0527 - accuracy: 0.9850 - val_loss: 0.0959 - val_accuracy: 0.9815\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0507 - accuracy: 0.9871 - val_loss: 0.1673 - val_accuracy: 0.9352\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.1045 - val_accuracy: 0.9722\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0467 - accuracy: 0.9902 - val_loss: 0.0988 - val_accuracy: 0.9815\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0496 - accuracy: 0.9881 - val_loss: 0.0879 - val_accuracy: 0.9815\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0601 - accuracy: 0.9861 - val_loss: 0.1212 - val_accuracy: 0.9583\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.1132 - val_accuracy: 0.9769\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0498 - accuracy: 0.9892 - val_loss: 0.0864 - val_accuracy: 0.9676\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0424 - accuracy: 0.9887 - val_loss: 0.0670 - val_accuracy: 0.9861\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 0.0727 - val_accuracy: 0.9815\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0495 - accuracy: 0.9861 - val_loss: 0.1489 - val_accuracy: 0.9491\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0460 - accuracy: 0.9892 - val_loss: 0.0581 - val_accuracy: 0.9861\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0407 - accuracy: 0.9902 - val_loss: 0.0691 - val_accuracy: 0.9861\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0330 - accuracy: 0.9964 - val_loss: 0.1100 - val_accuracy: 0.9722\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0330 - accuracy: 0.9928 - val_loss: 0.1099 - val_accuracy: 0.9722\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.0701 - val_accuracy: 0.9861\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0362 - accuracy: 0.9928 - val_loss: 0.0808 - val_accuracy: 0.9815\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0362 - accuracy: 0.9917 - val_loss: 0.0897 - val_accuracy: 0.9722\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0359 - accuracy: 0.9907 - val_loss: 0.0784 - val_accuracy: 0.9815\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 0.0838 - val_accuracy: 0.9769\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.0607 - val_accuracy: 0.9815\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 0.0667 - val_accuracy: 0.9861\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.0717 - val_accuracy: 0.9815\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 0.0830 - val_accuracy: 0.9769\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.0828 - val_accuracy: 0.9815\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0336 - accuracy: 0.9933 - val_loss: 0.1033 - val_accuracy: 0.9769\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 0.0656 - val_accuracy: 0.9815\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0641 - val_accuracy: 0.9769\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.0593 - val_accuracy: 0.9815\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0419 - accuracy: 0.9902 - val_loss: 0.0987 - val_accuracy: 0.9722\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0355 - accuracy: 0.9928 - val_loss: 0.1357 - val_accuracy: 0.9676\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.0668 - val_accuracy: 0.9769\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.0797 - val_accuracy: 0.9722\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0254 - accuracy: 0.9948 - val_loss: 0.0566 - val_accuracy: 0.9861\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0279 - accuracy: 0.9948 - val_loss: 0.0604 - val_accuracy: 0.9815\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.0707 - val_accuracy: 0.9815\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0705 - val_accuracy: 0.9861\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.1087 - val_accuracy: 0.9722\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.1699 - val_accuracy: 0.9398\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0328 - accuracy: 0.9907 - val_loss: 0.1173 - val_accuracy: 0.9722\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0210 - accuracy: 0.9959 - val_loss: 0.1017 - val_accuracy: 0.9722\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0455 - accuracy: 0.9856 - val_loss: 0.1459 - val_accuracy: 0.9630\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0288 - accuracy: 0.9938 - val_loss: 0.0930 - val_accuracy: 0.9769\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.0524 - val_accuracy: 0.9815\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0193 - accuracy: 0.9964 - val_loss: 0.0592 - val_accuracy: 0.9861\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0576 - val_accuracy: 0.9861\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 0.0787 - val_accuracy: 0.9769\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0658 - val_accuracy: 0.9769\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0257 - accuracy: 0.9897 - val_loss: 0.0562 - val_accuracy: 0.9861\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 0.1160 - val_accuracy: 0.9722\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 0.0734 - val_accuracy: 0.9769\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0348 - accuracy: 0.9907 - val_loss: 0.0672 - val_accuracy: 0.9815\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.0621 - val_accuracy: 0.9815\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0320 - accuracy: 0.9943 - val_loss: 0.0850 - val_accuracy: 0.9769\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0240 - accuracy: 0.9943 - val_loss: 0.0741 - val_accuracy: 0.9769\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0666 - val_accuracy: 0.9861\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0825 - val_accuracy: 0.9722\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0899 - val_accuracy: 0.9769\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.2631 - val_accuracy: 0.9259\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.1854 - val_accuracy: 0.9537\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0180 - accuracy: 0.9959 - val_loss: 0.0659 - val_accuracy: 0.9815\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0222 - accuracy: 0.9948 - val_loss: 0.0636 - val_accuracy: 0.9815\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 14ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0671 - val_accuracy: 0.9907\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.0472 - val_accuracy: 0.9861\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.1020 - val_accuracy: 0.9676\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0606 - val_accuracy: 0.9861\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.0586 - val_accuracy: 0.9907\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.0598 - val_accuracy: 0.9907\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.1839 - val_accuracy: 0.9537\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.1370 - val_accuracy: 0.9676\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 0.0964 - val_accuracy: 0.9722\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0624 - val_accuracy: 0.9722\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0641 - val_accuracy: 0.9769\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0195 - accuracy: 0.9959 - val_loss: 0.0421 - val_accuracy: 0.9861\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.0602 - val_accuracy: 0.9722\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.1106 - val_accuracy: 0.9676\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0497 - val_accuracy: 0.9815\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0678 - val_accuracy: 0.9815\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.0641 - val_accuracy: 0.9815\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0712 - val_accuracy: 0.9815\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.0670 - val_accuracy: 0.9769\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0787 - val_accuracy: 0.9722\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 0.0607 - val_accuracy: 0.9815\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0548 - val_accuracy: 0.9815\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0557 - val_accuracy: 0.9815\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.0978 - val_accuracy: 0.9769\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 0.0683 - val_accuracy: 0.9815\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0469 - val_accuracy: 0.9861\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0437 - val_accuracy: 0.9907\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.0447 - val_accuracy: 0.9815\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.1509 - val_accuracy: 0.9583\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0552 - val_accuracy: 0.9769\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 0.0657 - val_accuracy: 0.9907\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0832 - val_accuracy: 0.9815\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.0927 - val_accuracy: 0.9815\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0876 - val_accuracy: 0.9815\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0976 - val_accuracy: 0.9815\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.0899 - val_accuracy: 0.9815\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.0838 - val_accuracy: 0.9815\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0863 - val_accuracy: 0.9815\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0868 - val_accuracy: 0.9722\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0189 - accuracy: 0.9964 - val_loss: 0.0811 - val_accuracy: 0.9722\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9815\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0224 - accuracy: 0.9917 - val_loss: 0.0723 - val_accuracy: 0.9769\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 0.0906 - val_accuracy: 0.9769\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.9917 - val_loss: 0.0610 - val_accuracy: 0.9815\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0319 - accuracy: 0.9923 - val_loss: 0.0692 - val_accuracy: 0.9861\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0720 - val_accuracy: 0.9815\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 0.0865 - val_accuracy: 0.9769\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0470 - val_accuracy: 0.9815\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.0739 - val_accuracy: 0.9722\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0834 - val_accuracy: 0.9722\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.1998 - val_accuracy: 0.9722\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0642 - val_accuracy: 0.9815\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.1391 - val_accuracy: 0.9676\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0626 - val_accuracy: 0.9722\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.0857 - val_accuracy: 0.9769\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0899 - val_accuracy: 0.9769\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0931 - val_accuracy: 0.9722\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.1103 - val_accuracy: 0.9676\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 0.0619 - val_accuracy: 0.9861\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0535 - val_accuracy: 0.9861\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0577 - val_accuracy: 0.9815\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.0910 - val_accuracy: 0.9722\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0940 - val_accuracy: 0.9815\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.0775 - val_accuracy: 0.9861\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0813 - val_accuracy: 0.9861\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0910 - val_accuracy: 0.9861\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9861\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0827 - val_accuracy: 0.9769\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.1120 - val_accuracy: 0.9676\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.0726 - val_accuracy: 0.9769\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 0.0844 - val_accuracy: 0.9676\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.0830 - val_accuracy: 0.9815\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9861\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.1625 - val_accuracy: 0.9722\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.1091 - val_accuracy: 0.9769\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1300 - val_accuracy: 0.9815\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.1667 - val_accuracy: 0.9676\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.1296 - val_accuracy: 0.9722\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.1062 - val_accuracy: 0.9861\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0762 - val_accuracy: 0.9907\n",
      "Epoch 219/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0131 - accuracy: 0.9943 - val_loss: 0.0878 - val_accuracy: 0.9769\n",
      "Epoch 220/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.2633 - val_accuracy: 0.9444\n",
      "Epoch 221/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.1085 - val_accuracy: 0.9722\n",
      "Epoch 222/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.1301 - val_accuracy: 0.9722\n",
      "Epoch 223/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.0744 - val_accuracy: 0.9907\n",
      "Epoch 224/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0958 - val_accuracy: 0.9769\n",
      "Epoch 225/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0637 - val_accuracy: 0.9861\n",
      "Epoch 226/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0134 - accuracy: 0.9948 - val_loss: 0.0667 - val_accuracy: 0.9861\n",
      "Epoch 227/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0130 - accuracy: 0.9933 - val_loss: 0.0704 - val_accuracy: 0.9815\n",
      "Epoch 228/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0823 - val_accuracy: 0.9861\n",
      "Epoch 229/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0668 - val_accuracy: 0.9815\n",
      "Epoch 230/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.0732 - val_accuracy: 0.9815\n",
      "Epoch 231/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0826 - val_accuracy: 0.9769\n",
      "Epoch 232/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.4160 - val_accuracy: 0.9074\n",
      "Epoch 233/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
      "Epoch 234/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.1199 - val_accuracy: 0.9769\n",
      "Epoch 235/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0740 - val_accuracy: 0.9861\n",
      "Epoch 236/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0877 - val_accuracy: 0.9815\n",
      "Epoch 237/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0594 - val_accuracy: 0.9861\n",
      "Epoch 238/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0599 - val_accuracy: 0.9861\n",
      "Epoch 239/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.0663 - val_accuracy: 0.9815\n",
      "Epoch 239: early stopping\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9554\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 14ms/step - loss: 1.6301 - accuracy: 0.2341 - val_loss: 1.6952 - val_accuracy: 0.1991\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.5111 - accuracy: 0.3265 - val_loss: 1.7391 - val_accuracy: 0.1574\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.4529 - accuracy: 0.3657 - val_loss: 1.7229 - val_accuracy: 0.2407\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.3853 - accuracy: 0.4507 - val_loss: 1.5837 - val_accuracy: 0.3704\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.3397 - accuracy: 0.5111 - val_loss: 1.3378 - val_accuracy: 0.4120\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2831 - accuracy: 0.5611 - val_loss: 1.2175 - val_accuracy: 0.6204\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2542 - accuracy: 0.5926 - val_loss: 1.1492 - val_accuracy: 0.7315\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2065 - accuracy: 0.6075 - val_loss: 1.0921 - val_accuracy: 0.7685\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.1672 - accuracy: 0.6421 - val_loss: 1.0410 - val_accuracy: 0.7778\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.1287 - accuracy: 0.6509 - val_loss: 1.0075 - val_accuracy: 0.7639\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0931 - accuracy: 0.6756 - val_loss: 0.9683 - val_accuracy: 0.7731\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 1.0297 - accuracy: 0.6926 - val_loss: 0.9177 - val_accuracy: 0.7824\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0053 - accuracy: 0.6906 - val_loss: 0.8849 - val_accuracy: 0.7731\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.9753 - accuracy: 0.6998 - val_loss: 0.8712 - val_accuracy: 0.7639\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.9225 - accuracy: 0.7205 - val_loss: 0.8096 - val_accuracy: 0.7778\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.8739 - accuracy: 0.7256 - val_loss: 0.7796 - val_accuracy: 0.7917\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8337 - accuracy: 0.7323 - val_loss: 0.7166 - val_accuracy: 0.7917\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8060 - accuracy: 0.7344 - val_loss: 0.7003 - val_accuracy: 0.7917\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7807 - accuracy: 0.7406 - val_loss: 0.6567 - val_accuracy: 0.7870\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7350 - accuracy: 0.7468 - val_loss: 0.6353 - val_accuracy: 0.7870\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7100 - accuracy: 0.7592 - val_loss: 0.6170 - val_accuracy: 0.7778\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.7007 - accuracy: 0.7494 - val_loss: 0.5752 - val_accuracy: 0.8056\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.6474 - accuracy: 0.7757 - val_loss: 0.5491 - val_accuracy: 0.8194\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.6358 - accuracy: 0.7762 - val_loss: 0.5246 - val_accuracy: 0.8426\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.6060 - accuracy: 0.7911 - val_loss: 0.5131 - val_accuracy: 0.8380\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5827 - accuracy: 0.8092 - val_loss: 0.5006 - val_accuracy: 0.8611\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5722 - accuracy: 0.8149 - val_loss: 0.4534 - val_accuracy: 0.8796\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5496 - accuracy: 0.8298 - val_loss: 0.4501 - val_accuracy: 0.8843\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.5380 - accuracy: 0.8530 - val_loss: 0.4285 - val_accuracy: 0.9074\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5014 - accuracy: 0.8706 - val_loss: 0.4148 - val_accuracy: 0.8796\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4992 - accuracy: 0.8747 - val_loss: 0.4095 - val_accuracy: 0.8843\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4515 - accuracy: 0.8989 - val_loss: 0.3510 - val_accuracy: 0.9074\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.4324 - accuracy: 0.9067 - val_loss: 0.3420 - val_accuracy: 0.9213\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3958 - accuracy: 0.9263 - val_loss: 0.3162 - val_accuracy: 0.9306\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.3828 - accuracy: 0.9278 - val_loss: 0.2882 - val_accuracy: 0.9444\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3685 - accuracy: 0.9288 - val_loss: 0.2863 - val_accuracy: 0.9491\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3550 - accuracy: 0.9397 - val_loss: 0.2868 - val_accuracy: 0.9352\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3204 - accuracy: 0.9412 - val_loss: 0.2386 - val_accuracy: 0.9583\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3439 - accuracy: 0.9319 - val_loss: 0.2405 - val_accuracy: 0.9676\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3071 - accuracy: 0.9469 - val_loss: 0.2623 - val_accuracy: 0.9306\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3097 - accuracy: 0.9397 - val_loss: 0.2375 - val_accuracy: 0.9583\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2869 - accuracy: 0.9438 - val_loss: 0.2215 - val_accuracy: 0.9537\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2740 - accuracy: 0.9458 - val_loss: 0.2062 - val_accuracy: 0.9583\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2456 - accuracy: 0.9510 - val_loss: 0.2068 - val_accuracy: 0.9537\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2346 - accuracy: 0.9551 - val_loss: 0.1830 - val_accuracy: 0.9676\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.2308 - accuracy: 0.9556 - val_loss: 0.1643 - val_accuracy: 0.9769\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2283 - accuracy: 0.9505 - val_loss: 0.1835 - val_accuracy: 0.9537\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2086 - accuracy: 0.9624 - val_loss: 0.2021 - val_accuracy: 0.9352\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2145 - accuracy: 0.9515 - val_loss: 0.1549 - val_accuracy: 0.9676\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2200 - accuracy: 0.9510 - val_loss: 0.1927 - val_accuracy: 0.9537\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2081 - accuracy: 0.9536 - val_loss: 0.1515 - val_accuracy: 0.9630\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2017 - accuracy: 0.9556 - val_loss: 0.1625 - val_accuracy: 0.9537\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1681 - accuracy: 0.9629 - val_loss: 0.1619 - val_accuracy: 0.9491\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1724 - accuracy: 0.9608 - val_loss: 0.1162 - val_accuracy: 0.9722\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1712 - accuracy: 0.9644 - val_loss: 0.1569 - val_accuracy: 0.9491\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1516 - accuracy: 0.9670 - val_loss: 0.1323 - val_accuracy: 0.9630\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1628 - accuracy: 0.9644 - val_loss: 0.1156 - val_accuracy: 0.9722\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1477 - accuracy: 0.9665 - val_loss: 0.1348 - val_accuracy: 0.9537\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1614 - accuracy: 0.9624 - val_loss: 0.1295 - val_accuracy: 0.9630\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1454 - accuracy: 0.9670 - val_loss: 0.1151 - val_accuracy: 0.9676\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1309 - accuracy: 0.9701 - val_loss: 0.0947 - val_accuracy: 0.9676\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1351 - accuracy: 0.9654 - val_loss: 0.1055 - val_accuracy: 0.9722\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1315 - accuracy: 0.9727 - val_loss: 0.1449 - val_accuracy: 0.9583\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1279 - accuracy: 0.9685 - val_loss: 0.1003 - val_accuracy: 0.9676\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1345 - accuracy: 0.9701 - val_loss: 0.0963 - val_accuracy: 0.9722\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1110 - accuracy: 0.9783 - val_loss: 0.0867 - val_accuracy: 0.9769\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1121 - accuracy: 0.9711 - val_loss: 0.0927 - val_accuracy: 0.9722\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1116 - accuracy: 0.9727 - val_loss: 0.1046 - val_accuracy: 0.9676\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1074 - accuracy: 0.9742 - val_loss: 0.0964 - val_accuracy: 0.9676\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1086 - accuracy: 0.9706 - val_loss: 0.1402 - val_accuracy: 0.9583\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1109 - accuracy: 0.9701 - val_loss: 0.0927 - val_accuracy: 0.9722\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1003 - accuracy: 0.9706 - val_loss: 0.0938 - val_accuracy: 0.9630\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0983 - accuracy: 0.9722 - val_loss: 0.1159 - val_accuracy: 0.9630\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0868 - accuracy: 0.9758 - val_loss: 0.0990 - val_accuracy: 0.9630\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0949 - accuracy: 0.9778 - val_loss: 0.0867 - val_accuracy: 0.9722\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0879 - accuracy: 0.9758 - val_loss: 0.0917 - val_accuracy: 0.9676\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0844 - accuracy: 0.9799 - val_loss: 0.1251 - val_accuracy: 0.9537\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0948 - accuracy: 0.9768 - val_loss: 0.0898 - val_accuracy: 0.9722\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0831 - accuracy: 0.9773 - val_loss: 0.0908 - val_accuracy: 0.9722\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0744 - accuracy: 0.9789 - val_loss: 0.0860 - val_accuracy: 0.9722\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0635 - accuracy: 0.9840 - val_loss: 0.1225 - val_accuracy: 0.9491\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0731 - accuracy: 0.9830 - val_loss: 0.1332 - val_accuracy: 0.9537\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0704 - accuracy: 0.9840 - val_loss: 0.1098 - val_accuracy: 0.9630\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0746 - accuracy: 0.9799 - val_loss: 0.0819 - val_accuracy: 0.9769\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0780 - accuracy: 0.9799 - val_loss: 0.0745 - val_accuracy: 0.9722\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0641 - accuracy: 0.9856 - val_loss: 0.0735 - val_accuracy: 0.9676\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0691 - accuracy: 0.9799 - val_loss: 0.1000 - val_accuracy: 0.9630\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0791 - accuracy: 0.9773 - val_loss: 0.0857 - val_accuracy: 0.9722\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0634 - accuracy: 0.9840 - val_loss: 0.1199 - val_accuracy: 0.9722\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0611 - accuracy: 0.9871 - val_loss: 0.0849 - val_accuracy: 0.9769\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0589 - accuracy: 0.9876 - val_loss: 0.0993 - val_accuracy: 0.9676\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0547 - accuracy: 0.9861 - val_loss: 0.0941 - val_accuracy: 0.9676\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0534 - accuracy: 0.9850 - val_loss: 0.0781 - val_accuracy: 0.9722\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0504 - accuracy: 0.9856 - val_loss: 0.0615 - val_accuracy: 0.9769\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0444 - accuracy: 0.9881 - val_loss: 0.1014 - val_accuracy: 0.9630\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0569 - accuracy: 0.9845 - val_loss: 0.1023 - val_accuracy: 0.9676\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0623 - accuracy: 0.9856 - val_loss: 0.0727 - val_accuracy: 0.9676\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0582 - accuracy: 0.9840 - val_loss: 0.0705 - val_accuracy: 0.9769\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0460 - accuracy: 0.9881 - val_loss: 0.0676 - val_accuracy: 0.9815\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0605 - accuracy: 0.9850 - val_loss: 0.1437 - val_accuracy: 0.9583\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 0.0749 - val_accuracy: 0.9722\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0407 - accuracy: 0.9917 - val_loss: 0.1251 - val_accuracy: 0.9491\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0451 - accuracy: 0.9892 - val_loss: 0.0862 - val_accuracy: 0.9722\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0505 - accuracy: 0.9866 - val_loss: 0.7439 - val_accuracy: 0.8148\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0569 - accuracy: 0.9856 - val_loss: 0.1326 - val_accuracy: 0.9491\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0630 - accuracy: 0.9830 - val_loss: 0.1034 - val_accuracy: 0.9676\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0387 - accuracy: 0.9881 - val_loss: 0.0792 - val_accuracy: 0.9722\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0370 - accuracy: 0.9917 - val_loss: 0.0909 - val_accuracy: 0.9630\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0575 - accuracy: 0.9840 - val_loss: 0.0858 - val_accuracy: 0.9815\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 0.0566 - val_accuracy: 0.9676\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.0651 - val_accuracy: 0.9769\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0455 - accuracy: 0.9881 - val_loss: 0.0529 - val_accuracy: 0.9815\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0408 - accuracy: 0.9907 - val_loss: 0.0629 - val_accuracy: 0.9815\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0394 - accuracy: 0.9897 - val_loss: 0.0627 - val_accuracy: 0.9815\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0367 - accuracy: 0.9907 - val_loss: 0.0577 - val_accuracy: 0.9861\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0314 - accuracy: 0.9917 - val_loss: 0.0556 - val_accuracy: 0.9769\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0292 - accuracy: 0.9938 - val_loss: 0.0794 - val_accuracy: 0.9630\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0344 - accuracy: 0.9917 - val_loss: 0.0805 - val_accuracy: 0.9722\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9676\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 0.0477 - val_accuracy: 0.9815\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.0699 - val_accuracy: 0.9722\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0460 - accuracy: 0.9871 - val_loss: 0.0684 - val_accuracy: 0.9676\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.1073 - val_accuracy: 0.9630\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.0544 - val_accuracy: 0.9815\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0369 - accuracy: 0.9897 - val_loss: 0.0728 - val_accuracy: 0.9722\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.0918 - val_accuracy: 0.9722\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0399 - accuracy: 0.9912 - val_loss: 0.0732 - val_accuracy: 0.9769\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 0.0509 - val_accuracy: 0.9861\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.1500 - val_accuracy: 0.9630\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0436 - accuracy: 0.9876 - val_loss: 0.0463 - val_accuracy: 0.9769\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.0463 - val_accuracy: 0.9815\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0318 - accuracy: 0.9938 - val_loss: 0.0977 - val_accuracy: 0.9676\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.0595 - val_accuracy: 0.9861\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0270 - accuracy: 0.9948 - val_loss: 0.0499 - val_accuracy: 0.9815\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0241 - accuracy: 0.9948 - val_loss: 0.0601 - val_accuracy: 0.9769\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0797 - val_accuracy: 0.9676\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0319 - accuracy: 0.9928 - val_loss: 0.1829 - val_accuracy: 0.9537\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.0377 - val_accuracy: 0.9861\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0573 - val_accuracy: 0.9815\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0543 - val_accuracy: 0.9907\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.0396 - val_accuracy: 0.9861\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0282 - accuracy: 0.9933 - val_loss: 0.0413 - val_accuracy: 0.9861\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.0622 - val_accuracy: 0.9769\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.0519 - val_accuracy: 0.9861\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0890 - val_accuracy: 0.9722\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.1247 - val_accuracy: 0.9537\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0360 - accuracy: 0.9850 - val_loss: 0.0933 - val_accuracy: 0.9722\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0545 - val_accuracy: 0.9815\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0626 - val_accuracy: 0.9815\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0584 - val_accuracy: 0.9769\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0547 - val_accuracy: 0.9815\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0555 - val_accuracy: 0.9815\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0323 - accuracy: 0.9907 - val_loss: 0.0538 - val_accuracy: 0.9907\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.1056 - val_accuracy: 0.9769\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0257 - accuracy: 0.9902 - val_loss: 0.0439 - val_accuracy: 0.9861\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.0631 - val_accuracy: 0.9815\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0526 - val_accuracy: 0.9861\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0213 - accuracy: 0.9954 - val_loss: 0.0770 - val_accuracy: 0.9676\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.0620 - val_accuracy: 0.9722\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.0470 - val_accuracy: 0.9861\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 0.0902 - val_accuracy: 0.9722\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0263 - accuracy: 0.9943 - val_loss: 0.0562 - val_accuracy: 0.9769\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.0414 - val_accuracy: 0.9907\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0507 - val_accuracy: 0.9815\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.0602 - val_accuracy: 0.9769\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0246 - accuracy: 0.9943 - val_loss: 0.0788 - val_accuracy: 0.9722\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0536 - val_accuracy: 0.9769\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.0528 - val_accuracy: 0.9907\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.0360 - val_accuracy: 0.9861\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 0.0527 - val_accuracy: 0.9815\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.0840 - val_accuracy: 0.9769\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0631 - val_accuracy: 0.9861\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0645 - val_accuracy: 0.9769\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.0446 - val_accuracy: 0.9861\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.0528 - val_accuracy: 0.9815\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0589 - val_accuracy: 0.9907\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0456 - val_accuracy: 0.9907\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.0898 - val_accuracy: 0.9769\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0794 - val_accuracy: 0.9815\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.1167 - val_accuracy: 0.9630\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0231 - accuracy: 0.9954 - val_loss: 0.0682 - val_accuracy: 0.9769\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 0.0668 - val_accuracy: 0.9815\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0446 - val_accuracy: 0.9815\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0596 - val_accuracy: 0.9676\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0601 - val_accuracy: 0.9861\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0852 - val_accuracy: 0.9815\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 0.0582 - val_accuracy: 0.9769\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0539 - val_accuracy: 0.9815\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0516 - val_accuracy: 0.9861\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0868 - val_accuracy: 0.9769\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.1048 - val_accuracy: 0.9630\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.0469 - val_accuracy: 0.9815\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0552 - val_accuracy: 0.9861\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0203 - accuracy: 0.9964 - val_loss: 0.0719 - val_accuracy: 0.9815\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0555 - val_accuracy: 0.9815\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.0669 - val_accuracy: 0.9722\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0495 - val_accuracy: 0.9815\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0559 - val_accuracy: 0.9769\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.0490 - val_accuracy: 0.9907\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.0731 - val_accuracy: 0.9769\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0924 - val_accuracy: 0.9676\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0247 - accuracy: 0.9907 - val_loss: 0.0571 - val_accuracy: 0.9907\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.0815 - val_accuracy: 0.9815\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 0.1079 - val_accuracy: 0.9583\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.0619 - val_accuracy: 0.9769\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.0559 - val_accuracy: 0.9722\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.1456 - val_accuracy: 0.9630\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0770 - val_accuracy: 0.9769\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0818 - val_accuracy: 0.9722\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.0735 - val_accuracy: 0.9769\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0777 - val_accuracy: 0.9722\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9815\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0641 - val_accuracy: 0.9769\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0606 - val_accuracy: 0.9769\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.3232 - val_accuracy: 0.9167\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0811 - val_accuracy: 0.9769\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.1150 - val_accuracy: 0.9769\n",
      "Epoch 219/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1250 - val_accuracy: 0.9676\n",
      "Epoch 220/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0981 - val_accuracy: 0.9630\n",
      "Epoch 221/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.1111 - val_accuracy: 0.9722\n",
      "Epoch 222/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.0805 - val_accuracy: 0.9769\n",
      "Epoch 223/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0740 - val_accuracy: 0.9815\n",
      "Epoch 224/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0761 - val_accuracy: 0.9769\n",
      "Epoch 225/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0795 - val_accuracy: 0.9769\n",
      "Epoch 226/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0645 - val_accuracy: 0.9769\n",
      "Epoch 227/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.1868 - val_accuracy: 0.9583\n",
      "Epoch 228/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.0903 - val_accuracy: 0.9769\n",
      "Epoch 229/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0741 - val_accuracy: 0.9861\n",
      "Epoch 230/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.1045 - val_accuracy: 0.9722\n",
      "Epoch 231/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0617 - val_accuracy: 0.9815\n",
      "Epoch 232/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0664 - val_accuracy: 0.9722\n",
      "Epoch 233/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0667 - val_accuracy: 0.9861\n",
      "Epoch 234/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.1448 - val_accuracy: 0.9630\n",
      "Epoch 235/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0959 - val_accuracy: 0.9676\n",
      "Epoch 236/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0238 - accuracy: 0.9959 - val_loss: 0.0829 - val_accuracy: 0.9769\n",
      "Epoch 237/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.1204 - val_accuracy: 0.9630\n",
      "Epoch 238/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.1142 - val_accuracy: 0.9676\n",
      "Epoch 239/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.1130 - val_accuracy: 0.9722\n",
      "Epoch 240/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.1038 - val_accuracy: 0.9630\n",
      "Epoch 240: early stopping\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1389 - accuracy: 0.9598\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "97/97 [==============================] - 2s 14ms/step - loss: 1.5877 - accuracy: 0.2212 - val_loss: 1.6386 - val_accuracy: 0.1991\n",
      "Epoch 2/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.4042 - accuracy: 0.3419 - val_loss: 1.6474 - val_accuracy: 0.1991\n",
      "Epoch 3/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.3172 - accuracy: 0.4007 - val_loss: 1.5403 - val_accuracy: 0.1991\n",
      "Epoch 4/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.2715 - accuracy: 0.4631 - val_loss: 1.4323 - val_accuracy: 0.2176\n",
      "Epoch 5/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.2200 - accuracy: 0.5183 - val_loss: 1.2730 - val_accuracy: 0.4583\n",
      "Epoch 6/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.1783 - accuracy: 0.5560 - val_loss: 1.1437 - val_accuracy: 0.6204\n",
      "Epoch 7/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 1.1347 - accuracy: 0.5931 - val_loss: 1.0579 - val_accuracy: 0.6574\n",
      "Epoch 8/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0884 - accuracy: 0.6173 - val_loss: 0.9810 - val_accuracy: 0.7176\n",
      "Epoch 9/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 1.0610 - accuracy: 0.6431 - val_loss: 0.9594 - val_accuracy: 0.7037\n",
      "Epoch 10/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 1.0350 - accuracy: 0.6380 - val_loss: 0.8984 - val_accuracy: 0.6944\n",
      "Epoch 11/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.9768 - accuracy: 0.6828 - val_loss: 0.8607 - val_accuracy: 0.7037\n",
      "Epoch 12/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.9450 - accuracy: 0.6658 - val_loss: 0.7974 - val_accuracy: 0.7130\n",
      "Epoch 13/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.8962 - accuracy: 0.6823 - val_loss: 0.7634 - val_accuracy: 0.7269\n",
      "Epoch 14/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.8494 - accuracy: 0.6895 - val_loss: 0.7221 - val_accuracy: 0.7315\n",
      "Epoch 15/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.8166 - accuracy: 0.7035 - val_loss: 0.6922 - val_accuracy: 0.7222\n",
      "Epoch 16/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.7736 - accuracy: 0.7117 - val_loss: 0.6573 - val_accuracy: 0.7361\n",
      "Epoch 17/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.7552 - accuracy: 0.7076 - val_loss: 0.6275 - val_accuracy: 0.7500\n",
      "Epoch 18/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.7214 - accuracy: 0.7112 - val_loss: 0.6133 - val_accuracy: 0.7222\n",
      "Epoch 19/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.6984 - accuracy: 0.7102 - val_loss: 0.5847 - val_accuracy: 0.7315\n",
      "Epoch 20/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.6551 - accuracy: 0.7261 - val_loss: 0.5520 - val_accuracy: 0.7454\n",
      "Epoch 21/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.6225 - accuracy: 0.7359 - val_loss: 0.5335 - val_accuracy: 0.7454\n",
      "Epoch 22/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.6027 - accuracy: 0.7365 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 23/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5786 - accuracy: 0.7473 - val_loss: 0.5484 - val_accuracy: 0.7269\n",
      "Epoch 24/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.5630 - accuracy: 0.7813 - val_loss: 0.4794 - val_accuracy: 0.7824\n",
      "Epoch 25/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5390 - accuracy: 0.7916 - val_loss: 0.4527 - val_accuracy: 0.8009\n",
      "Epoch 26/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.5227 - accuracy: 0.8288 - val_loss: 0.4415 - val_accuracy: 0.8750\n",
      "Epoch 27/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4948 - accuracy: 0.8587 - val_loss: 0.4114 - val_accuracy: 0.8843\n",
      "Epoch 28/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.4719 - accuracy: 0.8747 - val_loss: 0.3758 - val_accuracy: 0.9213\n",
      "Epoch 29/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4522 - accuracy: 0.8901 - val_loss: 0.4000 - val_accuracy: 0.8889\n",
      "Epoch 30/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.4377 - accuracy: 0.8932 - val_loss: 0.3694 - val_accuracy: 0.9213\n",
      "Epoch 31/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3965 - accuracy: 0.9195 - val_loss: 0.3455 - val_accuracy: 0.9352\n",
      "Epoch 32/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3880 - accuracy: 0.9149 - val_loss: 0.3661 - val_accuracy: 0.9213\n",
      "Epoch 33/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3695 - accuracy: 0.9206 - val_loss: 0.3258 - val_accuracy: 0.9398\n",
      "Epoch 34/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3569 - accuracy: 0.9221 - val_loss: 0.3239 - val_accuracy: 0.9352\n",
      "Epoch 35/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.3409 - accuracy: 0.9330 - val_loss: 0.3002 - val_accuracy: 0.9444\n",
      "Epoch 36/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3248 - accuracy: 0.9299 - val_loss: 0.2672 - val_accuracy: 0.9537\n",
      "Epoch 37/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3017 - accuracy: 0.9319 - val_loss: 0.2724 - val_accuracy: 0.9491\n",
      "Epoch 38/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.3069 - accuracy: 0.9263 - val_loss: 0.2463 - val_accuracy: 0.9491\n",
      "Epoch 39/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2681 - accuracy: 0.9505 - val_loss: 0.2338 - val_accuracy: 0.9491\n",
      "Epoch 40/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2723 - accuracy: 0.9495 - val_loss: 0.2290 - val_accuracy: 0.9537\n",
      "Epoch 41/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2599 - accuracy: 0.9397 - val_loss: 0.2064 - val_accuracy: 0.9491\n",
      "Epoch 42/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2629 - accuracy: 0.9386 - val_loss: 0.2190 - val_accuracy: 0.9537\n",
      "Epoch 43/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.2188 - accuracy: 0.9577 - val_loss: 0.2317 - val_accuracy: 0.9352\n",
      "Epoch 44/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2164 - accuracy: 0.9500 - val_loss: 0.2210 - val_accuracy: 0.9491\n",
      "Epoch 45/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1980 - accuracy: 0.9526 - val_loss: 0.1816 - val_accuracy: 0.9491\n",
      "Epoch 46/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1983 - accuracy: 0.9515 - val_loss: 0.1836 - val_accuracy: 0.9537\n",
      "Epoch 47/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2023 - accuracy: 0.9489 - val_loss: 0.1659 - val_accuracy: 0.9630\n",
      "Epoch 48/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1792 - accuracy: 0.9587 - val_loss: 0.1601 - val_accuracy: 0.9491\n",
      "Epoch 49/500\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.1681 - accuracy: 0.9644 - val_loss: 0.1517 - val_accuracy: 0.9630\n",
      "Epoch 50/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1557 - accuracy: 0.9582 - val_loss: 0.1447 - val_accuracy: 0.9630\n",
      "Epoch 51/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1574 - accuracy: 0.9618 - val_loss: 0.1503 - val_accuracy: 0.9583\n",
      "Epoch 52/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1442 - accuracy: 0.9660 - val_loss: 0.1398 - val_accuracy: 0.9630\n",
      "Epoch 53/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1547 - accuracy: 0.9613 - val_loss: 0.1626 - val_accuracy: 0.9491\n",
      "Epoch 54/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1446 - accuracy: 0.9618 - val_loss: 0.1527 - val_accuracy: 0.9583\n",
      "Epoch 55/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1281 - accuracy: 0.9716 - val_loss: 0.2038 - val_accuracy: 0.9398\n",
      "Epoch 56/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.1238 - accuracy: 0.9747 - val_loss: 0.1332 - val_accuracy: 0.9722\n",
      "Epoch 57/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1205 - accuracy: 0.9675 - val_loss: 0.1447 - val_accuracy: 0.9537\n",
      "Epoch 58/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1142 - accuracy: 0.9732 - val_loss: 0.1484 - val_accuracy: 0.9537\n",
      "Epoch 59/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.9752 - val_loss: 0.1547 - val_accuracy: 0.9491\n",
      "Epoch 60/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1127 - accuracy: 0.9742 - val_loss: 0.1308 - val_accuracy: 0.9537\n",
      "Epoch 61/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1157 - accuracy: 0.9680 - val_loss: 0.1442 - val_accuracy: 0.9537\n",
      "Epoch 62/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1014 - accuracy: 0.9804 - val_loss: 0.1394 - val_accuracy: 0.9537\n",
      "Epoch 63/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1021 - accuracy: 0.9727 - val_loss: 0.1448 - val_accuracy: 0.9537\n",
      "Epoch 64/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0933 - accuracy: 0.9789 - val_loss: 0.1899 - val_accuracy: 0.9259\n",
      "Epoch 65/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0962 - accuracy: 0.9783 - val_loss: 0.1378 - val_accuracy: 0.9583\n",
      "Epoch 66/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0916 - accuracy: 0.9732 - val_loss: 0.1762 - val_accuracy: 0.9537\n",
      "Epoch 67/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.1037 - accuracy: 0.9737 - val_loss: 0.1290 - val_accuracy: 0.9583\n",
      "Epoch 68/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0933 - accuracy: 0.9783 - val_loss: 0.1505 - val_accuracy: 0.9491\n",
      "Epoch 69/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0976 - accuracy: 0.9711 - val_loss: 0.1631 - val_accuracy: 0.9444\n",
      "Epoch 70/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0789 - accuracy: 0.9835 - val_loss: 0.1593 - val_accuracy: 0.9583\n",
      "Epoch 71/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0934 - accuracy: 0.9747 - val_loss: 0.1221 - val_accuracy: 0.9630\n",
      "Epoch 72/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0736 - accuracy: 0.9830 - val_loss: 0.1487 - val_accuracy: 0.9491\n",
      "Epoch 73/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0764 - accuracy: 0.9819 - val_loss: 0.2098 - val_accuracy: 0.9352\n",
      "Epoch 74/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0802 - accuracy: 0.9799 - val_loss: 0.1572 - val_accuracy: 0.9444\n",
      "Epoch 75/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0761 - accuracy: 0.9789 - val_loss: 0.1352 - val_accuracy: 0.9537\n",
      "Epoch 76/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0816 - accuracy: 0.9768 - val_loss: 0.1258 - val_accuracy: 0.9630\n",
      "Epoch 77/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0787 - accuracy: 0.9825 - val_loss: 0.1925 - val_accuracy: 0.9259\n",
      "Epoch 78/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0614 - accuracy: 0.9850 - val_loss: 0.1529 - val_accuracy: 0.9491\n",
      "Epoch 79/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0841 - accuracy: 0.9758 - val_loss: 0.1693 - val_accuracy: 0.9444\n",
      "Epoch 80/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0744 - accuracy: 0.9789 - val_loss: 0.2137 - val_accuracy: 0.9213\n",
      "Epoch 81/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0721 - accuracy: 0.9778 - val_loss: 0.1286 - val_accuracy: 0.9537\n",
      "Epoch 82/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0624 - accuracy: 0.9876 - val_loss: 0.1505 - val_accuracy: 0.9537\n",
      "Epoch 83/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0526 - accuracy: 0.9871 - val_loss: 0.1364 - val_accuracy: 0.9537\n",
      "Epoch 84/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0540 - accuracy: 0.9876 - val_loss: 0.1553 - val_accuracy: 0.9491\n",
      "Epoch 85/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0539 - accuracy: 0.9871 - val_loss: 0.1328 - val_accuracy: 0.9491\n",
      "Epoch 86/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0539 - accuracy: 0.9856 - val_loss: 0.1502 - val_accuracy: 0.9444\n",
      "Epoch 87/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0559 - accuracy: 0.9881 - val_loss: 0.1494 - val_accuracy: 0.9583\n",
      "Epoch 88/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0598 - accuracy: 0.9850 - val_loss: 0.1247 - val_accuracy: 0.9537\n",
      "Epoch 89/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0433 - accuracy: 0.9907 - val_loss: 0.1218 - val_accuracy: 0.9537\n",
      "Epoch 90/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0550 - accuracy: 0.9845 - val_loss: 0.1549 - val_accuracy: 0.9583\n",
      "Epoch 91/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0512 - accuracy: 0.9866 - val_loss: 0.1153 - val_accuracy: 0.9676\n",
      "Epoch 92/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0381 - accuracy: 0.9928 - val_loss: 0.1445 - val_accuracy: 0.9491\n",
      "Epoch 93/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0494 - accuracy: 0.9912 - val_loss: 0.1389 - val_accuracy: 0.9630\n",
      "Epoch 94/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0506 - accuracy: 0.9866 - val_loss: 0.1853 - val_accuracy: 0.9491\n",
      "Epoch 95/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0564 - accuracy: 0.9856 - val_loss: 0.0985 - val_accuracy: 0.9676\n",
      "Epoch 96/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0513 - accuracy: 0.9845 - val_loss: 0.1275 - val_accuracy: 0.9537\n",
      "Epoch 97/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0495 - accuracy: 0.9892 - val_loss: 0.1476 - val_accuracy: 0.9630\n",
      "Epoch 98/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0420 - accuracy: 0.9917 - val_loss: 0.1684 - val_accuracy: 0.9583\n",
      "Epoch 99/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0438 - accuracy: 0.9897 - val_loss: 0.1220 - val_accuracy: 0.9537\n",
      "Epoch 100/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0384 - accuracy: 0.9897 - val_loss: 0.1313 - val_accuracy: 0.9676\n",
      "Epoch 101/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0364 - accuracy: 0.9948 - val_loss: 0.1463 - val_accuracy: 0.9630\n",
      "Epoch 102/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0523 - accuracy: 0.9850 - val_loss: 0.2711 - val_accuracy: 0.9167\n",
      "Epoch 103/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0678 - accuracy: 0.9789 - val_loss: 0.1423 - val_accuracy: 0.9583\n",
      "Epoch 104/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0509 - accuracy: 0.9861 - val_loss: 0.1243 - val_accuracy: 0.9630\n",
      "Epoch 105/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.1345 - val_accuracy: 0.9491\n",
      "Epoch 106/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0397 - accuracy: 0.9907 - val_loss: 0.1717 - val_accuracy: 0.9491\n",
      "Epoch 107/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.1255 - val_accuracy: 0.9583\n",
      "Epoch 108/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0361 - accuracy: 0.9897 - val_loss: 0.1930 - val_accuracy: 0.9444\n",
      "Epoch 109/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 0.1184 - val_accuracy: 0.9630\n",
      "Epoch 110/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0558 - accuracy: 0.9814 - val_loss: 0.1959 - val_accuracy: 0.9306\n",
      "Epoch 111/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.1689 - val_accuracy: 0.9444\n",
      "Epoch 112/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0364 - accuracy: 0.9923 - val_loss: 0.1148 - val_accuracy: 0.9676\n",
      "Epoch 113/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0423 - accuracy: 0.9897 - val_loss: 0.1301 - val_accuracy: 0.9491\n",
      "Epoch 114/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.1382 - val_accuracy: 0.9583\n",
      "Epoch 115/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0325 - accuracy: 0.9954 - val_loss: 0.1400 - val_accuracy: 0.9537\n",
      "Epoch 116/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.1274 - val_accuracy: 0.9537\n",
      "Epoch 117/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.1146 - val_accuracy: 0.9583\n",
      "Epoch 118/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0363 - accuracy: 0.9897 - val_loss: 0.1265 - val_accuracy: 0.9630\n",
      "Epoch 119/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.1019 - val_accuracy: 0.9676\n",
      "Epoch 120/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0306 - accuracy: 0.9933 - val_loss: 0.1139 - val_accuracy: 0.9630\n",
      "Epoch 121/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0362 - accuracy: 0.9907 - val_loss: 0.1515 - val_accuracy: 0.9537\n",
      "Epoch 122/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 0.1173 - val_accuracy: 0.9630\n",
      "Epoch 123/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0415 - accuracy: 0.9887 - val_loss: 0.2775 - val_accuracy: 0.9213\n",
      "Epoch 124/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0316 - accuracy: 0.9943 - val_loss: 0.1067 - val_accuracy: 0.9630\n",
      "Epoch 125/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 0.1674 - val_accuracy: 0.9444\n",
      "Epoch 126/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 0.1457 - val_accuracy: 0.9583\n",
      "Epoch 127/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.1709 - val_accuracy: 0.9444\n",
      "Epoch 128/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0279 - accuracy: 0.9938 - val_loss: 0.1322 - val_accuracy: 0.9583\n",
      "Epoch 129/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.1319 - val_accuracy: 0.9630\n",
      "Epoch 130/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 0.1258 - val_accuracy: 0.9537\n",
      "Epoch 131/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.0973 - val_accuracy: 0.9630\n",
      "Epoch 132/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.1206 - val_accuracy: 0.9630\n",
      "Epoch 133/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.1076 - val_accuracy: 0.9630\n",
      "Epoch 134/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0279 - accuracy: 0.9943 - val_loss: 0.1823 - val_accuracy: 0.9491\n",
      "Epoch 135/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.1253 - val_accuracy: 0.9583\n",
      "Epoch 136/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.1387 - val_accuracy: 0.9537\n",
      "Epoch 137/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0940 - val_accuracy: 0.9676\n",
      "Epoch 138/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0278 - accuracy: 0.9892 - val_loss: 0.0962 - val_accuracy: 0.9722\n",
      "Epoch 139/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0260 - accuracy: 0.9943 - val_loss: 0.1541 - val_accuracy: 0.9583\n",
      "Epoch 140/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 0.1383 - val_accuracy: 0.9583\n",
      "Epoch 141/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0271 - accuracy: 0.9907 - val_loss: 0.1587 - val_accuracy: 0.9537\n",
      "Epoch 142/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0347 - accuracy: 0.9876 - val_loss: 0.1611 - val_accuracy: 0.9491\n",
      "Epoch 143/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9892 - val_loss: 0.1566 - val_accuracy: 0.9491\n",
      "Epoch 144/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 0.1185 - val_accuracy: 0.9630\n",
      "Epoch 145/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0315 - accuracy: 0.9892 - val_loss: 0.1818 - val_accuracy: 0.9491\n",
      "Epoch 146/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.1159 - val_accuracy: 0.9722\n",
      "Epoch 147/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.1109 - val_accuracy: 0.9815\n",
      "Epoch 148/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 0.1109 - val_accuracy: 0.9676\n",
      "Epoch 149/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.1033 - val_accuracy: 0.9630\n",
      "Epoch 150/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0224 - accuracy: 0.9959 - val_loss: 0.1228 - val_accuracy: 0.9630\n",
      "Epoch 151/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.1437 - val_accuracy: 0.9537\n",
      "Epoch 152/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.1380 - val_accuracy: 0.9537\n",
      "Epoch 153/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.1044 - val_accuracy: 0.9722\n",
      "Epoch 154/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.0828 - val_accuracy: 0.9815\n",
      "Epoch 155/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 0.0976 - val_accuracy: 0.9722\n",
      "Epoch 156/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.1570 - val_accuracy: 0.9676\n",
      "Epoch 157/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.1019 - val_accuracy: 0.9722\n",
      "Epoch 158/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.1038 - val_accuracy: 0.9769\n",
      "Epoch 159/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.1090 - val_accuracy: 0.9630\n",
      "Epoch 160/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0909 - val_accuracy: 0.9722\n",
      "Epoch 161/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.0936 - val_accuracy: 0.9676\n",
      "Epoch 162/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.1527 - val_accuracy: 0.9491\n",
      "Epoch 163/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.0912 - val_accuracy: 0.9630\n",
      "Epoch 164/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.0917 - val_accuracy: 0.9676\n",
      "Epoch 165/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 0.1167 - val_accuracy: 0.9676\n",
      "Epoch 166/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.1249 - val_accuracy: 0.9583\n",
      "Epoch 167/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.1214 - val_accuracy: 0.9537\n",
      "Epoch 168/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.1294 - val_accuracy: 0.9583\n",
      "Epoch 169/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.1096 - val_accuracy: 0.9630\n",
      "Epoch 170/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.2087 - val_accuracy: 0.9537\n",
      "Epoch 171/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.1464 - val_accuracy: 0.9630\n",
      "Epoch 172/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 0.1334 - val_accuracy: 0.9676\n",
      "Epoch 173/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.1437 - val_accuracy: 0.9583\n",
      "Epoch 174/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.1315 - val_accuracy: 0.9676\n",
      "Epoch 175/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.1098 - val_accuracy: 0.9583\n",
      "Epoch 176/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.1237 - val_accuracy: 0.9630\n",
      "Epoch 177/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.1389 - val_accuracy: 0.9676\n",
      "Epoch 178/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.1197 - val_accuracy: 0.9630\n",
      "Epoch 179/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.1227 - val_accuracy: 0.9630\n",
      "Epoch 180/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.1663 - val_accuracy: 0.9630\n",
      "Epoch 181/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0353 - accuracy: 0.9917 - val_loss: 0.2146 - val_accuracy: 0.9352\n",
      "Epoch 182/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.1624 - val_accuracy: 0.9583\n",
      "Epoch 183/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.1326 - val_accuracy: 0.9630\n",
      "Epoch 184/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0943 - val_accuracy: 0.9676\n",
      "Epoch 185/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0984 - val_accuracy: 0.9630\n",
      "Epoch 186/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0947 - val_accuracy: 0.9583\n",
      "Epoch 187/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.1057 - val_accuracy: 0.9676\n",
      "Epoch 188/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 0.1435 - val_accuracy: 0.9630\n",
      "Epoch 189/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0215 - accuracy: 0.9917 - val_loss: 0.1164 - val_accuracy: 0.9630\n",
      "Epoch 190/500\n",
      "97/97 [==============================] - 1s 13ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.0791 - val_accuracy: 0.9861\n",
      "Epoch 191/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.1237 - val_accuracy: 0.9722\n",
      "Epoch 192/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0772 - val_accuracy: 0.9769\n",
      "Epoch 193/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
      "Epoch 194/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.1383 - val_accuracy: 0.9491\n",
      "Epoch 195/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.1077 - val_accuracy: 0.9630\n",
      "Epoch 196/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.1280 - val_accuracy: 0.9537\n",
      "Epoch 197/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1013 - val_accuracy: 0.9583\n",
      "Epoch 198/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0221 - accuracy: 0.9954 - val_loss: 0.1219 - val_accuracy: 0.9537\n",
      "Epoch 199/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.0799 - val_accuracy: 0.9769\n",
      "Epoch 200/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.1267 - val_accuracy: 0.9676\n",
      "Epoch 201/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 0.1225 - val_accuracy: 0.9583\n",
      "Epoch 202/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0929 - val_accuracy: 0.9722\n",
      "Epoch 203/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0976 - val_accuracy: 0.9722\n",
      "Epoch 204/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0186 - accuracy: 0.9923 - val_loss: 0.0898 - val_accuracy: 0.9676\n",
      "Epoch 205/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.1052 - val_accuracy: 0.9630\n",
      "Epoch 206/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.1107 - val_accuracy: 0.9676\n",
      "Epoch 207/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.1152 - val_accuracy: 0.9583\n",
      "Epoch 208/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1112 - val_accuracy: 0.9630\n",
      "Epoch 209/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.1165 - val_accuracy: 0.9676\n",
      "Epoch 210/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.1159 - val_accuracy: 0.9630\n",
      "Epoch 211/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0838 - val_accuracy: 0.9722\n",
      "Epoch 212/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.1154 - val_accuracy: 0.9537\n",
      "Epoch 213/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.0888 - val_accuracy: 0.9769\n",
      "Epoch 214/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0990 - val_accuracy: 0.9630\n",
      "Epoch 215/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.1054 - val_accuracy: 0.9722\n",
      "Epoch 216/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0841 - val_accuracy: 0.9722\n",
      "Epoch 217/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.1158 - val_accuracy: 0.9630\n",
      "Epoch 218/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0865 - val_accuracy: 0.9676\n",
      "Epoch 219/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0170 - accuracy: 0.9928 - val_loss: 0.1007 - val_accuracy: 0.9676\n",
      "Epoch 220/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.0976 - val_accuracy: 0.9630\n",
      "Epoch 221/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0147 - accuracy: 0.9938 - val_loss: 0.1337 - val_accuracy: 0.9583\n",
      "Epoch 222/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.1334 - val_accuracy: 0.9676\n",
      "Epoch 223/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.1311 - val_accuracy: 0.9630\n",
      "Epoch 224/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.1551 - val_accuracy: 0.9491\n",
      "Epoch 225/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0702 - val_accuracy: 0.9769\n",
      "Epoch 226/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1544 - val_accuracy: 0.9537\n",
      "Epoch 227/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.1662 - val_accuracy: 0.9630\n",
      "Epoch 228/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0205 - accuracy: 0.9917 - val_loss: 0.0919 - val_accuracy: 0.9676\n",
      "Epoch 229/500\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.0764 - val_accuracy: 0.9676\n",
      "Epoch 230/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.1202 - val_accuracy: 0.9722\n",
      "Epoch 231/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0849 - val_accuracy: 0.9769\n",
      "Epoch 232/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.1782 - val_accuracy: 0.9630\n",
      "Epoch 233/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1006 - val_accuracy: 0.9769\n",
      "Epoch 234/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.0791 - val_accuracy: 0.9722\n",
      "Epoch 235/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0865 - val_accuracy: 0.9815\n",
      "Epoch 236/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0733 - val_accuracy: 0.9769\n",
      "Epoch 237/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0240 - accuracy: 0.9954 - val_loss: 0.1499 - val_accuracy: 0.9676\n",
      "Epoch 238/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.1063 - val_accuracy: 0.9630\n",
      "Epoch 239/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.1181 - val_accuracy: 0.9769\n",
      "Epoch 240/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1462 - val_accuracy: 0.9722\n",
      "Epoch 241/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.0958 - val_accuracy: 0.9769\n",
      "Epoch 242/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0197 - accuracy: 0.9912 - val_loss: 0.1150 - val_accuracy: 0.9769\n",
      "Epoch 243/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0917 - val_accuracy: 0.9815\n",
      "Epoch 244/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0112 - accuracy: 0.9948 - val_loss: 0.0965 - val_accuracy: 0.9630\n",
      "Epoch 245/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.2689 - val_accuracy: 0.9537\n",
      "Epoch 246/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0807 - val_accuracy: 0.9722\n",
      "Epoch 247/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0370 - accuracy: 0.9923 - val_loss: 0.0921 - val_accuracy: 0.9722\n",
      "Epoch 248/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0946 - val_accuracy: 0.9722\n",
      "Epoch 249/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.1077 - val_accuracy: 0.9676\n",
      "Epoch 250/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9943 - val_loss: 0.0980 - val_accuracy: 0.9722\n",
      "Epoch 251/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.1005 - val_accuracy: 0.9722\n",
      "Epoch 252/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0914 - val_accuracy: 0.9722\n",
      "Epoch 253/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0991 - val_accuracy: 0.9722\n",
      "Epoch 254/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.1718 - val_accuracy: 0.9537\n",
      "Epoch 255/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0941 - val_accuracy: 0.9722\n",
      "Epoch 256/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0951 - val_accuracy: 0.9722\n",
      "Epoch 257/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0663 - val_accuracy: 0.9722\n",
      "Epoch 258/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0834 - val_accuracy: 0.9769\n",
      "Epoch 259/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9769\n",
      "Epoch 260/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0821 - val_accuracy: 0.9676\n",
      "Epoch 261/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.1461 - val_accuracy: 0.9630\n",
      "Epoch 262/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.0741 - val_accuracy: 0.9769\n",
      "Epoch 263/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.0535 - val_accuracy: 0.9815\n",
      "Epoch 264/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0131 - accuracy: 0.9948 - val_loss: 0.0576 - val_accuracy: 0.9861\n",
      "Epoch 265/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0108 - accuracy: 0.9948 - val_loss: 0.0660 - val_accuracy: 0.9815\n",
      "Epoch 266/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.0826 - val_accuracy: 0.9769\n",
      "Epoch 267/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.0709 - val_accuracy: 0.9815\n",
      "Epoch 268/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.0718 - val_accuracy: 0.9861\n",
      "Epoch 269/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0680 - val_accuracy: 0.9861\n",
      "Epoch 270/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0746 - val_accuracy: 0.9815\n",
      "Epoch 271/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.1007 - val_accuracy: 0.9722\n",
      "Epoch 272/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.1000 - val_accuracy: 0.9769\n",
      "Epoch 273/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.1064 - val_accuracy: 0.9583\n",
      "Epoch 274/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9769\n",
      "Epoch 275/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0743 - val_accuracy: 0.9769\n",
      "Epoch 276/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9769\n",
      "Epoch 277/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0700 - val_accuracy: 0.9769\n",
      "Epoch 278/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0779 - val_accuracy: 0.9722\n",
      "Epoch 279/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.1634 - val_accuracy: 0.9583\n",
      "Epoch 280/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.1834 - val_accuracy: 0.9491\n",
      "Epoch 281/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1077 - val_accuracy: 0.9769\n",
      "Epoch 282/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.1156 - val_accuracy: 0.9815\n",
      "Epoch 283/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.1978 - val_accuracy: 0.9444\n",
      "Epoch 284/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.1368 - val_accuracy: 0.9630\n",
      "Epoch 285/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0842 - val_accuracy: 0.9630\n",
      "Epoch 286/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.1074 - val_accuracy: 0.9676\n",
      "Epoch 287/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9769\n",
      "Epoch 288/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0771 - val_accuracy: 0.9769\n",
      "Epoch 289/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.0947 - val_accuracy: 0.9769\n",
      "Epoch 290/500\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0844 - val_accuracy: 0.9676\n",
      "Epoch 290: early stopping\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1782 - accuracy: 0.9576\n"
     ]
    }
   ],
   "source": [
    "a=[]  # accuracy\n",
    "t=[]  # time\n",
    "checkpoint_path='hybrid1.h5'\n",
    "for i in range(10):\n",
    "    print('[INFO] Creating Hybrid CNN+MLP...')\n",
    "    mlp = create_mlp(trainAttrXnorm.shape[1], regress=False)\n",
    "    cnn = create_cnn(32, 32, 3, regress=False) \n",
    "    combinedInput = concatenate([mlp.output, cnn.output])\n",
    "    x = Dense(8, activation=\"relu\")(combinedInput)\n",
    "    x = Dense(5)(x)\n",
    "    \n",
    "    keras_callbacks   = [\n",
    "      EarlyStopping(monitor='val_accuracy', patience=100, verbose=1),\n",
    "      ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)]\n",
    "\n",
    "    model_mixed = Model(inputs=[mlp.input, cnn.input], \n",
    "                    outputs=x, \n",
    "                    name=\"Hybrid_CNN_MLP\")\n",
    "    print('[INFO] Compiling model...') \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-3 / 200) \n",
    "    model_mixed.compile(optimizer=opt, \n",
    "                        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                        metrics=['accuracy'])\n",
    "    # train the model\n",
    "    print(\"[INFO] Training model...\")\n",
    "    import timeit\n",
    "    start = timeit.default_timer()\n",
    "    history_model_mixed = model_mixed.fit(\n",
    "              x=[trainAttrXnorm, trainImagesX], y=trainY,\n",
    "              validation_data=([validAttrXnorm, validImagesX], validY), \n",
    "              batch_size = 20,\n",
    "              epochs=500,\n",
    "              callbacks=[keras_callbacks])\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    best_model_mixed = load_model(checkpoint_path)\n",
    "    test_loss, test_acc = best_model_mixed.evaluate( [testAttrXnorm, testImagesX],  testY)\n",
    "    \n",
    "    a.append(test_acc)\n",
    "    t.append(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[254.10808069999985,\n",
       " 385.52748699999984,\n",
       " 263.4961357000002,\n",
       " 161.9845591000003,\n",
       " 320.9273565000003,\n",
       " 301.79611499999965,\n",
       " 198.34180200000083,\n",
       " 303.1207585000002,\n",
       " 278.5458414000004,\n",
       " 321.1469054999998]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.968478262424469,\n",
       " 0.9510869383811951,\n",
       " 0.945652186870575,\n",
       " 0.960869550704956,\n",
       " 0.969565212726593,\n",
       " 0.9510869383811951,\n",
       " 0.95652174949646,\n",
       " 0.9554347991943359,\n",
       " 0.959782600402832,\n",
       " 0.957608699798584]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278.89950414000015"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_1=np.mean(t) # average time\n",
    "t1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576086938381195"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_1=np.mean(a) # average accuracy\n",
    "a1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results (for last run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YpIvmP9zCT0-",
    "outputId": "a15c136a-475f-4882-bd93-d400cb5e06ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 0.1782 - accuracy: 0.9576 - 390ms/epoch - 13ms/step\n",
      "29/29 [==============================] - 0s 8ms/step\n",
      "CONFUSION MATRIX\n",
      " [[184   0   0   0   0]\n",
      " [  0 180   0   1   3]\n",
      " [  0   0 182   1   1]\n",
      " [  0   9   9 166   0]\n",
      " [  0   3   4   8 169]] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00       184\n",
      "       Inner       0.94      0.98      0.96       184\n",
      "       Outer       0.93      0.99      0.96       184\n",
      "        Ball       0.94      0.90      0.92       184\n",
      "        Comb       0.98      0.92      0.95       184\n",
      "\n",
      "    accuracy                           0.96       920\n",
      "   macro avg       0.96      0.96      0.96       920\n",
      "weighted avg       0.96      0.96      0.96       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "best_model_mixed = load_model(checkpoint_path)\n",
    "\n",
    "\n",
    "results(history_model_mixed, \n",
    "        best_model_mixed, \n",
    "        [testAttrXnorm, testImagesX], \n",
    "        testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 2s 31ms/step - loss: 1.8962 - accuracy: 0.0667 - val_loss: 1.6371 - val_accuracy: 0.0746\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.7100 - accuracy: 0.1000 - val_loss: 1.6741 - val_accuracy: 0.0746\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.6670 - accuracy: 0.0870 - val_loss: 1.6782 - val_accuracy: 0.0746\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.6450 - accuracy: 0.0907 - val_loss: 1.6917 - val_accuracy: 0.0746\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.6171 - accuracy: 0.1093 - val_loss: 1.6903 - val_accuracy: 0.0896\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.5818 - accuracy: 0.1444 - val_loss: 1.6706 - val_accuracy: 0.0896\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.5595 - accuracy: 0.2167 - val_loss: 1.6837 - val_accuracy: 0.0896\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.5512 - accuracy: 0.2796 - val_loss: 1.6805 - val_accuracy: 0.0597\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.5105 - accuracy: 0.3907 - val_loss: 1.6809 - val_accuracy: 0.0597\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.5035 - accuracy: 0.3944 - val_loss: 1.6777 - val_accuracy: 0.0746\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.4792 - accuracy: 0.4833 - val_loss: 1.6732 - val_accuracy: 0.0448\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.4872 - accuracy: 0.4944 - val_loss: 1.6648 - val_accuracy: 0.0746\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.4243 - accuracy: 0.5611 - val_loss: 1.5934 - val_accuracy: 0.4030\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.4113 - accuracy: 0.5463 - val_loss: 1.5440 - val_accuracy: 0.6269\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3884 - accuracy: 0.6037 - val_loss: 1.4950 - val_accuracy: 0.7313\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.3511 - accuracy: 0.6389 - val_loss: 1.4446 - val_accuracy: 0.7313\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3245 - accuracy: 0.6574 - val_loss: 1.4073 - val_accuracy: 0.7612\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.2965 - accuracy: 0.6889 - val_loss: 1.3731 - val_accuracy: 0.7612\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.2680 - accuracy: 0.6796 - val_loss: 1.3031 - val_accuracy: 0.7612\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.2266 - accuracy: 0.7370 - val_loss: 1.2712 - val_accuracy: 0.7910\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.1967 - accuracy: 0.7556 - val_loss: 1.2018 - val_accuracy: 0.7910\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.1604 - accuracy: 0.7574 - val_loss: 1.1468 - val_accuracy: 0.8060\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.1136 - accuracy: 0.7630 - val_loss: 1.0981 - val_accuracy: 0.8060\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.0663 - accuracy: 0.7870 - val_loss: 1.0566 - val_accuracy: 0.7910\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.0151 - accuracy: 0.7889 - val_loss: 1.0157 - val_accuracy: 0.8060\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.9928 - accuracy: 0.8056 - val_loss: 0.9688 - val_accuracy: 0.8060\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.9551 - accuracy: 0.7981 - val_loss: 0.9415 - val_accuracy: 0.8209\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.9185 - accuracy: 0.8019 - val_loss: 0.9129 - val_accuracy: 0.8358\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.8858 - accuracy: 0.8204 - val_loss: 0.8838 - val_accuracy: 0.8358\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.8450 - accuracy: 0.8093 - val_loss: 0.8742 - val_accuracy: 0.8060\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.8380 - accuracy: 0.8056 - val_loss: 0.8817 - val_accuracy: 0.8060\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.8134 - accuracy: 0.8056 - val_loss: 0.9096 - val_accuracy: 0.8209\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7538 - accuracy: 0.8148 - val_loss: 1.0434 - val_accuracy: 0.7910\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7423 - accuracy: 0.7870 - val_loss: 1.0093 - val_accuracy: 0.8060\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7291 - accuracy: 0.8222 - val_loss: 1.0725 - val_accuracy: 0.7910\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7205 - accuracy: 0.7852 - val_loss: 1.0734 - val_accuracy: 0.8060\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7056 - accuracy: 0.8148 - val_loss: 0.9814 - val_accuracy: 0.8209\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.7012 - accuracy: 0.8111 - val_loss: 0.7261 - val_accuracy: 0.8209\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7062 - accuracy: 0.8241 - val_loss: 0.6235 - val_accuracy: 0.8209\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6333 - accuracy: 0.8278 - val_loss: 0.6268 - val_accuracy: 0.8209\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6296 - accuracy: 0.8204 - val_loss: 0.6272 - val_accuracy: 0.8358\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6048 - accuracy: 0.8296 - val_loss: 0.6581 - val_accuracy: 0.8358\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5891 - accuracy: 0.8315 - val_loss: 0.6431 - val_accuracy: 0.8358\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6009 - accuracy: 0.8130 - val_loss: 0.5954 - val_accuracy: 0.8209\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5766 - accuracy: 0.8389 - val_loss: 0.6249 - val_accuracy: 0.8209\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5730 - accuracy: 0.8130 - val_loss: 0.6704 - val_accuracy: 0.8358\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.5313 - accuracy: 0.8463 - val_loss: 0.6173 - val_accuracy: 0.8507\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5391 - accuracy: 0.8463 - val_loss: 0.6581 - val_accuracy: 0.8507\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5444 - accuracy: 0.8352 - val_loss: 0.6714 - val_accuracy: 0.8657\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5431 - accuracy: 0.8259 - val_loss: 0.6686 - val_accuracy: 0.8657\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5583 - accuracy: 0.8296 - val_loss: 0.7593 - val_accuracy: 0.8358\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5398 - accuracy: 0.8370 - val_loss: 0.6499 - val_accuracy: 0.8358\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5086 - accuracy: 0.8500 - val_loss: 0.6365 - val_accuracy: 0.8358\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5026 - accuracy: 0.8241 - val_loss: 0.5775 - val_accuracy: 0.8358\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.5207 - accuracy: 0.8500 - val_loss: 0.5449 - val_accuracy: 0.8507\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4862 - accuracy: 0.8611 - val_loss: 0.4484 - val_accuracy: 0.8507\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5035 - accuracy: 0.8519 - val_loss: 0.4638 - val_accuracy: 0.8657\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4872 - accuracy: 0.8407 - val_loss: 0.7022 - val_accuracy: 0.8209\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5061 - accuracy: 0.8463 - val_loss: 0.6823 - val_accuracy: 0.8209\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4929 - accuracy: 0.8370 - val_loss: 0.7345 - val_accuracy: 0.8209\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4774 - accuracy: 0.8352 - val_loss: 0.7924 - val_accuracy: 0.8209\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4598 - accuracy: 0.8574 - val_loss: 0.8010 - val_accuracy: 0.8657\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4839 - accuracy: 0.8519 - val_loss: 0.7586 - val_accuracy: 0.8358\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4658 - accuracy: 0.8481 - val_loss: 0.6624 - val_accuracy: 0.8209\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4589 - accuracy: 0.8852 - val_loss: 0.6512 - val_accuracy: 0.8358\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4640 - accuracy: 0.8630 - val_loss: 0.5968 - val_accuracy: 0.8657\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4342 - accuracy: 0.8593 - val_loss: 0.6056 - val_accuracy: 0.8657\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4384 - accuracy: 0.8704 - val_loss: 0.6147 - val_accuracy: 0.8657\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4106 - accuracy: 0.8944 - val_loss: 0.6274 - val_accuracy: 0.8657\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4210 - accuracy: 0.8833 - val_loss: 0.6533 - val_accuracy: 0.8657\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4160 - accuracy: 0.8852 - val_loss: 0.5999 - val_accuracy: 0.8657\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4230 - accuracy: 0.8667 - val_loss: 0.6179 - val_accuracy: 0.8806\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.4059 - accuracy: 0.8815 - val_loss: 0.6003 - val_accuracy: 0.8507\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4001 - accuracy: 0.8796 - val_loss: 0.5273 - val_accuracy: 0.8657\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4148 - accuracy: 0.8870 - val_loss: 0.4355 - val_accuracy: 0.8507\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3986 - accuracy: 0.8611 - val_loss: 0.5189 - val_accuracy: 0.8657\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4006 - accuracy: 0.8815 - val_loss: 0.5123 - val_accuracy: 0.8507\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3816 - accuracy: 0.8852 - val_loss: 0.3829 - val_accuracy: 0.8657\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3937 - accuracy: 0.8704 - val_loss: 0.4325 - val_accuracy: 0.8657\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3693 - accuracy: 0.8852 - val_loss: 0.4647 - val_accuracy: 0.8806\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4193 - accuracy: 0.8963 - val_loss: 0.5408 - val_accuracy: 0.8358\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3533 - accuracy: 0.9019 - val_loss: 0.5911 - val_accuracy: 0.8507\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3516 - accuracy: 0.8944 - val_loss: 0.6272 - val_accuracy: 0.8657\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3919 - accuracy: 0.8889 - val_loss: 0.6512 - val_accuracy: 0.8507\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3643 - accuracy: 0.9019 - val_loss: 0.6272 - val_accuracy: 0.8507\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3536 - accuracy: 0.9019 - val_loss: 0.5706 - val_accuracy: 0.8507\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.3461 - accuracy: 0.9000 - val_loss: 0.5915 - val_accuracy: 0.8955\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3625 - accuracy: 0.9019 - val_loss: 0.6143 - val_accuracy: 0.8657\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3394 - accuracy: 0.8963 - val_loss: 0.6394 - val_accuracy: 0.8657\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3426 - accuracy: 0.8944 - val_loss: 0.5726 - val_accuracy: 0.8657\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3301 - accuracy: 0.9093 - val_loss: 0.4801 - val_accuracy: 0.8806\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3372 - accuracy: 0.9019 - val_loss: 0.5026 - val_accuracy: 0.8806\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3279 - accuracy: 0.9296 - val_loss: 0.5027 - val_accuracy: 0.8806\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3450 - accuracy: 0.9074 - val_loss: 0.5305 - val_accuracy: 0.8955\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3426 - accuracy: 0.9111 - val_loss: 0.6052 - val_accuracy: 0.8955\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3285 - accuracy: 0.9074 - val_loss: 0.5026 - val_accuracy: 0.8657\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3596 - accuracy: 0.9056 - val_loss: 0.4936 - val_accuracy: 0.8806\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3214 - accuracy: 0.9167 - val_loss: 0.5879 - val_accuracy: 0.8955\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3392 - accuracy: 0.9074 - val_loss: 0.3784 - val_accuracy: 0.8806\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.3515 - accuracy: 0.9130 - val_loss: 0.3483 - val_accuracy: 0.9104\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3347 - accuracy: 0.9000 - val_loss: 0.3819 - val_accuracy: 0.8507\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3094 - accuracy: 0.9130 - val_loss: 0.3685 - val_accuracy: 0.8806\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2977 - accuracy: 0.9241 - val_loss: 0.3589 - val_accuracy: 0.8507\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3353 - accuracy: 0.9185 - val_loss: 0.3403 - val_accuracy: 0.8806\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3040 - accuracy: 0.9296 - val_loss: 0.3405 - val_accuracy: 0.8955\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2924 - accuracy: 0.9352 - val_loss: 0.3500 - val_accuracy: 0.8806\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2873 - accuracy: 0.9204 - val_loss: 0.3614 - val_accuracy: 0.8657\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2711 - accuracy: 0.9259 - val_loss: 0.3386 - val_accuracy: 0.9104\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2982 - accuracy: 0.9037 - val_loss: 0.3113 - val_accuracy: 0.9104\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3139 - accuracy: 0.9037 - val_loss: 0.3181 - val_accuracy: 0.9254\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2774 - accuracy: 0.9352 - val_loss: 0.3907 - val_accuracy: 0.8955\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3040 - accuracy: 0.9093 - val_loss: 0.3793 - val_accuracy: 0.8955\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2673 - accuracy: 0.9315 - val_loss: 0.3325 - val_accuracy: 0.9104\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2779 - accuracy: 0.9333 - val_loss: 0.3557 - val_accuracy: 0.8955\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2731 - accuracy: 0.9426 - val_loss: 0.3532 - val_accuracy: 0.8955\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2666 - accuracy: 0.9333 - val_loss: 0.3780 - val_accuracy: 0.8955\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2822 - accuracy: 0.9185 - val_loss: 0.3047 - val_accuracy: 0.9254\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2763 - accuracy: 0.9389 - val_loss: 0.3103 - val_accuracy: 0.9254\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2596 - accuracy: 0.9426 - val_loss: 0.2999 - val_accuracy: 0.9104\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2570 - accuracy: 0.9500 - val_loss: 0.3041 - val_accuracy: 0.9104\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2786 - accuracy: 0.9259 - val_loss: 0.3197 - val_accuracy: 0.9254\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2660 - accuracy: 0.9389 - val_loss: 0.3403 - val_accuracy: 0.9104\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2553 - accuracy: 0.9315 - val_loss: 0.3352 - val_accuracy: 0.9254\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2631 - accuracy: 0.9370 - val_loss: 0.3349 - val_accuracy: 0.9254\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2465 - accuracy: 0.9389 - val_loss: 0.3565 - val_accuracy: 0.8955\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2677 - accuracy: 0.9426 - val_loss: 0.4454 - val_accuracy: 0.8806\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2733 - accuracy: 0.9389 - val_loss: 0.4302 - val_accuracy: 0.8955\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2878 - accuracy: 0.9259 - val_loss: 0.4257 - val_accuracy: 0.8955\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2848 - accuracy: 0.9278 - val_loss: 0.3945 - val_accuracy: 0.8955\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2518 - accuracy: 0.9370 - val_loss: 0.3534 - val_accuracy: 0.8955\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2372 - accuracy: 0.9519 - val_loss: 0.3285 - val_accuracy: 0.9104\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2620 - accuracy: 0.9426 - val_loss: 0.3292 - val_accuracy: 0.9104\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2454 - accuracy: 0.9500 - val_loss: 0.3245 - val_accuracy: 0.9104\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2456 - accuracy: 0.9463 - val_loss: 0.3294 - val_accuracy: 0.9104\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2422 - accuracy: 0.9444 - val_loss: 0.3140 - val_accuracy: 0.9254\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2507 - accuracy: 0.9463 - val_loss: 0.3269 - val_accuracy: 0.9104\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2300 - accuracy: 0.9500 - val_loss: 0.3333 - val_accuracy: 0.9254\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2370 - accuracy: 0.9444 - val_loss: 0.2835 - val_accuracy: 0.9104\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2250 - accuracy: 0.9407 - val_loss: 0.2911 - val_accuracy: 0.9254\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2454 - accuracy: 0.9315 - val_loss: 0.2934 - val_accuracy: 0.9254\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2246 - accuracy: 0.9426 - val_loss: 0.3037 - val_accuracy: 0.9254\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2006 - accuracy: 0.9574 - val_loss: 0.2973 - val_accuracy: 0.9254\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2274 - accuracy: 0.9556 - val_loss: 0.3018 - val_accuracy: 0.9254\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2120 - accuracy: 0.9519 - val_loss: 0.2994 - val_accuracy: 0.9254\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2178 - accuracy: 0.9574 - val_loss: 0.3506 - val_accuracy: 0.9104\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2238 - accuracy: 0.9500 - val_loss: 0.3166 - val_accuracy: 0.9254\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2364 - accuracy: 0.9407 - val_loss: 0.3481 - val_accuracy: 0.8955\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2099 - accuracy: 0.9593 - val_loss: 0.3479 - val_accuracy: 0.9104\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2341 - accuracy: 0.9426 - val_loss: 0.3048 - val_accuracy: 0.9254\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2297 - accuracy: 0.9463 - val_loss: 0.2914 - val_accuracy: 0.9254\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1990 - accuracy: 0.9426 - val_loss: 0.3888 - val_accuracy: 0.9104\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2315 - accuracy: 0.9426 - val_loss: 0.2892 - val_accuracy: 0.8955\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2102 - accuracy: 0.9426 - val_loss: 0.3428 - val_accuracy: 0.8955\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1791 - accuracy: 0.9574 - val_loss: 0.3669 - val_accuracy: 0.8955\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2028 - accuracy: 0.9593 - val_loss: 0.3986 - val_accuracy: 0.8955\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1709 - accuracy: 0.9648 - val_loss: 0.3714 - val_accuracy: 0.9104\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2185 - accuracy: 0.9426 - val_loss: 0.4205 - val_accuracy: 0.8955\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2028 - accuracy: 0.9593 - val_loss: 0.3478 - val_accuracy: 0.9104\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1967 - accuracy: 0.9630 - val_loss: 0.3197 - val_accuracy: 0.9104\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1884 - accuracy: 0.9593 - val_loss: 0.3279 - val_accuracy: 0.9104\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2034 - accuracy: 0.9481 - val_loss: 0.3482 - val_accuracy: 0.8955\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1891 - accuracy: 0.9481 - val_loss: 0.3143 - val_accuracy: 0.9254\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2095 - accuracy: 0.9500 - val_loss: 0.2962 - val_accuracy: 0.9254\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1748 - accuracy: 0.9630 - val_loss: 0.3598 - val_accuracy: 0.8955\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1768 - accuracy: 0.9704 - val_loss: 0.3258 - val_accuracy: 0.8955\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2282 - accuracy: 0.9315 - val_loss: 0.2909 - val_accuracy: 0.8955\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2295 - accuracy: 0.9519 - val_loss: 0.2958 - val_accuracy: 0.9104\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2192 - accuracy: 0.9481 - val_loss: 0.3999 - val_accuracy: 0.8806\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2112 - accuracy: 0.9389 - val_loss: 0.3072 - val_accuracy: 0.9104\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1723 - accuracy: 0.9704 - val_loss: 0.3571 - val_accuracy: 0.8806\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1697 - accuracy: 0.9611 - val_loss: 0.3413 - val_accuracy: 0.8955\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1797 - accuracy: 0.9630 - val_loss: 0.3102 - val_accuracy: 0.8955\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2167 - accuracy: 0.9444 - val_loss: 0.4368 - val_accuracy: 0.8209\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2168 - accuracy: 0.9444 - val_loss: 0.2886 - val_accuracy: 0.8955\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1581 - accuracy: 0.9704 - val_loss: 0.2596 - val_accuracy: 0.9254\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1490 - accuracy: 0.9722 - val_loss: 0.2687 - val_accuracy: 0.9104\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1771 - accuracy: 0.9722 - val_loss: 0.3942 - val_accuracy: 0.8955\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1932 - accuracy: 0.9685 - val_loss: 0.3366 - val_accuracy: 0.8955\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1618 - accuracy: 0.9611 - val_loss: 0.2665 - val_accuracy: 0.9104\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1659 - accuracy: 0.9667 - val_loss: 0.3636 - val_accuracy: 0.8657\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1916 - accuracy: 0.9537 - val_loss: 0.3487 - val_accuracy: 0.8657\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1952 - accuracy: 0.9481 - val_loss: 0.2945 - val_accuracy: 0.9104\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1845 - accuracy: 0.9574 - val_loss: 0.2777 - val_accuracy: 0.9104\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1615 - accuracy: 0.9611 - val_loss: 0.3010 - val_accuracy: 0.9104\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1503 - accuracy: 0.9704 - val_loss: 0.3164 - val_accuracy: 0.9104\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1440 - accuracy: 0.9648 - val_loss: 0.3436 - val_accuracy: 0.9104\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1916 - accuracy: 0.9556 - val_loss: 0.3209 - val_accuracy: 0.9104\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1524 - accuracy: 0.9611 - val_loss: 0.3005 - val_accuracy: 0.9104\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1281 - accuracy: 0.9796 - val_loss: 0.3140 - val_accuracy: 0.9104\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1545 - accuracy: 0.9704 - val_loss: 0.3026 - val_accuracy: 0.9104\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1339 - accuracy: 0.9796 - val_loss: 0.3670 - val_accuracy: 0.8806\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1429 - accuracy: 0.9759 - val_loss: 0.3544 - val_accuracy: 0.9104\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1532 - accuracy: 0.9648 - val_loss: 0.3427 - val_accuracy: 0.9104\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1595 - accuracy: 0.9611 - val_loss: 0.4382 - val_accuracy: 0.8657\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1747 - accuracy: 0.9574 - val_loss: 0.3563 - val_accuracy: 0.8955\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1498 - accuracy: 0.9759 - val_loss: 0.4297 - val_accuracy: 0.8806\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1391 - accuracy: 0.9759 - val_loss: 0.3581 - val_accuracy: 0.8955\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1682 - accuracy: 0.9648 - val_loss: 0.3049 - val_accuracy: 0.9104\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1414 - accuracy: 0.9759 - val_loss: 0.2895 - val_accuracy: 0.9104\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1617 - accuracy: 0.9630 - val_loss: 0.2991 - val_accuracy: 0.9104\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1766 - accuracy: 0.9648 - val_loss: 0.3523 - val_accuracy: 0.8955\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1674 - accuracy: 0.9611 - val_loss: 0.3579 - val_accuracy: 0.8955\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1506 - accuracy: 0.9685 - val_loss: 0.3196 - val_accuracy: 0.9104\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1346 - accuracy: 0.9722 - val_loss: 0.2845 - val_accuracy: 0.9254\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1437 - accuracy: 0.9704 - val_loss: 0.2734 - val_accuracy: 0.9254\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1409 - accuracy: 0.9704 - val_loss: 0.2848 - val_accuracy: 0.9254\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1215 - accuracy: 0.9778 - val_loss: 0.2871 - val_accuracy: 0.9254\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1348 - accuracy: 0.9759 - val_loss: 0.2907 - val_accuracy: 0.9254\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1226 - accuracy: 0.9704 - val_loss: 0.3336 - val_accuracy: 0.9254\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1323 - accuracy: 0.9722 - val_loss: 0.3280 - val_accuracy: 0.9254\n",
      "Epoch 210: early stopping\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7313 - accuracy: 0.7783\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.4799 - accuracy: 0.4722 - val_loss: 1.5467 - val_accuracy: 0.7164\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.2801 - accuracy: 0.6259 - val_loss: 1.4838 - val_accuracy: 0.7164\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.1985 - accuracy: 0.6667 - val_loss: 1.4341 - val_accuracy: 0.7164\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 1.1169 - accuracy: 0.6907 - val_loss: 1.4011 - val_accuracy: 0.7164\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.0492 - accuracy: 0.6944 - val_loss: 1.3801 - val_accuracy: 0.7164\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.9709 - accuracy: 0.6981 - val_loss: 1.3646 - val_accuracy: 0.7164\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.9388 - accuracy: 0.7185 - val_loss: 1.3557 - val_accuracy: 0.7164\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.9087 - accuracy: 0.7093 - val_loss: 1.3579 - val_accuracy: 0.7164\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8839 - accuracy: 0.7315 - val_loss: 1.3564 - val_accuracy: 0.7164\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8454 - accuracy: 0.7315 - val_loss: 1.3610 - val_accuracy: 0.7164\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.8481 - accuracy: 0.7222 - val_loss: 1.3811 - val_accuracy: 0.7164\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8015 - accuracy: 0.7315 - val_loss: 1.3689 - val_accuracy: 0.7164\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7888 - accuracy: 0.7333 - val_loss: 1.3276 - val_accuracy: 0.7164\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.7716 - accuracy: 0.7259 - val_loss: 1.2520 - val_accuracy: 0.7164\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.7446 - accuracy: 0.7426 - val_loss: 1.1394 - val_accuracy: 0.7164\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7421 - accuracy: 0.7278 - val_loss: 1.0199 - val_accuracy: 0.7164\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.7161 - accuracy: 0.7333 - val_loss: 0.9064 - val_accuracy: 0.7164\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6818 - accuracy: 0.7389 - val_loss: 0.8086 - val_accuracy: 0.7164\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6638 - accuracy: 0.7444 - val_loss: 0.7354 - val_accuracy: 0.7164\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6593 - accuracy: 0.7444 - val_loss: 0.6976 - val_accuracy: 0.7164\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6396 - accuracy: 0.7389 - val_loss: 0.6368 - val_accuracy: 0.7164\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.6540 - accuracy: 0.7426 - val_loss: 0.5875 - val_accuracy: 0.7313\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6274 - accuracy: 0.7481 - val_loss: 0.5604 - val_accuracy: 0.7164\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.6128 - accuracy: 0.7463 - val_loss: 0.5416 - val_accuracy: 0.7164\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6035 - accuracy: 0.7444 - val_loss: 0.5332 - val_accuracy: 0.7164\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5994 - accuracy: 0.7574 - val_loss: 0.5211 - val_accuracy: 0.7164\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5845 - accuracy: 0.7556 - val_loss: 0.5111 - val_accuracy: 0.7463\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5872 - accuracy: 0.7519 - val_loss: 0.5025 - val_accuracy: 0.7463\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5884 - accuracy: 0.7537 - val_loss: 0.4934 - val_accuracy: 0.7313\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5608 - accuracy: 0.7704 - val_loss: 0.4869 - val_accuracy: 0.7313\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5556 - accuracy: 0.7630 - val_loss: 0.4943 - val_accuracy: 0.7313\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5334 - accuracy: 0.7704 - val_loss: 0.5009 - val_accuracy: 0.7313\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.5562 - accuracy: 0.7630 - val_loss: 0.4776 - val_accuracy: 0.7612\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5255 - accuracy: 0.7759 - val_loss: 0.4744 - val_accuracy: 0.7313\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5115 - accuracy: 0.7630 - val_loss: 0.4708 - val_accuracy: 0.7463\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.5132 - accuracy: 0.7796 - val_loss: 0.4889 - val_accuracy: 0.7761\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5334 - accuracy: 0.7704 - val_loss: 0.4821 - val_accuracy: 0.7761\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.5079 - accuracy: 0.7889 - val_loss: 0.4618 - val_accuracy: 0.7910\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4998 - accuracy: 0.7907 - val_loss: 0.4548 - val_accuracy: 0.8060\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4684 - accuracy: 0.7944 - val_loss: 0.4508 - val_accuracy: 0.8060\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4939 - accuracy: 0.7926 - val_loss: 0.4582 - val_accuracy: 0.8060\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4718 - accuracy: 0.7963 - val_loss: 0.4467 - val_accuracy: 0.7910\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4716 - accuracy: 0.8037 - val_loss: 0.4648 - val_accuracy: 0.7761\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4594 - accuracy: 0.7944 - val_loss: 0.4609 - val_accuracy: 0.7910\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4785 - accuracy: 0.8074 - val_loss: 0.4597 - val_accuracy: 0.7910\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4492 - accuracy: 0.8148 - val_loss: 0.4542 - val_accuracy: 0.7910\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4421 - accuracy: 0.8056 - val_loss: 0.4343 - val_accuracy: 0.8060\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4325 - accuracy: 0.8056 - val_loss: 0.4516 - val_accuracy: 0.7761\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4359 - accuracy: 0.8037 - val_loss: 0.4324 - val_accuracy: 0.8209\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.4169 - accuracy: 0.8204 - val_loss: 0.4308 - val_accuracy: 0.8358\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4624 - accuracy: 0.7889 - val_loss: 0.4503 - val_accuracy: 0.7910\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4191 - accuracy: 0.8111 - val_loss: 0.4139 - val_accuracy: 0.8060\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.4354 - accuracy: 0.8037 - val_loss: 0.4120 - val_accuracy: 0.8209\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4313 - accuracy: 0.8259 - val_loss: 0.4233 - val_accuracy: 0.8507\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4038 - accuracy: 0.8167 - val_loss: 0.4143 - val_accuracy: 0.8209\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3898 - accuracy: 0.8389 - val_loss: 0.4105 - val_accuracy: 0.8209\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3953 - accuracy: 0.8426 - val_loss: 0.4059 - val_accuracy: 0.8209\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3839 - accuracy: 0.8259 - val_loss: 0.3999 - val_accuracy: 0.8209\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3807 - accuracy: 0.8463 - val_loss: 0.3955 - val_accuracy: 0.8358\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3767 - accuracy: 0.8333 - val_loss: 0.3930 - val_accuracy: 0.8358\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3807 - accuracy: 0.8296 - val_loss: 0.3855 - val_accuracy: 0.8657\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3803 - accuracy: 0.8333 - val_loss: 0.4112 - val_accuracy: 0.8209\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3761 - accuracy: 0.8241 - val_loss: 0.3976 - val_accuracy: 0.8358\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3720 - accuracy: 0.8315 - val_loss: 0.4186 - val_accuracy: 0.8507\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3565 - accuracy: 0.8426 - val_loss: 0.3922 - val_accuracy: 0.8507\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3539 - accuracy: 0.8481 - val_loss: 0.3758 - val_accuracy: 0.8507\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3509 - accuracy: 0.8407 - val_loss: 0.3693 - val_accuracy: 0.8507\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3546 - accuracy: 0.8426 - val_loss: 0.3748 - val_accuracy: 0.8358\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3506 - accuracy: 0.8463 - val_loss: 0.3888 - val_accuracy: 0.8209\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3714 - accuracy: 0.8315 - val_loss: 0.4373 - val_accuracy: 0.8209\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3491 - accuracy: 0.8426 - val_loss: 0.4186 - val_accuracy: 0.8209\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3369 - accuracy: 0.8519 - val_loss: 0.3965 - val_accuracy: 0.8209\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3512 - accuracy: 0.8389 - val_loss: 0.4090 - val_accuracy: 0.8358\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3306 - accuracy: 0.8500 - val_loss: 0.3886 - val_accuracy: 0.8358\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3183 - accuracy: 0.8593 - val_loss: 0.3676 - val_accuracy: 0.8507\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3314 - accuracy: 0.8426 - val_loss: 0.3903 - val_accuracy: 0.8358\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3311 - accuracy: 0.8593 - val_loss: 0.3735 - val_accuracy: 0.8657\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3201 - accuracy: 0.8500 - val_loss: 0.4078 - val_accuracy: 0.8358\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3175 - accuracy: 0.8611 - val_loss: 0.3985 - val_accuracy: 0.8657\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3140 - accuracy: 0.8519 - val_loss: 0.4048 - val_accuracy: 0.8507\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3529 - accuracy: 0.8407 - val_loss: 0.3944 - val_accuracy: 0.8507\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3325 - accuracy: 0.8500 - val_loss: 0.3801 - val_accuracy: 0.8507\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3136 - accuracy: 0.8574 - val_loss: 0.3861 - val_accuracy: 0.8657\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3185 - accuracy: 0.8611 - val_loss: 0.3781 - val_accuracy: 0.8955\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3104 - accuracy: 0.8611 - val_loss: 0.3841 - val_accuracy: 0.8507\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3095 - accuracy: 0.8648 - val_loss: 0.3684 - val_accuracy: 0.8955\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3060 - accuracy: 0.8685 - val_loss: 0.4659 - val_accuracy: 0.8507\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3124 - accuracy: 0.8759 - val_loss: 0.4053 - val_accuracy: 0.8507\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2906 - accuracy: 0.8667 - val_loss: 0.3679 - val_accuracy: 0.8806\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3198 - accuracy: 0.8630 - val_loss: 0.3835 - val_accuracy: 0.8806\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3111 - accuracy: 0.8667 - val_loss: 0.3498 - val_accuracy: 0.8806\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2864 - accuracy: 0.8685 - val_loss: 0.3499 - val_accuracy: 0.9104\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2855 - accuracy: 0.8833 - val_loss: 0.3533 - val_accuracy: 0.8955\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2673 - accuracy: 0.8889 - val_loss: 0.3524 - val_accuracy: 0.8955\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2869 - accuracy: 0.8759 - val_loss: 0.3864 - val_accuracy: 0.8507\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2732 - accuracy: 0.8852 - val_loss: 0.3707 - val_accuracy: 0.8806\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2818 - accuracy: 0.8852 - val_loss: 0.3594 - val_accuracy: 0.8955\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2716 - accuracy: 0.8778 - val_loss: 0.3716 - val_accuracy: 0.8806\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2744 - accuracy: 0.8833 - val_loss: 0.3836 - val_accuracy: 0.8657\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2510 - accuracy: 0.8889 - val_loss: 0.3359 - val_accuracy: 0.8955\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2670 - accuracy: 0.8926 - val_loss: 0.4382 - val_accuracy: 0.8657\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2716 - accuracy: 0.8963 - val_loss: 0.3502 - val_accuracy: 0.9104\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2476 - accuracy: 0.9167 - val_loss: 0.3555 - val_accuracy: 0.8955\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2480 - accuracy: 0.9093 - val_loss: 0.3370 - val_accuracy: 0.8955\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2713 - accuracy: 0.9000 - val_loss: 0.3294 - val_accuracy: 0.9104\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2584 - accuracy: 0.8907 - val_loss: 0.5240 - val_accuracy: 0.8507\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2512 - accuracy: 0.9259 - val_loss: 0.4064 - val_accuracy: 0.8657\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2393 - accuracy: 0.9111 - val_loss: 0.3202 - val_accuracy: 0.9104\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2344 - accuracy: 0.9148 - val_loss: 0.3414 - val_accuracy: 0.8955\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2417 - accuracy: 0.9037 - val_loss: 0.2949 - val_accuracy: 0.9254\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2427 - accuracy: 0.9074 - val_loss: 0.2785 - val_accuracy: 0.9552\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2437 - accuracy: 0.9148 - val_loss: 0.3095 - val_accuracy: 0.9403\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2170 - accuracy: 0.9185 - val_loss: 0.2832 - val_accuracy: 0.9552\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2317 - accuracy: 0.9222 - val_loss: 0.2980 - val_accuracy: 0.9254\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.2309 - accuracy: 0.9407 - val_loss: 0.2697 - val_accuracy: 0.9701\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2150 - accuracy: 0.9389 - val_loss: 0.2992 - val_accuracy: 0.9104\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2152 - accuracy: 0.9426 - val_loss: 0.2815 - val_accuracy: 0.9552\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2369 - accuracy: 0.9241 - val_loss: 0.2902 - val_accuracy: 0.9552\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2267 - accuracy: 0.9296 - val_loss: 0.2873 - val_accuracy: 0.9254\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2226 - accuracy: 0.9444 - val_loss: 0.3388 - val_accuracy: 0.8806\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2189 - accuracy: 0.9315 - val_loss: 0.2956 - val_accuracy: 0.9254\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2239 - accuracy: 0.9370 - val_loss: 0.2919 - val_accuracy: 0.9403\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2137 - accuracy: 0.9444 - val_loss: 0.2979 - val_accuracy: 0.9403\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2123 - accuracy: 0.9481 - val_loss: 0.3304 - val_accuracy: 0.9104\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2110 - accuracy: 0.9481 - val_loss: 0.3259 - val_accuracy: 0.9104\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1969 - accuracy: 0.9500 - val_loss: 0.2883 - val_accuracy: 0.9254\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2199 - accuracy: 0.9407 - val_loss: 0.3104 - val_accuracy: 0.9254\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1911 - accuracy: 0.9444 - val_loss: 0.3948 - val_accuracy: 0.8806\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2051 - accuracy: 0.9463 - val_loss: 0.3457 - val_accuracy: 0.8955\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2250 - accuracy: 0.9426 - val_loss: 0.5438 - val_accuracy: 0.8358\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2099 - accuracy: 0.9389 - val_loss: 0.3554 - val_accuracy: 0.9254\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2071 - accuracy: 0.9389 - val_loss: 0.3117 - val_accuracy: 0.9403\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1832 - accuracy: 0.9556 - val_loss: 0.3058 - val_accuracy: 0.9403\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1942 - accuracy: 0.9556 - val_loss: 0.3589 - val_accuracy: 0.8955\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2059 - accuracy: 0.9481 - val_loss: 0.3036 - val_accuracy: 0.9254\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1767 - accuracy: 0.9407 - val_loss: 0.3064 - val_accuracy: 0.9104\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1790 - accuracy: 0.9370 - val_loss: 0.2947 - val_accuracy: 0.9254\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1838 - accuracy: 0.9593 - val_loss: 0.3097 - val_accuracy: 0.9254\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1720 - accuracy: 0.9593 - val_loss: 0.3159 - val_accuracy: 0.9104\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1712 - accuracy: 0.9481 - val_loss: 0.3742 - val_accuracy: 0.8806\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1597 - accuracy: 0.9722 - val_loss: 0.3195 - val_accuracy: 0.9254\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1738 - accuracy: 0.9500 - val_loss: 0.2941 - val_accuracy: 0.9552\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1610 - accuracy: 0.9556 - val_loss: 0.3155 - val_accuracy: 0.9104\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1811 - accuracy: 0.9519 - val_loss: 0.3560 - val_accuracy: 0.8806\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1725 - accuracy: 0.9574 - val_loss: 0.2841 - val_accuracy: 0.9104\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1721 - accuracy: 0.9648 - val_loss: 0.4252 - val_accuracy: 0.8657\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1685 - accuracy: 0.9574 - val_loss: 0.3183 - val_accuracy: 0.9104\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1726 - accuracy: 0.9611 - val_loss: 0.2824 - val_accuracy: 0.9254\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1687 - accuracy: 0.9648 - val_loss: 0.3068 - val_accuracy: 0.8955\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1631 - accuracy: 0.9611 - val_loss: 0.2686 - val_accuracy: 0.9403\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1627 - accuracy: 0.9574 - val_loss: 0.3170 - val_accuracy: 0.8955\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1641 - accuracy: 0.9611 - val_loss: 0.3957 - val_accuracy: 0.8955\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1643 - accuracy: 0.9722 - val_loss: 0.2942 - val_accuracy: 0.9254\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1667 - accuracy: 0.9667 - val_loss: 0.2549 - val_accuracy: 0.9254\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1450 - accuracy: 0.9648 - val_loss: 0.2514 - val_accuracy: 0.9104\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1453 - accuracy: 0.9667 - val_loss: 0.2871 - val_accuracy: 0.9254\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1373 - accuracy: 0.9704 - val_loss: 0.3459 - val_accuracy: 0.9104\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1524 - accuracy: 0.9574 - val_loss: 0.3196 - val_accuracy: 0.9104\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1372 - accuracy: 0.9741 - val_loss: 0.2755 - val_accuracy: 0.9403\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1537 - accuracy: 0.9704 - val_loss: 0.2720 - val_accuracy: 0.9254\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1466 - accuracy: 0.9667 - val_loss: 0.3738 - val_accuracy: 0.9104\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1556 - accuracy: 0.9611 - val_loss: 0.2697 - val_accuracy: 0.9254\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1496 - accuracy: 0.9648 - val_loss: 0.3886 - val_accuracy: 0.8955\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1334 - accuracy: 0.9722 - val_loss: 0.2917 - val_accuracy: 0.9104\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1408 - accuracy: 0.9722 - val_loss: 0.2658 - val_accuracy: 0.9403\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1289 - accuracy: 0.9833 - val_loss: 0.2650 - val_accuracy: 0.9403\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1342 - accuracy: 0.9778 - val_loss: 0.2410 - val_accuracy: 0.9403\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1215 - accuracy: 0.9759 - val_loss: 0.2782 - val_accuracy: 0.9254\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1277 - accuracy: 0.9778 - val_loss: 0.3720 - val_accuracy: 0.9104\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1399 - accuracy: 0.9741 - val_loss: 0.2517 - val_accuracy: 0.9403\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1480 - accuracy: 0.9648 - val_loss: 0.2499 - val_accuracy: 0.9403\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.1336 - accuracy: 0.9759 - val_loss: 0.2174 - val_accuracy: 0.9851\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1222 - accuracy: 0.9796 - val_loss: 0.2487 - val_accuracy: 0.9403\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1133 - accuracy: 0.9759 - val_loss: 0.2225 - val_accuracy: 0.9552\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1211 - accuracy: 0.9796 - val_loss: 0.2443 - val_accuracy: 0.9552\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1258 - accuracy: 0.9741 - val_loss: 0.2971 - val_accuracy: 0.9104\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1366 - accuracy: 0.9685 - val_loss: 0.3462 - val_accuracy: 0.9104\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1167 - accuracy: 0.9759 - val_loss: 0.2416 - val_accuracy: 0.9552\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1246 - accuracy: 0.9870 - val_loss: 0.2447 - val_accuracy: 0.9552\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1193 - accuracy: 0.9759 - val_loss: 0.2503 - val_accuracy: 0.9552\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1137 - accuracy: 0.9833 - val_loss: 0.2181 - val_accuracy: 0.9552\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1036 - accuracy: 0.9722 - val_loss: 0.2830 - val_accuracy: 0.9104\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1107 - accuracy: 0.9815 - val_loss: 0.2365 - val_accuracy: 0.9552\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1265 - accuracy: 0.9778 - val_loss: 0.7465 - val_accuracy: 0.8657\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1457 - accuracy: 0.9648 - val_loss: 0.7143 - val_accuracy: 0.8657\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1581 - accuracy: 0.9611 - val_loss: 0.5827 - val_accuracy: 0.8657\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1240 - accuracy: 0.9778 - val_loss: 0.4940 - val_accuracy: 0.8806\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1351 - accuracy: 0.9722 - val_loss: 0.4478 - val_accuracy: 0.8806\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1248 - accuracy: 0.9704 - val_loss: 0.3837 - val_accuracy: 0.8806\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1382 - accuracy: 0.9704 - val_loss: 0.3261 - val_accuracy: 0.9104\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1435 - accuracy: 0.9611 - val_loss: 0.4158 - val_accuracy: 0.9104\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1325 - accuracy: 0.9630 - val_loss: 0.3851 - val_accuracy: 0.9104\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1288 - accuracy: 0.9815 - val_loss: 0.3311 - val_accuracy: 0.8955\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1225 - accuracy: 0.9759 - val_loss: 0.2920 - val_accuracy: 0.9104\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1206 - accuracy: 0.9704 - val_loss: 0.3309 - val_accuracy: 0.8955\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1011 - accuracy: 0.9704 - val_loss: 0.3075 - val_accuracy: 0.8955\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1268 - accuracy: 0.9741 - val_loss: 0.2847 - val_accuracy: 0.9104\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1209 - accuracy: 0.9759 - val_loss: 0.2723 - val_accuracy: 0.9104\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1155 - accuracy: 0.9685 - val_loss: 0.3297 - val_accuracy: 0.9104\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1139 - accuracy: 0.9778 - val_loss: 0.2702 - val_accuracy: 0.9104\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1098 - accuracy: 0.9815 - val_loss: 0.2905 - val_accuracy: 0.9254\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1001 - accuracy: 0.9741 - val_loss: 0.2756 - val_accuracy: 0.9104\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1212 - accuracy: 0.9722 - val_loss: 0.2726 - val_accuracy: 0.9104\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1302 - accuracy: 0.9722 - val_loss: 0.2503 - val_accuracy: 0.9104\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1000 - accuracy: 0.9833 - val_loss: 0.2701 - val_accuracy: 0.9254\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1018 - accuracy: 0.9796 - val_loss: 0.2135 - val_accuracy: 0.9254\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1064 - accuracy: 0.9741 - val_loss: 0.1854 - val_accuracy: 0.9552\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1110 - accuracy: 0.9778 - val_loss: 0.1864 - val_accuracy: 0.9701\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1241 - accuracy: 0.9704 - val_loss: 0.2064 - val_accuracy: 0.9403\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1065 - accuracy: 0.9778 - val_loss: 0.2672 - val_accuracy: 0.9403\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1069 - accuracy: 0.9759 - val_loss: 0.2419 - val_accuracy: 0.9403\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1158 - accuracy: 0.9833 - val_loss: 0.2716 - val_accuracy: 0.9254\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0991 - accuracy: 0.9796 - val_loss: 0.2592 - val_accuracy: 0.9403\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1153 - accuracy: 0.9685 - val_loss: 0.2764 - val_accuracy: 0.9403\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1114 - accuracy: 0.9741 - val_loss: 0.2996 - val_accuracy: 0.9254\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0853 - accuracy: 0.9870 - val_loss: 0.2864 - val_accuracy: 0.9254\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1207 - accuracy: 0.9704 - val_loss: 0.2272 - val_accuracy: 0.9403\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1027 - accuracy: 0.9704 - val_loss: 0.2363 - val_accuracy: 0.9254\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0997 - accuracy: 0.9722 - val_loss: 0.2739 - val_accuracy: 0.9403\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0879 - accuracy: 0.9833 - val_loss: 0.2792 - val_accuracy: 0.9403\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0842 - accuracy: 0.9833 - val_loss: 0.2586 - val_accuracy: 0.9403\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0930 - accuracy: 0.9870 - val_loss: 0.2723 - val_accuracy: 0.9403\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0756 - accuracy: 0.9870 - val_loss: 0.2681 - val_accuracy: 0.9403\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0660 - accuracy: 0.9926 - val_loss: 0.2515 - val_accuracy: 0.9403\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0726 - accuracy: 0.9889 - val_loss: 0.2362 - val_accuracy: 0.9403\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0672 - accuracy: 0.9889 - val_loss: 0.2456 - val_accuracy: 0.9403\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0779 - accuracy: 0.9870 - val_loss: 0.1916 - val_accuracy: 0.9552\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0812 - accuracy: 0.9833 - val_loss: 0.2426 - val_accuracy: 0.9403\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0946 - accuracy: 0.9833 - val_loss: 0.2536 - val_accuracy: 0.9403\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0648 - accuracy: 0.9889 - val_loss: 0.2818 - val_accuracy: 0.9254\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0581 - accuracy: 0.9944 - val_loss: 0.2834 - val_accuracy: 0.9104\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0636 - accuracy: 0.9926 - val_loss: 0.2724 - val_accuracy: 0.9403\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0627 - accuracy: 0.9907 - val_loss: 0.2640 - val_accuracy: 0.9403\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0700 - accuracy: 0.9889 - val_loss: 0.2457 - val_accuracy: 0.9403\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0684 - accuracy: 0.9889 - val_loss: 0.2302 - val_accuracy: 0.9403\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0641 - accuracy: 0.9926 - val_loss: 0.2254 - val_accuracy: 0.9403\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0618 - accuracy: 0.9852 - val_loss: 0.2179 - val_accuracy: 0.9403\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0667 - accuracy: 0.9833 - val_loss: 0.2596 - val_accuracy: 0.9403\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0458 - accuracy: 0.9981 - val_loss: 0.2771 - val_accuracy: 0.9403\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0621 - accuracy: 0.9870 - val_loss: 0.2615 - val_accuracy: 0.9403\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0787 - accuracy: 0.9815 - val_loss: 0.2899 - val_accuracy: 0.9403\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0581 - accuracy: 0.9907 - val_loss: 0.2543 - val_accuracy: 0.9403\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0640 - accuracy: 0.9852 - val_loss: 0.2563 - val_accuracy: 0.9403\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0586 - accuracy: 0.9907 - val_loss: 0.2633 - val_accuracy: 0.9403\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0579 - accuracy: 0.9926 - val_loss: 0.2524 - val_accuracy: 0.9403\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.9926 - val_loss: 0.2431 - val_accuracy: 0.9403\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0453 - accuracy: 0.9963 - val_loss: 0.2574 - val_accuracy: 0.9403\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0635 - accuracy: 0.9870 - val_loss: 0.2674 - val_accuracy: 0.9254\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0570 - accuracy: 0.9944 - val_loss: 0.2432 - val_accuracy: 0.9403\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0672 - accuracy: 0.9833 - val_loss: 0.2190 - val_accuracy: 0.9403\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0548 - accuracy: 0.9963 - val_loss: 0.2328 - val_accuracy: 0.9403\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0471 - accuracy: 0.9944 - val_loss: 0.2211 - val_accuracy: 0.9403\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0678 - accuracy: 0.9852 - val_loss: 0.1816 - val_accuracy: 0.9403\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0488 - accuracy: 0.9944 - val_loss: 0.2421 - val_accuracy: 0.9403\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0441 - accuracy: 0.9963 - val_loss: 0.2340 - val_accuracy: 0.9403\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0616 - accuracy: 0.9870 - val_loss: 0.2845 - val_accuracy: 0.9254\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0589 - accuracy: 0.9889 - val_loss: 0.1699 - val_accuracy: 0.9552\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0474 - accuracy: 0.9926 - val_loss: 0.1709 - val_accuracy: 0.9403\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0521 - accuracy: 0.9926 - val_loss: 0.2487 - val_accuracy: 0.9403\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0448 - accuracy: 0.9944 - val_loss: 0.2580 - val_accuracy: 0.9403\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0494 - accuracy: 0.9926 - val_loss: 0.2509 - val_accuracy: 0.9403\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0454 - accuracy: 0.9926 - val_loss: 0.2231 - val_accuracy: 0.9403\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0458 - accuracy: 0.9907 - val_loss: 0.1985 - val_accuracy: 0.9403\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0487 - accuracy: 0.9944 - val_loss: 0.2280 - val_accuracy: 0.9403\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0587 - accuracy: 0.9852 - val_loss: 0.2036 - val_accuracy: 0.9552\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0520 - accuracy: 0.9944 - val_loss: 0.3293 - val_accuracy: 0.9403\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9889 - val_loss: 0.2287 - val_accuracy: 0.9254\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0447 - accuracy: 0.9981 - val_loss: 0.2214 - val_accuracy: 0.9403\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0486 - accuracy: 0.9907 - val_loss: 0.2516 - val_accuracy: 0.9403\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0702 - accuracy: 0.9815 - val_loss: 0.2325 - val_accuracy: 0.9403\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0477 - accuracy: 0.9926 - val_loss: 0.2619 - val_accuracy: 0.9403\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0523 - accuracy: 0.9907 - val_loss: 0.2428 - val_accuracy: 0.9403\n",
      "Epoch 272: early stopping\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7642 - accuracy: 0.8457\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 2s 30ms/step - loss: 1.6186 - accuracy: 0.1389 - val_loss: 1.5982 - val_accuracy: 0.1194\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.5567 - accuracy: 0.1944 - val_loss: 1.5843 - val_accuracy: 0.5672\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.4625 - accuracy: 0.2630 - val_loss: 1.5558 - val_accuracy: 0.7761\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.4031 - accuracy: 0.4019 - val_loss: 1.5278 - val_accuracy: 0.7612\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.3553 - accuracy: 0.5704 - val_loss: 1.5056 - val_accuracy: 0.7313\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.3148 - accuracy: 0.6815 - val_loss: 1.4862 - val_accuracy: 0.7164\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.2894 - accuracy: 0.7444 - val_loss: 1.4724 - val_accuracy: 0.7164\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.2500 - accuracy: 0.7667 - val_loss: 1.4584 - val_accuracy: 0.7612\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.2313 - accuracy: 0.7407 - val_loss: 1.4318 - val_accuracy: 0.7761\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.1832 - accuracy: 0.7815 - val_loss: 1.3968 - val_accuracy: 0.7761\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.1575 - accuracy: 0.7889 - val_loss: 1.3645 - val_accuracy: 0.8060\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.1146 - accuracy: 0.7963 - val_loss: 1.3314 - val_accuracy: 0.8060\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.0987 - accuracy: 0.7852 - val_loss: 1.2889 - val_accuracy: 0.8060\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 1.0671 - accuracy: 0.8000 - val_loss: 1.2442 - val_accuracy: 0.8060\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.0445 - accuracy: 0.7852 - val_loss: 1.1818 - val_accuracy: 0.8060\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.0157 - accuracy: 0.7870 - val_loss: 1.1233 - val_accuracy: 0.8060\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.9789 - accuracy: 0.7963 - val_loss: 1.0729 - val_accuracy: 0.8060\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.9280 - accuracy: 0.8037 - val_loss: 1.0085 - val_accuracy: 0.8060\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.9311 - accuracy: 0.7870 - val_loss: 0.9529 - val_accuracy: 0.8060\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8938 - accuracy: 0.7852 - val_loss: 0.9057 - val_accuracy: 0.8060\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8530 - accuracy: 0.7833 - val_loss: 0.8610 - val_accuracy: 0.8060\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.8424 - accuracy: 0.7796 - val_loss: 0.8063 - val_accuracy: 0.8209\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8048 - accuracy: 0.8000 - val_loss: 0.7621 - val_accuracy: 0.8060\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.8042 - accuracy: 0.7870 - val_loss: 0.7326 - val_accuracy: 0.7910\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7548 - accuracy: 0.7963 - val_loss: 0.6895 - val_accuracy: 0.7910\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7487 - accuracy: 0.7963 - val_loss: 0.6546 - val_accuracy: 0.7910\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.7191 - accuracy: 0.7981 - val_loss: 0.6350 - val_accuracy: 0.7910\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6908 - accuracy: 0.8000 - val_loss: 0.6004 - val_accuracy: 0.7910\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6873 - accuracy: 0.8056 - val_loss: 0.5858 - val_accuracy: 0.7910\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.6655 - accuracy: 0.7889 - val_loss: 0.5598 - val_accuracy: 0.7910\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6532 - accuracy: 0.7981 - val_loss: 0.5502 - val_accuracy: 0.7910\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.6376 - accuracy: 0.7907 - val_loss: 0.5408 - val_accuracy: 0.7910\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6131 - accuracy: 0.8056 - val_loss: 0.5375 - val_accuracy: 0.7910\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6243 - accuracy: 0.7944 - val_loss: 0.5201 - val_accuracy: 0.7910\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.5967 - accuracy: 0.8019 - val_loss: 0.5159 - val_accuracy: 0.7910\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5902 - accuracy: 0.8056 - val_loss: 0.5078 - val_accuracy: 0.7910\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.6031 - accuracy: 0.7981 - val_loss: 0.5477 - val_accuracy: 0.8358\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5560 - accuracy: 0.7963 - val_loss: 0.4967 - val_accuracy: 0.8209\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.5506 - accuracy: 0.8056 - val_loss: 0.4859 - val_accuracy: 0.8507\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.5412 - accuracy: 0.8019 - val_loss: 0.4617 - val_accuracy: 0.8209\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5436 - accuracy: 0.8148 - val_loss: 0.4510 - val_accuracy: 0.8358\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5220 - accuracy: 0.8111 - val_loss: 0.4464 - val_accuracy: 0.8209\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5202 - accuracy: 0.8093 - val_loss: 0.4429 - val_accuracy: 0.8060\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5229 - accuracy: 0.8093 - val_loss: 0.4663 - val_accuracy: 0.7910\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5063 - accuracy: 0.8148 - val_loss: 0.4574 - val_accuracy: 0.7910\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4846 - accuracy: 0.8074 - val_loss: 0.4437 - val_accuracy: 0.8358\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4868 - accuracy: 0.8204 - val_loss: 0.4280 - val_accuracy: 0.8358\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4722 - accuracy: 0.8296 - val_loss: 0.4039 - val_accuracy: 0.8358\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4577 - accuracy: 0.8259 - val_loss: 0.4052 - val_accuracy: 0.8358\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4520 - accuracy: 0.8259 - val_loss: 0.4098 - val_accuracy: 0.8358\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4505 - accuracy: 0.8241 - val_loss: 0.4274 - val_accuracy: 0.8507\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4471 - accuracy: 0.8315 - val_loss: 0.4080 - val_accuracy: 0.8507\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4258 - accuracy: 0.8463 - val_loss: 0.4230 - val_accuracy: 0.8507\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.4552 - accuracy: 0.8407 - val_loss: 0.3810 - val_accuracy: 0.8657\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4335 - accuracy: 0.8500 - val_loss: 0.4087 - val_accuracy: 0.8657\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4292 - accuracy: 0.8574 - val_loss: 0.3607 - val_accuracy: 0.8806\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.4330 - accuracy: 0.8463 - val_loss: 0.3622 - val_accuracy: 0.8955\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3977 - accuracy: 0.8630 - val_loss: 0.3577 - val_accuracy: 0.8955\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3877 - accuracy: 0.8778 - val_loss: 0.3622 - val_accuracy: 0.8955\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3908 - accuracy: 0.8741 - val_loss: 0.3473 - val_accuracy: 0.8955\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3952 - accuracy: 0.8778 - val_loss: 0.3331 - val_accuracy: 0.8955\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3914 - accuracy: 0.8778 - val_loss: 0.3293 - val_accuracy: 0.8955\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3691 - accuracy: 0.8907 - val_loss: 0.3772 - val_accuracy: 0.8657\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3731 - accuracy: 0.8889 - val_loss: 0.3323 - val_accuracy: 0.8806\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3708 - accuracy: 0.8852 - val_loss: 0.3250 - val_accuracy: 0.9104\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3464 - accuracy: 0.8981 - val_loss: 0.3281 - val_accuracy: 0.8806\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3412 - accuracy: 0.8963 - val_loss: 0.3140 - val_accuracy: 0.8955\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3613 - accuracy: 0.8944 - val_loss: 0.3122 - val_accuracy: 0.9104\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3567 - accuracy: 0.8815 - val_loss: 0.3124 - val_accuracy: 0.8955\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3415 - accuracy: 0.8944 - val_loss: 0.3050 - val_accuracy: 0.8955\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3187 - accuracy: 0.9111 - val_loss: 0.3134 - val_accuracy: 0.8955\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3269 - accuracy: 0.9000 - val_loss: 0.3105 - val_accuracy: 0.8955\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3363 - accuracy: 0.8963 - val_loss: 0.2903 - val_accuracy: 0.9104\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3331 - accuracy: 0.9000 - val_loss: 0.3567 - val_accuracy: 0.9104\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3313 - accuracy: 0.9056 - val_loss: 0.2870 - val_accuracy: 0.9104\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3173 - accuracy: 0.9056 - val_loss: 0.2724 - val_accuracy: 0.9104\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2968 - accuracy: 0.9093 - val_loss: 0.2971 - val_accuracy: 0.8657\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2885 - accuracy: 0.9093 - val_loss: 0.2628 - val_accuracy: 0.9104\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2778 - accuracy: 0.9130 - val_loss: 0.2668 - val_accuracy: 0.9104\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3045 - accuracy: 0.9019 - val_loss: 0.3322 - val_accuracy: 0.8657\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2852 - accuracy: 0.9093 - val_loss: 0.2620 - val_accuracy: 0.9254\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2967 - accuracy: 0.9130 - val_loss: 0.3234 - val_accuracy: 0.8955\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2927 - accuracy: 0.9130 - val_loss: 0.2887 - val_accuracy: 0.8955\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2922 - accuracy: 0.9093 - val_loss: 0.2722 - val_accuracy: 0.8955\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2768 - accuracy: 0.9148 - val_loss: 0.2545 - val_accuracy: 0.9104\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2800 - accuracy: 0.9148 - val_loss: 0.2487 - val_accuracy: 0.9104\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2589 - accuracy: 0.9111 - val_loss: 0.2448 - val_accuracy: 0.8955\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2575 - accuracy: 0.9093 - val_loss: 0.2502 - val_accuracy: 0.8955\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2737 - accuracy: 0.9056 - val_loss: 0.2487 - val_accuracy: 0.9104\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2515 - accuracy: 0.9185 - val_loss: 0.2419 - val_accuracy: 0.9104\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2505 - accuracy: 0.9130 - val_loss: 0.2407 - val_accuracy: 0.9104\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2572 - accuracy: 0.9130 - val_loss: 0.2493 - val_accuracy: 0.8955\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2577 - accuracy: 0.9148 - val_loss: 0.2439 - val_accuracy: 0.8955\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2450 - accuracy: 0.9204 - val_loss: 0.2399 - val_accuracy: 0.9104\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2391 - accuracy: 0.9204 - val_loss: 0.2371 - val_accuracy: 0.8955\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2394 - accuracy: 0.9204 - val_loss: 0.2432 - val_accuracy: 0.8955\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2413 - accuracy: 0.9093 - val_loss: 0.2285 - val_accuracy: 0.9104\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2324 - accuracy: 0.9222 - val_loss: 0.2229 - val_accuracy: 0.9254\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2470 - accuracy: 0.9130 - val_loss: 0.2248 - val_accuracy: 0.9104\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2172 - accuracy: 0.9278 - val_loss: 0.2644 - val_accuracy: 0.8955\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2534 - accuracy: 0.9093 - val_loss: 0.2535 - val_accuracy: 0.9104\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2197 - accuracy: 0.9241 - val_loss: 0.2165 - val_accuracy: 0.8955\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2398 - accuracy: 0.9148 - val_loss: 0.2219 - val_accuracy: 0.8955\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.2383 - accuracy: 0.9074 - val_loss: 0.2258 - val_accuracy: 0.8955\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2185 - accuracy: 0.9130 - val_loss: 0.2144 - val_accuracy: 0.9104\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2197 - accuracy: 0.9185 - val_loss: 0.2203 - val_accuracy: 0.8955\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2179 - accuracy: 0.9222 - val_loss: 0.2535 - val_accuracy: 0.8806\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2014 - accuracy: 0.9241 - val_loss: 0.2237 - val_accuracy: 0.8955\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1860 - accuracy: 0.9241 - val_loss: 0.2166 - val_accuracy: 0.8955\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2216 - accuracy: 0.9278 - val_loss: 0.2414 - val_accuracy: 0.8955\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2050 - accuracy: 0.9315 - val_loss: 0.2098 - val_accuracy: 0.9104\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2164 - accuracy: 0.9148 - val_loss: 0.2125 - val_accuracy: 0.8955\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2223 - accuracy: 0.9148 - val_loss: 0.2192 - val_accuracy: 0.9104\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2151 - accuracy: 0.9241 - val_loss: 0.3506 - val_accuracy: 0.8657\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2022 - accuracy: 0.9315 - val_loss: 0.2935 - val_accuracy: 0.8657\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2102 - accuracy: 0.9259 - val_loss: 0.1998 - val_accuracy: 0.8955\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2016 - accuracy: 0.9315 - val_loss: 0.1969 - val_accuracy: 0.9104\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1870 - accuracy: 0.9352 - val_loss: 0.2534 - val_accuracy: 0.8806\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1859 - accuracy: 0.9352 - val_loss: 0.2194 - val_accuracy: 0.9104\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1861 - accuracy: 0.9259 - val_loss: 0.1917 - val_accuracy: 0.9104\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1952 - accuracy: 0.9241 - val_loss: 0.2576 - val_accuracy: 0.8955\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2191 - accuracy: 0.9204 - val_loss: 0.2693 - val_accuracy: 0.8806\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1898 - accuracy: 0.9352 - val_loss: 0.2158 - val_accuracy: 0.9104\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2275 - accuracy: 0.9167 - val_loss: 0.2145 - val_accuracy: 0.9104\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2190 - accuracy: 0.9148 - val_loss: 0.2202 - val_accuracy: 0.9104\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2166 - accuracy: 0.9148 - val_loss: 0.2044 - val_accuracy: 0.9104\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2017 - accuracy: 0.9315 - val_loss: 0.1938 - val_accuracy: 0.9104\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1824 - accuracy: 0.9333 - val_loss: 0.1718 - val_accuracy: 0.9104\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1815 - accuracy: 0.9389 - val_loss: 0.2233 - val_accuracy: 0.8955\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2052 - accuracy: 0.9296 - val_loss: 0.1961 - val_accuracy: 0.9104\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2055 - accuracy: 0.9259 - val_loss: 0.1766 - val_accuracy: 0.9104\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1769 - accuracy: 0.9426 - val_loss: 0.1748 - val_accuracy: 0.9104\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1937 - accuracy: 0.9278 - val_loss: 0.1698 - val_accuracy: 0.9254\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1704 - accuracy: 0.9315 - val_loss: 0.1994 - val_accuracy: 0.9104\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1680 - accuracy: 0.9519 - val_loss: 0.1910 - val_accuracy: 0.8955\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1719 - accuracy: 0.9296 - val_loss: 0.1805 - val_accuracy: 0.9104\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1642 - accuracy: 0.9333 - val_loss: 0.2161 - val_accuracy: 0.8955\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1562 - accuracy: 0.9389 - val_loss: 0.1904 - val_accuracy: 0.9104\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1740 - accuracy: 0.9352 - val_loss: 0.1792 - val_accuracy: 0.9254\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1504 - accuracy: 0.9481 - val_loss: 0.2139 - val_accuracy: 0.9104\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1433 - accuracy: 0.9519 - val_loss: 0.2519 - val_accuracy: 0.8955\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1500 - accuracy: 0.9352 - val_loss: 0.2784 - val_accuracy: 0.8955\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1510 - accuracy: 0.9481 - val_loss: 0.1785 - val_accuracy: 0.9104\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1372 - accuracy: 0.9519 - val_loss: 0.1599 - val_accuracy: 0.9254\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.1473 - accuracy: 0.9444 - val_loss: 0.1543 - val_accuracy: 0.9403\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1510 - accuracy: 0.9519 - val_loss: 0.1824 - val_accuracy: 0.9104\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1559 - accuracy: 0.9481 - val_loss: 0.1537 - val_accuracy: 0.9254\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1446 - accuracy: 0.9519 - val_loss: 0.1708 - val_accuracy: 0.9104\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.1491 - accuracy: 0.9556 - val_loss: 0.1452 - val_accuracy: 0.9552\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1488 - accuracy: 0.9593 - val_loss: 0.1480 - val_accuracy: 0.9254\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1306 - accuracy: 0.9574 - val_loss: 0.1779 - val_accuracy: 0.9254\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1431 - accuracy: 0.9352 - val_loss: 0.1818 - val_accuracy: 0.9104\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1524 - accuracy: 0.9556 - val_loss: 0.1536 - val_accuracy: 0.9254\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1287 - accuracy: 0.9648 - val_loss: 0.1470 - val_accuracy: 0.9104\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1289 - accuracy: 0.9667 - val_loss: 0.1780 - val_accuracy: 0.8955\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1319 - accuracy: 0.9556 - val_loss: 0.1720 - val_accuracy: 0.9254\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1343 - accuracy: 0.9537 - val_loss: 0.1770 - val_accuracy: 0.9254\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1338 - accuracy: 0.9667 - val_loss: 0.1689 - val_accuracy: 0.9254\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1389 - accuracy: 0.9630 - val_loss: 0.1545 - val_accuracy: 0.9104\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1289 - accuracy: 0.9500 - val_loss: 0.1718 - val_accuracy: 0.9104\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1317 - accuracy: 0.9630 - val_loss: 0.1549 - val_accuracy: 0.9254\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1138 - accuracy: 0.9685 - val_loss: 0.1579 - val_accuracy: 0.9254\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1552 - accuracy: 0.9426 - val_loss: 0.1652 - val_accuracy: 0.9254\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1128 - accuracy: 0.9722 - val_loss: 0.1692 - val_accuracy: 0.9254\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1256 - accuracy: 0.9685 - val_loss: 0.1381 - val_accuracy: 0.9552\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1152 - accuracy: 0.9778 - val_loss: 0.1335 - val_accuracy: 0.9254\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1176 - accuracy: 0.9685 - val_loss: 0.1280 - val_accuracy: 0.9104\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1275 - accuracy: 0.9667 - val_loss: 0.1593 - val_accuracy: 0.9254\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1232 - accuracy: 0.9704 - val_loss: 0.1598 - val_accuracy: 0.9104\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1120 - accuracy: 0.9778 - val_loss: 0.1845 - val_accuracy: 0.9254\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1088 - accuracy: 0.9741 - val_loss: 0.1451 - val_accuracy: 0.9254\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1115 - accuracy: 0.9722 - val_loss: 0.1699 - val_accuracy: 0.9104\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1049 - accuracy: 0.9852 - val_loss: 0.1628 - val_accuracy: 0.9254\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0930 - accuracy: 0.9815 - val_loss: 0.1595 - val_accuracy: 0.9254\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0981 - accuracy: 0.9852 - val_loss: 0.1212 - val_accuracy: 0.9403\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0866 - accuracy: 0.9907 - val_loss: 0.1325 - val_accuracy: 0.9552\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1008 - accuracy: 0.9870 - val_loss: 0.1700 - val_accuracy: 0.9403\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0984 - accuracy: 0.9852 - val_loss: 0.1621 - val_accuracy: 0.9403\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0986 - accuracy: 0.9815 - val_loss: 0.1644 - val_accuracy: 0.9403\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1079 - accuracy: 0.9815 - val_loss: 0.1748 - val_accuracy: 0.9254\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0996 - accuracy: 0.9833 - val_loss: 0.1815 - val_accuracy: 0.9403\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0955 - accuracy: 0.9852 - val_loss: 0.1452 - val_accuracy: 0.9403\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1005 - accuracy: 0.9870 - val_loss: 0.1327 - val_accuracy: 0.9403\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0858 - accuracy: 0.9889 - val_loss: 0.1528 - val_accuracy: 0.9403\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0783 - accuracy: 0.9944 - val_loss: 0.1696 - val_accuracy: 0.9403\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0931 - accuracy: 0.9815 - val_loss: 0.1175 - val_accuracy: 0.9552\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0820 - accuracy: 0.9815 - val_loss: 0.1065 - val_accuracy: 0.9552\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0840 - accuracy: 0.9907 - val_loss: 0.1263 - val_accuracy: 0.9403\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1006 - accuracy: 0.9796 - val_loss: 0.1700 - val_accuracy: 0.9254\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0874 - accuracy: 0.9852 - val_loss: 0.1651 - val_accuracy: 0.9403\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0908 - accuracy: 0.9833 - val_loss: 0.1263 - val_accuracy: 0.9552\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0824 - accuracy: 0.9907 - val_loss: 0.1297 - val_accuracy: 0.9552\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0817 - accuracy: 0.9815 - val_loss: 0.1474 - val_accuracy: 0.9552\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0789 - accuracy: 0.9870 - val_loss: 0.1522 - val_accuracy: 0.9552\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0834 - accuracy: 0.9870 - val_loss: 0.1675 - val_accuracy: 0.9552\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.0935 - accuracy: 0.9815 - val_loss: 0.1113 - val_accuracy: 0.9701\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.0882 - accuracy: 0.9796 - val_loss: 0.0977 - val_accuracy: 0.9851\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0839 - accuracy: 0.9852 - val_loss: 0.1082 - val_accuracy: 0.9552\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0743 - accuracy: 0.9944 - val_loss: 0.1314 - val_accuracy: 0.9552\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0668 - accuracy: 0.9963 - val_loss: 0.1227 - val_accuracy: 0.9552\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0782 - accuracy: 0.9833 - val_loss: 0.1496 - val_accuracy: 0.9403\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1135 - accuracy: 0.9685 - val_loss: 0.1397 - val_accuracy: 0.9552\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1014 - accuracy: 0.9704 - val_loss: 0.1341 - val_accuracy: 0.9403\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0907 - accuracy: 0.9778 - val_loss: 0.1990 - val_accuracy: 0.9254\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0675 - accuracy: 0.9926 - val_loss: 0.1185 - val_accuracy: 0.9552\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0921 - accuracy: 0.9852 - val_loss: 0.0956 - val_accuracy: 0.9701\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0775 - accuracy: 0.9870 - val_loss: 0.0971 - val_accuracy: 0.9552\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0769 - accuracy: 0.9815 - val_loss: 0.1078 - val_accuracy: 0.9552\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0684 - accuracy: 0.9926 - val_loss: 0.0890 - val_accuracy: 0.9701\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0712 - accuracy: 0.9889 - val_loss: 0.0801 - val_accuracy: 0.9701\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9907 - val_loss: 0.3559 - val_accuracy: 0.9254\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0892 - accuracy: 0.9741 - val_loss: 0.2020 - val_accuracy: 0.9254\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0920 - accuracy: 0.9796 - val_loss: 0.0929 - val_accuracy: 0.9701\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0613 - accuracy: 0.9926 - val_loss: 0.1058 - val_accuracy: 0.9552\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0698 - accuracy: 0.9907 - val_loss: 0.1258 - val_accuracy: 0.9552\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0676 - accuracy: 0.9870 - val_loss: 0.1326 - val_accuracy: 0.9552\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0629 - accuracy: 0.9907 - val_loss: 0.1168 - val_accuracy: 0.9552\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0779 - accuracy: 0.9815 - val_loss: 0.1321 - val_accuracy: 0.9552\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0685 - accuracy: 0.9833 - val_loss: 0.1465 - val_accuracy: 0.9701\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0744 - accuracy: 0.9796 - val_loss: 0.1260 - val_accuracy: 0.9701\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0624 - accuracy: 0.9889 - val_loss: 0.0970 - val_accuracy: 0.9701\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0611 - accuracy: 0.9889 - val_loss: 0.1053 - val_accuracy: 0.9552\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0515 - accuracy: 0.9926 - val_loss: 0.0751 - val_accuracy: 0.9851\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0520 - accuracy: 0.9963 - val_loss: 0.2614 - val_accuracy: 0.8955\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0556 - accuracy: 0.9907 - val_loss: 0.1126 - val_accuracy: 0.9552\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0703 - accuracy: 0.9796 - val_loss: 0.1932 - val_accuracy: 0.9403\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0630 - accuracy: 0.9870 - val_loss: 0.1289 - val_accuracy: 0.9552\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0701 - accuracy: 0.9833 - val_loss: 0.0850 - val_accuracy: 0.9701\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0621 - accuracy: 0.9870 - val_loss: 0.1737 - val_accuracy: 0.9254\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0528 - accuracy: 0.9852 - val_loss: 0.0864 - val_accuracy: 0.9701\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0490 - accuracy: 0.9907 - val_loss: 0.0933 - val_accuracy: 0.9701\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0553 - accuracy: 0.9889 - val_loss: 0.0915 - val_accuracy: 0.9701\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0517 - accuracy: 0.9926 - val_loss: 0.1117 - val_accuracy: 0.9701\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0669 - accuracy: 0.9852 - val_loss: 0.1652 - val_accuracy: 0.9552\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0481 - accuracy: 0.9889 - val_loss: 0.1806 - val_accuracy: 0.9403\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0580 - accuracy: 0.9815 - val_loss: 0.1586 - val_accuracy: 0.9552\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0549 - accuracy: 0.9926 - val_loss: 0.1068 - val_accuracy: 0.9552\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0428 - accuracy: 0.9926 - val_loss: 0.1273 - val_accuracy: 0.9552\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0418 - accuracy: 0.9926 - val_loss: 0.1235 - val_accuracy: 0.9552\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0560 - accuracy: 0.9907 - val_loss: 0.0887 - val_accuracy: 0.9552\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0923 - val_accuracy: 0.9701\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0484 - accuracy: 0.9926 - val_loss: 0.0994 - val_accuracy: 0.9701\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0436 - accuracy: 0.9907 - val_loss: 0.0908 - val_accuracy: 0.9701\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0412 - accuracy: 0.9889 - val_loss: 0.0925 - val_accuracy: 0.9701\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0339 - accuracy: 0.9963 - val_loss: 0.0735 - val_accuracy: 0.9851\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0398 - accuracy: 0.9963 - val_loss: 0.0831 - val_accuracy: 0.9851\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0446 - accuracy: 0.9944 - val_loss: 0.0788 - val_accuracy: 0.9851\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0460 - accuracy: 0.9926 - val_loss: 0.0626 - val_accuracy: 0.9851\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0378 - accuracy: 0.9944 - val_loss: 0.1348 - val_accuracy: 0.9552\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0438 - accuracy: 0.9926 - val_loss: 0.1267 - val_accuracy: 0.9552\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0475 - accuracy: 0.9926 - val_loss: 0.1226 - val_accuracy: 0.9552\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0533 - accuracy: 0.9889 - val_loss: 0.1235 - val_accuracy: 0.9701\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0349 - accuracy: 0.9944 - val_loss: 0.1576 - val_accuracy: 0.9701\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0414 - accuracy: 0.9907 - val_loss: 0.1097 - val_accuracy: 0.9701\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0511 - accuracy: 0.9796 - val_loss: 0.0737 - val_accuracy: 0.9701\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0482 - accuracy: 0.9870 - val_loss: 0.0997 - val_accuracy: 0.9552\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0335 - accuracy: 0.9944 - val_loss: 0.0906 - val_accuracy: 0.9701\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0396 - accuracy: 0.9944 - val_loss: 0.0748 - val_accuracy: 0.9552\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0417 - accuracy: 0.9926 - val_loss: 0.0555 - val_accuracy: 0.9851\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0297 - accuracy: 0.9963 - val_loss: 0.0504 - val_accuracy: 0.9851\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0458 - accuracy: 0.9926 - val_loss: 0.1454 - val_accuracy: 0.9552\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0368 - accuracy: 0.9907 - val_loss: 0.1484 - val_accuracy: 0.9552\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0315 - accuracy: 0.9926 - val_loss: 0.1271 - val_accuracy: 0.9552\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0459 - accuracy: 0.9889 - val_loss: 0.1114 - val_accuracy: 0.9552\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0317 - accuracy: 0.9963 - val_loss: 0.1152 - val_accuracy: 0.9552\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.1068 - val_accuracy: 0.9552\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0384 - accuracy: 0.9907 - val_loss: 0.1144 - val_accuracy: 0.9552\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0308 - accuracy: 0.9944 - val_loss: 0.1203 - val_accuracy: 0.9552\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0326 - accuracy: 0.9907 - val_loss: 0.1121 - val_accuracy: 0.9552\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0258 - accuracy: 0.9981 - val_loss: 0.1071 - val_accuracy: 0.9701\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0280 - accuracy: 0.9981 - val_loss: 0.1426 - val_accuracy: 0.9552\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0468 - accuracy: 0.9889 - val_loss: 0.0881 - val_accuracy: 0.9552\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0912 - val_accuracy: 0.9552\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0385 - accuracy: 0.9926 - val_loss: 0.0774 - val_accuracy: 0.9701\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0300 - accuracy: 0.9963 - val_loss: 0.1199 - val_accuracy: 0.9552\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0935 - val_accuracy: 0.9701\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0303 - accuracy: 0.9944 - val_loss: 0.1099 - val_accuracy: 0.9701\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0278 - accuracy: 0.9944 - val_loss: 0.1006 - val_accuracy: 0.9701\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0376 - accuracy: 0.9926 - val_loss: 0.1007 - val_accuracy: 0.9701\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0398 - accuracy: 0.9926 - val_loss: 0.1051 - val_accuracy: 0.9701\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.0946 - val_accuracy: 0.9851\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0288 - accuracy: 0.9926 - val_loss: 0.0966 - val_accuracy: 0.9851\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.1041 - val_accuracy: 0.9701\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.1167 - val_accuracy: 0.9701\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0261 - accuracy: 0.9981 - val_loss: 0.1134 - val_accuracy: 0.9701\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0230 - accuracy: 0.9981 - val_loss: 0.0994 - val_accuracy: 0.9701\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0353 - accuracy: 0.9981 - val_loss: 0.0817 - val_accuracy: 0.9851\n",
      "Epoch 288/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.0717 - val_accuracy: 0.9701\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.0720 - val_accuracy: 0.9701\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.0573 - val_accuracy: 0.9701\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 0.0652 - val_accuracy: 0.9851\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0374 - accuracy: 0.9907 - val_loss: 0.0827 - val_accuracy: 0.9851\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0380 - accuracy: 0.9926 - val_loss: 0.1013 - val_accuracy: 0.9552\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0310 - accuracy: 0.9889 - val_loss: 0.1220 - val_accuracy: 0.9403\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0713 - accuracy: 0.9759 - val_loss: 0.0493 - val_accuracy: 0.9851\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.0584 - val_accuracy: 0.9701\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 0.0855 - val_accuracy: 0.9701\n",
      "Epoch 297: early stopping\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5906 - accuracy: 0.8413\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.6608 - accuracy: 0.1056 - val_loss: 1.6589 - val_accuracy: 0.0896\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.5946 - accuracy: 0.1556 - val_loss: 1.6438 - val_accuracy: 0.0896\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.5546 - accuracy: 0.1704 - val_loss: 1.6005 - val_accuracy: 0.1045\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.5172 - accuracy: 0.2389 - val_loss: 1.5743 - val_accuracy: 0.7612\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.4832 - accuracy: 0.3611 - val_loss: 1.5628 - val_accuracy: 0.7612\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.4425 - accuracy: 0.5444 - val_loss: 1.5922 - val_accuracy: 0.1791\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.4364 - accuracy: 0.5704 - val_loss: 1.5797 - val_accuracy: 0.2985\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.4257 - accuracy: 0.6407 - val_loss: 1.5569 - val_accuracy: 0.5821\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.4044 - accuracy: 0.6741 - val_loss: 1.5859 - val_accuracy: 0.2090\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 1.3938 - accuracy: 0.7204 - val_loss: 1.5881 - val_accuracy: 0.2537\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.3844 - accuracy: 0.7074 - val_loss: 1.5777 - val_accuracy: 0.3284\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.3620 - accuracy: 0.7148 - val_loss: 1.5185 - val_accuracy: 0.5373\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.3196 - accuracy: 0.7444 - val_loss: 1.4725 - val_accuracy: 0.5373\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.2782 - accuracy: 0.7852 - val_loss: 1.4318 - val_accuracy: 0.6119\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 1.2506 - accuracy: 0.8056 - val_loss: 1.4018 - val_accuracy: 0.6269\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.2083 - accuracy: 0.8241 - val_loss: 1.3315 - val_accuracy: 0.7164\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.1900 - accuracy: 0.8074 - val_loss: 1.2273 - val_accuracy: 0.8358\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.1456 - accuracy: 0.8222 - val_loss: 1.1675 - val_accuracy: 0.8209\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.0954 - accuracy: 0.8315 - val_loss: 1.0817 - val_accuracy: 0.8657\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 1.0622 - accuracy: 0.8296 - val_loss: 1.0194 - val_accuracy: 0.8657\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.0145 - accuracy: 0.8333 - val_loss: 0.9686 - val_accuracy: 0.8507\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.9598 - accuracy: 0.8463 - val_loss: 0.9188 - val_accuracy: 0.8657\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.9364 - accuracy: 0.8444 - val_loss: 0.8581 - val_accuracy: 0.8358\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.9055 - accuracy: 0.8241 - val_loss: 0.8078 - val_accuracy: 0.8358\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.8616 - accuracy: 0.8537 - val_loss: 0.7631 - val_accuracy: 0.8209\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.8180 - accuracy: 0.8426 - val_loss: 0.7259 - val_accuracy: 0.8209\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.7809 - accuracy: 0.8500 - val_loss: 0.7004 - val_accuracy: 0.8209\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.7447 - accuracy: 0.8463 - val_loss: 0.6692 - val_accuracy: 0.8358\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.7010 - accuracy: 0.8574 - val_loss: 0.6366 - val_accuracy: 0.8358\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6954 - accuracy: 0.8389 - val_loss: 0.6192 - val_accuracy: 0.8209\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6630 - accuracy: 0.8333 - val_loss: 0.6010 - val_accuracy: 0.8209\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6372 - accuracy: 0.8315 - val_loss: 0.5910 - val_accuracy: 0.8358\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.6102 - accuracy: 0.8722 - val_loss: 0.5599 - val_accuracy: 0.8209\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5877 - accuracy: 0.8667 - val_loss: 0.5542 - val_accuracy: 0.8209\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5606 - accuracy: 0.8593 - val_loss: 0.5510 - val_accuracy: 0.8209\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5605 - accuracy: 0.8500 - val_loss: 0.5346 - val_accuracy: 0.8358\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5510 - accuracy: 0.8426 - val_loss: 0.5172 - val_accuracy: 0.8358\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.5281 - accuracy: 0.8685 - val_loss: 0.5033 - val_accuracy: 0.8358\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5142 - accuracy: 0.8537 - val_loss: 0.5096 - val_accuracy: 0.8358\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.5129 - accuracy: 0.8574 - val_loss: 0.5058 - val_accuracy: 0.8358\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4921 - accuracy: 0.8593 - val_loss: 0.5002 - val_accuracy: 0.8358\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4647 - accuracy: 0.8704 - val_loss: 0.4950 - val_accuracy: 0.8358\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4970 - accuracy: 0.8537 - val_loss: 0.5038 - val_accuracy: 0.8358\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4413 - accuracy: 0.8722 - val_loss: 0.4939 - val_accuracy: 0.8358\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4212 - accuracy: 0.8796 - val_loss: 0.4996 - val_accuracy: 0.8209\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4284 - accuracy: 0.8796 - val_loss: 0.4782 - val_accuracy: 0.8209\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4567 - accuracy: 0.8630 - val_loss: 0.4668 - val_accuracy: 0.8209\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3847 - accuracy: 0.9037 - val_loss: 0.4497 - val_accuracy: 0.8358\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4275 - accuracy: 0.8685 - val_loss: 0.4398 - val_accuracy: 0.8209\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3857 - accuracy: 0.9074 - val_loss: 0.4632 - val_accuracy: 0.8209\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3667 - accuracy: 0.9000 - val_loss: 0.4352 - val_accuracy: 0.8507\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3874 - accuracy: 0.8796 - val_loss: 0.4067 - val_accuracy: 0.8507\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3957 - accuracy: 0.8759 - val_loss: 0.4041 - val_accuracy: 0.8507\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3524 - accuracy: 0.8944 - val_loss: 0.4222 - val_accuracy: 0.8657\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8778 - val_loss: 0.4011 - val_accuracy: 0.8657\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3619 - accuracy: 0.8926 - val_loss: 0.3871 - val_accuracy: 0.8806\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3339 - accuracy: 0.9111 - val_loss: 0.4190 - val_accuracy: 0.8507\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3537 - accuracy: 0.8944 - val_loss: 0.4295 - val_accuracy: 0.8507\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3732 - accuracy: 0.9019 - val_loss: 0.4361 - val_accuracy: 0.8806\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3591 - accuracy: 0.8963 - val_loss: 0.4021 - val_accuracy: 0.8955\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3130 - accuracy: 0.9000 - val_loss: 0.3760 - val_accuracy: 0.8806\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3130 - accuracy: 0.9130 - val_loss: 0.3776 - val_accuracy: 0.8806\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.9148 - val_loss: 0.3592 - val_accuracy: 0.8955\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2954 - accuracy: 0.9111 - val_loss: 0.3369 - val_accuracy: 0.8955\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2989 - accuracy: 0.9019 - val_loss: 0.3614 - val_accuracy: 0.8657\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2959 - accuracy: 0.9148 - val_loss: 0.3655 - val_accuracy: 0.8806\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3047 - accuracy: 0.8963 - val_loss: 0.3241 - val_accuracy: 0.8955\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3184 - accuracy: 0.8963 - val_loss: 0.3168 - val_accuracy: 0.8955\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2804 - accuracy: 0.9185 - val_loss: 0.3207 - val_accuracy: 0.8955\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2734 - accuracy: 0.9204 - val_loss: 0.3379 - val_accuracy: 0.8806\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2943 - accuracy: 0.9074 - val_loss: 0.3601 - val_accuracy: 0.8657\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2652 - accuracy: 0.9241 - val_loss: 0.3805 - val_accuracy: 0.8806\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2972 - accuracy: 0.8981 - val_loss: 0.3655 - val_accuracy: 0.8657\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2513 - accuracy: 0.9426 - val_loss: 0.3397 - val_accuracy: 0.8806\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2460 - accuracy: 0.9370 - val_loss: 0.3351 - val_accuracy: 0.8806\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2388 - accuracy: 0.9389 - val_loss: 0.3196 - val_accuracy: 0.8955\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2670 - accuracy: 0.9167 - val_loss: 0.3091 - val_accuracy: 0.8806\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2447 - accuracy: 0.9278 - val_loss: 0.3290 - val_accuracy: 0.8657\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2631 - accuracy: 0.9148 - val_loss: 0.3115 - val_accuracy: 0.8806\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2429 - accuracy: 0.9296 - val_loss: 0.3312 - val_accuracy: 0.8657\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2542 - accuracy: 0.9222 - val_loss: 0.3122 - val_accuracy: 0.8955\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2447 - accuracy: 0.9389 - val_loss: 0.3594 - val_accuracy: 0.8657\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2341 - accuracy: 0.9130 - val_loss: 0.3412 - val_accuracy: 0.8507\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2295 - accuracy: 0.9333 - val_loss: 0.3112 - val_accuracy: 0.8806\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2598 - accuracy: 0.9185 - val_loss: 0.3012 - val_accuracy: 0.8657\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2226 - accuracy: 0.9444 - val_loss: 0.3065 - val_accuracy: 0.8657\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2205 - accuracy: 0.9444 - val_loss: 0.2973 - val_accuracy: 0.8806\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2343 - accuracy: 0.9444 - val_loss: 0.2831 - val_accuracy: 0.8955\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2040 - accuracy: 0.9463 - val_loss: 0.2835 - val_accuracy: 0.8955\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1869 - accuracy: 0.9593 - val_loss: 0.2930 - val_accuracy: 0.8806\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2067 - accuracy: 0.9463 - val_loss: 0.3218 - val_accuracy: 0.8507\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1800 - accuracy: 0.9667 - val_loss: 0.3339 - val_accuracy: 0.8507\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2057 - accuracy: 0.9481 - val_loss: 0.2857 - val_accuracy: 0.8806\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2025 - accuracy: 0.9481 - val_loss: 0.2729 - val_accuracy: 0.8806\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1887 - accuracy: 0.9500 - val_loss: 0.2673 - val_accuracy: 0.9104\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1952 - accuracy: 0.9407 - val_loss: 0.2524 - val_accuracy: 0.9254\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1915 - accuracy: 0.9389 - val_loss: 0.2574 - val_accuracy: 0.8955\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1644 - accuracy: 0.9611 - val_loss: 0.2530 - val_accuracy: 0.8955\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1660 - accuracy: 0.9574 - val_loss: 0.2713 - val_accuracy: 0.8955\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1941 - accuracy: 0.9481 - val_loss: 0.2566 - val_accuracy: 0.8955\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1825 - accuracy: 0.9444 - val_loss: 0.2745 - val_accuracy: 0.8955\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1677 - accuracy: 0.9537 - val_loss: 0.2650 - val_accuracy: 0.8955\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1568 - accuracy: 0.9648 - val_loss: 0.2425 - val_accuracy: 0.9104\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1699 - accuracy: 0.9593 - val_loss: 0.2705 - val_accuracy: 0.8955\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1816 - accuracy: 0.9481 - val_loss: 0.3078 - val_accuracy: 0.8806\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1955 - accuracy: 0.9426 - val_loss: 0.2536 - val_accuracy: 0.9104\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1639 - accuracy: 0.9537 - val_loss: 0.2669 - val_accuracy: 0.9104\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1496 - accuracy: 0.9722 - val_loss: 0.2570 - val_accuracy: 0.9104\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1597 - accuracy: 0.9519 - val_loss: 0.2640 - val_accuracy: 0.9104\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1397 - accuracy: 0.9741 - val_loss: 0.3143 - val_accuracy: 0.8657\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2049 - accuracy: 0.9333 - val_loss: 0.2432 - val_accuracy: 0.9104\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1586 - accuracy: 0.9519 - val_loss: 0.2429 - val_accuracy: 0.8955\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1642 - accuracy: 0.9519 - val_loss: 0.2810 - val_accuracy: 0.8955\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1374 - accuracy: 0.9593 - val_loss: 0.2520 - val_accuracy: 0.8955\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1417 - accuracy: 0.9630 - val_loss: 0.2455 - val_accuracy: 0.8955\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1573 - accuracy: 0.9556 - val_loss: 0.2846 - val_accuracy: 0.8806\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1379 - accuracy: 0.9704 - val_loss: 0.2540 - val_accuracy: 0.9104\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1422 - accuracy: 0.9704 - val_loss: 0.2791 - val_accuracy: 0.8955\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1266 - accuracy: 0.9741 - val_loss: 0.2530 - val_accuracy: 0.9104\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1276 - accuracy: 0.9759 - val_loss: 0.2297 - val_accuracy: 0.9254\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.2286 - val_accuracy: 0.9104\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1359 - accuracy: 0.9722 - val_loss: 0.2643 - val_accuracy: 0.9104\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1334 - accuracy: 0.9704 - val_loss: 0.2460 - val_accuracy: 0.9104\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1528 - accuracy: 0.9611 - val_loss: 0.2842 - val_accuracy: 0.8955\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1378 - accuracy: 0.9630 - val_loss: 0.3133 - val_accuracy: 0.8955\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1056 - accuracy: 0.9759 - val_loss: 0.2617 - val_accuracy: 0.8806\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1377 - accuracy: 0.9630 - val_loss: 0.3403 - val_accuracy: 0.8806\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1095 - accuracy: 0.9759 - val_loss: 0.2841 - val_accuracy: 0.8806\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1120 - accuracy: 0.9759 - val_loss: 0.2998 - val_accuracy: 0.8806\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1150 - accuracy: 0.9796 - val_loss: 0.2686 - val_accuracy: 0.9104\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1225 - accuracy: 0.9741 - val_loss: 0.2697 - val_accuracy: 0.8806\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1169 - accuracy: 0.9741 - val_loss: 0.3910 - val_accuracy: 0.8657\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1267 - accuracy: 0.9704 - val_loss: 0.2548 - val_accuracy: 0.8806\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1199 - accuracy: 0.9685 - val_loss: 0.2336 - val_accuracy: 0.8955\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1272 - accuracy: 0.9593 - val_loss: 0.2553 - val_accuracy: 0.8955\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1189 - accuracy: 0.9704 - val_loss: 0.2619 - val_accuracy: 0.8955\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1072 - accuracy: 0.9722 - val_loss: 0.3160 - val_accuracy: 0.8806\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1309 - accuracy: 0.9630 - val_loss: 0.2770 - val_accuracy: 0.8955\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1027 - accuracy: 0.9722 - val_loss: 0.2787 - val_accuracy: 0.8806\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0974 - accuracy: 0.9796 - val_loss: 0.2861 - val_accuracy: 0.8955\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1041 - accuracy: 0.9759 - val_loss: 0.2879 - val_accuracy: 0.8955\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0954 - accuracy: 0.9815 - val_loss: 0.2766 - val_accuracy: 0.8806\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0898 - accuracy: 0.9870 - val_loss: 0.2657 - val_accuracy: 0.8955\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0981 - accuracy: 0.9759 - val_loss: 0.3050 - val_accuracy: 0.8955\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1106 - accuracy: 0.9778 - val_loss: 0.2916 - val_accuracy: 0.9104\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1107 - accuracy: 0.9667 - val_loss: 0.3342 - val_accuracy: 0.8955\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0985 - accuracy: 0.9685 - val_loss: 0.2754 - val_accuracy: 0.9104\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1016 - accuracy: 0.9741 - val_loss: 0.2366 - val_accuracy: 0.9104\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1046 - accuracy: 0.9796 - val_loss: 0.2338 - val_accuracy: 0.9104\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0990 - accuracy: 0.9667 - val_loss: 0.2243 - val_accuracy: 0.9104\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0860 - accuracy: 0.9759 - val_loss: 0.2561 - val_accuracy: 0.8955\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1063 - accuracy: 0.9722 - val_loss: 0.2536 - val_accuracy: 0.8806\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0982 - accuracy: 0.9704 - val_loss: 0.2323 - val_accuracy: 0.8955\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1104 - accuracy: 0.9722 - val_loss: 0.2518 - val_accuracy: 0.8955\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0891 - accuracy: 0.9778 - val_loss: 0.2376 - val_accuracy: 0.8955\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0688 - accuracy: 0.9870 - val_loss: 0.2276 - val_accuracy: 0.9104\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0957 - accuracy: 0.9722 - val_loss: 0.2194 - val_accuracy: 0.9254\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0744 - accuracy: 0.9796 - val_loss: 0.2379 - val_accuracy: 0.9403\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0858 - accuracy: 0.9796 - val_loss: 0.2591 - val_accuracy: 0.9104\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0888 - accuracy: 0.9796 - val_loss: 0.2805 - val_accuracy: 0.8955\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1024 - accuracy: 0.9722 - val_loss: 0.3116 - val_accuracy: 0.8955\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0905 - accuracy: 0.9741 - val_loss: 0.2319 - val_accuracy: 0.9104\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1275 - accuracy: 0.9611 - val_loss: 0.2144 - val_accuracy: 0.9104\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9722 - val_loss: 0.2271 - val_accuracy: 0.8955\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1071 - accuracy: 0.9648 - val_loss: 0.2046 - val_accuracy: 0.9254\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0893 - accuracy: 0.9796 - val_loss: 0.2142 - val_accuracy: 0.9254\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.2265 - val_accuracy: 0.9254\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0981 - accuracy: 0.9796 - val_loss: 0.2202 - val_accuracy: 0.9254\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0745 - accuracy: 0.9833 - val_loss: 0.2329 - val_accuracy: 0.9254\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0651 - accuracy: 0.9907 - val_loss: 0.2491 - val_accuracy: 0.9254\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.2654 - val_accuracy: 0.8955\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0660 - accuracy: 0.9889 - val_loss: 0.2760 - val_accuracy: 0.8955\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0725 - accuracy: 0.9778 - val_loss: 0.2531 - val_accuracy: 0.8955\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0703 - accuracy: 0.9870 - val_loss: 0.2353 - val_accuracy: 0.9254\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1020 - accuracy: 0.9815 - val_loss: 0.2376 - val_accuracy: 0.9254\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0530 - accuracy: 0.9907 - val_loss: 0.2494 - val_accuracy: 0.9254\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0609 - accuracy: 0.9852 - val_loss: 0.2331 - val_accuracy: 0.9254\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0824 - accuracy: 0.9778 - val_loss: 0.2196 - val_accuracy: 0.9254\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0844 - accuracy: 0.9833 - val_loss: 0.2283 - val_accuracy: 0.9254\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0811 - accuracy: 0.9796 - val_loss: 0.2323 - val_accuracy: 0.9104\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0724 - accuracy: 0.9833 - val_loss: 0.2316 - val_accuracy: 0.9254\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0710 - accuracy: 0.9815 - val_loss: 0.2398 - val_accuracy: 0.9254\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0958 - accuracy: 0.9667 - val_loss: 0.2311 - val_accuracy: 0.9254\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0653 - accuracy: 0.9907 - val_loss: 0.2115 - val_accuracy: 0.9254\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0591 - accuracy: 0.9796 - val_loss: 0.2101 - val_accuracy: 0.9104\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0741 - accuracy: 0.9778 - val_loss: 0.2210 - val_accuracy: 0.9104\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0778 - accuracy: 0.9796 - val_loss: 0.2842 - val_accuracy: 0.8657\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0908 - accuracy: 0.9778 - val_loss: 0.2790 - val_accuracy: 0.8955\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.9759 - val_loss: 0.3403 - val_accuracy: 0.8955\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1107 - accuracy: 0.9704 - val_loss: 0.3510 - val_accuracy: 0.8657\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0839 - accuracy: 0.9815 - val_loss: 0.3830 - val_accuracy: 0.8806\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0964 - accuracy: 0.9778 - val_loss: 0.4306 - val_accuracy: 0.8806\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0538 - accuracy: 0.9907 - val_loss: 0.2779 - val_accuracy: 0.9254\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0637 - accuracy: 0.9833 - val_loss: 0.2673 - val_accuracy: 0.9104\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0713 - accuracy: 0.9796 - val_loss: 0.2672 - val_accuracy: 0.9104\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0580 - accuracy: 0.9907 - val_loss: 0.2687 - val_accuracy: 0.9104\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0634 - accuracy: 0.9889 - val_loss: 0.2596 - val_accuracy: 0.8955\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0571 - accuracy: 0.9852 - val_loss: 0.2613 - val_accuracy: 0.8955\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0705 - accuracy: 0.9815 - val_loss: 0.2694 - val_accuracy: 0.9104\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0645 - accuracy: 0.9870 - val_loss: 0.2224 - val_accuracy: 0.9104\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0545 - accuracy: 0.9870 - val_loss: 0.2559 - val_accuracy: 0.9104\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0413 - accuracy: 0.9889 - val_loss: 0.2790 - val_accuracy: 0.9104\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0621 - accuracy: 0.9889 - val_loss: 0.2984 - val_accuracy: 0.9104\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0648 - accuracy: 0.9815 - val_loss: 0.2861 - val_accuracy: 0.9104\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0579 - accuracy: 0.9870 - val_loss: 0.3019 - val_accuracy: 0.9104\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0477 - accuracy: 0.9963 - val_loss: 0.2915 - val_accuracy: 0.9104\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0545 - accuracy: 0.9870 - val_loss: 0.2926 - val_accuracy: 0.9104\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0627 - accuracy: 0.9870 - val_loss: 0.3039 - val_accuracy: 0.9104\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0537 - accuracy: 0.9852 - val_loss: 0.3122 - val_accuracy: 0.8955\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0421 - accuracy: 0.9963 - val_loss: 0.3019 - val_accuracy: 0.8955\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0598 - accuracy: 0.9870 - val_loss: 0.3438 - val_accuracy: 0.8806\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0489 - accuracy: 0.9889 - val_loss: 0.3016 - val_accuracy: 0.9104\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0623 - accuracy: 0.9815 - val_loss: 0.2703 - val_accuracy: 0.9104\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0813 - accuracy: 0.9759 - val_loss: 0.2973 - val_accuracy: 0.9254\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0620 - accuracy: 0.9852 - val_loss: 0.3241 - val_accuracy: 0.8806\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0730 - accuracy: 0.9815 - val_loss: 0.3027 - val_accuracy: 0.9254\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0640 - accuracy: 0.9907 - val_loss: 0.2922 - val_accuracy: 0.9104\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0369 - accuracy: 0.9907 - val_loss: 0.2913 - val_accuracy: 0.8955\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0464 - accuracy: 0.9889 - val_loss: 0.2783 - val_accuracy: 0.8955\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0646 - accuracy: 0.9833 - val_loss: 0.2723 - val_accuracy: 0.9254\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0599 - accuracy: 0.9870 - val_loss: 0.2759 - val_accuracy: 0.9104\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0474 - accuracy: 0.9907 - val_loss: 0.2890 - val_accuracy: 0.9254\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0718 - accuracy: 0.9833 - val_loss: 0.2648 - val_accuracy: 0.8955\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0902 - accuracy: 0.9722 - val_loss: 0.4071 - val_accuracy: 0.8955\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0498 - accuracy: 0.9889 - val_loss: 0.2883 - val_accuracy: 0.8955\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0533 - accuracy: 0.9907 - val_loss: 0.3129 - val_accuracy: 0.8657\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0417 - accuracy: 0.9907 - val_loss: 0.2804 - val_accuracy: 0.8806\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0645 - accuracy: 0.9870 - val_loss: 0.3257 - val_accuracy: 0.9104\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0651 - accuracy: 0.9889 - val_loss: 0.3117 - val_accuracy: 0.9104\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.3111 - val_accuracy: 0.8955\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0476 - accuracy: 0.9889 - val_loss: 0.2948 - val_accuracy: 0.9254\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0455 - accuracy: 0.9852 - val_loss: 0.2651 - val_accuracy: 0.9104\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0483 - accuracy: 0.9926 - val_loss: 0.2681 - val_accuracy: 0.9104\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0445 - accuracy: 0.9926 - val_loss: 0.2479 - val_accuracy: 0.9254\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9889 - val_loss: 0.2478 - val_accuracy: 0.9104\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0404 - accuracy: 0.9889 - val_loss: 0.2564 - val_accuracy: 0.9104\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.2374 - val_accuracy: 0.9104\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0472 - accuracy: 0.9907 - val_loss: 0.2352 - val_accuracy: 0.9254\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.2514 - val_accuracy: 0.9254\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.2489 - val_accuracy: 0.9254\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0407 - accuracy: 0.9926 - val_loss: 0.2713 - val_accuracy: 0.9104\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0584 - accuracy: 0.9870 - val_loss: 0.2948 - val_accuracy: 0.9104\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0530 - accuracy: 0.9815 - val_loss: 0.4522 - val_accuracy: 0.8657\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0604 - accuracy: 0.9833 - val_loss: 0.3783 - val_accuracy: 0.8507\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0543 - accuracy: 0.9833 - val_loss: 0.2399 - val_accuracy: 0.8955\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.2228 - val_accuracy: 0.9104\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0584 - accuracy: 0.9796 - val_loss: 0.2129 - val_accuracy: 0.9254\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9963 - val_loss: 0.2068 - val_accuracy: 0.9104\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 0.9963 - val_loss: 0.2004 - val_accuracy: 0.9254\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9944 - val_loss: 0.2271 - val_accuracy: 0.8955\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0468 - accuracy: 0.9870 - val_loss: 0.2036 - val_accuracy: 0.9104\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9963 - val_loss: 0.1857 - val_accuracy: 0.9254\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0412 - accuracy: 0.9889 - val_loss: 0.1858 - val_accuracy: 0.9254\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0542 - accuracy: 0.9796 - val_loss: 0.2227 - val_accuracy: 0.9104\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0356 - accuracy: 0.9926 - val_loss: 0.2304 - val_accuracy: 0.9254\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0429 - accuracy: 0.9907 - val_loss: 0.2227 - val_accuracy: 0.9254\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0394 - accuracy: 0.9889 - val_loss: 0.2462 - val_accuracy: 0.9104\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0375 - accuracy: 0.9889 - val_loss: 0.2458 - val_accuracy: 0.8955\n",
      "Epoch 258: early stopping\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5682 - accuracy: 0.8130\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 2s 31ms/step - loss: 1.6069 - accuracy: 0.2148 - val_loss: 1.6888 - val_accuracy: 0.0597\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.4552 - accuracy: 0.4241 - val_loss: 1.7798 - val_accuracy: 0.0597\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.2952 - accuracy: 0.6185 - val_loss: 1.8653 - val_accuracy: 0.0597\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.1943 - accuracy: 0.7426 - val_loss: 1.9150 - val_accuracy: 0.0597\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.1118 - accuracy: 0.7685 - val_loss: 1.9350 - val_accuracy: 0.0597\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.0512 - accuracy: 0.7759 - val_loss: 1.9439 - val_accuracy: 0.0597\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.0142 - accuracy: 0.7796 - val_loss: 1.9398 - val_accuracy: 0.0597\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.9738 - accuracy: 0.7907 - val_loss: 1.9463 - val_accuracy: 0.0597\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.9457 - accuracy: 0.7981 - val_loss: 1.9621 - val_accuracy: 0.0597\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.9100 - accuracy: 0.7907 - val_loss: 1.9639 - val_accuracy: 0.0597\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.9042 - accuracy: 0.7815 - val_loss: 1.9519 - val_accuracy: 0.0597\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8321 - accuracy: 0.8037 - val_loss: 1.9134 - val_accuracy: 0.0597\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.8165 - accuracy: 0.8167 - val_loss: 1.8832 - val_accuracy: 0.0597\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7712 - accuracy: 0.8093 - val_loss: 1.8385 - val_accuracy: 0.0597\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.7545 - accuracy: 0.8019 - val_loss: 1.7596 - val_accuracy: 0.0597\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7395 - accuracy: 0.8111 - val_loss: 1.6107 - val_accuracy: 0.3731\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.7373 - accuracy: 0.8167 - val_loss: 1.4265 - val_accuracy: 0.5970\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7065 - accuracy: 0.8111 - val_loss: 1.2367 - val_accuracy: 0.7164\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6779 - accuracy: 0.8185 - val_loss: 1.0617 - val_accuracy: 0.7612\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6916 - accuracy: 0.8130 - val_loss: 0.9655 - val_accuracy: 0.7910\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6652 - accuracy: 0.8093 - val_loss: 0.8358 - val_accuracy: 0.8209\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6510 - accuracy: 0.8222 - val_loss: 0.7329 - val_accuracy: 0.8209\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.6245 - accuracy: 0.8259 - val_loss: 0.6821 - val_accuracy: 0.8209\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6239 - accuracy: 0.8185 - val_loss: 0.6296 - val_accuracy: 0.8358\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5969 - accuracy: 0.8296 - val_loss: 0.5889 - val_accuracy: 0.8358\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.5953 - accuracy: 0.8259 - val_loss: 0.5569 - val_accuracy: 0.8358\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.5429 - accuracy: 0.8296 - val_loss: 0.5072 - val_accuracy: 0.8507\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5728 - accuracy: 0.8259 - val_loss: 0.4908 - val_accuracy: 0.8507\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.5629 - accuracy: 0.8333 - val_loss: 0.4722 - val_accuracy: 0.8507\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5432 - accuracy: 0.8111 - val_loss: 0.4600 - val_accuracy: 0.8507\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.8296 - val_loss: 0.4548 - val_accuracy: 0.8507\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5452 - accuracy: 0.8185 - val_loss: 0.4594 - val_accuracy: 0.8507\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5488 - accuracy: 0.8167 - val_loss: 0.4617 - val_accuracy: 0.8657\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5190 - accuracy: 0.8296 - val_loss: 0.4540 - val_accuracy: 0.8657\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4865 - accuracy: 0.8556 - val_loss: 0.4473 - val_accuracy: 0.8657\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4951 - accuracy: 0.8407 - val_loss: 0.4343 - val_accuracy: 0.8657\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4858 - accuracy: 0.8259 - val_loss: 0.4338 - val_accuracy: 0.8657\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4889 - accuracy: 0.8333 - val_loss: 0.4339 - val_accuracy: 0.8507\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4847 - accuracy: 0.8315 - val_loss: 0.4340 - val_accuracy: 0.8507\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4676 - accuracy: 0.8389 - val_loss: 0.4159 - val_accuracy: 0.8507\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4677 - accuracy: 0.8444 - val_loss: 0.4163 - val_accuracy: 0.8507\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4649 - accuracy: 0.8481 - val_loss: 0.4100 - val_accuracy: 0.8507\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4388 - accuracy: 0.8444 - val_loss: 0.4010 - val_accuracy: 0.8507\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4369 - accuracy: 0.8370 - val_loss: 0.3969 - val_accuracy: 0.8507\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4287 - accuracy: 0.8444 - val_loss: 0.4002 - val_accuracy: 0.8657\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4294 - accuracy: 0.8481 - val_loss: 0.4026 - val_accuracy: 0.8657\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4387 - accuracy: 0.8426 - val_loss: 0.3849 - val_accuracy: 0.8657\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4213 - accuracy: 0.8444 - val_loss: 0.3860 - val_accuracy: 0.8657\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4414 - accuracy: 0.8556 - val_loss: 0.3822 - val_accuracy: 0.8657\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4120 - accuracy: 0.8537 - val_loss: 0.3743 - val_accuracy: 0.8657\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3876 - accuracy: 0.8611 - val_loss: 0.3757 - val_accuracy: 0.8657\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4067 - accuracy: 0.8519 - val_loss: 0.3981 - val_accuracy: 0.8806\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3994 - accuracy: 0.8574 - val_loss: 0.3747 - val_accuracy: 0.8657\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4030 - accuracy: 0.8556 - val_loss: 0.3787 - val_accuracy: 0.8657\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3863 - accuracy: 0.8611 - val_loss: 0.3694 - val_accuracy: 0.8657\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.3922 - accuracy: 0.8685 - val_loss: 0.3708 - val_accuracy: 0.8657\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3749 - accuracy: 0.8519 - val_loss: 0.3635 - val_accuracy: 0.8507\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3849 - accuracy: 0.8667 - val_loss: 0.3592 - val_accuracy: 0.8507\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3548 - accuracy: 0.8722 - val_loss: 0.3564 - val_accuracy: 0.8657\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3679 - accuracy: 0.8574 - val_loss: 0.3892 - val_accuracy: 0.8657\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3713 - accuracy: 0.8593 - val_loss: 0.3625 - val_accuracy: 0.8657\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3454 - accuracy: 0.8685 - val_loss: 0.3620 - val_accuracy: 0.8657\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3649 - accuracy: 0.8593 - val_loss: 0.3609 - val_accuracy: 0.8657\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3517 - accuracy: 0.8685 - val_loss: 0.3583 - val_accuracy: 0.8507\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3558 - accuracy: 0.8778 - val_loss: 0.3480 - val_accuracy: 0.8806\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3455 - accuracy: 0.8778 - val_loss: 0.3652 - val_accuracy: 0.8955\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3690 - accuracy: 0.8630 - val_loss: 0.3234 - val_accuracy: 0.8657\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3452 - accuracy: 0.8741 - val_loss: 0.3351 - val_accuracy: 0.8955\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3447 - accuracy: 0.8778 - val_loss: 0.3378 - val_accuracy: 0.8806\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3371 - accuracy: 0.8667 - val_loss: 0.3469 - val_accuracy: 0.8955\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3418 - accuracy: 0.8796 - val_loss: 0.3157 - val_accuracy: 0.8806\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3371 - accuracy: 0.8796 - val_loss: 0.3349 - val_accuracy: 0.8955\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3214 - accuracy: 0.8852 - val_loss: 0.3287 - val_accuracy: 0.8955\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3134 - accuracy: 0.8944 - val_loss: 0.3382 - val_accuracy: 0.9104\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3309 - accuracy: 0.8815 - val_loss: 0.3223 - val_accuracy: 0.8955\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3083 - accuracy: 0.8815 - val_loss: 0.3149 - val_accuracy: 0.8955\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3026 - accuracy: 0.9000 - val_loss: 0.3236 - val_accuracy: 0.8955\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3190 - accuracy: 0.8833 - val_loss: 0.3363 - val_accuracy: 0.8806\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3049 - accuracy: 0.8778 - val_loss: 0.3177 - val_accuracy: 0.8806\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2875 - accuracy: 0.8963 - val_loss: 0.3259 - val_accuracy: 0.8806\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3085 - accuracy: 0.8944 - val_loss: 0.3539 - val_accuracy: 0.8806\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3000 - accuracy: 0.9019 - val_loss: 0.3394 - val_accuracy: 0.8806\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2834 - accuracy: 0.9093 - val_loss: 0.3287 - val_accuracy: 0.8806\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3067 - accuracy: 0.9056 - val_loss: 0.3207 - val_accuracy: 0.8507\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2913 - accuracy: 0.9019 - val_loss: 0.3155 - val_accuracy: 0.9104\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2763 - accuracy: 0.9037 - val_loss: 0.3032 - val_accuracy: 0.8955\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2703 - accuracy: 0.9074 - val_loss: 0.3140 - val_accuracy: 0.9104\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2958 - accuracy: 0.8981 - val_loss: 0.2990 - val_accuracy: 0.8955\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2619 - accuracy: 0.9074 - val_loss: 0.2981 - val_accuracy: 0.8955\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2624 - accuracy: 0.9019 - val_loss: 0.2844 - val_accuracy: 0.8955\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2790 - accuracy: 0.9167 - val_loss: 0.3010 - val_accuracy: 0.8955\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2861 - accuracy: 0.9037 - val_loss: 0.3165 - val_accuracy: 0.9104\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2686 - accuracy: 0.9148 - val_loss: 0.2965 - val_accuracy: 0.9104\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2472 - accuracy: 0.9185 - val_loss: 0.2879 - val_accuracy: 0.8955\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2688 - accuracy: 0.9296 - val_loss: 0.2928 - val_accuracy: 0.8806\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2560 - accuracy: 0.9185 - val_loss: 0.2866 - val_accuracy: 0.9104\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2549 - accuracy: 0.9241 - val_loss: 0.3290 - val_accuracy: 0.9104\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2343 - accuracy: 0.9296 - val_loss: 0.3456 - val_accuracy: 0.9104\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2515 - accuracy: 0.9259 - val_loss: 0.2953 - val_accuracy: 0.9104\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.2479 - accuracy: 0.9241 - val_loss: 0.2598 - val_accuracy: 0.9104\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2390 - accuracy: 0.9259 - val_loss: 0.3019 - val_accuracy: 0.8955\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2400 - accuracy: 0.9259 - val_loss: 0.2904 - val_accuracy: 0.9104\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2270 - accuracy: 0.9315 - val_loss: 0.2528 - val_accuracy: 0.9104\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2294 - accuracy: 0.9370 - val_loss: 0.2695 - val_accuracy: 0.8955\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2468 - accuracy: 0.9278 - val_loss: 0.2609 - val_accuracy: 0.8955\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2216 - accuracy: 0.9370 - val_loss: 0.2559 - val_accuracy: 0.9104\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2356 - accuracy: 0.9370 - val_loss: 0.2479 - val_accuracy: 0.9104\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.2287 - accuracy: 0.9370 - val_loss: 0.2444 - val_accuracy: 0.9254\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2267 - accuracy: 0.9352 - val_loss: 0.2371 - val_accuracy: 0.9254\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2220 - accuracy: 0.9389 - val_loss: 0.2550 - val_accuracy: 0.9104\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2062 - accuracy: 0.9500 - val_loss: 0.2429 - val_accuracy: 0.8955\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2086 - accuracy: 0.9370 - val_loss: 0.2373 - val_accuracy: 0.8955\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2300 - accuracy: 0.9278 - val_loss: 0.2352 - val_accuracy: 0.8955\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2180 - accuracy: 0.9296 - val_loss: 0.2360 - val_accuracy: 0.8955\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2050 - accuracy: 0.9389 - val_loss: 0.2610 - val_accuracy: 0.9104\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2078 - accuracy: 0.9352 - val_loss: 0.2794 - val_accuracy: 0.9104\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1940 - accuracy: 0.9500 - val_loss: 0.2638 - val_accuracy: 0.9104\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1949 - accuracy: 0.9463 - val_loss: 0.2608 - val_accuracy: 0.9104\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.2063 - accuracy: 0.9259 - val_loss: 0.2741 - val_accuracy: 0.9104\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1811 - accuracy: 0.9556 - val_loss: 0.2146 - val_accuracy: 0.9104\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1794 - accuracy: 0.9426 - val_loss: 0.2184 - val_accuracy: 0.9104\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1844 - accuracy: 0.9519 - val_loss: 0.2153 - val_accuracy: 0.9104\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1802 - accuracy: 0.9481 - val_loss: 0.2140 - val_accuracy: 0.9254\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1820 - accuracy: 0.9648 - val_loss: 0.2195 - val_accuracy: 0.9254\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1763 - accuracy: 0.9574 - val_loss: 0.2277 - val_accuracy: 0.9254\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1649 - accuracy: 0.9593 - val_loss: 0.2226 - val_accuracy: 0.9104\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.2093 - accuracy: 0.9389 - val_loss: 0.2092 - val_accuracy: 0.9104\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.1729 - accuracy: 0.9537 - val_loss: 0.2178 - val_accuracy: 0.9403\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1624 - accuracy: 0.9481 - val_loss: 0.2317 - val_accuracy: 0.9104\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1576 - accuracy: 0.9519 - val_loss: 0.2885 - val_accuracy: 0.9104\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1797 - accuracy: 0.9444 - val_loss: 0.2720 - val_accuracy: 0.9104\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1515 - accuracy: 0.9556 - val_loss: 0.2154 - val_accuracy: 0.9403\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1442 - accuracy: 0.9630 - val_loss: 0.2175 - val_accuracy: 0.9254\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1389 - accuracy: 0.9648 - val_loss: 0.2207 - val_accuracy: 0.9254\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1402 - accuracy: 0.9685 - val_loss: 0.2145 - val_accuracy: 0.9254\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1498 - accuracy: 0.9593 - val_loss: 0.2239 - val_accuracy: 0.9254\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1385 - accuracy: 0.9722 - val_loss: 0.2337 - val_accuracy: 0.9104\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1497 - accuracy: 0.9630 - val_loss: 0.2530 - val_accuracy: 0.9104\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1285 - accuracy: 0.9704 - val_loss: 0.2647 - val_accuracy: 0.9104\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1377 - accuracy: 0.9685 - val_loss: 0.2055 - val_accuracy: 0.9254\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1307 - accuracy: 0.9648 - val_loss: 0.2362 - val_accuracy: 0.9104\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1241 - accuracy: 0.9704 - val_loss: 0.2173 - val_accuracy: 0.9254\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1350 - accuracy: 0.9759 - val_loss: 0.2161 - val_accuracy: 0.9254\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1279 - accuracy: 0.9630 - val_loss: 0.2310 - val_accuracy: 0.9254\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1322 - accuracy: 0.9685 - val_loss: 0.2627 - val_accuracy: 0.9104\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1328 - accuracy: 0.9722 - val_loss: 0.2142 - val_accuracy: 0.9254\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1138 - accuracy: 0.9704 - val_loss: 0.2822 - val_accuracy: 0.9104\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1114 - accuracy: 0.9833 - val_loss: 0.2213 - val_accuracy: 0.9104\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1085 - accuracy: 0.9759 - val_loss: 0.2238 - val_accuracy: 0.9104\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1151 - accuracy: 0.9759 - val_loss: 0.2379 - val_accuracy: 0.9254\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1215 - accuracy: 0.9667 - val_loss: 0.2817 - val_accuracy: 0.9104\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1205 - accuracy: 0.9574 - val_loss: 0.2246 - val_accuracy: 0.9254\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1202 - accuracy: 0.9722 - val_loss: 0.2432 - val_accuracy: 0.9254\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1012 - accuracy: 0.9778 - val_loss: 0.2482 - val_accuracy: 0.9104\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1099 - accuracy: 0.9741 - val_loss: 0.2395 - val_accuracy: 0.9104\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1424 - accuracy: 0.9593 - val_loss: 0.2562 - val_accuracy: 0.9104\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1184 - accuracy: 0.9704 - val_loss: 0.2349 - val_accuracy: 0.9254\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1159 - accuracy: 0.9722 - val_loss: 0.2211 - val_accuracy: 0.9254\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1057 - accuracy: 0.9759 - val_loss: 0.2218 - val_accuracy: 0.9403\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1233 - accuracy: 0.9667 - val_loss: 0.2873 - val_accuracy: 0.9104\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0940 - accuracy: 0.9741 - val_loss: 0.3412 - val_accuracy: 0.8955\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0933 - accuracy: 0.9741 - val_loss: 0.2906 - val_accuracy: 0.9104\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1055 - accuracy: 0.9685 - val_loss: 0.2149 - val_accuracy: 0.9403\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1253 - accuracy: 0.9630 - val_loss: 0.2435 - val_accuracy: 0.9104\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0958 - accuracy: 0.9741 - val_loss: 0.2250 - val_accuracy: 0.9254\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1060 - accuracy: 0.9796 - val_loss: 0.2230 - val_accuracy: 0.9254\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.1354 - accuracy: 0.9574 - val_loss: 0.2107 - val_accuracy: 0.9552\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1210 - accuracy: 0.9685 - val_loss: 0.2076 - val_accuracy: 0.9403\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1026 - accuracy: 0.9722 - val_loss: 0.1997 - val_accuracy: 0.9254\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1152 - accuracy: 0.9685 - val_loss: 0.2526 - val_accuracy: 0.9104\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0975 - accuracy: 0.9741 - val_loss: 0.2194 - val_accuracy: 0.9254\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0951 - accuracy: 0.9778 - val_loss: 0.1985 - val_accuracy: 0.9403\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1073 - accuracy: 0.9722 - val_loss: 0.2093 - val_accuracy: 0.9254\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0797 - accuracy: 0.9778 - val_loss: 0.1957 - val_accuracy: 0.9403\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0947 - accuracy: 0.9741 - val_loss: 0.2090 - val_accuracy: 0.9254\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0776 - accuracy: 0.9778 - val_loss: 0.2460 - val_accuracy: 0.9104\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0711 - accuracy: 0.9833 - val_loss: 0.2721 - val_accuracy: 0.9104\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1009 - accuracy: 0.9667 - val_loss: 0.2677 - val_accuracy: 0.9254\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0831 - accuracy: 0.9796 - val_loss: 0.3406 - val_accuracy: 0.9104\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0899 - accuracy: 0.9759 - val_loss: 0.2975 - val_accuracy: 0.9104\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0723 - accuracy: 0.9815 - val_loss: 0.2915 - val_accuracy: 0.8955\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1170 - accuracy: 0.9574 - val_loss: 0.2671 - val_accuracy: 0.9104\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1033 - accuracy: 0.9685 - val_loss: 0.1980 - val_accuracy: 0.9254\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1028 - accuracy: 0.9759 - val_loss: 0.1985 - val_accuracy: 0.9254\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0945 - accuracy: 0.9704 - val_loss: 0.2042 - val_accuracy: 0.9552\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0797 - accuracy: 0.9815 - val_loss: 0.2869 - val_accuracy: 0.9254\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0910 - accuracy: 0.9759 - val_loss: 0.2478 - val_accuracy: 0.9254\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0972 - accuracy: 0.9704 - val_loss: 0.3256 - val_accuracy: 0.9104\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0817 - accuracy: 0.9778 - val_loss: 0.3248 - val_accuracy: 0.9104\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0897 - accuracy: 0.9741 - val_loss: 0.2244 - val_accuracy: 0.9254\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0851 - accuracy: 0.9741 - val_loss: 0.2310 - val_accuracy: 0.9403\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0855 - accuracy: 0.9796 - val_loss: 0.2731 - val_accuracy: 0.9104\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0865 - accuracy: 0.9759 - val_loss: 0.2460 - val_accuracy: 0.9104\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0637 - accuracy: 0.9852 - val_loss: 0.2325 - val_accuracy: 0.9254\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0726 - accuracy: 0.9815 - val_loss: 0.2219 - val_accuracy: 0.9552\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0720 - accuracy: 0.9833 - val_loss: 0.2418 - val_accuracy: 0.9254\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0838 - accuracy: 0.9815 - val_loss: 0.2483 - val_accuracy: 0.9104\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0881 - accuracy: 0.9759 - val_loss: 0.2457 - val_accuracy: 0.9254\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0759 - accuracy: 0.9796 - val_loss: 0.2569 - val_accuracy: 0.9254\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.2417 - val_accuracy: 0.9254\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1257 - accuracy: 0.9593 - val_loss: 0.2822 - val_accuracy: 0.9104\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1022 - accuracy: 0.9667 - val_loss: 0.2890 - val_accuracy: 0.8955\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1007 - accuracy: 0.9648 - val_loss: 0.3263 - val_accuracy: 0.8955\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0882 - accuracy: 0.9741 - val_loss: 0.2460 - val_accuracy: 0.9254\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0959 - accuracy: 0.9722 - val_loss: 0.2336 - val_accuracy: 0.9254\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0893 - accuracy: 0.9704 - val_loss: 0.2427 - val_accuracy: 0.9104\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1175 - accuracy: 0.9667 - val_loss: 0.2379 - val_accuracy: 0.9104\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0879 - accuracy: 0.9778 - val_loss: 0.2512 - val_accuracy: 0.9104\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0811 - accuracy: 0.9778 - val_loss: 0.2146 - val_accuracy: 0.9254\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0971 - accuracy: 0.9741 - val_loss: 0.2508 - val_accuracy: 0.9104\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.2535 - val_accuracy: 0.9104\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1183 - accuracy: 0.9519 - val_loss: 0.2322 - val_accuracy: 0.9254\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0958 - accuracy: 0.9685 - val_loss: 0.2022 - val_accuracy: 0.9403\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0921 - accuracy: 0.9759 - val_loss: 0.2035 - val_accuracy: 0.9403\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0931 - accuracy: 0.9722 - val_loss: 0.2039 - val_accuracy: 0.9552\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0926 - accuracy: 0.9704 - val_loss: 0.2104 - val_accuracy: 0.9403\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0949 - accuracy: 0.9759 - val_loss: 0.2033 - val_accuracy: 0.9403\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1011 - accuracy: 0.9759 - val_loss: 0.2228 - val_accuracy: 0.9254\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0852 - accuracy: 0.9778 - val_loss: 0.2036 - val_accuracy: 0.9403\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1001 - accuracy: 0.9759 - val_loss: 0.1911 - val_accuracy: 0.9403\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0672 - accuracy: 0.9907 - val_loss: 0.1820 - val_accuracy: 0.9403\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.1816 - val_accuracy: 0.9403\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0919 - accuracy: 0.9759 - val_loss: 0.1834 - val_accuracy: 0.9552\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0865 - accuracy: 0.9796 - val_loss: 0.1796 - val_accuracy: 0.9552\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0949 - accuracy: 0.9778 - val_loss: 0.1675 - val_accuracy: 0.9552\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.1594 - val_accuracy: 0.9552\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0689 - accuracy: 0.9889 - val_loss: 0.1926 - val_accuracy: 0.9403\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0705 - accuracy: 0.9852 - val_loss: 0.2519 - val_accuracy: 0.9254\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0874 - accuracy: 0.9685 - val_loss: 0.2620 - val_accuracy: 0.9104\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1037 - accuracy: 0.9667 - val_loss: 0.1875 - val_accuracy: 0.9403\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.1895 - val_accuracy: 0.9403\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0856 - accuracy: 0.9741 - val_loss: 0.1791 - val_accuracy: 0.9552\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0969 - accuracy: 0.9685 - val_loss: 0.1767 - val_accuracy: 0.9552\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0767 - accuracy: 0.9759 - val_loss: 0.1749 - val_accuracy: 0.9552\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0738 - accuracy: 0.9796 - val_loss: 0.1947 - val_accuracy: 0.9403\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0724 - accuracy: 0.9852 - val_loss: 0.1939 - val_accuracy: 0.9403\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0773 - accuracy: 0.9815 - val_loss: 0.1674 - val_accuracy: 0.9552\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0722 - accuracy: 0.9852 - val_loss: 0.1762 - val_accuracy: 0.9403\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0663 - accuracy: 0.9796 - val_loss: 0.2131 - val_accuracy: 0.9254\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0671 - accuracy: 0.9778 - val_loss: 0.2175 - val_accuracy: 0.9254\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0729 - accuracy: 0.9815 - val_loss: 0.2062 - val_accuracy: 0.9403\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0556 - accuracy: 0.9907 - val_loss: 0.1994 - val_accuracy: 0.9403\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.1869 - val_accuracy: 0.9403\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0811 - accuracy: 0.9722 - val_loss: 0.1739 - val_accuracy: 0.9552\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0621 - accuracy: 0.9815 - val_loss: 0.1705 - val_accuracy: 0.9552\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0496 - accuracy: 0.9907 - val_loss: 0.1740 - val_accuracy: 0.9552\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0588 - accuracy: 0.9889 - val_loss: 0.1785 - val_accuracy: 0.9552\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0651 - accuracy: 0.9759 - val_loss: 0.1867 - val_accuracy: 0.9403\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0801 - accuracy: 0.9704 - val_loss: 0.2096 - val_accuracy: 0.9403\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.2057 - val_accuracy: 0.9403\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0706 - accuracy: 0.9815 - val_loss: 0.1825 - val_accuracy: 0.9403\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0592 - accuracy: 0.9833 - val_loss: 0.2371 - val_accuracy: 0.9254\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0588 - accuracy: 0.9833 - val_loss: 0.2601 - val_accuracy: 0.9104\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0727 - accuracy: 0.9704 - val_loss: 0.1789 - val_accuracy: 0.9254\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0743 - accuracy: 0.9759 - val_loss: 0.1951 - val_accuracy: 0.9552\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0517 - accuracy: 0.9889 - val_loss: 0.2132 - val_accuracy: 0.9403\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0591 - accuracy: 0.9833 - val_loss: 0.2119 - val_accuracy: 0.9403\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0516 - accuracy: 0.9889 - val_loss: 0.1847 - val_accuracy: 0.9403\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0578 - accuracy: 0.9852 - val_loss: 0.1749 - val_accuracy: 0.9552\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0698 - accuracy: 0.9833 - val_loss: 0.1710 - val_accuracy: 0.9552\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0547 - accuracy: 0.9907 - val_loss: 0.1764 - val_accuracy: 0.9403\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0573 - accuracy: 0.9833 - val_loss: 0.1797 - val_accuracy: 0.9403\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0531 - accuracy: 0.9889 - val_loss: 0.1841 - val_accuracy: 0.9403\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 0.1792 - val_accuracy: 0.9403\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0448 - accuracy: 0.9944 - val_loss: 0.1765 - val_accuracy: 0.9403\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0720 - accuracy: 0.9704 - val_loss: 0.1706 - val_accuracy: 0.9552\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0405 - accuracy: 0.9926 - val_loss: 0.1680 - val_accuracy: 0.9552\n",
      "Epoch 267: early stopping\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5841 - accuracy: 0.7565\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.6826 - accuracy: 0.0852 - val_loss: 1.6207 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.5396 - accuracy: 0.1222 - val_loss: 1.6355 - val_accuracy: 0.0746\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.4766 - accuracy: 0.2352 - val_loss: 1.6469 - val_accuracy: 0.0746\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.4324 - accuracy: 0.2722 - val_loss: 1.6546 - val_accuracy: 0.0746\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.4210 - accuracy: 0.3407 - val_loss: 1.6297 - val_accuracy: 0.0746\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.3690 - accuracy: 0.4352 - val_loss: 1.5870 - val_accuracy: 0.0746\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.3446 - accuracy: 0.4981 - val_loss: 1.5648 - val_accuracy: 0.0746\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.3126 - accuracy: 0.5889 - val_loss: 1.5325 - val_accuracy: 0.0746\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.2917 - accuracy: 0.6130 - val_loss: 1.4786 - val_accuracy: 0.0746\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.2637 - accuracy: 0.6611 - val_loss: 1.4218 - val_accuracy: 0.0746\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.2442 - accuracy: 0.6870 - val_loss: 1.3676 - val_accuracy: 0.1343\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.2073 - accuracy: 0.7074 - val_loss: 1.3287 - val_accuracy: 0.5522\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.1908 - accuracy: 0.7426 - val_loss: 1.2963 - val_accuracy: 0.7612\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 1.1604 - accuracy: 0.7593 - val_loss: 1.2928 - val_accuracy: 0.7910\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.1145 - accuracy: 0.7722 - val_loss: 1.2570 - val_accuracy: 0.7910\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.0952 - accuracy: 0.7778 - val_loss: 1.2111 - val_accuracy: 0.7910\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.0574 - accuracy: 0.7944 - val_loss: 1.1631 - val_accuracy: 0.7910\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.0529 - accuracy: 0.7667 - val_loss: 1.1272 - val_accuracy: 0.7761\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.0289 - accuracy: 0.7833 - val_loss: 1.0804 - val_accuracy: 0.7761\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.9954 - accuracy: 0.7889 - val_loss: 1.0328 - val_accuracy: 0.7910\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.9826 - accuracy: 0.7796 - val_loss: 0.9832 - val_accuracy: 0.7761\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.9795 - accuracy: 0.7796 - val_loss: 0.9417 - val_accuracy: 0.7910\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.9235 - accuracy: 0.8037 - val_loss: 0.9024 - val_accuracy: 0.8060\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.9212 - accuracy: 0.7963 - val_loss: 0.8713 - val_accuracy: 0.8060\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.8762 - accuracy: 0.7889 - val_loss: 0.8373 - val_accuracy: 0.8060\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.8747 - accuracy: 0.7926 - val_loss: 0.8053 - val_accuracy: 0.8060\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.8415 - accuracy: 0.7944 - val_loss: 0.7794 - val_accuracy: 0.7910\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.8097 - accuracy: 0.8074 - val_loss: 0.7482 - val_accuracy: 0.8060\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.7938 - accuracy: 0.8111 - val_loss: 0.7421 - val_accuracy: 0.7910\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.7881 - accuracy: 0.8000 - val_loss: 0.7195 - val_accuracy: 0.7910\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.7734 - accuracy: 0.8093 - val_loss: 0.7027 - val_accuracy: 0.7910\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.7486 - accuracy: 0.8019 - val_loss: 0.6865 - val_accuracy: 0.7910\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.7153 - accuracy: 0.8167 - val_loss: 0.6664 - val_accuracy: 0.7910\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.7191 - accuracy: 0.8037 - val_loss: 0.6520 - val_accuracy: 0.8060\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.6953 - accuracy: 0.7944 - val_loss: 0.6397 - val_accuracy: 0.8060\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.6935 - accuracy: 0.8019 - val_loss: 0.6269 - val_accuracy: 0.8209\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.6530 - accuracy: 0.8111 - val_loss: 0.6084 - val_accuracy: 0.8358\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.6244 - accuracy: 0.8000 - val_loss: 0.5909 - val_accuracy: 0.8209\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.6314 - accuracy: 0.8130 - val_loss: 0.5713 - val_accuracy: 0.8358\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.6130 - accuracy: 0.8074 - val_loss: 0.5672 - val_accuracy: 0.8060\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.6307 - accuracy: 0.7926 - val_loss: 0.5623 - val_accuracy: 0.8060\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5887 - accuracy: 0.8185 - val_loss: 0.5503 - val_accuracy: 0.8209\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5851 - accuracy: 0.8111 - val_loss: 0.5391 - val_accuracy: 0.8358\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5703 - accuracy: 0.8111 - val_loss: 0.5310 - val_accuracy: 0.8358\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5681 - accuracy: 0.8037 - val_loss: 0.5490 - val_accuracy: 0.8358\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5589 - accuracy: 0.8148 - val_loss: 0.5304 - val_accuracy: 0.8060\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5675 - accuracy: 0.8111 - val_loss: 0.5084 - val_accuracy: 0.8209\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5313 - accuracy: 0.8111 - val_loss: 0.5403 - val_accuracy: 0.8209\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5389 - accuracy: 0.8278 - val_loss: 0.5037 - val_accuracy: 0.8209\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5272 - accuracy: 0.8259 - val_loss: 0.5067 - val_accuracy: 0.8209\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5103 - accuracy: 0.8241 - val_loss: 0.4977 - val_accuracy: 0.8209\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5280 - accuracy: 0.8204 - val_loss: 0.4866 - val_accuracy: 0.8507\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5243 - accuracy: 0.8185 - val_loss: 0.4915 - val_accuracy: 0.8358\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5124 - accuracy: 0.8333 - val_loss: 0.4980 - val_accuracy: 0.7910\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5153 - accuracy: 0.8259 - val_loss: 0.4932 - val_accuracy: 0.8209\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4947 - accuracy: 0.8241 - val_loss: 0.5076 - val_accuracy: 0.7910\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5361 - accuracy: 0.8185 - val_loss: 0.4684 - val_accuracy: 0.8358\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4737 - accuracy: 0.8352 - val_loss: 0.4518 - val_accuracy: 0.8358\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4854 - accuracy: 0.8167 - val_loss: 0.4085 - val_accuracy: 0.8358\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4589 - accuracy: 0.8407 - val_loss: 0.4193 - val_accuracy: 0.8209\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4605 - accuracy: 0.8370 - val_loss: 0.4177 - val_accuracy: 0.8507\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4321 - accuracy: 0.8537 - val_loss: 0.4126 - val_accuracy: 0.8507\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4267 - accuracy: 0.8463 - val_loss: 0.4070 - val_accuracy: 0.8507\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4496 - accuracy: 0.8574 - val_loss: 0.3960 - val_accuracy: 0.8507\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4503 - accuracy: 0.8407 - val_loss: 0.3953 - val_accuracy: 0.8507\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4325 - accuracy: 0.8370 - val_loss: 0.4175 - val_accuracy: 0.8358\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4262 - accuracy: 0.8463 - val_loss: 0.4014 - val_accuracy: 0.8507\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4287 - accuracy: 0.8426 - val_loss: 0.3945 - val_accuracy: 0.8507\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4067 - accuracy: 0.8741 - val_loss: 0.3948 - val_accuracy: 0.8507\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3960 - accuracy: 0.8611 - val_loss: 0.4000 - val_accuracy: 0.8507\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3927 - accuracy: 0.8574 - val_loss: 0.3988 - val_accuracy: 0.8507\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4006 - accuracy: 0.8667 - val_loss: 0.4628 - val_accuracy: 0.8060\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3899 - accuracy: 0.8667 - val_loss: 0.4243 - val_accuracy: 0.8060\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3839 - accuracy: 0.8556 - val_loss: 0.4208 - val_accuracy: 0.8358\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4107 - accuracy: 0.8556 - val_loss: 0.4113 - val_accuracy: 0.8358\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3889 - accuracy: 0.8630 - val_loss: 0.3948 - val_accuracy: 0.8358\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3955 - accuracy: 0.8593 - val_loss: 0.4177 - val_accuracy: 0.8060\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3722 - accuracy: 0.8630 - val_loss: 0.3879 - val_accuracy: 0.8209\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3728 - accuracy: 0.8741 - val_loss: 0.3953 - val_accuracy: 0.8657\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3493 - accuracy: 0.8852 - val_loss: 0.3655 - val_accuracy: 0.8507\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3625 - accuracy: 0.8778 - val_loss: 0.3666 - val_accuracy: 0.8507\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3373 - accuracy: 0.8796 - val_loss: 0.3729 - val_accuracy: 0.8358\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3617 - accuracy: 0.8685 - val_loss: 0.3794 - val_accuracy: 0.8507\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3565 - accuracy: 0.8741 - val_loss: 0.3689 - val_accuracy: 0.8358\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3312 - accuracy: 0.8852 - val_loss: 0.3629 - val_accuracy: 0.8507\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3578 - accuracy: 0.8722 - val_loss: 0.3656 - val_accuracy: 0.8358\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3454 - accuracy: 0.8870 - val_loss: 0.3808 - val_accuracy: 0.8358\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3740 - accuracy: 0.8759 - val_loss: 0.3594 - val_accuracy: 0.8507\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3625 - accuracy: 0.8796 - val_loss: 0.3775 - val_accuracy: 0.8358\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3534 - accuracy: 0.8722 - val_loss: 0.4031 - val_accuracy: 0.8358\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3625 - accuracy: 0.8704 - val_loss: 0.3903 - val_accuracy: 0.8358\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3661 - accuracy: 0.8833 - val_loss: 0.3556 - val_accuracy: 0.8657\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3392 - accuracy: 0.8796 - val_loss: 0.3524 - val_accuracy: 0.8657\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3589 - accuracy: 0.8741 - val_loss: 0.3676 - val_accuracy: 0.8657\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3371 - accuracy: 0.8759 - val_loss: 0.4005 - val_accuracy: 0.8657\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3195 - accuracy: 0.8889 - val_loss: 0.4911 - val_accuracy: 0.8358\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3283 - accuracy: 0.8833 - val_loss: 0.4538 - val_accuracy: 0.8358\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3378 - accuracy: 0.8889 - val_loss: 0.4001 - val_accuracy: 0.8507\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3169 - accuracy: 0.8852 - val_loss: 0.3658 - val_accuracy: 0.8507\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3224 - accuracy: 0.8870 - val_loss: 0.3478 - val_accuracy: 0.8657\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2801 - accuracy: 0.8852 - val_loss: 0.3399 - val_accuracy: 0.8358\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2966 - accuracy: 0.8944 - val_loss: 0.3385 - val_accuracy: 0.8507\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3043 - accuracy: 0.9037 - val_loss: 0.3311 - val_accuracy: 0.8806\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2850 - accuracy: 0.9037 - val_loss: 0.3385 - val_accuracy: 0.8657\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2838 - accuracy: 0.8907 - val_loss: 0.3397 - val_accuracy: 0.8657\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2761 - accuracy: 0.8944 - val_loss: 0.3301 - val_accuracy: 0.8657\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2848 - accuracy: 0.8944 - val_loss: 0.3325 - val_accuracy: 0.8657\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3043 - accuracy: 0.8778 - val_loss: 0.3268 - val_accuracy: 0.8657\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2883 - accuracy: 0.9000 - val_loss: 0.3245 - val_accuracy: 0.8507\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3028 - accuracy: 0.8907 - val_loss: 0.3084 - val_accuracy: 0.8657\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2878 - accuracy: 0.8870 - val_loss: 0.3069 - val_accuracy: 0.8657\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2661 - accuracy: 0.9111 - val_loss: 0.3158 - val_accuracy: 0.8507\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2716 - accuracy: 0.9019 - val_loss: 0.3350 - val_accuracy: 0.8358\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2567 - accuracy: 0.9093 - val_loss: 0.3455 - val_accuracy: 0.8358\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2799 - accuracy: 0.8926 - val_loss: 0.3420 - val_accuracy: 0.8657\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2765 - accuracy: 0.8926 - val_loss: 0.3067 - val_accuracy: 0.8657\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2689 - accuracy: 0.9019 - val_loss: 0.2924 - val_accuracy: 0.8657\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2622 - accuracy: 0.9019 - val_loss: 0.3149 - val_accuracy: 0.8507\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2599 - accuracy: 0.9056 - val_loss: 0.3349 - val_accuracy: 0.8507\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2433 - accuracy: 0.9019 - val_loss: 0.3148 - val_accuracy: 0.8657\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2728 - accuracy: 0.8926 - val_loss: 0.3253 - val_accuracy: 0.8657\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2639 - accuracy: 0.8963 - val_loss: 0.3821 - val_accuracy: 0.8358\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2453 - accuracy: 0.9093 - val_loss: 0.3087 - val_accuracy: 0.8955\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2346 - accuracy: 0.9074 - val_loss: 0.3168 - val_accuracy: 0.8806\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2325 - accuracy: 0.9185 - val_loss: 0.3254 - val_accuracy: 0.8657\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2502 - accuracy: 0.9093 - val_loss: 0.3238 - val_accuracy: 0.8507\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2510 - accuracy: 0.9056 - val_loss: 0.3484 - val_accuracy: 0.8507\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2307 - accuracy: 0.9148 - val_loss: 0.4425 - val_accuracy: 0.8060\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2638 - accuracy: 0.8907 - val_loss: 0.3417 - val_accuracy: 0.8657\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2527 - accuracy: 0.9111 - val_loss: 0.3620 - val_accuracy: 0.8358\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2379 - accuracy: 0.9185 - val_loss: 0.3427 - val_accuracy: 0.8657\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2380 - accuracy: 0.9130 - val_loss: 0.3272 - val_accuracy: 0.8657\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2465 - accuracy: 0.9111 - val_loss: 0.3162 - val_accuracy: 0.8657\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2172 - accuracy: 0.9130 - val_loss: 0.2985 - val_accuracy: 0.8507\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2345 - accuracy: 0.9093 - val_loss: 0.3166 - val_accuracy: 0.8657\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2173 - accuracy: 0.9148 - val_loss: 0.3097 - val_accuracy: 0.8657\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2152 - accuracy: 0.9241 - val_loss: 0.3050 - val_accuracy: 0.8657\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1997 - accuracy: 0.9204 - val_loss: 0.3344 - val_accuracy: 0.8806\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2160 - accuracy: 0.9204 - val_loss: 0.3047 - val_accuracy: 0.8657\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2126 - accuracy: 0.9222 - val_loss: 0.3092 - val_accuracy: 0.8657\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2220 - accuracy: 0.9241 - val_loss: 0.3316 - val_accuracy: 0.8806\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1996 - accuracy: 0.9222 - val_loss: 0.3367 - val_accuracy: 0.8507\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1933 - accuracy: 0.9167 - val_loss: 0.4379 - val_accuracy: 0.8358\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2107 - accuracy: 0.9167 - val_loss: 0.3484 - val_accuracy: 0.8358\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1916 - accuracy: 0.9333 - val_loss: 0.3284 - val_accuracy: 0.8507\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1990 - accuracy: 0.9185 - val_loss: 0.3045 - val_accuracy: 0.8657\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2040 - accuracy: 0.9278 - val_loss: 0.2698 - val_accuracy: 0.8806\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1991 - accuracy: 0.9222 - val_loss: 0.2502 - val_accuracy: 0.8657\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1938 - accuracy: 0.9370 - val_loss: 0.2722 - val_accuracy: 0.8955\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1994 - accuracy: 0.9296 - val_loss: 0.2731 - val_accuracy: 0.8955\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2232 - accuracy: 0.9130 - val_loss: 0.3340 - val_accuracy: 0.8507\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2036 - accuracy: 0.9259 - val_loss: 0.3040 - val_accuracy: 0.8806\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1831 - accuracy: 0.9315 - val_loss: 0.2656 - val_accuracy: 0.8806\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2158 - accuracy: 0.9241 - val_loss: 0.2636 - val_accuracy: 0.8955\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1775 - accuracy: 0.9241 - val_loss: 0.2786 - val_accuracy: 0.8955\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1857 - accuracy: 0.9241 - val_loss: 0.3231 - val_accuracy: 0.8806\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1957 - accuracy: 0.9241 - val_loss: 0.3213 - val_accuracy: 0.8806\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1905 - accuracy: 0.9315 - val_loss: 0.3484 - val_accuracy: 0.8657\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1927 - accuracy: 0.9222 - val_loss: 0.3218 - val_accuracy: 0.8806\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1818 - accuracy: 0.9333 - val_loss: 0.3230 - val_accuracy: 0.8657\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1710 - accuracy: 0.9352 - val_loss: 0.3310 - val_accuracy: 0.8955\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1567 - accuracy: 0.9426 - val_loss: 0.3232 - val_accuracy: 0.8657\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1801 - accuracy: 0.9500 - val_loss: 0.3220 - val_accuracy: 0.8507\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1918 - accuracy: 0.9278 - val_loss: 0.3065 - val_accuracy: 0.8657\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1740 - accuracy: 0.9259 - val_loss: 0.3126 - val_accuracy: 0.8806\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1803 - accuracy: 0.9352 - val_loss: 0.3044 - val_accuracy: 0.8806\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.1727 - accuracy: 0.9444 - val_loss: 0.2898 - val_accuracy: 0.9104\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1972 - accuracy: 0.9315 - val_loss: 0.3697 - val_accuracy: 0.8657\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1865 - accuracy: 0.9259 - val_loss: 0.4070 - val_accuracy: 0.8507\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1705 - accuracy: 0.9278 - val_loss: 0.3485 - val_accuracy: 0.8507\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1771 - accuracy: 0.9296 - val_loss: 0.3488 - val_accuracy: 0.8955\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1707 - accuracy: 0.9444 - val_loss: 0.3580 - val_accuracy: 0.8806\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1827 - accuracy: 0.9333 - val_loss: 0.3276 - val_accuracy: 0.8657\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1759 - accuracy: 0.9370 - val_loss: 0.3197 - val_accuracy: 0.8955\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1560 - accuracy: 0.9519 - val_loss: 0.3145 - val_accuracy: 0.8806\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1599 - accuracy: 0.9352 - val_loss: 0.3142 - val_accuracy: 0.8806\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1701 - accuracy: 0.9315 - val_loss: 0.2796 - val_accuracy: 0.8955\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1577 - accuracy: 0.9481 - val_loss: 0.3554 - val_accuracy: 0.8507\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1679 - accuracy: 0.9519 - val_loss: 0.3501 - val_accuracy: 0.8806\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1836 - accuracy: 0.9500 - val_loss: 0.2984 - val_accuracy: 0.9104\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.1746 - accuracy: 0.9315 - val_loss: 0.2576 - val_accuracy: 0.9254\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1754 - accuracy: 0.9389 - val_loss: 0.2476 - val_accuracy: 0.9254\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1680 - accuracy: 0.9537 - val_loss: 0.2623 - val_accuracy: 0.9104\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1694 - accuracy: 0.9444 - val_loss: 0.2619 - val_accuracy: 0.9104\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1562 - accuracy: 0.9426 - val_loss: 0.2933 - val_accuracy: 0.8955\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1594 - accuracy: 0.9444 - val_loss: 0.2900 - val_accuracy: 0.8955\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1545 - accuracy: 0.9463 - val_loss: 0.3293 - val_accuracy: 0.8955\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1829 - accuracy: 0.9389 - val_loss: 0.3329 - val_accuracy: 0.8806\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1445 - accuracy: 0.9574 - val_loss: 0.3165 - val_accuracy: 0.9104\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1584 - accuracy: 0.9444 - val_loss: 0.2897 - val_accuracy: 0.8955\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1575 - accuracy: 0.9519 - val_loss: 0.3160 - val_accuracy: 0.8806\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1420 - accuracy: 0.9537 - val_loss: 0.2701 - val_accuracy: 0.9254\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1383 - accuracy: 0.9593 - val_loss: 0.2821 - val_accuracy: 0.9254\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1507 - accuracy: 0.9500 - val_loss: 0.3742 - val_accuracy: 0.8657\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1623 - accuracy: 0.9481 - val_loss: 0.3820 - val_accuracy: 0.8657\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1414 - accuracy: 0.9611 - val_loss: 0.2848 - val_accuracy: 0.9104\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1375 - accuracy: 0.9574 - val_loss: 0.2795 - val_accuracy: 0.9254\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1407 - accuracy: 0.9685 - val_loss: 0.2989 - val_accuracy: 0.9104\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1780 - accuracy: 0.9389 - val_loss: 0.2734 - val_accuracy: 0.9254\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1231 - accuracy: 0.9611 - val_loss: 0.2656 - val_accuracy: 0.9254\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1518 - accuracy: 0.9463 - val_loss: 0.2598 - val_accuracy: 0.9403\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1108 - accuracy: 0.9648 - val_loss: 0.2521 - val_accuracy: 0.9403\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1643 - accuracy: 0.9593 - val_loss: 0.2544 - val_accuracy: 0.9403\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1481 - accuracy: 0.9593 - val_loss: 0.2835 - val_accuracy: 0.9254\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1189 - accuracy: 0.9778 - val_loss: 0.2425 - val_accuracy: 0.9403\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1230 - accuracy: 0.9685 - val_loss: 0.2789 - val_accuracy: 0.9254\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1260 - accuracy: 0.9574 - val_loss: 0.2776 - val_accuracy: 0.9403\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1153 - accuracy: 0.9741 - val_loss: 0.2905 - val_accuracy: 0.9254\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1252 - accuracy: 0.9556 - val_loss: 0.2871 - val_accuracy: 0.9403\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1441 - accuracy: 0.9611 - val_loss: 0.2530 - val_accuracy: 0.9403\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1394 - accuracy: 0.9593 - val_loss: 0.2562 - val_accuracy: 0.9403\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1313 - accuracy: 0.9574 - val_loss: 0.2656 - val_accuracy: 0.9104\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1459 - accuracy: 0.9500 - val_loss: 0.2665 - val_accuracy: 0.9104\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1339 - accuracy: 0.9593 - val_loss: 0.2758 - val_accuracy: 0.9104\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1312 - accuracy: 0.9593 - val_loss: 0.2908 - val_accuracy: 0.9254\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1401 - accuracy: 0.9556 - val_loss: 0.2882 - val_accuracy: 0.9254\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1314 - accuracy: 0.9667 - val_loss: 0.2908 - val_accuracy: 0.9104\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1435 - accuracy: 0.9463 - val_loss: 0.2973 - val_accuracy: 0.9254\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1319 - accuracy: 0.9667 - val_loss: 0.2783 - val_accuracy: 0.9254\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1212 - accuracy: 0.9667 - val_loss: 0.2794 - val_accuracy: 0.9254\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1158 - accuracy: 0.9722 - val_loss: 0.3027 - val_accuracy: 0.9254\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0893 - accuracy: 0.9796 - val_loss: 0.2943 - val_accuracy: 0.9254\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1464 - accuracy: 0.9389 - val_loss: 0.3131 - val_accuracy: 0.9403\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1246 - accuracy: 0.9630 - val_loss: 0.3210 - val_accuracy: 0.9403\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1102 - accuracy: 0.9741 - val_loss: 0.3319 - val_accuracy: 0.9104\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1243 - accuracy: 0.9593 - val_loss: 0.4051 - val_accuracy: 0.9104\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1133 - accuracy: 0.9593 - val_loss: 0.4880 - val_accuracy: 0.8955\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1232 - accuracy: 0.9593 - val_loss: 0.3359 - val_accuracy: 0.9403\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.3265 - val_accuracy: 0.9104\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1098 - accuracy: 0.9741 - val_loss: 0.4097 - val_accuracy: 0.8955\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1396 - accuracy: 0.9481 - val_loss: 0.2978 - val_accuracy: 0.9403\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1213 - accuracy: 0.9704 - val_loss: 0.2821 - val_accuracy: 0.9403\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1060 - accuracy: 0.9667 - val_loss: 0.3107 - val_accuracy: 0.9403\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1072 - accuracy: 0.9667 - val_loss: 0.3236 - val_accuracy: 0.9403\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0855 - accuracy: 0.9778 - val_loss: 0.2830 - val_accuracy: 0.9403\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0988 - accuracy: 0.9759 - val_loss: 0.2745 - val_accuracy: 0.9403\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0933 - accuracy: 0.9741 - val_loss: 0.2632 - val_accuracy: 0.9254\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1019 - accuracy: 0.9759 - val_loss: 0.2920 - val_accuracy: 0.9403\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1155 - accuracy: 0.9759 - val_loss: 0.2722 - val_accuracy: 0.9403\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0979 - accuracy: 0.9741 - val_loss: 0.2379 - val_accuracy: 0.8955\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1043 - accuracy: 0.9630 - val_loss: 0.2342 - val_accuracy: 0.9254\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0898 - accuracy: 0.9704 - val_loss: 0.2748 - val_accuracy: 0.9403\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1099 - accuracy: 0.9704 - val_loss: 0.2793 - val_accuracy: 0.9403\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1001 - accuracy: 0.9759 - val_loss: 0.2723 - val_accuracy: 0.9403\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0984 - accuracy: 0.9722 - val_loss: 0.2697 - val_accuracy: 0.9403\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0811 - accuracy: 0.9833 - val_loss: 0.2614 - val_accuracy: 0.9403\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0971 - accuracy: 0.9704 - val_loss: 0.2751 - val_accuracy: 0.9403\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1287 - accuracy: 0.9556 - val_loss: 0.2691 - val_accuracy: 0.9403\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1176 - accuracy: 0.9704 - val_loss: 0.2455 - val_accuracy: 0.9403\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1066 - accuracy: 0.9741 - val_loss: 0.2609 - val_accuracy: 0.9403\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1046 - accuracy: 0.9722 - val_loss: 0.2977 - val_accuracy: 0.9403\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1003 - accuracy: 0.9722 - val_loss: 0.2669 - val_accuracy: 0.9403\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0945 - accuracy: 0.9722 - val_loss: 0.2581 - val_accuracy: 0.9403\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0960 - accuracy: 0.9667 - val_loss: 0.2741 - val_accuracy: 0.9403\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1069 - accuracy: 0.9648 - val_loss: 0.2773 - val_accuracy: 0.9403\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1056 - accuracy: 0.9778 - val_loss: 0.2979 - val_accuracy: 0.9403\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1166 - accuracy: 0.9593 - val_loss: 0.3205 - val_accuracy: 0.9403\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0947 - accuracy: 0.9759 - val_loss: 0.3157 - val_accuracy: 0.9403\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 0.9759 - val_loss: 0.2891 - val_accuracy: 0.9403\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0789 - accuracy: 0.9907 - val_loss: 0.2882 - val_accuracy: 0.9403\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0926 - accuracy: 0.9667 - val_loss: 0.2787 - val_accuracy: 0.9403\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0829 - accuracy: 0.9833 - val_loss: 0.2560 - val_accuracy: 0.9403\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0826 - accuracy: 0.9778 - val_loss: 0.2517 - val_accuracy: 0.9403\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1478 - accuracy: 0.9630 - val_loss: 0.2178 - val_accuracy: 0.9403\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.2899 - val_accuracy: 0.9403\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0860 - accuracy: 0.9722 - val_loss: 0.2590 - val_accuracy: 0.9403\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1011 - accuracy: 0.9648 - val_loss: 0.2541 - val_accuracy: 0.9403\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0745 - accuracy: 0.9852 - val_loss: 0.2756 - val_accuracy: 0.9403\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0860 - accuracy: 0.9796 - val_loss: 0.2709 - val_accuracy: 0.9403\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0742 - accuracy: 0.9778 - val_loss: 0.2837 - val_accuracy: 0.9403\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0785 - accuracy: 0.9778 - val_loss: 0.2722 - val_accuracy: 0.9403\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0939 - accuracy: 0.9648 - val_loss: 0.2703 - val_accuracy: 0.9403\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0755 - accuracy: 0.9778 - val_loss: 0.2788 - val_accuracy: 0.9403\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1066 - accuracy: 0.9648 - val_loss: 0.2992 - val_accuracy: 0.9403\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9704 - val_loss: 0.2996 - val_accuracy: 0.9403\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 0.9722 - val_loss: 0.3023 - val_accuracy: 0.9403\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0943 - accuracy: 0.9741 - val_loss: 0.2858 - val_accuracy: 0.9403\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.2491 - val_accuracy: 0.9403\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0845 - accuracy: 0.9759 - val_loss: 0.2333 - val_accuracy: 0.9403\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0769 - accuracy: 0.9741 - val_loss: 0.2524 - val_accuracy: 0.9403\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0992 - accuracy: 0.9685 - val_loss: 0.2511 - val_accuracy: 0.9403\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0791 - accuracy: 0.9796 - val_loss: 0.2472 - val_accuracy: 0.9403\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0937 - accuracy: 0.9648 - val_loss: 0.2212 - val_accuracy: 0.9104\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0983 - accuracy: 0.9685 - val_loss: 0.2604 - val_accuracy: 0.9403\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0854 - accuracy: 0.9759 - val_loss: 0.2488 - val_accuracy: 0.9403\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0832 - accuracy: 0.9648 - val_loss: 0.2335 - val_accuracy: 0.9403\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0805 - accuracy: 0.9759 - val_loss: 0.2207 - val_accuracy: 0.9403\n",
      "Epoch 288/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0786 - accuracy: 0.9833 - val_loss: 0.2292 - val_accuracy: 0.9403\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0902 - accuracy: 0.9704 - val_loss: 0.2816 - val_accuracy: 0.9403\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0824 - accuracy: 0.9778 - val_loss: 0.3213 - val_accuracy: 0.9403\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9704 - val_loss: 0.2758 - val_accuracy: 0.9403\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0875 - accuracy: 0.9759 - val_loss: 0.2791 - val_accuracy: 0.9403\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0759 - accuracy: 0.9778 - val_loss: 0.2842 - val_accuracy: 0.9403\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0915 - accuracy: 0.9722 - val_loss: 0.2680 - val_accuracy: 0.9403\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0878 - accuracy: 0.9759 - val_loss: 0.2666 - val_accuracy: 0.9403\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.2593 - val_accuracy: 0.9403\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1003 - accuracy: 0.9722 - val_loss: 0.2392 - val_accuracy: 0.9403\n",
      "Epoch 298/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0525 - accuracy: 0.9907 - val_loss: 0.2373 - val_accuracy: 0.9403\n",
      "Epoch 299/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0848 - accuracy: 0.9833 - val_loss: 0.2828 - val_accuracy: 0.9403\n",
      "Epoch 300/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0712 - accuracy: 0.9833 - val_loss: 0.2791 - val_accuracy: 0.9403\n",
      "Epoch 301/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0691 - accuracy: 0.9852 - val_loss: 0.2580 - val_accuracy: 0.9403\n",
      "Epoch 301: early stopping\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5659 - accuracy: 0.7935\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2576 - accuracy: 0.6259 - val_loss: 1.5705 - val_accuracy: 0.5373\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.0681 - accuracy: 0.7167 - val_loss: 1.5432 - val_accuracy: 0.7761\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.9880 - accuracy: 0.7148 - val_loss: 1.5247 - val_accuracy: 0.7612\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.9203 - accuracy: 0.7519 - val_loss: 1.5067 - val_accuracy: 0.7164\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.8712 - accuracy: 0.7611 - val_loss: 1.4930 - val_accuracy: 0.7164\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.8587 - accuracy: 0.7667 - val_loss: 1.4789 - val_accuracy: 0.7164\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.8430 - accuracy: 0.7574 - val_loss: 1.4580 - val_accuracy: 0.7164\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.7857 - accuracy: 0.7593 - val_loss: 1.4240 - val_accuracy: 0.7164\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.7486 - accuracy: 0.7630 - val_loss: 1.2973 - val_accuracy: 0.7164\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.7300 - accuracy: 0.7648 - val_loss: 1.1288 - val_accuracy: 0.7164\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6896 - accuracy: 0.7648 - val_loss: 0.9815 - val_accuracy: 0.7164\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6892 - accuracy: 0.7722 - val_loss: 0.9294 - val_accuracy: 0.7164\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6770 - accuracy: 0.7630 - val_loss: 0.8465 - val_accuracy: 0.7164\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6449 - accuracy: 0.7704 - val_loss: 0.8181 - val_accuracy: 0.7313\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6526 - accuracy: 0.7630 - val_loss: 0.7893 - val_accuracy: 0.7313\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6448 - accuracy: 0.7611 - val_loss: 0.8252 - val_accuracy: 0.7612\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6153 - accuracy: 0.7685 - val_loss: 0.9000 - val_accuracy: 0.7612\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.6079 - accuracy: 0.7704 - val_loss: 0.8879 - val_accuracy: 0.7761\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.5998 - accuracy: 0.7556 - val_loss: 0.8494 - val_accuracy: 0.7910\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.6019 - accuracy: 0.7722 - val_loss: 0.7703 - val_accuracy: 0.7910\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5823 - accuracy: 0.7667 - val_loss: 0.6744 - val_accuracy: 0.7910\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5855 - accuracy: 0.7630 - val_loss: 0.6081 - val_accuracy: 0.7910\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5484 - accuracy: 0.7778 - val_loss: 0.5879 - val_accuracy: 0.7910\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5406 - accuracy: 0.7741 - val_loss: 0.5497 - val_accuracy: 0.7910\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5642 - accuracy: 0.7722 - val_loss: 0.5288 - val_accuracy: 0.7910\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5502 - accuracy: 0.7704 - val_loss: 0.5241 - val_accuracy: 0.7910\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5352 - accuracy: 0.7667 - val_loss: 0.5070 - val_accuracy: 0.7910\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.7667 - val_loss: 0.4880 - val_accuracy: 0.7910\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5132 - accuracy: 0.7741 - val_loss: 0.4874 - val_accuracy: 0.7910\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5140 - accuracy: 0.7741 - val_loss: 0.4766 - val_accuracy: 0.7910\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5164 - accuracy: 0.7722 - val_loss: 0.4608 - val_accuracy: 0.7910\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.5142 - accuracy: 0.7704 - val_loss: 0.4505 - val_accuracy: 0.7910\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.5092 - accuracy: 0.7778 - val_loss: 0.4518 - val_accuracy: 0.7910\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4985 - accuracy: 0.7685 - val_loss: 0.4418 - val_accuracy: 0.7910\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4935 - accuracy: 0.7704 - val_loss: 0.4346 - val_accuracy: 0.7910\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4936 - accuracy: 0.7722 - val_loss: 0.4393 - val_accuracy: 0.7910\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4864 - accuracy: 0.7704 - val_loss: 0.4319 - val_accuracy: 0.7910\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4836 - accuracy: 0.7648 - val_loss: 0.4326 - val_accuracy: 0.7910\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4765 - accuracy: 0.7796 - val_loss: 0.4277 - val_accuracy: 0.7910\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4867 - accuracy: 0.7759 - val_loss: 0.4403 - val_accuracy: 0.7910\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.4295 - val_accuracy: 0.7910\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.4326 - val_accuracy: 0.7910\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4706 - accuracy: 0.7759 - val_loss: 0.4233 - val_accuracy: 0.7910\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4660 - accuracy: 0.7759 - val_loss: 0.4303 - val_accuracy: 0.7910\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4714 - accuracy: 0.7722 - val_loss: 0.4249 - val_accuracy: 0.7910\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4213 - val_accuracy: 0.7910\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4597 - accuracy: 0.7741 - val_loss: 0.4156 - val_accuracy: 0.7910\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4812 - accuracy: 0.7722 - val_loss: 0.4252 - val_accuracy: 0.7910\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4496 - accuracy: 0.7759 - val_loss: 0.4041 - val_accuracy: 0.7910\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.4125 - val_accuracy: 0.7910\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4482 - accuracy: 0.7778 - val_loss: 0.4020 - val_accuracy: 0.7910\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.7815 - val_loss: 0.4035 - val_accuracy: 0.7910\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.4058 - val_accuracy: 0.7910\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4426 - accuracy: 0.7815 - val_loss: 0.3924 - val_accuracy: 0.7910\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.7778 - val_loss: 0.3971 - val_accuracy: 0.7910\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4249 - accuracy: 0.7796 - val_loss: 0.3957 - val_accuracy: 0.7910\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.3976 - val_accuracy: 0.7910\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4333 - accuracy: 0.7759 - val_loss: 0.3895 - val_accuracy: 0.7910\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4336 - accuracy: 0.7778 - val_loss: 0.3927 - val_accuracy: 0.7910\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4210 - accuracy: 0.7759 - val_loss: 0.3890 - val_accuracy: 0.7910\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4310 - accuracy: 0.7796 - val_loss: 0.3893 - val_accuracy: 0.7910\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4262 - accuracy: 0.7796 - val_loss: 0.3864 - val_accuracy: 0.7910\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.7833 - val_loss: 0.3796 - val_accuracy: 0.7910\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4226 - accuracy: 0.7815 - val_loss: 0.3792 - val_accuracy: 0.7910\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4120 - accuracy: 0.7870 - val_loss: 0.3829 - val_accuracy: 0.7910\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4115 - accuracy: 0.7796 - val_loss: 0.3843 - val_accuracy: 0.7910\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4067 - accuracy: 0.7870 - val_loss: 0.3768 - val_accuracy: 0.7910\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4112 - accuracy: 0.7796 - val_loss: 0.3850 - val_accuracy: 0.7910\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3867 - accuracy: 0.7889 - val_loss: 0.3752 - val_accuracy: 0.7910\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.4040 - accuracy: 0.7833 - val_loss: 0.3732 - val_accuracy: 0.7910\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3988 - accuracy: 0.7944 - val_loss: 0.3703 - val_accuracy: 0.7910\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3881 - accuracy: 0.7907 - val_loss: 0.3732 - val_accuracy: 0.7910\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4002 - accuracy: 0.7852 - val_loss: 0.3748 - val_accuracy: 0.7910\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3985 - accuracy: 0.7870 - val_loss: 0.3779 - val_accuracy: 0.8060\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3869 - accuracy: 0.7926 - val_loss: 0.3632 - val_accuracy: 0.8060\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3962 - accuracy: 0.7889 - val_loss: 0.3674 - val_accuracy: 0.8060\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3949 - accuracy: 0.8000 - val_loss: 0.3535 - val_accuracy: 0.8209\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3850 - accuracy: 0.7926 - val_loss: 0.3557 - val_accuracy: 0.8209\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3819 - accuracy: 0.8019 - val_loss: 0.3524 - val_accuracy: 0.8358\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3897 - accuracy: 0.8000 - val_loss: 0.3516 - val_accuracy: 0.8507\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3775 - accuracy: 0.8037 - val_loss: 0.3557 - val_accuracy: 0.8358\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3764 - accuracy: 0.8074 - val_loss: 0.3815 - val_accuracy: 0.8358\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3793 - accuracy: 0.7981 - val_loss: 0.3535 - val_accuracy: 0.8358\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3708 - accuracy: 0.8074 - val_loss: 0.3495 - val_accuracy: 0.8209\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3627 - accuracy: 0.8204 - val_loss: 0.3416 - val_accuracy: 0.8507\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3662 - accuracy: 0.8204 - val_loss: 0.3502 - val_accuracy: 0.8209\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3615 - accuracy: 0.8278 - val_loss: 0.3594 - val_accuracy: 0.8657\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3681 - accuracy: 0.8222 - val_loss: 0.3520 - val_accuracy: 0.8358\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3759 - accuracy: 0.8204 - val_loss: 0.3715 - val_accuracy: 0.8209\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3575 - accuracy: 0.8315 - val_loss: 0.3543 - val_accuracy: 0.8358\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3614 - accuracy: 0.8185 - val_loss: 0.3467 - val_accuracy: 0.8358\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3764 - accuracy: 0.8222 - val_loss: 0.3430 - val_accuracy: 0.8507\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3668 - accuracy: 0.8333 - val_loss: 0.3431 - val_accuracy: 0.8657\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3646 - accuracy: 0.8352 - val_loss: 0.3413 - val_accuracy: 0.8209\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3449 - accuracy: 0.8426 - val_loss: 0.3351 - val_accuracy: 0.8358\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3704 - accuracy: 0.8389 - val_loss: 0.3364 - val_accuracy: 0.8657\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3561 - accuracy: 0.8296 - val_loss: 0.3380 - val_accuracy: 0.8806\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3715 - accuracy: 0.8481 - val_loss: 0.3305 - val_accuracy: 0.8358\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3399 - accuracy: 0.8630 - val_loss: 0.3282 - val_accuracy: 0.8507\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3356 - accuracy: 0.8370 - val_loss: 0.3246 - val_accuracy: 0.8358\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3478 - accuracy: 0.8333 - val_loss: 0.3203 - val_accuracy: 0.8507\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3455 - accuracy: 0.8500 - val_loss: 0.3163 - val_accuracy: 0.8507\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3316 - accuracy: 0.8444 - val_loss: 0.3140 - val_accuracy: 0.8507\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3498 - accuracy: 0.8463 - val_loss: 0.3158 - val_accuracy: 0.8507\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3260 - accuracy: 0.8722 - val_loss: 0.3229 - val_accuracy: 0.8507\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3338 - accuracy: 0.8519 - val_loss: 0.3162 - val_accuracy: 0.8657\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3333 - accuracy: 0.8778 - val_loss: 0.3124 - val_accuracy: 0.8955\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3217 - accuracy: 0.8815 - val_loss: 0.3145 - val_accuracy: 0.8507\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3206 - accuracy: 0.8667 - val_loss: 0.3252 - val_accuracy: 0.8507\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3290 - accuracy: 0.8648 - val_loss: 0.3158 - val_accuracy: 0.8955\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3138 - accuracy: 0.8796 - val_loss: 0.3136 - val_accuracy: 0.8806\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3112 - accuracy: 0.8815 - val_loss: 0.3035 - val_accuracy: 0.9104\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3348 - accuracy: 0.8519 - val_loss: 0.3033 - val_accuracy: 0.8806\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3247 - accuracy: 0.8648 - val_loss: 0.3000 - val_accuracy: 0.8955\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3012 - accuracy: 0.8833 - val_loss: 0.2999 - val_accuracy: 0.8955\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3229 - accuracy: 0.8778 - val_loss: 0.3082 - val_accuracy: 0.8955\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.8815 - val_loss: 0.3064 - val_accuracy: 0.8955\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2977 - accuracy: 0.8870 - val_loss: 0.2974 - val_accuracy: 0.9104\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3037 - accuracy: 0.8833 - val_loss: 0.3020 - val_accuracy: 0.8507\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3225 - accuracy: 0.8574 - val_loss: 0.2916 - val_accuracy: 0.8806\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3060 - accuracy: 0.8667 - val_loss: 0.2906 - val_accuracy: 0.8806\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.3062 - accuracy: 0.8889 - val_loss: 0.2927 - val_accuracy: 0.8806\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.3086 - accuracy: 0.8815 - val_loss: 0.2920 - val_accuracy: 0.8955\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2913 - accuracy: 0.8981 - val_loss: 0.3030 - val_accuracy: 0.8955\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2912 - accuracy: 0.8981 - val_loss: 0.3029 - val_accuracy: 0.9104\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.2807 - accuracy: 0.9019 - val_loss: 0.2828 - val_accuracy: 0.9254\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2808 - accuracy: 0.9074 - val_loss: 0.2683 - val_accuracy: 0.9254\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2899 - accuracy: 0.9000 - val_loss: 0.2609 - val_accuracy: 0.9254\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2826 - accuracy: 0.9000 - val_loss: 0.2616 - val_accuracy: 0.9254\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2858 - accuracy: 0.8944 - val_loss: 0.2583 - val_accuracy: 0.9254\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2822 - accuracy: 0.9019 - val_loss: 0.2609 - val_accuracy: 0.9104\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2826 - accuracy: 0.9093 - val_loss: 0.2632 - val_accuracy: 0.8955\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2650 - accuracy: 0.8944 - val_loss: 0.2684 - val_accuracy: 0.9104\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2745 - accuracy: 0.9074 - val_loss: 0.2557 - val_accuracy: 0.9104\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2775 - accuracy: 0.9074 - val_loss: 0.2571 - val_accuracy: 0.8955\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2615 - accuracy: 0.9130 - val_loss: 0.2510 - val_accuracy: 0.8955\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2624 - accuracy: 0.9148 - val_loss: 0.2448 - val_accuracy: 0.9104\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2647 - accuracy: 0.9278 - val_loss: 0.2492 - val_accuracy: 0.9254\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2653 - accuracy: 0.9241 - val_loss: 0.2434 - val_accuracy: 0.9104\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2649 - accuracy: 0.9333 - val_loss: 0.2469 - val_accuracy: 0.9104\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2653 - accuracy: 0.9315 - val_loss: 0.2403 - val_accuracy: 0.9254\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2485 - accuracy: 0.9315 - val_loss: 0.2419 - val_accuracy: 0.9104\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2504 - accuracy: 0.9167 - val_loss: 0.2272 - val_accuracy: 0.9254\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.2404 - accuracy: 0.9241 - val_loss: 0.2265 - val_accuracy: 0.9254\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2541 - accuracy: 0.9241 - val_loss: 0.2338 - val_accuracy: 0.9552\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2421 - accuracy: 0.9444 - val_loss: 0.2167 - val_accuracy: 0.9701\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2456 - accuracy: 0.9278 - val_loss: 0.2192 - val_accuracy: 0.9104\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2514 - accuracy: 0.9222 - val_loss: 0.2188 - val_accuracy: 0.9254\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2539 - accuracy: 0.9370 - val_loss: 0.2164 - val_accuracy: 0.9552\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2450 - accuracy: 0.9333 - val_loss: 0.2132 - val_accuracy: 0.9254\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2378 - accuracy: 0.9407 - val_loss: 0.2104 - val_accuracy: 0.9403\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2360 - accuracy: 0.9389 - val_loss: 0.1963 - val_accuracy: 0.9701\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2205 - accuracy: 0.9500 - val_loss: 0.1991 - val_accuracy: 0.9851\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2309 - accuracy: 0.9667 - val_loss: 0.2050 - val_accuracy: 0.9701\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2310 - accuracy: 0.9500 - val_loss: 0.2017 - val_accuracy: 0.9851\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2235 - accuracy: 0.9481 - val_loss: 0.2830 - val_accuracy: 0.9254\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2120 - accuracy: 0.9648 - val_loss: 0.2107 - val_accuracy: 0.9403\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2229 - accuracy: 0.9537 - val_loss: 0.2047 - val_accuracy: 0.9254\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2050 - accuracy: 0.9389 - val_loss: 0.2516 - val_accuracy: 0.9403\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2118 - accuracy: 0.9444 - val_loss: 0.2081 - val_accuracy: 0.9403\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1998 - accuracy: 0.9537 - val_loss: 0.2045 - val_accuracy: 0.9403\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1979 - accuracy: 0.9593 - val_loss: 0.2001 - val_accuracy: 0.9403\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2132 - accuracy: 0.9481 - val_loss: 0.1973 - val_accuracy: 0.9403\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1989 - accuracy: 0.9556 - val_loss: 0.2089 - val_accuracy: 0.9403\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1915 - accuracy: 0.9611 - val_loss: 0.1980 - val_accuracy: 0.9552\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.2054 - accuracy: 0.9556 - val_loss: 0.1963 - val_accuracy: 0.9552\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1891 - accuracy: 0.9593 - val_loss: 0.1853 - val_accuracy: 0.9552\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1795 - accuracy: 0.9648 - val_loss: 0.1878 - val_accuracy: 0.9403\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1989 - accuracy: 0.9519 - val_loss: 0.1820 - val_accuracy: 0.9403\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1982 - accuracy: 0.9667 - val_loss: 0.1882 - val_accuracy: 0.9701\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1869 - accuracy: 0.9630 - val_loss: 0.1722 - val_accuracy: 0.9403\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1867 - accuracy: 0.9667 - val_loss: 0.1724 - val_accuracy: 0.9851\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1897 - accuracy: 0.9593 - val_loss: 0.1588 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1912 - accuracy: 0.9574 - val_loss: 0.1674 - val_accuracy: 0.9851\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 0.9648 - val_loss: 0.1596 - val_accuracy: 0.9851\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1841 - accuracy: 0.9667 - val_loss: 0.1726 - val_accuracy: 0.9552\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1976 - accuracy: 0.9593 - val_loss: 0.1755 - val_accuracy: 0.9403\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1745 - accuracy: 0.9685 - val_loss: 0.1627 - val_accuracy: 0.9701\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1722 - accuracy: 0.9611 - val_loss: 0.1530 - val_accuracy: 0.9701\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1613 - accuracy: 0.9759 - val_loss: 0.1466 - val_accuracy: 0.9851\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1542 - accuracy: 0.9796 - val_loss: 0.1440 - val_accuracy: 0.9701\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1454 - accuracy: 0.9796 - val_loss: 0.1530 - val_accuracy: 0.9701\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1552 - accuracy: 0.9648 - val_loss: 0.1635 - val_accuracy: 0.9552\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1477 - accuracy: 0.9778 - val_loss: 0.1817 - val_accuracy: 0.9701\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1605 - accuracy: 0.9648 - val_loss: 0.1524 - val_accuracy: 0.9701\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1718 - accuracy: 0.9741 - val_loss: 0.1508 - val_accuracy: 0.9851\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1487 - accuracy: 0.9741 - val_loss: 0.1484 - val_accuracy: 0.9701\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1549 - accuracy: 0.9778 - val_loss: 0.1415 - val_accuracy: 0.9701\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1353 - accuracy: 0.9815 - val_loss: 0.1376 - val_accuracy: 0.9552\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1362 - accuracy: 0.9852 - val_loss: 0.1539 - val_accuracy: 0.9403\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1340 - accuracy: 0.9870 - val_loss: 0.1513 - val_accuracy: 0.9701\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1440 - accuracy: 0.9815 - val_loss: 0.1416 - val_accuracy: 0.9552\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1305 - accuracy: 0.9796 - val_loss: 0.1519 - val_accuracy: 0.9552\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1367 - accuracy: 0.9833 - val_loss: 0.1401 - val_accuracy: 0.9701\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1268 - accuracy: 0.9833 - val_loss: 0.1323 - val_accuracy: 0.9701\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1305 - accuracy: 0.9852 - val_loss: 0.1262 - val_accuracy: 0.9701\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1311 - accuracy: 0.9796 - val_loss: 0.1147 - val_accuracy: 0.9851\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1271 - accuracy: 0.9852 - val_loss: 0.1122 - val_accuracy: 0.9851\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1286 - accuracy: 0.9759 - val_loss: 0.1145 - val_accuracy: 0.9701\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1217 - accuracy: 0.9796 - val_loss: 0.1082 - val_accuracy: 0.9701\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1335 - accuracy: 0.9685 - val_loss: 0.1274 - val_accuracy: 0.9701\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1262 - accuracy: 0.9852 - val_loss: 0.1323 - val_accuracy: 0.9552\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1225 - accuracy: 0.9778 - val_loss: 0.1134 - val_accuracy: 0.9552\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1199 - accuracy: 0.9815 - val_loss: 0.1152 - val_accuracy: 0.9552\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1281 - accuracy: 0.9704 - val_loss: 0.1266 - val_accuracy: 0.9701\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1313 - accuracy: 0.9778 - val_loss: 0.1152 - val_accuracy: 0.9701\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1175 - accuracy: 0.9741 - val_loss: 0.1043 - val_accuracy: 0.9701\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1222 - accuracy: 0.9796 - val_loss: 0.1118 - val_accuracy: 0.9701\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1175 - accuracy: 0.9741 - val_loss: 0.1139 - val_accuracy: 0.9701\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0991 - accuracy: 0.9926 - val_loss: 0.1095 - val_accuracy: 0.9552\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1263 - accuracy: 0.9759 - val_loss: 0.1040 - val_accuracy: 0.9851\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1297 - accuracy: 0.9778 - val_loss: 0.1129 - val_accuracy: 0.9701\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1199 - accuracy: 0.9722 - val_loss: 0.1066 - val_accuracy: 0.9851\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1019 - accuracy: 0.9815 - val_loss: 0.1231 - val_accuracy: 0.9701\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1175 - accuracy: 0.9704 - val_loss: 0.1307 - val_accuracy: 0.9552\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0852 - accuracy: 0.9870 - val_loss: 0.1057 - val_accuracy: 0.9552\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1020 - accuracy: 0.9833 - val_loss: 0.1284 - val_accuracy: 0.9552\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1012 - accuracy: 0.9815 - val_loss: 0.1088 - val_accuracy: 0.9701\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0943 - accuracy: 0.9815 - val_loss: 0.1022 - val_accuracy: 0.9701\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1049 - accuracy: 0.9741 - val_loss: 0.0931 - val_accuracy: 0.9701\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0931 - accuracy: 0.9815 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0929 - accuracy: 0.9833 - val_loss: 0.0953 - val_accuracy: 0.9701\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0994 - accuracy: 0.9852 - val_loss: 0.0946 - val_accuracy: 0.9552\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0908 - accuracy: 0.9852 - val_loss: 0.0877 - val_accuracy: 0.9701\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0877 - accuracy: 0.9870 - val_loss: 0.0857 - val_accuracy: 0.9701\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.1041 - accuracy: 0.9815 - val_loss: 0.0950 - val_accuracy: 0.9701\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0857 - accuracy: 0.9926 - val_loss: 0.1025 - val_accuracy: 0.9701\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0916 - accuracy: 0.9778 - val_loss: 0.1138 - val_accuracy: 0.9552\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.9870 - val_loss: 0.0961 - val_accuracy: 0.9701\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0895 - accuracy: 0.9870 - val_loss: 0.0855 - val_accuracy: 0.9701\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0645 - accuracy: 0.9926 - val_loss: 0.1041 - val_accuracy: 0.9701\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0763 - accuracy: 0.9889 - val_loss: 0.1349 - val_accuracy: 0.9552\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0742 - accuracy: 0.9889 - val_loss: 0.1208 - val_accuracy: 0.9403\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1032 - accuracy: 0.9722 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0782 - accuracy: 0.9889 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0664 - accuracy: 0.9926 - val_loss: 0.0739 - val_accuracy: 0.9701\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0837 - accuracy: 0.9852 - val_loss: 0.0676 - val_accuracy: 0.9851\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0723 - accuracy: 0.9870 - val_loss: 0.0659 - val_accuracy: 0.9851\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0907 - accuracy: 0.9778 - val_loss: 0.1037 - val_accuracy: 0.9552\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0808 - accuracy: 0.9907 - val_loss: 0.0786 - val_accuracy: 0.9701\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0750 - accuracy: 0.9889 - val_loss: 0.0758 - val_accuracy: 0.9701\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0852 - accuracy: 0.9833 - val_loss: 0.0776 - val_accuracy: 0.9851\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0770 - accuracy: 0.9907 - val_loss: 0.0703 - val_accuracy: 0.9851\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0830 - accuracy: 0.9889 - val_loss: 0.0751 - val_accuracy: 0.9851\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0640 - accuracy: 0.9944 - val_loss: 0.0771 - val_accuracy: 0.9851\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9926 - val_loss: 0.0773 - val_accuracy: 0.9701\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0639 - accuracy: 0.9926 - val_loss: 0.0764 - val_accuracy: 0.9701\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0685 - accuracy: 0.9889 - val_loss: 0.0631 - val_accuracy: 0.9851\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0746 - accuracy: 0.9852 - val_loss: 0.0776 - val_accuracy: 0.9701\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0672 - accuracy: 0.9926 - val_loss: 0.0692 - val_accuracy: 0.9701\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0587 - accuracy: 0.9889 - val_loss: 0.0776 - val_accuracy: 0.9701\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0676 - accuracy: 0.9870 - val_loss: 0.0769 - val_accuracy: 0.9701\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0643 - accuracy: 0.9889 - val_loss: 0.0729 - val_accuracy: 0.9701\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 0.9926 - val_loss: 0.0807 - val_accuracy: 0.9701\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 0.9926 - val_loss: 0.0823 - val_accuracy: 0.9851\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0585 - accuracy: 0.9833 - val_loss: 0.0817 - val_accuracy: 0.9851\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0531 - accuracy: 0.9963 - val_loss: 0.0879 - val_accuracy: 0.9701\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0566 - accuracy: 0.9889 - val_loss: 0.0789 - val_accuracy: 0.9701\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0682 - accuracy: 0.9796 - val_loss: 0.0638 - val_accuracy: 0.9851\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0665 - accuracy: 0.9852 - val_loss: 0.0709 - val_accuracy: 0.9851\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0581 - accuracy: 0.9889 - val_loss: 0.0777 - val_accuracy: 0.9701\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0496 - accuracy: 0.9926 - val_loss: 0.0905 - val_accuracy: 0.9701\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0570 - accuracy: 0.9944 - val_loss: 0.0711 - val_accuracy: 0.9701\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0489 - accuracy: 0.9981 - val_loss: 0.0830 - val_accuracy: 0.9552\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0503 - accuracy: 0.9963 - val_loss: 0.1085 - val_accuracy: 0.9552\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0646 - accuracy: 0.9833 - val_loss: 0.0714 - val_accuracy: 0.9851\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0392 - accuracy: 0.9981 - val_loss: 0.0797 - val_accuracy: 0.9851\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 0.9944 - val_loss: 0.0856 - val_accuracy: 0.9851\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0640 - accuracy: 0.9889 - val_loss: 0.0794 - val_accuracy: 0.9851\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 0.9944 - val_loss: 0.0723 - val_accuracy: 0.9851\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9851\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0528 - accuracy: 0.9870 - val_loss: 0.0887 - val_accuracy: 0.9701\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.9926 - val_loss: 0.0829 - val_accuracy: 0.9701\n",
      "Epoch 273: early stopping\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.8413\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 2.1488 - accuracy: 0.0963 - val_loss: 1.6437 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 2.0047 - accuracy: 0.1315 - val_loss: 1.6998 - val_accuracy: 0.0299\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.8679 - accuracy: 0.1704 - val_loss: 1.7723 - val_accuracy: 0.0746\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.8375 - accuracy: 0.1981 - val_loss: 1.8425 - val_accuracy: 0.0746\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.7784 - accuracy: 0.2148 - val_loss: 1.8980 - val_accuracy: 0.0746\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.7449 - accuracy: 0.2241 - val_loss: 1.9225 - val_accuracy: 0.0746\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.7584 - accuracy: 0.2333 - val_loss: 1.9580 - val_accuracy: 0.0746\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.6940 - accuracy: 0.2278 - val_loss: 1.9815 - val_accuracy: 0.0746\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.6494 - accuracy: 0.3148 - val_loss: 1.9637 - val_accuracy: 0.0746\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.6156 - accuracy: 0.3093 - val_loss: 1.9263 - val_accuracy: 0.0896\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.6137 - accuracy: 0.3519 - val_loss: 1.9774 - val_accuracy: 0.0896\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.5887 - accuracy: 0.4000 - val_loss: 1.9308 - val_accuracy: 0.0896\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.5841 - accuracy: 0.3981 - val_loss: 1.7573 - val_accuracy: 0.0896\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.5301 - accuracy: 0.4130 - val_loss: 1.6692 - val_accuracy: 0.0746\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.4865 - accuracy: 0.4870 - val_loss: 1.5812 - val_accuracy: 0.0597\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 1.4962 - accuracy: 0.5204 - val_loss: 1.5275 - val_accuracy: 0.1343\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.4820 - accuracy: 0.5185 - val_loss: 1.5072 - val_accuracy: 0.1194\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.4683 - accuracy: 0.5352 - val_loss: 1.4693 - val_accuracy: 0.1642\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 1.4424 - accuracy: 0.5852 - val_loss: 1.4288 - val_accuracy: 0.4179\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.4151 - accuracy: 0.6389 - val_loss: 1.3952 - val_accuracy: 0.5821\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.4000 - accuracy: 0.6370 - val_loss: 1.3660 - val_accuracy: 0.6119\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.3882 - accuracy: 0.6500 - val_loss: 1.3461 - val_accuracy: 0.7463\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 1.3646 - accuracy: 0.6833 - val_loss: 1.3309 - val_accuracy: 0.7761\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 1.3441 - accuracy: 0.6611 - val_loss: 1.3119 - val_accuracy: 0.8060\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.3152 - accuracy: 0.6778 - val_loss: 1.2928 - val_accuracy: 0.7910\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.3140 - accuracy: 0.7019 - val_loss: 1.2733 - val_accuracy: 0.7910\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.2967 - accuracy: 0.7315 - val_loss: 1.2493 - val_accuracy: 0.8209\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.2836 - accuracy: 0.7148 - val_loss: 1.2385 - val_accuracy: 0.8060\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.2652 - accuracy: 0.7444 - val_loss: 1.2100 - val_accuracy: 0.8507\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.2241 - accuracy: 0.7870 - val_loss: 1.1930 - val_accuracy: 0.8507\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.2343 - accuracy: 0.7519 - val_loss: 1.1850 - val_accuracy: 0.8209\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.2002 - accuracy: 0.8148 - val_loss: 1.1565 - val_accuracy: 0.8358\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.1767 - accuracy: 0.7963 - val_loss: 1.1515 - val_accuracy: 0.8209\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.1642 - accuracy: 0.7926 - val_loss: 1.1082 - val_accuracy: 0.8060\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.1514 - accuracy: 0.7963 - val_loss: 1.0810 - val_accuracy: 0.8060\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.1253 - accuracy: 0.8130 - val_loss: 1.0957 - val_accuracy: 0.7910\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.1068 - accuracy: 0.8074 - val_loss: 1.0724 - val_accuracy: 0.7761\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.0886 - accuracy: 0.8167 - val_loss: 1.0432 - val_accuracy: 0.7761\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.0613 - accuracy: 0.8111 - val_loss: 1.0110 - val_accuracy: 0.7910\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.0475 - accuracy: 0.7852 - val_loss: 0.9856 - val_accuracy: 0.8060\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.0062 - accuracy: 0.8074 - val_loss: 0.9715 - val_accuracy: 0.8060\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1.0179 - accuracy: 0.8019 - val_loss: 0.9529 - val_accuracy: 0.8060\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.9833 - accuracy: 0.7870 - val_loss: 0.9341 - val_accuracy: 0.7910\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.9837 - accuracy: 0.7944 - val_loss: 0.9171 - val_accuracy: 0.7761\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.9455 - accuracy: 0.8204 - val_loss: 0.8861 - val_accuracy: 0.8060\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.9166 - accuracy: 0.8111 - val_loss: 0.8584 - val_accuracy: 0.8060\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.8941 - accuracy: 0.8278 - val_loss: 0.8508 - val_accuracy: 0.7910\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.8818 - accuracy: 0.7981 - val_loss: 0.8436 - val_accuracy: 0.7761\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.8618 - accuracy: 0.8111 - val_loss: 0.8324 - val_accuracy: 0.7761\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.8461 - accuracy: 0.8019 - val_loss: 0.8183 - val_accuracy: 0.7761\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.8438 - accuracy: 0.8130 - val_loss: 0.7869 - val_accuracy: 0.7761\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.8139 - accuracy: 0.7944 - val_loss: 0.7729 - val_accuracy: 0.7761\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.7929 - accuracy: 0.8037 - val_loss: 0.7612 - val_accuracy: 0.7761\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.7698 - accuracy: 0.8074 - val_loss: 0.7425 - val_accuracy: 0.7761\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.7585 - accuracy: 0.8130 - val_loss: 0.7260 - val_accuracy: 0.7761\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.7564 - accuracy: 0.7963 - val_loss: 0.7077 - val_accuracy: 0.7761\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.7203 - accuracy: 0.8167 - val_loss: 0.6899 - val_accuracy: 0.7761\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.7205 - accuracy: 0.8000 - val_loss: 0.6793 - val_accuracy: 0.7761\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.7109 - accuracy: 0.8111 - val_loss: 0.6684 - val_accuracy: 0.7761\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6835 - accuracy: 0.8278 - val_loss: 0.6487 - val_accuracy: 0.7761\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.6627 - accuracy: 0.8148 - val_loss: 0.6224 - val_accuracy: 0.7761\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6468 - accuracy: 0.8167 - val_loss: 0.6176 - val_accuracy: 0.7761\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6510 - accuracy: 0.8259 - val_loss: 0.6050 - val_accuracy: 0.7761\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.6404 - accuracy: 0.8370 - val_loss: 0.6018 - val_accuracy: 0.7761\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6262 - accuracy: 0.8333 - val_loss: 0.5890 - val_accuracy: 0.7761\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6205 - accuracy: 0.8148 - val_loss: 0.5781 - val_accuracy: 0.7761\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.6097 - accuracy: 0.8296 - val_loss: 0.5746 - val_accuracy: 0.7761\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.6105 - accuracy: 0.8037 - val_loss: 0.5616 - val_accuracy: 0.7761\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5871 - accuracy: 0.8185 - val_loss: 0.5686 - val_accuracy: 0.7761\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.5699 - accuracy: 0.8296 - val_loss: 0.5652 - val_accuracy: 0.7761\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5671 - accuracy: 0.8352 - val_loss: 0.5567 - val_accuracy: 0.7910\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5753 - accuracy: 0.8241 - val_loss: 0.5482 - val_accuracy: 0.7910\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5551 - accuracy: 0.8241 - val_loss: 0.5676 - val_accuracy: 0.7910\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5589 - accuracy: 0.8315 - val_loss: 0.5318 - val_accuracy: 0.8060\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5271 - accuracy: 0.8370 - val_loss: 0.5093 - val_accuracy: 0.7910\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.5402 - accuracy: 0.8333 - val_loss: 0.5020 - val_accuracy: 0.7910\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5104 - accuracy: 0.8315 - val_loss: 0.4965 - val_accuracy: 0.7910\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5561 - accuracy: 0.8259 - val_loss: 0.4764 - val_accuracy: 0.7910\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.5121 - accuracy: 0.8315 - val_loss: 0.4844 - val_accuracy: 0.7761\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4922 - accuracy: 0.8407 - val_loss: 0.4869 - val_accuracy: 0.7761\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4995 - accuracy: 0.8315 - val_loss: 0.4732 - val_accuracy: 0.7761\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.5044 - accuracy: 0.8204 - val_loss: 0.4729 - val_accuracy: 0.7761\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4941 - accuracy: 0.8259 - val_loss: 0.4683 - val_accuracy: 0.7761\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4586 - accuracy: 0.8481 - val_loss: 0.4715 - val_accuracy: 0.7761\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.4660 - accuracy: 0.8537 - val_loss: 0.4565 - val_accuracy: 0.7761\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4863 - accuracy: 0.8389 - val_loss: 0.4477 - val_accuracy: 0.7910\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4425 - accuracy: 0.8389 - val_loss: 0.4708 - val_accuracy: 0.7910\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 0.8519 - val_loss: 0.4547 - val_accuracy: 0.7761\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4535 - accuracy: 0.8426 - val_loss: 0.4453 - val_accuracy: 0.7910\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4823 - accuracy: 0.8222 - val_loss: 0.4395 - val_accuracy: 0.7612\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4357 - accuracy: 0.8593 - val_loss: 0.4255 - val_accuracy: 0.7612\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4555 - accuracy: 0.8463 - val_loss: 0.4124 - val_accuracy: 0.8060\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4135 - accuracy: 0.8685 - val_loss: 0.4040 - val_accuracy: 0.8060\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4322 - accuracy: 0.8426 - val_loss: 0.3972 - val_accuracy: 0.8060\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4265 - accuracy: 0.8426 - val_loss: 0.4264 - val_accuracy: 0.7910\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.4038 - accuracy: 0.8611 - val_loss: 0.4274 - val_accuracy: 0.7910\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8481 - val_loss: 0.4110 - val_accuracy: 0.7910\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4290 - accuracy: 0.8500 - val_loss: 0.4425 - val_accuracy: 0.7612\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3985 - accuracy: 0.8574 - val_loss: 0.4201 - val_accuracy: 0.7612\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4001 - accuracy: 0.8667 - val_loss: 0.4136 - val_accuracy: 0.7612\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4347 - accuracy: 0.8407 - val_loss: 0.3939 - val_accuracy: 0.7761\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3805 - accuracy: 0.8741 - val_loss: 0.3550 - val_accuracy: 0.8209\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3866 - accuracy: 0.8481 - val_loss: 0.3549 - val_accuracy: 0.7910\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3827 - accuracy: 0.8648 - val_loss: 0.3505 - val_accuracy: 0.8060\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3871 - accuracy: 0.8611 - val_loss: 0.3419 - val_accuracy: 0.8060\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3789 - accuracy: 0.8667 - val_loss: 0.3447 - val_accuracy: 0.8507\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3556 - accuracy: 0.8722 - val_loss: 0.3534 - val_accuracy: 0.8507\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.8722 - val_loss: 0.3643 - val_accuracy: 0.8358\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.8500 - val_loss: 0.3606 - val_accuracy: 0.8358\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3599 - accuracy: 0.8630 - val_loss: 0.3413 - val_accuracy: 0.8358\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.8630 - val_loss: 0.3297 - val_accuracy: 0.8358\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3484 - accuracy: 0.8741 - val_loss: 0.3051 - val_accuracy: 0.8507\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.3539 - accuracy: 0.8685 - val_loss: 0.2969 - val_accuracy: 0.8955\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3350 - accuracy: 0.8630 - val_loss: 0.3066 - val_accuracy: 0.8806\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3654 - accuracy: 0.8611 - val_loss: 0.3078 - val_accuracy: 0.8806\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.3493 - accuracy: 0.8593 - val_loss: 0.3407 - val_accuracy: 0.8806\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3775 - accuracy: 0.8593 - val_loss: 0.3039 - val_accuracy: 0.8806\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3516 - accuracy: 0.8593 - val_loss: 0.3433 - val_accuracy: 0.8358\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3388 - accuracy: 0.8704 - val_loss: 0.3193 - val_accuracy: 0.8358\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3320 - accuracy: 0.8648 - val_loss: 0.3355 - val_accuracy: 0.8507\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3230 - accuracy: 0.8722 - val_loss: 0.3128 - val_accuracy: 0.8507\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3290 - accuracy: 0.8704 - val_loss: 0.2959 - val_accuracy: 0.8806\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3166 - accuracy: 0.8815 - val_loss: 0.3130 - val_accuracy: 0.8657\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3302 - accuracy: 0.8648 - val_loss: 0.2966 - val_accuracy: 0.8806\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3219 - accuracy: 0.8741 - val_loss: 0.2901 - val_accuracy: 0.8806\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8685 - val_loss: 0.2982 - val_accuracy: 0.8806\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3281 - accuracy: 0.8704 - val_loss: 0.3549 - val_accuracy: 0.8507\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3024 - accuracy: 0.8889 - val_loss: 0.2927 - val_accuracy: 0.8955\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2836 - accuracy: 0.8944 - val_loss: 0.3186 - val_accuracy: 0.8657\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.3010 - accuracy: 0.8759 - val_loss: 0.3267 - val_accuracy: 0.8507\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2901 - accuracy: 0.8926 - val_loss: 0.3021 - val_accuracy: 0.8507\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2955 - accuracy: 0.8870 - val_loss: 0.2754 - val_accuracy: 0.8955\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2893 - accuracy: 0.8963 - val_loss: 0.2707 - val_accuracy: 0.8806\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3202 - accuracy: 0.8852 - val_loss: 0.3639 - val_accuracy: 0.8507\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2806 - accuracy: 0.8796 - val_loss: 0.2645 - val_accuracy: 0.8806\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2871 - accuracy: 0.8833 - val_loss: 0.2623 - val_accuracy: 0.8806\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2654 - accuracy: 0.8963 - val_loss: 0.2972 - val_accuracy: 0.8507\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2899 - accuracy: 0.8815 - val_loss: 0.2609 - val_accuracy: 0.9104\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2798 - accuracy: 0.8981 - val_loss: 0.2496 - val_accuracy: 0.9254\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2772 - accuracy: 0.8907 - val_loss: 0.2545 - val_accuracy: 0.8955\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2871 - accuracy: 0.8907 - val_loss: 0.3193 - val_accuracy: 0.8806\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2701 - accuracy: 0.8907 - val_loss: 0.2601 - val_accuracy: 0.8806\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2825 - accuracy: 0.8944 - val_loss: 0.2503 - val_accuracy: 0.8955\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2653 - accuracy: 0.9019 - val_loss: 0.2784 - val_accuracy: 0.8657\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2814 - accuracy: 0.8926 - val_loss: 0.2578 - val_accuracy: 0.9104\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2630 - accuracy: 0.9093 - val_loss: 0.2485 - val_accuracy: 0.9254\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2676 - accuracy: 0.8870 - val_loss: 0.2465 - val_accuracy: 0.8955\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2646 - accuracy: 0.9037 - val_loss: 0.2801 - val_accuracy: 0.8806\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3168 - accuracy: 0.8796 - val_loss: 0.2569 - val_accuracy: 0.8806\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2719 - accuracy: 0.8981 - val_loss: 0.2725 - val_accuracy: 0.8657\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2609 - accuracy: 0.9019 - val_loss: 0.2780 - val_accuracy: 0.8657\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2553 - accuracy: 0.9019 - val_loss: 0.2634 - val_accuracy: 0.9104\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2531 - accuracy: 0.9074 - val_loss: 0.3058 - val_accuracy: 0.8806\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2461 - accuracy: 0.9130 - val_loss: 0.2493 - val_accuracy: 0.8955\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2704 - accuracy: 0.8963 - val_loss: 0.2567 - val_accuracy: 0.8806\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2664 - accuracy: 0.8926 - val_loss: 0.2859 - val_accuracy: 0.8507\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2527 - accuracy: 0.8981 - val_loss: 0.2789 - val_accuracy: 0.8657\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2732 - accuracy: 0.9037 - val_loss: 0.2739 - val_accuracy: 0.8657\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2426 - accuracy: 0.9185 - val_loss: 0.2420 - val_accuracy: 0.8955\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2501 - accuracy: 0.9093 - val_loss: 0.3111 - val_accuracy: 0.8657\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2652 - accuracy: 0.8981 - val_loss: 0.2327 - val_accuracy: 0.9254\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2414 - accuracy: 0.9130 - val_loss: 0.2593 - val_accuracy: 0.8806\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2412 - accuracy: 0.9074 - val_loss: 0.2525 - val_accuracy: 0.8806\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2283 - accuracy: 0.9037 - val_loss: 0.3681 - val_accuracy: 0.8657\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2369 - accuracy: 0.9167 - val_loss: 0.3868 - val_accuracy: 0.8358\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2111 - accuracy: 0.9259 - val_loss: 0.3542 - val_accuracy: 0.8806\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 0.9074 - val_loss: 0.3305 - val_accuracy: 0.8657\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2590 - accuracy: 0.9056 - val_loss: 0.2544 - val_accuracy: 0.8657\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2355 - accuracy: 0.9185 - val_loss: 0.2697 - val_accuracy: 0.8657\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2453 - accuracy: 0.9130 - val_loss: 0.2477 - val_accuracy: 0.8806\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2228 - accuracy: 0.9241 - val_loss: 0.2319 - val_accuracy: 0.8955\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.9056 - val_loss: 0.2580 - val_accuracy: 0.8955\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2335 - accuracy: 0.9130 - val_loss: 0.2607 - val_accuracy: 0.8806\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2576 - accuracy: 0.9130 - val_loss: 0.2442 - val_accuracy: 0.8955\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2138 - accuracy: 0.9296 - val_loss: 0.2440 - val_accuracy: 0.8955\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2186 - accuracy: 0.9278 - val_loss: 0.2411 - val_accuracy: 0.8955\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2230 - accuracy: 0.9111 - val_loss: 0.2540 - val_accuracy: 0.8806\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2261 - accuracy: 0.9241 - val_loss: 0.2343 - val_accuracy: 0.8955\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1920 - accuracy: 0.9352 - val_loss: 0.2422 - val_accuracy: 0.9254\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2025 - accuracy: 0.9315 - val_loss: 0.2320 - val_accuracy: 0.9104\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1880 - accuracy: 0.9352 - val_loss: 0.2304 - val_accuracy: 0.8955\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2195 - accuracy: 0.9259 - val_loss: 0.2243 - val_accuracy: 0.9104\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2088 - accuracy: 0.9204 - val_loss: 0.2204 - val_accuracy: 0.8806\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2088 - accuracy: 0.9333 - val_loss: 0.2249 - val_accuracy: 0.8955\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2195 - accuracy: 0.9259 - val_loss: 0.2294 - val_accuracy: 0.8955\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2074 - accuracy: 0.9333 - val_loss: 0.2229 - val_accuracy: 0.8955\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1882 - accuracy: 0.9500 - val_loss: 0.2167 - val_accuracy: 0.9104\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2036 - accuracy: 0.9241 - val_loss: 0.2202 - val_accuracy: 0.8955\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2099 - accuracy: 0.9315 - val_loss: 0.2176 - val_accuracy: 0.8955\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2013 - accuracy: 0.9333 - val_loss: 0.3808 - val_accuracy: 0.8507\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2211 - accuracy: 0.9278 - val_loss: 0.2683 - val_accuracy: 0.8657\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2082 - accuracy: 0.9370 - val_loss: 0.2520 - val_accuracy: 0.8806\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2375 - accuracy: 0.9093 - val_loss: 0.2257 - val_accuracy: 0.8806\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1918 - accuracy: 0.9407 - val_loss: 0.2184 - val_accuracy: 0.8955\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2009 - accuracy: 0.9241 - val_loss: 0.2643 - val_accuracy: 0.8806\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2050 - accuracy: 0.9296 - val_loss: 0.2188 - val_accuracy: 0.8806\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2221 - accuracy: 0.9352 - val_loss: 0.2283 - val_accuracy: 0.8955\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1850 - accuracy: 0.9352 - val_loss: 0.2095 - val_accuracy: 0.9104\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2335 - accuracy: 0.9167 - val_loss: 0.3593 - val_accuracy: 0.8507\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2389 - accuracy: 0.9185 - val_loss: 0.3217 - val_accuracy: 0.8657\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2092 - accuracy: 0.9148 - val_loss: 0.3468 - val_accuracy: 0.8657\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1908 - accuracy: 0.9389 - val_loss: 0.2614 - val_accuracy: 0.8955\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1868 - accuracy: 0.9333 - val_loss: 0.2293 - val_accuracy: 0.8657\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1806 - accuracy: 0.9444 - val_loss: 0.2385 - val_accuracy: 0.8955\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2137 - accuracy: 0.9352 - val_loss: 0.2558 - val_accuracy: 0.8806\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1882 - accuracy: 0.9444 - val_loss: 0.2300 - val_accuracy: 0.8806\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2020 - accuracy: 0.9222 - val_loss: 0.2214 - val_accuracy: 0.8806\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1979 - accuracy: 0.9278 - val_loss: 0.2346 - val_accuracy: 0.9254\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1736 - accuracy: 0.9463 - val_loss: 0.2484 - val_accuracy: 0.8955\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2003 - accuracy: 0.9389 - val_loss: 0.2408 - val_accuracy: 0.8955\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1845 - accuracy: 0.9407 - val_loss: 0.3050 - val_accuracy: 0.8507\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2126 - accuracy: 0.9370 - val_loss: 0.2509 - val_accuracy: 0.8955\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2323 - accuracy: 0.9130 - val_loss: 0.2699 - val_accuracy: 0.8806\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2018 - accuracy: 0.9352 - val_loss: 0.2777 - val_accuracy: 0.8955\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2021 - accuracy: 0.9389 - val_loss: 0.2416 - val_accuracy: 0.8955\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2027 - accuracy: 0.9370 - val_loss: 0.3120 - val_accuracy: 0.8806\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1855 - accuracy: 0.9370 - val_loss: 0.2330 - val_accuracy: 0.9254\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1716 - accuracy: 0.9389 - val_loss: 0.2374 - val_accuracy: 0.9104\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1514 - accuracy: 0.9648 - val_loss: 0.2231 - val_accuracy: 0.9104\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.2217 - accuracy: 0.9296 - val_loss: 0.2209 - val_accuracy: 0.9104\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1882 - accuracy: 0.9278 - val_loss: 0.2296 - val_accuracy: 0.9104\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1868 - accuracy: 0.9259 - val_loss: 0.2198 - val_accuracy: 0.9104\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1462 - accuracy: 0.9537 - val_loss: 0.2191 - val_accuracy: 0.9104\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1785 - accuracy: 0.9352 - val_loss: 0.2103 - val_accuracy: 0.9254\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1502 - accuracy: 0.9611 - val_loss: 0.2134 - val_accuracy: 0.9104\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1664 - accuracy: 0.9537 - val_loss: 0.2230 - val_accuracy: 0.9104\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1492 - accuracy: 0.9611 - val_loss: 0.2283 - val_accuracy: 0.9254\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1511 - accuracy: 0.9519 - val_loss: 0.2118 - val_accuracy: 0.9104\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1756 - accuracy: 0.9389 - val_loss: 0.2666 - val_accuracy: 0.8806\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1596 - accuracy: 0.9500 - val_loss: 0.2377 - val_accuracy: 0.8955\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1718 - accuracy: 0.9370 - val_loss: 0.2292 - val_accuracy: 0.8955\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1634 - accuracy: 0.9370 - val_loss: 0.2133 - val_accuracy: 0.8955\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1444 - accuracy: 0.9611 - val_loss: 0.2253 - val_accuracy: 0.8955\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.2049 - accuracy: 0.9333 - val_loss: 0.2371 - val_accuracy: 0.8806\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1871 - accuracy: 0.9241 - val_loss: 0.2234 - val_accuracy: 0.9254\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1549 - accuracy: 0.9556 - val_loss: 0.2214 - val_accuracy: 0.9254\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1987 - accuracy: 0.9333 - val_loss: 0.2230 - val_accuracy: 0.9254\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.1502 - accuracy: 0.9463 - val_loss: 0.2164 - val_accuracy: 0.9254\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1585 - accuracy: 0.9444 - val_loss: 0.2032 - val_accuracy: 0.9254\n",
      "Epoch 239: early stopping\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7482 - accuracy: 0.7000\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 2s 31ms/step - loss: 1.5790 - accuracy: 0.1759 - val_loss: 1.5988 - val_accuracy: 0.7612\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.5245 - accuracy: 0.2130 - val_loss: 1.5972 - val_accuracy: 0.7463\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.4842 - accuracy: 0.2259 - val_loss: 1.5990 - val_accuracy: 0.0746\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.4456 - accuracy: 0.3056 - val_loss: 1.5929 - val_accuracy: 0.0597\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.4101 - accuracy: 0.3778 - val_loss: 1.5844 - val_accuracy: 0.3284\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.3714 - accuracy: 0.4722 - val_loss: 1.5525 - val_accuracy: 0.7164\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.3327 - accuracy: 0.5685 - val_loss: 1.5348 - val_accuracy: 0.7164\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.2937 - accuracy: 0.6000 - val_loss: 1.5248 - val_accuracy: 0.7164\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.2848 - accuracy: 0.6241 - val_loss: 1.5148 - val_accuracy: 0.7313\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.2424 - accuracy: 0.6593 - val_loss: 1.4939 - val_accuracy: 0.7313\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.2043 - accuracy: 0.7000 - val_loss: 1.4725 - val_accuracy: 0.7612\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.1882 - accuracy: 0.7167 - val_loss: 1.4389 - val_accuracy: 0.7612\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.1559 - accuracy: 0.7407 - val_loss: 1.4025 - val_accuracy: 0.7761\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.1159 - accuracy: 0.7722 - val_loss: 1.3538 - val_accuracy: 0.7761\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 1.1032 - accuracy: 0.7611 - val_loss: 1.3180 - val_accuracy: 0.7761\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1.0537 - accuracy: 0.7907 - val_loss: 1.2931 - val_accuracy: 0.7910\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1.0408 - accuracy: 0.7630 - val_loss: 1.2109 - val_accuracy: 0.7910\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.9971 - accuracy: 0.7926 - val_loss: 1.1419 - val_accuracy: 0.8060\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.9649 - accuracy: 0.8074 - val_loss: 1.0937 - val_accuracy: 0.8060\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.9403 - accuracy: 0.7981 - val_loss: 1.0250 - val_accuracy: 0.8060\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.9201 - accuracy: 0.8000 - val_loss: 0.9784 - val_accuracy: 0.8060\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8922 - accuracy: 0.8148 - val_loss: 0.9148 - val_accuracy: 0.8358\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8684 - accuracy: 0.7944 - val_loss: 0.8644 - val_accuracy: 0.8209\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8353 - accuracy: 0.8167 - val_loss: 0.8239 - val_accuracy: 0.8358\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.8116 - accuracy: 0.8185 - val_loss: 0.7777 - val_accuracy: 0.8358\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.7913 - accuracy: 0.8185 - val_loss: 0.7325 - val_accuracy: 0.8358\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.7828 - accuracy: 0.8019 - val_loss: 0.7069 - val_accuracy: 0.8507\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.7389 - accuracy: 0.8130 - val_loss: 0.6887 - val_accuracy: 0.8507\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.7227 - accuracy: 0.8037 - val_loss: 0.6588 - val_accuracy: 0.8507\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.7159 - accuracy: 0.8093 - val_loss: 0.6306 - val_accuracy: 0.8507\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6941 - accuracy: 0.8111 - val_loss: 0.6072 - val_accuracy: 0.8507\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6794 - accuracy: 0.8204 - val_loss: 0.5944 - val_accuracy: 0.8358\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6458 - accuracy: 0.8222 - val_loss: 0.5792 - val_accuracy: 0.8358\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6402 - accuracy: 0.8148 - val_loss: 0.5571 - val_accuracy: 0.8358\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6432 - accuracy: 0.8056 - val_loss: 0.5455 - val_accuracy: 0.8209\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6165 - accuracy: 0.8093 - val_loss: 0.5295 - val_accuracy: 0.8209\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.6067 - accuracy: 0.8019 - val_loss: 0.5199 - val_accuracy: 0.8209\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5879 - accuracy: 0.8278 - val_loss: 0.5117 - val_accuracy: 0.8507\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5866 - accuracy: 0.8130 - val_loss: 0.4990 - val_accuracy: 0.8507\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5860 - accuracy: 0.8167 - val_loss: 0.4981 - val_accuracy: 0.8507\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5613 - accuracy: 0.8241 - val_loss: 0.4853 - val_accuracy: 0.8209\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5487 - accuracy: 0.8259 - val_loss: 0.4799 - val_accuracy: 0.8507\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5290 - accuracy: 0.8333 - val_loss: 0.4758 - val_accuracy: 0.8507\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5174 - accuracy: 0.8185 - val_loss: 0.4638 - val_accuracy: 0.8507\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5326 - accuracy: 0.8352 - val_loss: 0.4631 - val_accuracy: 0.8507\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5318 - accuracy: 0.8056 - val_loss: 0.4588 - val_accuracy: 0.8507\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5042 - accuracy: 0.8296 - val_loss: 0.4416 - val_accuracy: 0.8507\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.5023 - accuracy: 0.8426 - val_loss: 0.4351 - val_accuracy: 0.8507\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.4837 - accuracy: 0.8333 - val_loss: 0.4302 - val_accuracy: 0.8806\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4896 - accuracy: 0.8407 - val_loss: 0.4386 - val_accuracy: 0.8806\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4870 - accuracy: 0.8204 - val_loss: 0.4090 - val_accuracy: 0.8806\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4694 - accuracy: 0.8352 - val_loss: 0.4031 - val_accuracy: 0.8806\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4689 - accuracy: 0.8185 - val_loss: 0.4045 - val_accuracy: 0.8806\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4633 - accuracy: 0.8426 - val_loss: 0.3912 - val_accuracy: 0.8955\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4520 - accuracy: 0.8519 - val_loss: 0.3807 - val_accuracy: 0.8955\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4430 - accuracy: 0.8593 - val_loss: 0.3935 - val_accuracy: 0.8955\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4589 - accuracy: 0.8537 - val_loss: 0.3926 - val_accuracy: 0.8955\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4364 - accuracy: 0.8574 - val_loss: 0.3585 - val_accuracy: 0.9254\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4357 - accuracy: 0.8537 - val_loss: 0.3533 - val_accuracy: 0.9104\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.4085 - accuracy: 0.8685 - val_loss: 0.3446 - val_accuracy: 0.9403\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4080 - accuracy: 0.8833 - val_loss: 0.3479 - val_accuracy: 0.9254\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4012 - accuracy: 0.8796 - val_loss: 0.3375 - val_accuracy: 0.8955\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4243 - accuracy: 0.8685 - val_loss: 0.3393 - val_accuracy: 0.9104\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4026 - accuracy: 0.8741 - val_loss: 0.3349 - val_accuracy: 0.8955\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.4003 - accuracy: 0.8833 - val_loss: 0.3090 - val_accuracy: 0.9254\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3770 - accuracy: 0.8963 - val_loss: 0.2985 - val_accuracy: 0.9254\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3973 - accuracy: 0.8907 - val_loss: 0.2967 - val_accuracy: 0.9403\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3765 - accuracy: 0.8796 - val_loss: 0.2997 - val_accuracy: 0.9104\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3585 - accuracy: 0.8870 - val_loss: 0.2963 - val_accuracy: 0.9254\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3620 - accuracy: 0.9037 - val_loss: 0.2913 - val_accuracy: 0.9104\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3561 - accuracy: 0.8981 - val_loss: 0.3105 - val_accuracy: 0.9104\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3284 - accuracy: 0.9278 - val_loss: 0.2863 - val_accuracy: 0.9104\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3318 - accuracy: 0.9204 - val_loss: 0.2837 - val_accuracy: 0.9403\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3287 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.9104\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3219 - accuracy: 0.9130 - val_loss: 0.3223 - val_accuracy: 0.9104\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3330 - accuracy: 0.9111 - val_loss: 0.2821 - val_accuracy: 0.9104\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3115 - accuracy: 0.9315 - val_loss: 0.2555 - val_accuracy: 0.9254\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3059 - accuracy: 0.9315 - val_loss: 0.2505 - val_accuracy: 0.9254\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3316 - accuracy: 0.9093 - val_loss: 0.2418 - val_accuracy: 0.9403\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2957 - accuracy: 0.9315 - val_loss: 0.3104 - val_accuracy: 0.9104\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2985 - accuracy: 0.9222 - val_loss: 0.2455 - val_accuracy: 0.9254\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.2883 - accuracy: 0.9352 - val_loss: 0.2328 - val_accuracy: 0.9552\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2915 - accuracy: 0.9296 - val_loss: 0.2548 - val_accuracy: 0.8955\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2970 - accuracy: 0.9222 - val_loss: 0.2277 - val_accuracy: 0.9254\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2926 - accuracy: 0.9148 - val_loss: 0.2410 - val_accuracy: 0.9104\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2935 - accuracy: 0.9241 - val_loss: 0.2204 - val_accuracy: 0.9403\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2812 - accuracy: 0.9259 - val_loss: 0.2286 - val_accuracy: 0.9552\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2567 - accuracy: 0.9481 - val_loss: 0.2164 - val_accuracy: 0.9552\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2544 - accuracy: 0.9481 - val_loss: 0.2153 - val_accuracy: 0.9403\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2726 - accuracy: 0.9296 - val_loss: 0.2137 - val_accuracy: 0.9552\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2724 - accuracy: 0.9370 - val_loss: 0.2372 - val_accuracy: 0.9403\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.2759 - accuracy: 0.9204 - val_loss: 0.2177 - val_accuracy: 0.9701\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2522 - accuracy: 0.9389 - val_loss: 0.2481 - val_accuracy: 0.9254\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2444 - accuracy: 0.9593 - val_loss: 0.2329 - val_accuracy: 0.9104\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2372 - accuracy: 0.9500 - val_loss: 0.2090 - val_accuracy: 0.9552\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2525 - accuracy: 0.9389 - val_loss: 0.2031 - val_accuracy: 0.9403\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2374 - accuracy: 0.9574 - val_loss: 0.1877 - val_accuracy: 0.9552\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2240 - accuracy: 0.9519 - val_loss: 0.1912 - val_accuracy: 0.9552\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2175 - accuracy: 0.9556 - val_loss: 0.1890 - val_accuracy: 0.9403\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2368 - accuracy: 0.9389 - val_loss: 0.1811 - val_accuracy: 0.9552\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2205 - accuracy: 0.9500 - val_loss: 0.1857 - val_accuracy: 0.9552\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2162 - accuracy: 0.9444 - val_loss: 0.1933 - val_accuracy: 0.9552\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2044 - accuracy: 0.9611 - val_loss: 0.1712 - val_accuracy: 0.9701\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1895 - accuracy: 0.9704 - val_loss: 0.1624 - val_accuracy: 0.9552\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1916 - accuracy: 0.9741 - val_loss: 0.1670 - val_accuracy: 0.9552\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1845 - accuracy: 0.9593 - val_loss: 0.2067 - val_accuracy: 0.9104\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1959 - accuracy: 0.9630 - val_loss: 0.1767 - val_accuracy: 0.9403\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2135 - accuracy: 0.9648 - val_loss: 0.1954 - val_accuracy: 0.9104\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2016 - accuracy: 0.9519 - val_loss: 0.1696 - val_accuracy: 0.9552\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2040 - accuracy: 0.9481 - val_loss: 0.1703 - val_accuracy: 0.9552\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2070 - accuracy: 0.9574 - val_loss: 0.2072 - val_accuracy: 0.9254\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1967 - accuracy: 0.9611 - val_loss: 0.1693 - val_accuracy: 0.9552\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1780 - accuracy: 0.9611 - val_loss: 0.1986 - val_accuracy: 0.9104\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1982 - accuracy: 0.9519 - val_loss: 0.1657 - val_accuracy: 0.9552\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2060 - accuracy: 0.9481 - val_loss: 0.1708 - val_accuracy: 0.9552\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1822 - accuracy: 0.9500 - val_loss: 0.1664 - val_accuracy: 0.9552\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1806 - accuracy: 0.9648 - val_loss: 0.1489 - val_accuracy: 0.9552\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1768 - accuracy: 0.9667 - val_loss: 0.1526 - val_accuracy: 0.9552\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1735 - accuracy: 0.9667 - val_loss: 0.1599 - val_accuracy: 0.9552\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1603 - accuracy: 0.9722 - val_loss: 0.1639 - val_accuracy: 0.9701\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1709 - accuracy: 0.9667 - val_loss: 0.1547 - val_accuracy: 0.9701\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1818 - accuracy: 0.9593 - val_loss: 0.2165 - val_accuracy: 0.8955\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.2034 - accuracy: 0.9556 - val_loss: 0.1735 - val_accuracy: 0.9254\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1804 - accuracy: 0.9537 - val_loss: 0.1635 - val_accuracy: 0.9552\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1486 - accuracy: 0.9741 - val_loss: 0.3317 - val_accuracy: 0.8806\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1438 - accuracy: 0.9759 - val_loss: 0.1519 - val_accuracy: 0.9701\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1634 - accuracy: 0.9611 - val_loss: 0.1510 - val_accuracy: 0.9552\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1473 - accuracy: 0.9648 - val_loss: 0.1464 - val_accuracy: 0.9701\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1509 - accuracy: 0.9667 - val_loss: 0.1501 - val_accuracy: 0.9701\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1347 - accuracy: 0.9759 - val_loss: 0.1860 - val_accuracy: 0.9104\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1592 - accuracy: 0.9667 - val_loss: 0.1449 - val_accuracy: 0.9701\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1621 - accuracy: 0.9667 - val_loss: 0.1384 - val_accuracy: 0.9701\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1299 - accuracy: 0.9815 - val_loss: 0.1301 - val_accuracy: 0.9701\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1400 - accuracy: 0.9796 - val_loss: 0.1452 - val_accuracy: 0.9701\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1334 - accuracy: 0.9741 - val_loss: 0.1371 - val_accuracy: 0.9552\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1281 - accuracy: 0.9815 - val_loss: 0.1309 - val_accuracy: 0.9552\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1352 - accuracy: 0.9704 - val_loss: 0.1272 - val_accuracy: 0.9701\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1138 - accuracy: 0.9907 - val_loss: 0.1756 - val_accuracy: 0.9104\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1239 - accuracy: 0.9759 - val_loss: 0.1425 - val_accuracy: 0.9403\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1191 - accuracy: 0.9815 - val_loss: 0.1327 - val_accuracy: 0.9701\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1235 - accuracy: 0.9833 - val_loss: 0.1299 - val_accuracy: 0.9552\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1204 - accuracy: 0.9796 - val_loss: 0.1519 - val_accuracy: 0.9552\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1158 - accuracy: 0.9852 - val_loss: 0.1573 - val_accuracy: 0.9701\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1183 - accuracy: 0.9741 - val_loss: 0.1368 - val_accuracy: 0.9701\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1285 - accuracy: 0.9796 - val_loss: 0.1326 - val_accuracy: 0.9552\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1094 - accuracy: 0.9778 - val_loss: 0.1320 - val_accuracy: 0.9552\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1270 - accuracy: 0.9722 - val_loss: 0.1288 - val_accuracy: 0.9701\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1408 - accuracy: 0.9722 - val_loss: 0.1570 - val_accuracy: 0.9403\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1289 - accuracy: 0.9741 - val_loss: 0.1352 - val_accuracy: 0.9701\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1184 - accuracy: 0.9704 - val_loss: 0.1257 - val_accuracy: 0.9701\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1107 - accuracy: 0.9722 - val_loss: 0.1239 - val_accuracy: 0.9701\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1155 - accuracy: 0.9778 - val_loss: 0.1582 - val_accuracy: 0.9552\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0996 - accuracy: 0.9889 - val_loss: 0.1268 - val_accuracy: 0.9701\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1028 - accuracy: 0.9833 - val_loss: 0.1313 - val_accuracy: 0.9701\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1046 - accuracy: 0.9796 - val_loss: 0.1305 - val_accuracy: 0.9701\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1208 - accuracy: 0.9833 - val_loss: 0.1328 - val_accuracy: 0.9701\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1195 - accuracy: 0.9759 - val_loss: 0.1306 - val_accuracy: 0.9552\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1149 - accuracy: 0.9611 - val_loss: 0.1272 - val_accuracy: 0.9552\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1022 - accuracy: 0.9759 - val_loss: 0.1215 - val_accuracy: 0.9552\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1066 - accuracy: 0.9741 - val_loss: 0.1358 - val_accuracy: 0.9403\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1052 - accuracy: 0.9759 - val_loss: 0.1682 - val_accuracy: 0.9254\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0922 - accuracy: 0.9833 - val_loss: 0.1693 - val_accuracy: 0.9254\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0841 - accuracy: 0.9796 - val_loss: 0.1369 - val_accuracy: 0.9552\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0927 - accuracy: 0.9815 - val_loss: 0.2390 - val_accuracy: 0.9254\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0877 - accuracy: 0.9833 - val_loss: 0.1451 - val_accuracy: 0.9552\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0940 - accuracy: 0.9815 - val_loss: 0.1417 - val_accuracy: 0.9552\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0935 - accuracy: 0.9815 - val_loss: 0.1415 - val_accuracy: 0.9701\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0990 - accuracy: 0.9852 - val_loss: 0.1412 - val_accuracy: 0.9552\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0822 - accuracy: 0.9852 - val_loss: 0.1279 - val_accuracy: 0.9552\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0818 - accuracy: 0.9833 - val_loss: 0.1164 - val_accuracy: 0.9552\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0869 - accuracy: 0.9852 - val_loss: 0.1187 - val_accuracy: 0.9552\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0942 - accuracy: 0.9778 - val_loss: 0.1473 - val_accuracy: 0.9254\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0841 - accuracy: 0.9833 - val_loss: 0.1323 - val_accuracy: 0.9701\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0941 - accuracy: 0.9778 - val_loss: 0.2742 - val_accuracy: 0.8806\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.0896 - accuracy: 0.9796 - val_loss: 0.1255 - val_accuracy: 0.9851\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.1088 - accuracy: 0.9759 - val_loss: 0.1122 - val_accuracy: 0.9701\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0745 - accuracy: 0.9907 - val_loss: 0.1353 - val_accuracy: 0.9701\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0816 - accuracy: 0.9889 - val_loss: 0.1098 - val_accuracy: 0.9851\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0681 - accuracy: 0.9852 - val_loss: 0.1241 - val_accuracy: 0.9701\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0807 - accuracy: 0.9870 - val_loss: 0.1111 - val_accuracy: 0.9851\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0800 - accuracy: 0.9796 - val_loss: 0.1091 - val_accuracy: 0.9851\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0853 - accuracy: 0.9852 - val_loss: 0.1126 - val_accuracy: 0.9851\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0764 - accuracy: 0.9852 - val_loss: 0.1086 - val_accuracy: 0.9851\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0680 - accuracy: 0.9907 - val_loss: 0.1133 - val_accuracy: 0.9851\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0766 - accuracy: 0.9833 - val_loss: 0.1123 - val_accuracy: 0.9851\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9944 - val_loss: 0.1084 - val_accuracy: 0.9851\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0648 - accuracy: 0.9889 - val_loss: 0.1247 - val_accuracy: 0.9701\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0927 - accuracy: 0.9741 - val_loss: 0.1175 - val_accuracy: 0.9552\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0808 - accuracy: 0.9870 - val_loss: 0.1098 - val_accuracy: 0.9851\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0744 - accuracy: 0.9833 - val_loss: 0.1221 - val_accuracy: 0.9851\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0690 - accuracy: 0.9889 - val_loss: 0.1308 - val_accuracy: 0.9701\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0556 - accuracy: 0.9907 - val_loss: 0.1340 - val_accuracy: 0.9552\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9889 - val_loss: 0.1262 - val_accuracy: 0.9701\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0697 - accuracy: 0.9889 - val_loss: 0.1327 - val_accuracy: 0.9701\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0806 - accuracy: 0.9852 - val_loss: 0.1218 - val_accuracy: 0.9701\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0780 - accuracy: 0.9852 - val_loss: 0.1186 - val_accuracy: 0.9701\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0693 - accuracy: 0.9907 - val_loss: 0.1124 - val_accuracy: 0.9851\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0685 - accuracy: 0.9870 - val_loss: 0.1175 - val_accuracy: 0.9851\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0743 - accuracy: 0.9852 - val_loss: 0.1179 - val_accuracy: 0.9851\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0717 - accuracy: 0.9796 - val_loss: 0.1161 - val_accuracy: 0.9851\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0665 - accuracy: 0.9870 - val_loss: 0.1093 - val_accuracy: 0.9851\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0600 - accuracy: 0.9870 - val_loss: 0.1111 - val_accuracy: 0.9851\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0749 - accuracy: 0.9778 - val_loss: 0.1370 - val_accuracy: 0.9851\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0756 - accuracy: 0.9852 - val_loss: 0.1351 - val_accuracy: 0.9552\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0619 - accuracy: 0.9907 - val_loss: 0.1325 - val_accuracy: 0.9552\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0703 - accuracy: 0.9852 - val_loss: 0.1199 - val_accuracy: 0.9851\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0646 - accuracy: 0.9852 - val_loss: 0.1228 - val_accuracy: 0.9701\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0735 - accuracy: 0.9889 - val_loss: 0.1235 - val_accuracy: 0.9701\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0683 - accuracy: 0.9926 - val_loss: 0.1283 - val_accuracy: 0.9701\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0531 - accuracy: 0.9926 - val_loss: 0.1255 - val_accuracy: 0.9701\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0582 - accuracy: 0.9926 - val_loss: 0.1179 - val_accuracy: 0.9701\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0577 - accuracy: 0.9889 - val_loss: 0.1137 - val_accuracy: 0.9851\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0907 - accuracy: 0.9741 - val_loss: 0.1148 - val_accuracy: 0.9701\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0592 - accuracy: 0.9889 - val_loss: 0.1228 - val_accuracy: 0.9701\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9907 - val_loss: 0.1184 - val_accuracy: 0.9851\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0511 - accuracy: 0.9944 - val_loss: 0.1213 - val_accuracy: 0.9701\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0626 - accuracy: 0.9870 - val_loss: 0.1194 - val_accuracy: 0.9851\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0762 - accuracy: 0.9852 - val_loss: 0.1142 - val_accuracy: 0.9701\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0725 - accuracy: 0.9870 - val_loss: 0.1334 - val_accuracy: 0.9701\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0610 - accuracy: 0.9926 - val_loss: 0.1082 - val_accuracy: 0.9851\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0502 - accuracy: 0.9963 - val_loss: 0.1133 - val_accuracy: 0.9851\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0410 - accuracy: 0.9926 - val_loss: 0.1130 - val_accuracy: 0.9701\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0510 - accuracy: 0.9907 - val_loss: 0.1075 - val_accuracy: 0.9552\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0561 - accuracy: 0.9870 - val_loss: 0.1080 - val_accuracy: 0.9701\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0560 - accuracy: 0.9889 - val_loss: 0.1166 - val_accuracy: 0.9701\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0519 - accuracy: 0.9870 - val_loss: 0.1177 - val_accuracy: 0.9701\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0619 - accuracy: 0.9870 - val_loss: 0.1219 - val_accuracy: 0.9552\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0530 - accuracy: 0.9870 - val_loss: 0.1141 - val_accuracy: 0.9701\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0382 - accuracy: 0.9944 - val_loss: 0.1098 - val_accuracy: 0.9701\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0358 - accuracy: 0.9963 - val_loss: 0.1185 - val_accuracy: 0.9701\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0439 - accuracy: 0.9926 - val_loss: 0.1175 - val_accuracy: 0.9701\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0483 - accuracy: 0.9907 - val_loss: 0.1161 - val_accuracy: 0.9851\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0605 - accuracy: 0.9870 - val_loss: 0.1148 - val_accuracy: 0.9851\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0654 - accuracy: 0.9815 - val_loss: 0.1162 - val_accuracy: 0.9851\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0436 - accuracy: 0.9963 - val_loss: 0.1144 - val_accuracy: 0.9851\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0613 - accuracy: 0.9889 - val_loss: 0.1106 - val_accuracy: 0.9701\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0548 - accuracy: 0.9870 - val_loss: 0.1164 - val_accuracy: 0.9701\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0522 - accuracy: 0.9944 - val_loss: 0.1241 - val_accuracy: 0.9701\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0558 - accuracy: 0.9852 - val_loss: 0.1148 - val_accuracy: 0.9701\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0420 - accuracy: 0.9963 - val_loss: 0.1142 - val_accuracy: 0.9552\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0366 - accuracy: 0.9944 - val_loss: 0.1165 - val_accuracy: 0.9552\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0507 - accuracy: 0.9889 - val_loss: 0.1183 - val_accuracy: 0.9701\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0463 - accuracy: 0.9889 - val_loss: 0.1165 - val_accuracy: 0.9552\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0489 - accuracy: 0.9889 - val_loss: 0.1127 - val_accuracy: 0.9552\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0363 - accuracy: 0.9926 - val_loss: 0.1108 - val_accuracy: 0.9701\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0379 - accuracy: 0.9944 - val_loss: 0.1133 - val_accuracy: 0.9701\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0422 - accuracy: 0.9926 - val_loss: 0.1213 - val_accuracy: 0.9701\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0489 - accuracy: 0.9852 - val_loss: 0.1057 - val_accuracy: 0.9851\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0499 - accuracy: 0.9907 - val_loss: 0.1091 - val_accuracy: 0.9701\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0529 - accuracy: 0.9889 - val_loss: 0.1087 - val_accuracy: 0.9701\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0395 - accuracy: 0.9944 - val_loss: 0.1097 - val_accuracy: 0.9552\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0374 - accuracy: 0.9907 - val_loss: 0.1166 - val_accuracy: 0.9552\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0429 - accuracy: 0.9926 - val_loss: 0.1126 - val_accuracy: 0.9552\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9944 - val_loss: 0.1117 - val_accuracy: 0.9552\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0491 - accuracy: 0.9889 - val_loss: 0.1098 - val_accuracy: 0.9851\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0406 - accuracy: 0.9889 - val_loss: 0.1227 - val_accuracy: 0.9552\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0313 - accuracy: 0.9981 - val_loss: 0.1071 - val_accuracy: 0.9851\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 0.1069 - val_accuracy: 0.9851\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0399 - accuracy: 0.9926 - val_loss: 0.1467 - val_accuracy: 0.9403\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0695 - accuracy: 0.9759 - val_loss: 0.3020 - val_accuracy: 0.9104\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0541 - accuracy: 0.9889 - val_loss: 0.1507 - val_accuracy: 0.9552\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.1339 - val_accuracy: 0.9403\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0504 - accuracy: 0.9889 - val_loss: 0.1294 - val_accuracy: 0.9552\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.1350 - val_accuracy: 0.9552\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0485 - accuracy: 0.9907 - val_loss: 0.1263 - val_accuracy: 0.9403\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0534 - accuracy: 0.9889 - val_loss: 0.1250 - val_accuracy: 0.9552\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0770 - accuracy: 0.9796 - val_loss: 0.1249 - val_accuracy: 0.9552\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0445 - accuracy: 0.9926 - val_loss: 0.1269 - val_accuracy: 0.9552\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.1257 - val_accuracy: 0.9552\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0395 - accuracy: 0.9944 - val_loss: 0.1222 - val_accuracy: 0.9552\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0377 - accuracy: 0.9907 - val_loss: 0.1106 - val_accuracy: 0.9701\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0415 - accuracy: 0.9889 - val_loss: 0.1106 - val_accuracy: 0.9851\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0365 - accuracy: 0.9907 - val_loss: 0.3085 - val_accuracy: 0.8657\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0548 - accuracy: 0.9870 - val_loss: 0.1395 - val_accuracy: 0.9552\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.0369 - accuracy: 0.9944 - val_loss: 0.1141 - val_accuracy: 0.9701\n",
      "Epoch 275: early stopping\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5956 - accuracy: 0.8457\n",
      "[INFO] Creating Hybrid CNN+MLP...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training model...\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 2s 29ms/step - loss: 1.4803 - accuracy: 0.4722 - val_loss: 1.6096 - val_accuracy: 0.0896\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.2790 - accuracy: 0.6704 - val_loss: 1.6057 - val_accuracy: 0.0746\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.1826 - accuracy: 0.7463 - val_loss: 1.6019 - val_accuracy: 0.0746\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.1383 - accuracy: 0.7481 - val_loss: 1.5967 - val_accuracy: 0.8209\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.0807 - accuracy: 0.7259 - val_loss: 1.5501 - val_accuracy: 0.7612\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.0286 - accuracy: 0.7611 - val_loss: 1.5462 - val_accuracy: 0.3134\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 1.0334 - accuracy: 0.7722 - val_loss: 1.5554 - val_accuracy: 0.0746\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.9591 - accuracy: 0.7759 - val_loss: 1.5853 - val_accuracy: 0.0746\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.9144 - accuracy: 0.8000 - val_loss: 1.6412 - val_accuracy: 0.0597\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.8989 - accuracy: 0.7907 - val_loss: 1.6660 - val_accuracy: 0.0597\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.8767 - accuracy: 0.7722 - val_loss: 1.6870 - val_accuracy: 0.0597\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.8582 - accuracy: 0.7759 - val_loss: 1.6972 - val_accuracy: 0.0597\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.8379 - accuracy: 0.7907 - val_loss: 1.7062 - val_accuracy: 0.0597\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.8131 - accuracy: 0.8056 - val_loss: 1.7090 - val_accuracy: 0.0597\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.8160 - accuracy: 0.7815 - val_loss: 1.6078 - val_accuracy: 0.1791\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7814 - accuracy: 0.7870 - val_loss: 1.4369 - val_accuracy: 0.3433\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7666 - accuracy: 0.7796 - val_loss: 1.3050 - val_accuracy: 0.4776\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.7403 - accuracy: 0.8019 - val_loss: 1.0928 - val_accuracy: 0.6567\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7091 - accuracy: 0.7833 - val_loss: 0.9283 - val_accuracy: 0.7313\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7005 - accuracy: 0.8130 - val_loss: 0.8238 - val_accuracy: 0.7612\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6968 - accuracy: 0.8093 - val_loss: 0.7644 - val_accuracy: 0.7761\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.6963 - accuracy: 0.7963 - val_loss: 0.7185 - val_accuracy: 0.7761\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6564 - accuracy: 0.8222 - val_loss: 0.6756 - val_accuracy: 0.8060\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6455 - accuracy: 0.8019 - val_loss: 0.6371 - val_accuracy: 0.8060\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.6265 - accuracy: 0.8037 - val_loss: 0.6139 - val_accuracy: 0.7910\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6451 - accuracy: 0.8000 - val_loss: 0.5854 - val_accuracy: 0.7910\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6211 - accuracy: 0.8000 - val_loss: 0.5639 - val_accuracy: 0.7910\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5947 - accuracy: 0.8111 - val_loss: 0.5695 - val_accuracy: 0.8060\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5966 - accuracy: 0.8241 - val_loss: 0.5617 - val_accuracy: 0.7910\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.6119 - accuracy: 0.8130 - val_loss: 0.5572 - val_accuracy: 0.8060\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5798 - accuracy: 0.8074 - val_loss: 0.5475 - val_accuracy: 0.8060\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5749 - accuracy: 0.8093 - val_loss: 0.5362 - val_accuracy: 0.8060\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5767 - accuracy: 0.8019 - val_loss: 0.5330 - val_accuracy: 0.7910\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5722 - accuracy: 0.8148 - val_loss: 0.5220 - val_accuracy: 0.7761\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.5544 - accuracy: 0.8352 - val_loss: 0.5542 - val_accuracy: 0.7612\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.5479 - accuracy: 0.8315 - val_loss: 0.5310 - val_accuracy: 0.7761\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5220 - accuracy: 0.8185 - val_loss: 0.5187 - val_accuracy: 0.7612\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5506 - accuracy: 0.8259 - val_loss: 0.5322 - val_accuracy: 0.7761\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.8222 - val_loss: 0.4895 - val_accuracy: 0.7761\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5130 - accuracy: 0.8278 - val_loss: 0.4772 - val_accuracy: 0.7612\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4986 - accuracy: 0.8167 - val_loss: 0.4843 - val_accuracy: 0.7910\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4791 - accuracy: 0.8444 - val_loss: 0.4955 - val_accuracy: 0.7910\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.8259 - val_loss: 0.5016 - val_accuracy: 0.8209\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4923 - accuracy: 0.8463 - val_loss: 0.4865 - val_accuracy: 0.8209\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4843 - accuracy: 0.8407 - val_loss: 0.4561 - val_accuracy: 0.8358\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.5024 - accuracy: 0.8204 - val_loss: 0.4651 - val_accuracy: 0.8358\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.4810 - accuracy: 0.8370 - val_loss: 0.4528 - val_accuracy: 0.8507\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4611 - accuracy: 0.8556 - val_loss: 0.4706 - val_accuracy: 0.8507\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4547 - accuracy: 0.8426 - val_loss: 0.5078 - val_accuracy: 0.8358\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4577 - accuracy: 0.8611 - val_loss: 0.4569 - val_accuracy: 0.8209\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4412 - accuracy: 0.8556 - val_loss: 0.4528 - val_accuracy: 0.8358\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4439 - accuracy: 0.8556 - val_loss: 0.4424 - val_accuracy: 0.8358\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4157 - accuracy: 0.8741 - val_loss: 0.4683 - val_accuracy: 0.8209\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4673 - accuracy: 0.8519 - val_loss: 0.4392 - val_accuracy: 0.8209\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.4337 - accuracy: 0.8796 - val_loss: 0.4484 - val_accuracy: 0.8209\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.4198 - accuracy: 0.8796 - val_loss: 0.4301 - val_accuracy: 0.8358\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3921 - accuracy: 0.8944 - val_loss: 0.4150 - val_accuracy: 0.8209\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.4104 - accuracy: 0.8963 - val_loss: 0.4026 - val_accuracy: 0.8507\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3893 - accuracy: 0.9111 - val_loss: 0.4006 - val_accuracy: 0.8806\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.4152 - accuracy: 0.8963 - val_loss: 0.3876 - val_accuracy: 0.9104\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3853 - accuracy: 0.9148 - val_loss: 0.4199 - val_accuracy: 0.8955\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4011 - accuracy: 0.8889 - val_loss: 0.4321 - val_accuracy: 0.8657\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3986 - accuracy: 0.9019 - val_loss: 0.3373 - val_accuracy: 0.9104\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3972 - accuracy: 0.8889 - val_loss: 0.3715 - val_accuracy: 0.8955\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.4016 - accuracy: 0.9056 - val_loss: 0.4399 - val_accuracy: 0.8955\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3743 - accuracy: 0.9019 - val_loss: 0.4921 - val_accuracy: 0.8657\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.3978 - accuracy: 0.8870 - val_loss: 0.3657 - val_accuracy: 0.9403\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3643 - accuracy: 0.9074 - val_loss: 0.3761 - val_accuracy: 0.9254\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3667 - accuracy: 0.9037 - val_loss: 0.3757 - val_accuracy: 0.8955\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3401 - accuracy: 0.9333 - val_loss: 0.3792 - val_accuracy: 0.9104\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 1s 19ms/step - loss: 0.3658 - accuracy: 0.9037 - val_loss: 0.3500 - val_accuracy: 0.8955\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3513 - accuracy: 0.9111 - val_loss: 0.4105 - val_accuracy: 0.8806\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3743 - accuracy: 0.9019 - val_loss: 0.3426 - val_accuracy: 0.9403\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3391 - accuracy: 0.9148 - val_loss: 0.3937 - val_accuracy: 0.9104\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3059 - accuracy: 0.9352 - val_loss: 0.3545 - val_accuracy: 0.9254\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3233 - accuracy: 0.9148 - val_loss: 0.3513 - val_accuracy: 0.8955\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3231 - accuracy: 0.9296 - val_loss: 0.3196 - val_accuracy: 0.8955\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3056 - accuracy: 0.9407 - val_loss: 0.3251 - val_accuracy: 0.9403\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3118 - accuracy: 0.9222 - val_loss: 0.3316 - val_accuracy: 0.9254\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2930 - accuracy: 0.9426 - val_loss: 0.4324 - val_accuracy: 0.8657\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3256 - accuracy: 0.9259 - val_loss: 0.3177 - val_accuracy: 0.9254\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3041 - accuracy: 0.9315 - val_loss: 0.3371 - val_accuracy: 0.8955\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3094 - accuracy: 0.9296 - val_loss: 0.3477 - val_accuracy: 0.8955\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2800 - accuracy: 0.9519 - val_loss: 0.3923 - val_accuracy: 0.8955\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2952 - accuracy: 0.9407 - val_loss: 0.3248 - val_accuracy: 0.9104\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3274 - accuracy: 0.9185 - val_loss: 0.4068 - val_accuracy: 0.8806\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2813 - accuracy: 0.9278 - val_loss: 0.3580 - val_accuracy: 0.8806\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.3102 - accuracy: 0.9278 - val_loss: 0.3191 - val_accuracy: 0.9254\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.3402 - accuracy: 0.9093 - val_loss: 0.3158 - val_accuracy: 0.9254\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2626 - accuracy: 0.9463 - val_loss: 0.3261 - val_accuracy: 0.9104\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2756 - accuracy: 0.9444 - val_loss: 0.2938 - val_accuracy: 0.9403\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2785 - accuracy: 0.9352 - val_loss: 0.2856 - val_accuracy: 0.9254\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2836 - accuracy: 0.9241 - val_loss: 0.3294 - val_accuracy: 0.8955\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.2451 - accuracy: 0.9463 - val_loss: 0.3468 - val_accuracy: 0.8806\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2416 - accuracy: 0.9593 - val_loss: 0.3293 - val_accuracy: 0.8806\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2391 - accuracy: 0.9426 - val_loss: 0.2638 - val_accuracy: 0.9254\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.2398 - accuracy: 0.9630 - val_loss: 0.2883 - val_accuracy: 0.8955\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2303 - accuracy: 0.9519 - val_loss: 0.3811 - val_accuracy: 0.8806\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2521 - accuracy: 0.9463 - val_loss: 0.4763 - val_accuracy: 0.8507\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2210 - accuracy: 0.9574 - val_loss: 0.3634 - val_accuracy: 0.8806\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2353 - accuracy: 0.9519 - val_loss: 0.3981 - val_accuracy: 0.8657\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2400 - accuracy: 0.9444 - val_loss: 0.3178 - val_accuracy: 0.8657\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2277 - accuracy: 0.9481 - val_loss: 0.2676 - val_accuracy: 0.9104\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.2100 - accuracy: 0.9519 - val_loss: 0.2418 - val_accuracy: 0.9254\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2207 - accuracy: 0.9556 - val_loss: 0.2320 - val_accuracy: 0.9104\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2112 - accuracy: 0.9648 - val_loss: 0.2350 - val_accuracy: 0.9254\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2003 - accuracy: 0.9556 - val_loss: 0.2347 - val_accuracy: 0.9254\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2059 - accuracy: 0.9481 - val_loss: 0.2342 - val_accuracy: 0.9104\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2120 - accuracy: 0.9537 - val_loss: 0.2716 - val_accuracy: 0.8955\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1888 - accuracy: 0.9574 - val_loss: 0.2737 - val_accuracy: 0.9104\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1735 - accuracy: 0.9759 - val_loss: 0.2667 - val_accuracy: 0.9254\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2045 - accuracy: 0.9481 - val_loss: 0.3883 - val_accuracy: 0.8806\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1976 - accuracy: 0.9556 - val_loss: 0.2946 - val_accuracy: 0.9254\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1893 - accuracy: 0.9537 - val_loss: 0.2674 - val_accuracy: 0.9104\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2040 - accuracy: 0.9593 - val_loss: 0.4622 - val_accuracy: 0.8806\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2070 - accuracy: 0.9556 - val_loss: 0.2524 - val_accuracy: 0.9104\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1767 - accuracy: 0.9556 - val_loss: 0.2318 - val_accuracy: 0.9254\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1601 - accuracy: 0.9741 - val_loss: 0.2549 - val_accuracy: 0.9254\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1871 - accuracy: 0.9593 - val_loss: 0.2459 - val_accuracy: 0.9254\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1556 - accuracy: 0.9759 - val_loss: 0.3925 - val_accuracy: 0.8806\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1985 - accuracy: 0.9463 - val_loss: 0.4167 - val_accuracy: 0.8806\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1681 - accuracy: 0.9704 - val_loss: 0.3237 - val_accuracy: 0.8657\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1693 - accuracy: 0.9722 - val_loss: 0.4350 - val_accuracy: 0.8657\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1870 - accuracy: 0.9611 - val_loss: 0.5281 - val_accuracy: 0.8657\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1817 - accuracy: 0.9519 - val_loss: 0.4329 - val_accuracy: 0.8806\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1671 - accuracy: 0.9556 - val_loss: 0.3364 - val_accuracy: 0.8955\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1360 - accuracy: 0.9685 - val_loss: 0.2807 - val_accuracy: 0.8955\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1606 - accuracy: 0.9630 - val_loss: 0.4464 - val_accuracy: 0.8657\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2067 - accuracy: 0.9556 - val_loss: 0.5403 - val_accuracy: 0.8507\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.2049 - accuracy: 0.9481 - val_loss: 0.3008 - val_accuracy: 0.8657\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1617 - accuracy: 0.9574 - val_loss: 0.2385 - val_accuracy: 0.9104\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1485 - accuracy: 0.9685 - val_loss: 0.2207 - val_accuracy: 0.9104\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1352 - accuracy: 0.9685 - val_loss: 0.2517 - val_accuracy: 0.8955\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1531 - accuracy: 0.9685 - val_loss: 0.2265 - val_accuracy: 0.9254\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1538 - accuracy: 0.9630 - val_loss: 0.1920 - val_accuracy: 0.9254\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1495 - accuracy: 0.9667 - val_loss: 0.2233 - val_accuracy: 0.9254\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1645 - accuracy: 0.9648 - val_loss: 0.1986 - val_accuracy: 0.9104\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1345 - accuracy: 0.9685 - val_loss: 0.2348 - val_accuracy: 0.8955\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1406 - accuracy: 0.9685 - val_loss: 0.2248 - val_accuracy: 0.8806\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1303 - accuracy: 0.9630 - val_loss: 0.1878 - val_accuracy: 0.9104\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1321 - accuracy: 0.9704 - val_loss: 0.2298 - val_accuracy: 0.8955\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1122 - accuracy: 0.9907 - val_loss: 0.2691 - val_accuracy: 0.8806\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1105 - accuracy: 0.9778 - val_loss: 0.2475 - val_accuracy: 0.8955\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1825 - accuracy: 0.9537 - val_loss: 0.2221 - val_accuracy: 0.9104\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.1284 - accuracy: 0.9741 - val_loss: 0.1948 - val_accuracy: 0.9104\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1065 - accuracy: 0.9796 - val_loss: 0.2220 - val_accuracy: 0.8955\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.1225 - accuracy: 0.9722 - val_loss: 0.1885 - val_accuracy: 0.9552\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1296 - accuracy: 0.9648 - val_loss: 0.1608 - val_accuracy: 0.9403\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1192 - accuracy: 0.9759 - val_loss: 0.1748 - val_accuracy: 0.9104\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1086 - accuracy: 0.9796 - val_loss: 0.1907 - val_accuracy: 0.9104\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1148 - accuracy: 0.9704 - val_loss: 0.2478 - val_accuracy: 0.8955\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1095 - accuracy: 0.9815 - val_loss: 0.2692 - val_accuracy: 0.8955\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1109 - accuracy: 0.9685 - val_loss: 0.3208 - val_accuracy: 0.8806\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1014 - accuracy: 0.9815 - val_loss: 0.3155 - val_accuracy: 0.8806\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0935 - accuracy: 0.9815 - val_loss: 0.2803 - val_accuracy: 0.8955\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1036 - accuracy: 0.9759 - val_loss: 0.3458 - val_accuracy: 0.8955\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0940 - accuracy: 0.9778 - val_loss: 0.2928 - val_accuracy: 0.8955\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0931 - accuracy: 0.9778 - val_loss: 0.2951 - val_accuracy: 0.8955\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0906 - accuracy: 0.9852 - val_loss: 0.2554 - val_accuracy: 0.8955\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1200 - accuracy: 0.9704 - val_loss: 0.2079 - val_accuracy: 0.9104\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1301 - accuracy: 0.9704 - val_loss: 0.2258 - val_accuracy: 0.9104\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0981 - accuracy: 0.9759 - val_loss: 0.2134 - val_accuracy: 0.9104\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0814 - accuracy: 0.9833 - val_loss: 0.2049 - val_accuracy: 0.9254\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0822 - accuracy: 0.9815 - val_loss: 0.1919 - val_accuracy: 0.9254\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1133 - accuracy: 0.9722 - val_loss: 0.2014 - val_accuracy: 0.9104\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0856 - accuracy: 0.9815 - val_loss: 0.1874 - val_accuracy: 0.9254\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1072 - accuracy: 0.9759 - val_loss: 0.1964 - val_accuracy: 0.9254\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0911 - accuracy: 0.9852 - val_loss: 0.2216 - val_accuracy: 0.9104\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1005 - accuracy: 0.9833 - val_loss: 0.2461 - val_accuracy: 0.8955\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0802 - accuracy: 0.9852 - val_loss: 0.2220 - val_accuracy: 0.8955\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0742 - accuracy: 0.9833 - val_loss: 0.2136 - val_accuracy: 0.8955\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0740 - accuracy: 0.9889 - val_loss: 0.1638 - val_accuracy: 0.9254\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0764 - accuracy: 0.9852 - val_loss: 0.1821 - val_accuracy: 0.9254\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0722 - accuracy: 0.9815 - val_loss: 0.2086 - val_accuracy: 0.9104\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0954 - accuracy: 0.9796 - val_loss: 0.1724 - val_accuracy: 0.9254\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0776 - accuracy: 0.9870 - val_loss: 0.2010 - val_accuracy: 0.9104\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.1322 - accuracy: 0.9759 - val_loss: 0.2222 - val_accuracy: 0.9104\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0972 - accuracy: 0.9741 - val_loss: 0.2513 - val_accuracy: 0.9104\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0779 - accuracy: 0.9852 - val_loss: 0.2152 - val_accuracy: 0.9254\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1007 - accuracy: 0.9685 - val_loss: 0.1860 - val_accuracy: 0.9254\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0858 - accuracy: 0.9778 - val_loss: 0.4272 - val_accuracy: 0.8955\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1055 - accuracy: 0.9685 - val_loss: 0.3500 - val_accuracy: 0.8955\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1332 - accuracy: 0.9537 - val_loss: 0.4836 - val_accuracy: 0.8507\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1685 - accuracy: 0.9407 - val_loss: 0.5053 - val_accuracy: 0.8657\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1429 - accuracy: 0.9611 - val_loss: 0.3461 - val_accuracy: 0.8955\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1358 - accuracy: 0.9574 - val_loss: 0.1854 - val_accuracy: 0.9254\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1031 - accuracy: 0.9796 - val_loss: 0.2358 - val_accuracy: 0.9104\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0927 - accuracy: 0.9796 - val_loss: 0.2541 - val_accuracy: 0.9254\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1224 - accuracy: 0.9648 - val_loss: 0.5531 - val_accuracy: 0.8657\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1433 - accuracy: 0.9593 - val_loss: 0.4653 - val_accuracy: 0.8806\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1598 - accuracy: 0.9537 - val_loss: 0.3281 - val_accuracy: 0.8806\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0972 - accuracy: 0.9759 - val_loss: 0.2768 - val_accuracy: 0.9104\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1091 - accuracy: 0.9759 - val_loss: 0.1915 - val_accuracy: 0.9254\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0782 - accuracy: 0.9815 - val_loss: 0.2251 - val_accuracy: 0.9254\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1267 - accuracy: 0.9685 - val_loss: 0.2449 - val_accuracy: 0.9254\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0862 - accuracy: 0.9741 - val_loss: 0.2482 - val_accuracy: 0.9254\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0784 - accuracy: 0.9815 - val_loss: 0.2286 - val_accuracy: 0.9403\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0797 - accuracy: 0.9852 - val_loss: 0.2248 - val_accuracy: 0.9254\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1014 - accuracy: 0.9741 - val_loss: 0.1856 - val_accuracy: 0.9254\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0536 - accuracy: 0.9907 - val_loss: 0.1907 - val_accuracy: 0.9254\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0762 - accuracy: 0.9852 - val_loss: 0.2131 - val_accuracy: 0.9254\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0767 - accuracy: 0.9778 - val_loss: 0.2142 - val_accuracy: 0.9403\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0846 - accuracy: 0.9815 - val_loss: 0.2210 - val_accuracy: 0.9254\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0700 - accuracy: 0.9796 - val_loss: 0.2990 - val_accuracy: 0.9254\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0614 - accuracy: 0.9815 - val_loss: 0.3262 - val_accuracy: 0.9104\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0724 - accuracy: 0.9833 - val_loss: 0.2680 - val_accuracy: 0.9104\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0616 - accuracy: 0.9833 - val_loss: 0.2712 - val_accuracy: 0.9104\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0640 - accuracy: 0.9870 - val_loss: 0.5249 - val_accuracy: 0.8806\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0886 - accuracy: 0.9833 - val_loss: 0.4547 - val_accuracy: 0.8806\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0875 - accuracy: 0.9759 - val_loss: 0.3719 - val_accuracy: 0.8806\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0783 - accuracy: 0.9833 - val_loss: 0.2975 - val_accuracy: 0.9104\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0661 - accuracy: 0.9870 - val_loss: 0.2292 - val_accuracy: 0.9104\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0624 - accuracy: 0.9815 - val_loss: 0.1895 - val_accuracy: 0.9254\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0681 - accuracy: 0.9852 - val_loss: 0.1774 - val_accuracy: 0.9254\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0597 - accuracy: 0.9870 - val_loss: 0.1880 - val_accuracy: 0.9104\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0956 - accuracy: 0.9815 - val_loss: 0.1900 - val_accuracy: 0.9254\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0595 - accuracy: 0.9852 - val_loss: 0.1740 - val_accuracy: 0.9403\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0665 - accuracy: 0.9833 - val_loss: 0.1796 - val_accuracy: 0.9254\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 19ms/step - loss: 0.0734 - accuracy: 0.9852 - val_loss: 0.1462 - val_accuracy: 0.9403\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.1066 - accuracy: 0.9741 - val_loss: 0.1536 - val_accuracy: 0.9403\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0981 - accuracy: 0.9759 - val_loss: 0.1516 - val_accuracy: 0.9254\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0857 - accuracy: 0.9759 - val_loss: 0.1411 - val_accuracy: 0.9403\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0680 - accuracy: 0.9815 - val_loss: 0.1764 - val_accuracy: 0.9104\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0775 - accuracy: 0.9778 - val_loss: 0.1646 - val_accuracy: 0.9254\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0828 - accuracy: 0.9796 - val_loss: 0.1680 - val_accuracy: 0.9403\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.1695 - val_accuracy: 0.9403\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0599 - accuracy: 0.9870 - val_loss: 0.1565 - val_accuracy: 0.9403\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0494 - accuracy: 0.9944 - val_loss: 0.1938 - val_accuracy: 0.9403\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0468 - accuracy: 0.9889 - val_loss: 0.2060 - val_accuracy: 0.9104\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0617 - accuracy: 0.9852 - val_loss: 0.2135 - val_accuracy: 0.9254\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0486 - accuracy: 0.9907 - val_loss: 0.2650 - val_accuracy: 0.9104\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0543 - accuracy: 0.9926 - val_loss: 0.2288 - val_accuracy: 0.9254\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0509 - accuracy: 0.9870 - val_loss: 0.1871 - val_accuracy: 0.9254\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0681 - accuracy: 0.9796 - val_loss: 0.1708 - val_accuracy: 0.9254\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0514 - accuracy: 0.9889 - val_loss: 0.1717 - val_accuracy: 0.9403\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0546 - accuracy: 0.9907 - val_loss: 0.3204 - val_accuracy: 0.9254\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0644 - accuracy: 0.9870 - val_loss: 0.3754 - val_accuracy: 0.8955\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0662 - accuracy: 0.9852 - val_loss: 0.3201 - val_accuracy: 0.9104\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0605 - accuracy: 0.9778 - val_loss: 0.2415 - val_accuracy: 0.9254\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0518 - accuracy: 0.9907 - val_loss: 0.1690 - val_accuracy: 0.9254\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0741 - accuracy: 0.9852 - val_loss: 0.1574 - val_accuracy: 0.9254\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0729 - accuracy: 0.9852 - val_loss: 0.2238 - val_accuracy: 0.9104\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0534 - accuracy: 0.9815 - val_loss: 0.2439 - val_accuracy: 0.9104\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.2361 - val_accuracy: 0.9254\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0592 - accuracy: 0.9889 - val_loss: 0.1997 - val_accuracy: 0.9254\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0566 - accuracy: 0.9889 - val_loss: 0.2292 - val_accuracy: 0.9254\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.0753 - accuracy: 0.9722 - val_loss: 0.5694 - val_accuracy: 0.8657\n",
      "Epoch 247: early stopping\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7613 - accuracy: 0.7489\n"
     ]
    }
   ],
   "source": [
    "a=[]  # accuracy\n",
    "t=[]  # time\n",
    "checkpoint_path='hybrid1.h5'\n",
    "for i in range(10):\n",
    "    print('[INFO] Creating Hybrid CNN+MLP...')\n",
    "    mlp = create_mlp(trainAttrXnorm10.shape[1], regress=False)\n",
    "    cnn = create_cnn(32, 32, 3, regress=False) \n",
    "    combinedInput = concatenate([mlp.output, cnn.output])\n",
    "    x = Dense(8, activation=\"relu\")(combinedInput)\n",
    "    x = Dense(5)(x)\n",
    "    \n",
    "    keras_callbacks   = [\n",
    "      EarlyStopping(monitor='val_accuracy', patience=100, verbose=1),\n",
    "      ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)]\n",
    "\n",
    "    model_mixed = Model(inputs=[mlp.input, cnn.input], \n",
    "                    outputs=x, \n",
    "                    name=\"Hybrid_CNN_MLP\")\n",
    "    print('[INFO] Compiling model...') \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-3 / 200) \n",
    "    model_mixed.compile(optimizer=opt, \n",
    "                        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                        metrics=['accuracy'])\n",
    "    # train the model\n",
    "    print(\"[INFO] Training model...\")\n",
    "    import timeit\n",
    "    start = timeit.default_timer()\n",
    "    history_model_mixed = model_mixed.fit(\n",
    "              x=[trainAttrXnorm10, trainImagesX10], y=trainY10,\n",
    "              validation_data=([validAttrXnorm10, validImagesX10], validY10), \n",
    "              batch_size = 20,\n",
    "              epochs=500,\n",
    "              callbacks=[keras_callbacks])\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    best_model_mixed = load_model(checkpoint_path)\n",
    "    test_loss, test_acc = best_model_mixed.evaluate( [testAttrXnorm, testImagesX],  testY)\n",
    "    \n",
    "    a.append(test_acc)\n",
    "    t.append(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[118.91883019999841,\n",
       " 147.15418639999916,\n",
       " 151.3564425000004,\n",
       " 103.94854560000022,\n",
       " 136.00367320000078,\n",
       " 143.1594798999995,\n",
       " 120.86176509999859,\n",
       " 91.4291787000002,\n",
       " 144.41090879999865,\n",
       " 122.60984179999832]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7782608866691589,\n",
       " 0.845652163028717,\n",
       " 0.841304361820221,\n",
       " 0.813043475151062,\n",
       " 0.7565217614173889,\n",
       " 0.79347825050354,\n",
       " 0.841304361820221,\n",
       " 0.699999988079071,\n",
       " 0.845652163028717,\n",
       " 0.748913049697876]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.98528521999943"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_10=np.mean(t) # average time\n",
    "t1_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964130461215972"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_10=np.mean(a) # average accuracy\n",
    "a1_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of HybridCNN+MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LPC-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder_=\"D:\\\\Mohammad paper\\\\LPC-NN\\\\to_submit_Trans_on_Ins_Meas\\\\CORRECTED\\\\data\\\\lpc\\\\CSV\\\\\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.1882</td>\n",
       "      <td>0.45501</td>\n",
       "      <td>-0.24350</td>\n",
       "      <td>0.064977</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>-0.030387</td>\n",
       "      <td>-0.018263</td>\n",
       "      <td>-0.032903</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.009543</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>-0.024277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.1747</td>\n",
       "      <td>0.46731</td>\n",
       "      <td>-0.24488</td>\n",
       "      <td>0.067928</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>-0.041066</td>\n",
       "      <td>-0.049452</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>0.018806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>-0.027561</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.031766</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.012947</td>\n",
       "      <td>-0.010429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.1939</td>\n",
       "      <td>0.46652</td>\n",
       "      <td>-0.24324</td>\n",
       "      <td>0.045133</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>-0.073964</td>\n",
       "      <td>-0.030209</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>-0.033212</td>\n",
       "      <td>0.036464</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.015868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.2141</td>\n",
       "      <td>0.51752</td>\n",
       "      <td>-0.29823</td>\n",
       "      <td>0.093176</td>\n",
       "      <td>0.048646</td>\n",
       "      <td>-0.081795</td>\n",
       "      <td>-0.025413</td>\n",
       "      <td>-0.003962</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015432</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>-0.018596</td>\n",
       "      <td>0.030259</td>\n",
       "      <td>-0.003972</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>-0.008951</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.2318</td>\n",
       "      <td>0.56214</td>\n",
       "      <td>-0.35028</td>\n",
       "      <td>0.126910</td>\n",
       "      <td>0.015878</td>\n",
       "      <td>-0.016951</td>\n",
       "      <td>-0.083535</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009512</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>-0.029536</td>\n",
       "      <td>0.042919</td>\n",
       "      <td>-0.011677</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>-0.010465</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.4540</td>\n",
       "      <td>0.91214</td>\n",
       "      <td>-0.42414</td>\n",
       "      <td>0.153950</td>\n",
       "      <td>-0.062926</td>\n",
       "      <td>0.138680</td>\n",
       "      <td>-0.365820</td>\n",
       "      <td>0.234460</td>\n",
       "      <td>0.086976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.099319</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>-0.010073</td>\n",
       "      <td>0.066307</td>\n",
       "      <td>-0.023049</td>\n",
       "      <td>0.042467</td>\n",
       "      <td>0.025965</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.4459</td>\n",
       "      <td>0.96853</td>\n",
       "      <td>-0.50716</td>\n",
       "      <td>0.186040</td>\n",
       "      <td>-0.066022</td>\n",
       "      <td>0.105940</td>\n",
       "      <td>-0.329610</td>\n",
       "      <td>0.248560</td>\n",
       "      <td>0.059083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054845</td>\n",
       "      <td>-0.022686</td>\n",
       "      <td>-0.009512</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.024959</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>0.052826</td>\n",
       "      <td>0.039675</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.3385</td>\n",
       "      <td>0.76229</td>\n",
       "      <td>-0.32220</td>\n",
       "      <td>0.054202</td>\n",
       "      <td>0.030506</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>-0.248430</td>\n",
       "      <td>0.116820</td>\n",
       "      <td>0.178150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057604</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>-0.024799</td>\n",
       "      <td>0.026363</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.056143</td>\n",
       "      <td>-0.045662</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>0.031014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.3624</td>\n",
       "      <td>0.79442</td>\n",
       "      <td>-0.33862</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>0.078665</td>\n",
       "      <td>-0.029010</td>\n",
       "      <td>-0.234540</td>\n",
       "      <td>0.122320</td>\n",
       "      <td>0.165670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052991</td>\n",
       "      <td>-0.031515</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>0.036034</td>\n",
       "      <td>-0.006137</td>\n",
       "      <td>0.049593</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>0.034697</td>\n",
       "      <td>0.041619</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.3993</td>\n",
       "      <td>0.79567</td>\n",
       "      <td>-0.32367</td>\n",
       "      <td>0.058947</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.098153</td>\n",
       "      <td>-0.367610</td>\n",
       "      <td>0.281090</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070971</td>\n",
       "      <td>-0.026932</td>\n",
       "      <td>-0.003784</td>\n",
       "      <td>-0.005792</td>\n",
       "      <td>0.025969</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.026655</td>\n",
       "      <td>0.020953</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2155 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1        2        3         4         5         6         7   \\\n",
       "0      1 -1.1882  0.45501 -0.24350  0.064977  0.003803 -0.030387 -0.018263   \n",
       "1      1 -1.1747  0.46731 -0.24488  0.067928 -0.001249 -0.041066 -0.049452   \n",
       "2      1 -1.1939  0.46652 -0.24324  0.045133  0.037782 -0.073964 -0.030209   \n",
       "3      1 -1.2141  0.51752 -0.29823  0.093176  0.048646 -0.081795 -0.025413   \n",
       "4      1 -1.2318  0.56214 -0.35028  0.126910  0.015878 -0.016951 -0.083535   \n",
       "...   ..     ...      ...      ...       ...       ...       ...       ...   \n",
       "2150   1 -1.4540  0.91214 -0.42414  0.153950 -0.062926  0.138680 -0.365820   \n",
       "2151   1 -1.4459  0.96853 -0.50716  0.186040 -0.066022  0.105940 -0.329610   \n",
       "2152   1 -1.3385  0.76229 -0.32220  0.054202  0.030506  0.011325 -0.248430   \n",
       "2153   1 -1.3624  0.79442 -0.33862  0.053516  0.078665 -0.029010 -0.234540   \n",
       "2154   1 -1.3993  0.79567 -0.32367  0.058947  0.005538  0.098153 -0.367610   \n",
       "\n",
       "            8         9   ...        42        43        44        45  \\\n",
       "0    -0.032903  0.008215  ...  0.012128  0.009543 -0.000238 -0.001693   \n",
       "1     0.009204  0.018806  ...  0.003182  0.015661 -0.027561  0.025756   \n",
       "2     0.019220  0.017296  ... -0.009377  0.023592 -0.033212  0.036464   \n",
       "3    -0.003962  0.017245  ... -0.015432  0.019323 -0.018596  0.030259   \n",
       "4     0.023411 -0.002820  ... -0.009512  0.010308 -0.029536  0.042919   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "2150  0.234460  0.086976  ... -0.000473 -0.099319  0.034728 -0.010073   \n",
       "2151  0.248560  0.059083  ... -0.054845 -0.022686 -0.009512  0.016065   \n",
       "2152  0.116820  0.178150  ... -0.057604 -0.029538 -0.024799  0.026363   \n",
       "2153  0.122320  0.165670  ... -0.052991 -0.031515 -0.027306  0.036034   \n",
       "2154  0.281090  0.019917  ... -0.070971 -0.026932 -0.003784 -0.005792   \n",
       "\n",
       "            46        47        48        49        50  51  \n",
       "0     0.023079  0.011074  0.012264  0.024563 -0.024277   1  \n",
       "1     0.031766  0.005893  0.016709  0.012947 -0.010429   1  \n",
       "2     0.010720  0.011301  0.007843  0.022704 -0.015868   1  \n",
       "3    -0.003972  0.039241 -0.008951  0.027268 -0.010254   1  \n",
       "4    -0.011677  0.053403 -0.010465  0.025847 -0.013370   1  \n",
       "...        ...       ...       ...       ...       ...  ..  \n",
       "2150  0.066307 -0.023049  0.042467  0.025965  0.034108   5  \n",
       "2151  0.028363  0.024959 -0.012643  0.052826  0.039675   5  \n",
       "2152  0.002584  0.056143 -0.045662  0.067982  0.031014   5  \n",
       "2153 -0.006137  0.049593 -0.009802  0.034697  0.041619   5  \n",
       "2154  0.025969  0.018065  0.009756  0.026655  0.020953   5  \n",
       "\n",
       "[2155 rows x 52 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# Path to train\n",
    "path_to_train=root_folder_+\"Z_0_TRAIN_70_STEP_2500_OVERLAP_50_PERCERNT_LPC_50_.csv\"\n",
    "\n",
    "\n",
    "#Loading training data\n",
    "data_raw = pd.read_csv(path_to_train,header=None)\n",
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2155, 50)\n"
     ]
    }
   ],
   "source": [
    "data = data_raw.iloc[np.random.permutation(len(data_raw))]\n",
    "labels=data.iloc[:,51]\n",
    "features = data.iloc[:,1:51]\n",
    "X=features\n",
    "y=np.ravel(labels)\n",
    "X_train, y_train = shuffle(X, y)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to test\n",
    "path_to_test=root_folder_+\"Z_0_TEST_70_STEP_2500_OVERLAP_50_PERCERNT_LPC_50_.csv\"\n",
    "\n",
    "#Loading testing data\n",
    "data12 = pd.read_csv(path_to_test,header=None)\n",
    "labels12=data12.iloc[:,51]\n",
    "features12 = data12.iloc[:,1:51]\n",
    "X12=features12\n",
    "y12=np.ravel(labels12)\n",
    "X_test=X12;\n",
    "y_test=y12;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 5)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myN=5; #number of classes\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y_train=y_train-1;\n",
    "y_test=y_test-1;\n",
    "# Convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, myN) \n",
    "Y_test = np_utils.to_categorical(y_test, myN)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='bestmodel_0_0_LPC_NN'\n",
    "confusion_title=\"Confusion matrix of SUSU dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LPC-NN_10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 19s - loss: 1.6487 - accuracy: 0.1111INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.6285 - accuracy: 0.1315 - val_loss: 1.6080 - val_accuracy: 0.1991\n",
      "Epoch 2/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5933 - accuracy: 0.2222INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.5908 - accuracy: 0.2656 - val_loss: 1.5746 - val_accuracy: 0.2870\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5305 - accuracy: 0.4444INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5551 - accuracy: 0.3641 - val_loss: 1.5420 - val_accuracy: 0.3981\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5438 - accuracy: 0.4444INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5207 - accuracy: 0.4905 - val_loss: 1.5100 - val_accuracy: 0.5231\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5517 - accuracy: 0.4815INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4869 - accuracy: 0.5596 - val_loss: 1.4776 - val_accuracy: 0.5787\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4787 - accuracy: 0.5556INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.4529 - accuracy: 0.6003 - val_loss: 1.4449 - val_accuracy: 0.6111\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4878 - accuracy: 0.4074INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4188 - accuracy: 0.6436 - val_loss: 1.4116 - val_accuracy: 0.6481\n",
      "Epoch 8/500\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 1.3844 - accuracy: 0.6887INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3839 - accuracy: 0.6900 - val_loss: 1.3776 - val_accuracy: 0.7361\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3507 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3488 - accuracy: 0.7932 - val_loss: 1.3430 - val_accuracy: 0.8426\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3811 - accuracy: 0.8148INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3128 - accuracy: 0.8716 - val_loss: 1.3077 - val_accuracy: 0.9167\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3897 - accuracy: 0.7407INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.2764 - accuracy: 0.9165 - val_loss: 1.2723 - val_accuracy: 0.9398\n",
      "Epoch 12/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2320 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2393 - accuracy: 0.9402 - val_loss: 1.2359 - val_accuracy: 0.9630\n",
      "Epoch 13/500\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 1.2027 - accuracy: 0.9635INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.2019 - accuracy: 0.9629 - val_loss: 1.1990 - val_accuracy: 0.9769\n",
      "Epoch 14/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2104 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1639 - accuracy: 0.9752 - val_loss: 1.1616 - val_accuracy: 0.9861\n",
      "Epoch 15/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1549 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1258 - accuracy: 0.9835 - val_loss: 1.1241 - val_accuracy: 0.9954\n",
      "Epoch 16/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1180 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.0877 - accuracy: 0.9907 - val_loss: 1.0865 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 1.0491 - accuracy: 0.9912 - val_loss: 1.0486 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 970us/step - loss: 1.0106 - accuracy: 0.9912 - val_loss: 1.0111 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 893us/step - loss: 0.9725 - accuracy: 0.9933 - val_loss: 0.9736 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.9348 - accuracy: 0.9943 - val_loss: 0.9369 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.8977 - accuracy: 0.9959 - val_loss: 0.9005 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.8613 - accuracy: 0.9974 - val_loss: 0.8645 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.8258 - accuracy: 0.9985 - val_loss: 0.8297 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.7912 - accuracy: 0.9990 - val_loss: 0.7960 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.7575 - accuracy: 0.9990 - val_loss: 0.7631 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.7250 - accuracy: 0.9990 - val_loss: 0.7311 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.6936 - accuracy: 0.9995 - val_loss: 0.7003 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.6633 - accuracy: 0.9995 - val_loss: 0.6707 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6342 - accuracy: 0.9995 - val_loss: 0.6420 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6063 - accuracy: 0.9995 - val_loss: 0.6146 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.5796 - accuracy: 0.9995 - val_loss: 0.5883 - val_accuracy: 0.9954\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5538 - accuracy: 0.9995 - val_loss: 0.5632 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5294 - accuracy: 0.9995 - val_loss: 0.5390 - val_accuracy: 0.9954\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5060 - accuracy: 0.9990 - val_loss: 0.5160 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.4838 - accuracy: 0.9995 - val_loss: 0.4939 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.4624 - accuracy: 0.9990 - val_loss: 0.4728 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.4419 - accuracy: 0.9990 - val_loss: 0.4526 - val_accuracy: 0.9954\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.4226 - accuracy: 0.9990 - val_loss: 0.4334 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.4040 - accuracy: 0.9990 - val_loss: 0.4149 - val_accuracy: 0.9954\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.3864 - accuracy: 0.9990 - val_loss: 0.3973 - val_accuracy: 0.9954\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 717us/step - loss: 0.3695 - accuracy: 0.9990 - val_loss: 0.3807 - val_accuracy: 0.9954\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 986us/step - loss: 0.3534 - accuracy: 0.9990 - val_loss: 0.3649 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.3381 - accuracy: 0.9990 - val_loss: 0.3496 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 850us/step - loss: 0.3235 - accuracy: 0.9990 - val_loss: 0.3350 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.3097 - accuracy: 0.9990 - val_loss: 0.3212 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.2964 - accuracy: 0.9990 - val_loss: 0.3078 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.2837 - accuracy: 0.9990 - val_loss: 0.2952 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.2716 - accuracy: 0.9990 - val_loss: 0.2831 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.2600 - accuracy: 0.9990 - val_loss: 0.2715 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.2491 - accuracy: 0.9990 - val_loss: 0.2604 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.2386 - accuracy: 0.9990 - val_loss: 0.2501 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.2285 - accuracy: 0.9990 - val_loss: 0.2397 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.2189 - accuracy: 0.9990 - val_loss: 0.2301 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.2097 - accuracy: 0.9990 - val_loss: 0.2209 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.2011 - accuracy: 0.9990 - val_loss: 0.2121 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.1927 - accuracy: 0.9990 - val_loss: 0.2035 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.1847 - accuracy: 0.9990 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.1771 - accuracy: 0.9990 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.1698 - accuracy: 0.9990 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.1628 - accuracy: 0.9990 - val_loss: 0.1733 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.1562 - accuracy: 0.9990 - val_loss: 0.1665 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.1498 - accuracy: 0.9990 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.1438 - accuracy: 0.9990 - val_loss: 0.1538 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.1380 - accuracy: 0.9990 - val_loss: 0.1478 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.1325 - accuracy: 0.9990 - val_loss: 0.1422 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.1271 - accuracy: 0.9990 - val_loss: 0.1368 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.1221 - accuracy: 0.9990 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.1173 - accuracy: 0.9990 - val_loss: 0.1266 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 848us/step - loss: 0.1126 - accuracy: 0.9990 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.1082 - accuracy: 0.9990 - val_loss: 0.1172 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.1040 - accuracy: 0.9990 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.0999 - accuracy: 0.9990 - val_loss: 0.1086 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.0960 - accuracy: 0.9990 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.0923 - accuracy: 0.9990 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0888 - accuracy: 0.9990 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0854 - accuracy: 0.9990 - val_loss: 0.0935 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.0821 - accuracy: 0.9990 - val_loss: 0.0901 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.0790 - accuracy: 0.9990 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.0761 - accuracy: 0.9990 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.0732 - accuracy: 0.9990 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0705 - accuracy: 0.9990 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.0679 - accuracy: 0.9990 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0654 - accuracy: 0.9990 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0630 - accuracy: 0.9990 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.0607 - accuracy: 0.9990 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.0585 - accuracy: 0.9990 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0564 - accuracy: 0.9990 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.0544 - accuracy: 0.9990 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0524 - accuracy: 0.9990 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0505 - accuracy: 0.9990 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0488 - accuracy: 0.9990 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0471 - accuracy: 0.9990 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 771us/step - loss: 0.0454 - accuracy: 0.9990 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.0438 - accuracy: 0.9990 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.0423 - accuracy: 0.9990 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 986us/step - loss: 0.0408 - accuracy: 0.9990 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0395 - accuracy: 0.9990 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.0381 - accuracy: 0.9990 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.0368 - accuracy: 0.9990 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0356 - accuracy: 0.9990 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.0344 - accuracy: 0.9990 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.0333 - accuracy: 0.9990 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0322 - accuracy: 0.9990 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.0311 - accuracy: 0.9990 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 634us/step - loss: 0.0301 - accuracy: 0.9990 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0291 - accuracy: 0.9990 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0282 - accuracy: 0.9990 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.0273 - accuracy: 0.9990 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0264 - accuracy: 0.9990 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.0255 - accuracy: 0.9990 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0247 - accuracy: 0.9990 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0240 - accuracy: 0.9990 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0232 - accuracy: 0.9990 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0225 - accuracy: 0.9990 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0218 - accuracy: 0.9990 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.0211 - accuracy: 0.9990 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 116: early stopping\n",
      "29/29 - 0s - loss: 1.0380 - accuracy: 0.9935 - 101ms/epoch - 3ms/step\n",
      "1\n",
      "Epoch 1/500\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.6030 - accuracy: 0.1066 INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.6012 - accuracy: 0.1088 - val_loss: 1.5829 - val_accuracy: 0.1250\n",
      "Epoch 2/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5809 - accuracy: 0.1111INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5559 - accuracy: 0.1841 - val_loss: 1.5424 - val_accuracy: 0.2037\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5530 - accuracy: 0.1852INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.5177 - accuracy: 0.2873 - val_loss: 1.5071 - val_accuracy: 0.4167\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4822 - accuracy: 0.5926INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4827 - accuracy: 0.5374 - val_loss: 1.4739 - val_accuracy: 0.5833\n",
      "Epoch 5/500\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 1.4492 - accuracy: 0.6070INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4489 - accuracy: 0.6044 - val_loss: 1.4409 - val_accuracy: 0.6019\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4575 - accuracy: 0.4815INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4153 - accuracy: 0.6653 - val_loss: 1.4083 - val_accuracy: 0.6620\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4094 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3817 - accuracy: 0.7127 - val_loss: 1.3754 - val_accuracy: 0.7546\n",
      "Epoch 8/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3082 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3475 - accuracy: 0.7710 - val_loss: 1.3416 - val_accuracy: 0.7870\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2950 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3128 - accuracy: 0.8448 - val_loss: 1.3074 - val_accuracy: 0.8519\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3268 - accuracy: 0.8889INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2771 - accuracy: 0.8747 - val_loss: 1.2722 - val_accuracy: 0.8796\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2900 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2410 - accuracy: 0.8819 - val_loss: 1.2368 - val_accuracy: 0.8981\n",
      "Epoch 12/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2194 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2043 - accuracy: 0.9108 - val_loss: 1.2002 - val_accuracy: 0.9398\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2015 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.1667 - accuracy: 0.9288 - val_loss: 1.1633 - val_accuracy: 0.9444\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 833us/step - loss: 1.1289 - accuracy: 0.9526 - val_loss: 1.1258 - val_accuracy: 0.9444\n",
      "Epoch 15/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1330 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0907 - accuracy: 0.9634 - val_loss: 1.0882 - val_accuracy: 0.9630\n",
      "Epoch 16/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1005 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.0524 - accuracy: 0.9783 - val_loss: 1.0507 - val_accuracy: 0.9722\n",
      "Epoch 17/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.0363 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0141 - accuracy: 0.9799 - val_loss: 1.0129 - val_accuracy: 0.9769\n",
      "Epoch 18/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.0159 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.9758 - accuracy: 0.9902 - val_loss: 0.9754 - val_accuracy: 0.9861\n",
      "Epoch 19/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 0.9998 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.9380 - accuracy: 0.9943 - val_loss: 0.9381 - val_accuracy: 0.9907\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.9003 - accuracy: 0.9959 - val_loss: 0.9013 - val_accuracy: 0.9907\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 907us/step - loss: 0.8634 - accuracy: 0.9969 - val_loss: 0.8651 - val_accuracy: 0.9907\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 673us/step - loss: 0.8272 - accuracy: 0.9990 - val_loss: 0.8297 - val_accuracy: 0.9907\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.7917 - accuracy: 0.9990 - val_loss: 0.7949 - val_accuracy: 0.9907\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.7572 - accuracy: 0.9990 - val_loss: 0.7609 - val_accuracy: 0.9907\n",
      "Epoch 25/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 0.7574 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.7238 - accuracy: 0.9985 - val_loss: 0.7283 - val_accuracy: 0.9954\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 678us/step - loss: 0.6914 - accuracy: 0.9995 - val_loss: 0.6966 - val_accuracy: 0.9954\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 978us/step - loss: 0.6600 - accuracy: 0.9995 - val_loss: 0.6659 - val_accuracy: 0.9954\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.6300 - accuracy: 0.9995 - val_loss: 0.6366 - val_accuracy: 0.9954\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 709us/step - loss: 0.6008 - accuracy: 0.9995 - val_loss: 0.6082 - val_accuracy: 0.9954\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.5731 - accuracy: 0.9995 - val_loss: 0.5809 - val_accuracy: 0.9954\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5465 - accuracy: 0.9990 - val_loss: 0.5551 - val_accuracy: 0.9954\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 840us/step - loss: 0.5211 - accuracy: 0.9990 - val_loss: 0.5301 - val_accuracy: 0.9954\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.4968 - accuracy: 0.9990 - val_loss: 0.5063 - val_accuracy: 0.9954\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.4737 - accuracy: 0.9990 - val_loss: 0.4836 - val_accuracy: 0.9954\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.4517 - accuracy: 0.9995 - val_loss: 0.4621 - val_accuracy: 0.9954\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 674us/step - loss: 0.4307 - accuracy: 0.9995 - val_loss: 0.4415 - val_accuracy: 0.9954\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.4106 - accuracy: 0.9995 - val_loss: 0.4218 - val_accuracy: 0.9954\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.3915 - accuracy: 0.9995 - val_loss: 0.4029 - val_accuracy: 0.9954\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.3733 - accuracy: 0.9995 - val_loss: 0.3851 - val_accuracy: 0.9954\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.3560 - accuracy: 0.9995 - val_loss: 0.3682 - val_accuracy: 0.9954\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.3397 - accuracy: 0.9995 - val_loss: 0.3519 - val_accuracy: 0.9954\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 667us/step - loss: 0.3241 - accuracy: 0.9995 - val_loss: 0.3363 - val_accuracy: 0.9954\n",
      "Epoch 43/500\n",
      "61/72 [========================>.....] - ETA: 0s - loss: 0.3123 - accuracy: 0.9994INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3093 - accuracy: 0.9995 - val_loss: 0.3218 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.2952 - accuracy: 0.9990 - val_loss: 0.3079 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.2818 - accuracy: 0.9990 - val_loss: 0.2945 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.2691 - accuracy: 0.9990 - val_loss: 0.2820 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.2570 - accuracy: 0.9990 - val_loss: 0.2698 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 653us/step - loss: 0.2455 - accuracy: 0.9990 - val_loss: 0.2584 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9990 - val_loss: 0.2473 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.2241 - accuracy: 0.9990 - val_loss: 0.2369 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.2142 - accuracy: 0.9990 - val_loss: 0.2270 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9990 - val_loss: 0.2175 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.1959 - accuracy: 0.9990 - val_loss: 0.2086 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 709us/step - loss: 0.1873 - accuracy: 0.9990 - val_loss: 0.1999 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.1793 - accuracy: 0.9990 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.1715 - accuracy: 0.9990 - val_loss: 0.1839 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 688us/step - loss: 0.1642 - accuracy: 0.9990 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.1572 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.1506 - accuracy: 0.9990 - val_loss: 0.1626 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.1443 - accuracy: 0.9990 - val_loss: 0.1562 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.1383 - accuracy: 0.9990 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.1325 - accuracy: 0.9990 - val_loss: 0.1441 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.1271 - accuracy: 0.9990 - val_loss: 0.1385 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.1219 - accuracy: 0.9990 - val_loss: 0.1332 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.1168 - accuracy: 0.9990 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 911us/step - loss: 0.1121 - accuracy: 0.9990 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.1076 - accuracy: 0.9990 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.1033 - accuracy: 0.9990 - val_loss: 0.1140 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.0992 - accuracy: 0.9990 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.0952 - accuracy: 0.9990 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 715us/step - loss: 0.0915 - accuracy: 0.9990 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0879 - accuracy: 0.9990 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0845 - accuracy: 0.9990 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 731us/step - loss: 0.0812 - accuracy: 0.9990 - val_loss: 0.0910 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 726us/step - loss: 0.0781 - accuracy: 0.9990 - val_loss: 0.0877 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 974us/step - loss: 0.0752 - accuracy: 0.9990 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0723 - accuracy: 0.9990 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.0696 - accuracy: 0.9990 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0670 - accuracy: 0.9990 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.0645 - accuracy: 0.9990 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 731us/step - loss: 0.0621 - accuracy: 0.9990 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.0598 - accuracy: 0.9990 - val_loss: 0.0683 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.0576 - accuracy: 0.9990 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.0556 - accuracy: 0.9990 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.0535 - accuracy: 0.9990 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 841us/step - loss: 0.0516 - accuracy: 0.9990 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.0498 - accuracy: 0.9990 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 978us/step - loss: 0.0480 - accuracy: 0.9990 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.0463 - accuracy: 0.9990 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 743us/step - loss: 0.0447 - accuracy: 0.9990 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 866us/step - loss: 0.0431 - accuracy: 0.9990 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.0416 - accuracy: 0.9990 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.0402 - accuracy: 0.9990 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.0388 - accuracy: 0.9990 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.0375 - accuracy: 0.9990 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.0362 - accuracy: 0.9990 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 768us/step - loss: 0.0350 - accuracy: 0.9990 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.0338 - accuracy: 0.9990 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 908us/step - loss: 0.0327 - accuracy: 0.9990 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.0316 - accuracy: 0.9990 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.0305 - accuracy: 0.9990 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 929us/step - loss: 0.0295 - accuracy: 0.9990 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 654us/step - loss: 0.0286 - accuracy: 0.9990 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.0277 - accuracy: 0.9990 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 934us/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.0259 - accuracy: 0.9990 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 767us/step - loss: 0.0251 - accuracy: 0.9990 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.0243 - accuracy: 0.9990 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 889us/step - loss: 0.0235 - accuracy: 0.9990 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0228 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.0201 - accuracy: 0.9990 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 869us/step - loss: 0.0194 - accuracy: 0.9990 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0189 - accuracy: 0.9990 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0183 - accuracy: 0.9990 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.0178 - accuracy: 0.9990 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.0172 - accuracy: 0.9990 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.0167 - accuracy: 0.9990 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.0162 - accuracy: 0.9990 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.0157 - accuracy: 0.9990 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.0153 - accuracy: 0.9990 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 911us/step - loss: 0.0148 - accuracy: 0.9995 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0144 - accuracy: 0.9990 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.0140 - accuracy: 0.9995 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.0136 - accuracy: 0.9995 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.0132 - accuracy: 0.9995 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 855us/step - loss: 0.0128 - accuracy: 0.9995 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.0118 - accuracy: 0.9995 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.0115 - accuracy: 0.9995 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 907us/step - loss: 0.0112 - accuracy: 0.9995 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 861us/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 869us/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 865us/step - loss: 0.0092 - accuracy: 0.9995 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 143: early stopping\n",
      "29/29 - 0s - loss: 0.2828 - accuracy: 0.9989 - 96ms/epoch - 3ms/step\n",
      "2\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 19s - loss: 1.7106 - accuracy: 0.0741INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.6374 - accuracy: 0.0629 - val_loss: 1.6243 - val_accuracy: 0.1481\n",
      "Epoch 2/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.6045 - accuracy: 0.0741INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.5946 - accuracy: 0.2140 - val_loss: 1.5840 - val_accuracy: 0.2685\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.6264 - accuracy: 0.3333INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5559 - accuracy: 0.3718 - val_loss: 1.5468 - val_accuracy: 0.4352\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5698 - accuracy: 0.3704INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5189 - accuracy: 0.5028 - val_loss: 1.5103 - val_accuracy: 0.5093\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5326 - accuracy: 0.3704INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.4824 - accuracy: 0.5740 - val_loss: 1.4745 - val_accuracy: 0.5648\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5335 - accuracy: 0.4444INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.4460 - accuracy: 0.5900 - val_loss: 1.4385 - val_accuracy: 0.5833\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.4191 - accuracy: 0.6667INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4095 - accuracy: 0.6091 - val_loss: 1.4026 - val_accuracy: 0.6157\n",
      "Epoch 8/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3805 - accuracy: 0.7037INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3726 - accuracy: 0.6209 - val_loss: 1.3663 - val_accuracy: 0.6250\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3734 - accuracy: 0.5926INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3353 - accuracy: 0.6488 - val_loss: 1.3294 - val_accuracy: 0.6481\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3261 - accuracy: 0.5926INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2974 - accuracy: 0.6988 - val_loss: 1.2921 - val_accuracy: 0.7315\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2876 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.2590 - accuracy: 0.7927 - val_loss: 1.2542 - val_accuracy: 0.8380\n",
      "Epoch 12/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2056 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2201 - accuracy: 0.8566 - val_loss: 1.2160 - val_accuracy: 0.9167\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2262 - accuracy: 0.8889INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1806 - accuracy: 0.9216 - val_loss: 1.1771 - val_accuracy: 0.9352\n",
      "Epoch 14/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1161 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1411 - accuracy: 0.9448 - val_loss: 1.1377 - val_accuracy: 0.9630\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1013 - accuracy: 0.9706INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1013 - accuracy: 0.9706 - val_loss: 1.0984 - val_accuracy: 0.9769\n",
      "Epoch 16/500\n",
      "60/72 [========================>.....] - ETA: 0s - loss: 1.0662 - accuracy: 0.9759INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.0610 - accuracy: 0.9763 - val_loss: 1.0590 - val_accuracy: 0.9954\n",
      "Epoch 17/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.0537 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0211 - accuracy: 0.9799 - val_loss: 1.0192 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.9813 - accuracy: 0.9845 - val_loss: 0.9806 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.9419 - accuracy: 0.9902 - val_loss: 0.9419 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.9032 - accuracy: 0.9917 - val_loss: 0.9037 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.8651 - accuracy: 0.9959 - val_loss: 0.8662 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.8279 - accuracy: 0.9964 - val_loss: 0.8299 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7918 - accuracy: 0.9985 - val_loss: 0.7944 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7564 - accuracy: 0.9974 - val_loss: 0.7598 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.7225 - accuracy: 0.9985 - val_loss: 0.7265 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 631us/step - loss: 0.6898 - accuracy: 0.9985 - val_loss: 0.6947 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.9990 - val_loss: 0.6641 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6285 - accuracy: 0.9990 - val_loss: 0.6347 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 679us/step - loss: 0.5997 - accuracy: 0.9995 - val_loss: 0.6064 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5723 - accuracy: 0.9995 - val_loss: 0.5796 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 661us/step - loss: 0.5461 - accuracy: 0.9995 - val_loss: 0.5539 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.5210 - accuracy: 0.9995 - val_loss: 0.5295 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 668us/step - loss: 0.4973 - accuracy: 0.9995 - val_loss: 0.5059 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.4745 - accuracy: 0.9995 - val_loss: 0.4838 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.4529 - accuracy: 0.9995 - val_loss: 0.4626 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.4323 - accuracy: 0.9995 - val_loss: 0.4424 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.4128 - accuracy: 0.9990 - val_loss: 0.4231 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3941 - accuracy: 0.9990 - val_loss: 0.4046 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.3763 - accuracy: 0.9990 - val_loss: 0.3872 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.3595 - accuracy: 0.9990 - val_loss: 0.3706 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3434 - accuracy: 0.9990 - val_loss: 0.3547 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3281 - accuracy: 0.9990 - val_loss: 0.3395 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.3135 - accuracy: 0.9990 - val_loss: 0.3250 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.2996 - accuracy: 0.9990 - val_loss: 0.3113 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.2865 - accuracy: 0.9990 - val_loss: 0.2981 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.9990 - val_loss: 0.2856 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 593us/step - loss: 0.2619 - accuracy: 0.9990 - val_loss: 0.2737 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 700us/step - loss: 0.2503 - accuracy: 0.9990 - val_loss: 0.2621 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.2395 - accuracy: 0.9990 - val_loss: 0.2512 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.2291 - accuracy: 0.9990 - val_loss: 0.2408 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.2192 - accuracy: 0.9990 - val_loss: 0.2309 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 729us/step - loss: 0.2097 - accuracy: 0.9990 - val_loss: 0.2215 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.2007 - accuracy: 0.9990 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.1922 - accuracy: 0.9990 - val_loss: 0.2036 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.1840 - accuracy: 0.9990 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.1761 - accuracy: 0.9990 - val_loss: 0.1875 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.1687 - accuracy: 0.9990 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.1616 - accuracy: 0.9990 - val_loss: 0.1729 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.1548 - accuracy: 0.9990 - val_loss: 0.1659 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.1483 - accuracy: 0.9990 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9990 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1363 - accuracy: 0.9990 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1307 - accuracy: 0.9990 - val_loss: 0.1413 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1253 - accuracy: 0.9990 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.1202 - accuracy: 0.9990 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.1153 - accuracy: 0.9990 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1106 - accuracy: 0.9990 - val_loss: 0.1206 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 686us/step - loss: 0.1062 - accuracy: 0.9990 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.1020 - accuracy: 0.9990 - val_loss: 0.1116 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.0978 - accuracy: 0.9990 - val_loss: 0.1074 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9990 - val_loss: 0.1035 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.0903 - accuracy: 0.9990 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.0867 - accuracy: 0.9990 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0834 - accuracy: 0.9990 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0801 - accuracy: 0.9990 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0770 - accuracy: 0.9990 - val_loss: 0.0857 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 631us/step - loss: 0.0741 - accuracy: 0.9990 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9990 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0685 - accuracy: 0.9990 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0660 - accuracy: 0.9990 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.0635 - accuracy: 0.9990 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0611 - accuracy: 0.9990 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0588 - accuracy: 0.9990 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0567 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0546 - accuracy: 0.9990 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0526 - accuracy: 0.9990 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0507 - accuracy: 0.9990 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.0489 - accuracy: 0.9990 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0471 - accuracy: 0.9990 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0454 - accuracy: 0.9990 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0438 - accuracy: 0.9990 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0423 - accuracy: 0.9990 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0408 - accuracy: 0.9990 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0394 - accuracy: 0.9990 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0380 - accuracy: 0.9990 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0367 - accuracy: 0.9990 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0355 - accuracy: 0.9990 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0343 - accuracy: 0.9990 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 949us/step - loss: 0.0331 - accuracy: 0.9990 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0320 - accuracy: 0.9990 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0309 - accuracy: 0.9990 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0299 - accuracy: 0.9990 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.0289 - accuracy: 0.9990 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0279 - accuracy: 0.9990 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.0270 - accuracy: 0.9990 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.0261 - accuracy: 0.9990 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.0253 - accuracy: 0.9990 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0245 - accuracy: 0.9990 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0237 - accuracy: 0.9990 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0230 - accuracy: 0.9990 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0222 - accuracy: 0.9990 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.0215 - accuracy: 0.9990 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 850us/step - loss: 0.0208 - accuracy: 0.9990 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.0202 - accuracy: 0.9990 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.0196 - accuracy: 0.9990 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.0190 - accuracy: 0.9990 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 993us/step - loss: 0.0184 - accuracy: 0.9990 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 117: early stopping\n",
      "29/29 - 0s - loss: 0.9688 - accuracy: 0.9783 - 116ms/epoch - 4ms/step\n",
      "3\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 18s - loss: 1.6982 - accuracy: 0.3704INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.6112 - accuracy: 0.3837 - val_loss: 1.5932 - val_accuracy: 0.3426\n",
      "Epoch 2/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5703 - accuracy: 0.3704INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.5598 - accuracy: 0.3724 - val_loss: 1.5470 - val_accuracy: 0.3611\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5242 - accuracy: 0.4444INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5175 - accuracy: 0.4415 - val_loss: 1.5068 - val_accuracy: 0.5231\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4973 - accuracy: 0.5556INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4798 - accuracy: 0.6070 - val_loss: 1.4704 - val_accuracy: 0.6806\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4291 - accuracy: 0.8148INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.4443 - accuracy: 0.6777 - val_loss: 1.4351 - val_accuracy: 0.7130\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4245 - accuracy: 0.7407INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4089 - accuracy: 0.7225 - val_loss: 1.4002 - val_accuracy: 0.7222\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3807 - accuracy: 0.8148INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3737 - accuracy: 0.7370 - val_loss: 1.3653 - val_accuracy: 0.7361\n",
      "Epoch 8/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3362 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.3377 - accuracy: 0.7602 - val_loss: 1.3296 - val_accuracy: 0.7917\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2601 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.3015 - accuracy: 0.8262 - val_loss: 1.2936 - val_accuracy: 0.8611\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2507 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2640 - accuracy: 0.9067 - val_loss: 1.2570 - val_accuracy: 0.9167\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.2595 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2266 - accuracy: 0.9453 - val_loss: 1.2196 - val_accuracy: 0.9676\n",
      "Epoch 12/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2882 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.1881 - accuracy: 0.9768 - val_loss: 1.1821 - val_accuracy: 0.9815\n",
      "Epoch 13/500\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 1.1553 - accuracy: 0.9845INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1496 - accuracy: 0.9835 - val_loss: 1.1439 - val_accuracy: 0.9907\n",
      "Epoch 14/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1560 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1105 - accuracy: 0.9881 - val_loss: 1.1058 - val_accuracy: 0.9954\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 1.0710 - accuracy: 0.9933 - val_loss: 1.0669 - val_accuracy: 0.9954\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 1.0319 - accuracy: 0.9897 - val_loss: 1.0283 - val_accuracy: 0.9954\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.9925 - accuracy: 0.9959 - val_loss: 0.9900 - val_accuracy: 0.9954\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.9537 - accuracy: 0.9969 - val_loss: 0.9520 - val_accuracy: 0.9954\n",
      "Epoch 19/500\n",
      "61/72 [========================>.....] - ETA: 0s - loss: 0.9217 - accuracy: 0.9970INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.9153 - accuracy: 0.9969 - val_loss: 0.9147 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 721us/step - loss: 0.8775 - accuracy: 0.9974 - val_loss: 0.8776 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.8406 - accuracy: 0.9985 - val_loss: 0.8417 - val_accuracy: 0.9954\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 697us/step - loss: 0.8045 - accuracy: 0.9990 - val_loss: 0.8066 - val_accuracy: 0.9954\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.7694 - accuracy: 0.9990 - val_loss: 0.7724 - val_accuracy: 0.9954\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 916us/step - loss: 0.7354 - accuracy: 0.9990 - val_loss: 0.7393 - val_accuracy: 0.9954\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 655us/step - loss: 0.7026 - accuracy: 0.9990 - val_loss: 0.7076 - val_accuracy: 0.9954\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 999us/step - loss: 0.6711 - accuracy: 0.9990 - val_loss: 0.6767 - val_accuracy: 0.9954\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 617us/step - loss: 0.6407 - accuracy: 0.9990 - val_loss: 0.6475 - val_accuracy: 0.9954\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.6116 - accuracy: 0.9990 - val_loss: 0.6189 - val_accuracy: 0.9954\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 923us/step - loss: 0.5837 - accuracy: 0.9990 - val_loss: 0.5919 - val_accuracy: 0.9954\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.5572 - accuracy: 0.9990 - val_loss: 0.5660 - val_accuracy: 0.9954\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 993us/step - loss: 0.5318 - accuracy: 0.9990 - val_loss: 0.5414 - val_accuracy: 0.9954\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.5076 - accuracy: 0.9990 - val_loss: 0.5175 - val_accuracy: 0.9954\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 692us/step - loss: 0.4845 - accuracy: 0.9990 - val_loss: 0.4951 - val_accuracy: 0.9954\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 973us/step - loss: 0.4624 - accuracy: 0.9990 - val_loss: 0.4734 - val_accuracy: 0.9954\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.4415 - accuracy: 0.9990 - val_loss: 0.4530 - val_accuracy: 0.9954\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 988us/step - loss: 0.4215 - accuracy: 0.9990 - val_loss: 0.4334 - val_accuracy: 0.9954\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.4025 - accuracy: 0.9990 - val_loss: 0.4147 - val_accuracy: 0.9954\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 860us/step - loss: 0.3845 - accuracy: 0.9990 - val_loss: 0.3969 - val_accuracy: 0.9954\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.3672 - accuracy: 0.9990 - val_loss: 0.3800 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.3508 - accuracy: 0.9990 - val_loss: 0.3637 - val_accuracy: 0.9954\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.9990 - val_loss: 0.3485 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3204 - accuracy: 0.9990 - val_loss: 0.3336 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.3063 - accuracy: 0.9990 - val_loss: 0.3197 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.2929 - accuracy: 0.9990 - val_loss: 0.3063 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2800 - accuracy: 0.9990 - val_loss: 0.2936 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2678 - accuracy: 0.9990 - val_loss: 0.2814 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.2562 - accuracy: 0.9990 - val_loss: 0.2697 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2451 - accuracy: 0.9990 - val_loss: 0.2587 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2345 - accuracy: 0.9990 - val_loss: 0.2480 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 659us/step - loss: 0.2245 - accuracy: 0.9990 - val_loss: 0.2378 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.2148 - accuracy: 0.9990 - val_loss: 0.2281 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2056 - accuracy: 0.9990 - val_loss: 0.2189 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.1969 - accuracy: 0.9990 - val_loss: 0.2100 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.1885 - accuracy: 0.9990 - val_loss: 0.2016 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.1806 - accuracy: 0.9990 - val_loss: 0.1935 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.1730 - accuracy: 0.9990 - val_loss: 0.1856 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9990 - val_loss: 0.1782 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.1589 - accuracy: 0.9990 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.1522 - accuracy: 0.9990 - val_loss: 0.1644 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.1459 - accuracy: 0.9990 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1399 - accuracy: 0.9990 - val_loss: 0.1518 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1342 - accuracy: 0.9990 - val_loss: 0.1460 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.1287 - accuracy: 0.9990 - val_loss: 0.1403 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.1234 - accuracy: 0.9990 - val_loss: 0.1349 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.1185 - accuracy: 0.9990 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.1137 - accuracy: 0.9990 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.1091 - accuracy: 0.9990 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.1048 - accuracy: 0.9990 - val_loss: 0.1156 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.1007 - accuracy: 0.9990 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.0967 - accuracy: 0.9990 - val_loss: 0.1072 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.0929 - accuracy: 0.9990 - val_loss: 0.1032 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.0893 - accuracy: 0.9990 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0859 - accuracy: 0.9990 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 730us/step - loss: 0.0825 - accuracy: 0.9990 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0794 - accuracy: 0.9990 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 721us/step - loss: 0.0763 - accuracy: 0.9990 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.0734 - accuracy: 0.9990 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0706 - accuracy: 0.9990 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0680 - accuracy: 0.9990 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.0655 - accuracy: 0.9990 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0630 - accuracy: 0.9990 - val_loss: 0.0717 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.0607 - accuracy: 0.9990 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 0.0585 - accuracy: 0.9990 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 951us/step - loss: 0.0564 - accuracy: 0.9990 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.0543 - accuracy: 0.9990 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 658us/step - loss: 0.0524 - accuracy: 0.9990 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 945us/step - loss: 0.0505 - accuracy: 0.9990 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9990 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0470 - accuracy: 0.9990 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.0454 - accuracy: 0.9990 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 731us/step - loss: 0.0438 - accuracy: 0.9990 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.0422 - accuracy: 0.9990 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0408 - accuracy: 0.9990 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 778us/step - loss: 0.0394 - accuracy: 0.9990 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.0380 - accuracy: 0.9990 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 654us/step - loss: 0.0367 - accuracy: 0.9990 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.0355 - accuracy: 0.9990 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.0343 - accuracy: 0.9990 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 747us/step - loss: 0.0332 - accuracy: 0.9990 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.0321 - accuracy: 0.9990 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.0310 - accuracy: 0.9990 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.0300 - accuracy: 0.9990 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 742us/step - loss: 0.0290 - accuracy: 0.9990 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.0281 - accuracy: 0.9990 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 714us/step - loss: 0.0272 - accuracy: 0.9990 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0263 - accuracy: 0.9990 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 747us/step - loss: 0.0255 - accuracy: 0.9990 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.0247 - accuracy: 0.9990 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 706us/step - loss: 0.0239 - accuracy: 0.9990 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.0224 - accuracy: 0.9990 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.0211 - accuracy: 0.9990 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.0204 - accuracy: 0.9990 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.0192 - accuracy: 0.9990 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0186 - accuracy: 0.9990 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9990 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.0175 - accuracy: 0.9990 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 119: early stopping\n",
      "29/29 - 0s - loss: 0.8632 - accuracy: 0.9967 - 94ms/epoch - 3ms/step\n",
      "4\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 37s - loss: 1.6005 - accuracy: 0.2593INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.6357 - accuracy: 0.2017 - val_loss: 1.6067 - val_accuracy: 0.1852\n",
      "Epoch 2/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.6611 - accuracy: 0.2222INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5776 - accuracy: 0.2145 - val_loss: 1.5593 - val_accuracy: 0.2361\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5825 - accuracy: 0.1481INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5331 - accuracy: 0.3698 - val_loss: 1.5201 - val_accuracy: 0.4398\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5066 - accuracy: 0.4815INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4955 - accuracy: 0.5003 - val_loss: 1.4850 - val_accuracy: 0.6204\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4714 - accuracy: 0.5926INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.4598 - accuracy: 0.7071 - val_loss: 1.4518 - val_accuracy: 0.7083\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4244 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4252 - accuracy: 0.7695 - val_loss: 1.4187 - val_accuracy: 0.7315\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.4051 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3907 - accuracy: 0.7715 - val_loss: 1.3848 - val_accuracy: 0.7500\n",
      "Epoch 8/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3878 - accuracy: 0.6667INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3559 - accuracy: 0.7880 - val_loss: 1.3507 - val_accuracy: 0.7824\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3650 - accuracy: 0.6667INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.3206 - accuracy: 0.8056 - val_loss: 1.3162 - val_accuracy: 0.8056\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2720 - accuracy: 0.8148INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.2844 - accuracy: 0.8432 - val_loss: 1.2810 - val_accuracy: 0.8657\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2023 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2478 - accuracy: 0.8814 - val_loss: 1.2450 - val_accuracy: 0.9074\n",
      "Epoch 12/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1903 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2107 - accuracy: 0.8999 - val_loss: 1.2089 - val_accuracy: 0.9213\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2315 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1732 - accuracy: 0.9345 - val_loss: 1.1719 - val_accuracy: 0.9491\n",
      "Epoch 14/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1424 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.1352 - accuracy: 0.9618 - val_loss: 1.1347 - val_accuracy: 0.9722\n",
      "Epoch 15/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1494 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.0971 - accuracy: 0.9752 - val_loss: 1.0973 - val_accuracy: 0.9861\n",
      "Epoch 16/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.0279 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0589 - accuracy: 0.9825 - val_loss: 1.0599 - val_accuracy: 0.9907\n",
      "Epoch 17/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.0261 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0209 - accuracy: 0.9876 - val_loss: 1.0225 - val_accuracy: 0.9954\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.9830 - accuracy: 0.9902 - val_loss: 0.9858 - val_accuracy: 0.9954\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.9457 - accuracy: 0.9954 - val_loss: 0.9490 - val_accuracy: 0.9954\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.9088 - accuracy: 0.9959 - val_loss: 0.9132 - val_accuracy: 0.9954\n",
      "Epoch 21/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 0.8604 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.8726 - accuracy: 0.9969 - val_loss: 0.8780 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.8372 - accuracy: 0.9969 - val_loss: 0.8434 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.8026 - accuracy: 0.9974 - val_loss: 0.8095 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.7693 - accuracy: 0.9979 - val_loss: 0.7767 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7367 - accuracy: 0.9985 - val_loss: 0.7450 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 0.7053 - accuracy: 0.9985 - val_loss: 0.7142 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.9985 - val_loss: 0.6848 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.6458 - accuracy: 0.9985 - val_loss: 0.6562 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6178 - accuracy: 0.9985 - val_loss: 0.6287 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5912 - accuracy: 0.9990 - val_loss: 0.6025 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 768us/step - loss: 0.5654 - accuracy: 0.9990 - val_loss: 0.5772 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.5409 - accuracy: 0.9995 - val_loss: 0.5531 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5173 - accuracy: 0.9995 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.4948 - accuracy: 0.9995 - val_loss: 0.5079 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.4733 - accuracy: 0.9990 - val_loss: 0.4871 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.4528 - accuracy: 0.9995 - val_loss: 0.4665 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.4332 - accuracy: 0.9995 - val_loss: 0.4472 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.4145 - accuracy: 0.9990 - val_loss: 0.4287 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.3966 - accuracy: 0.9990 - val_loss: 0.4111 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3796 - accuracy: 0.9990 - val_loss: 0.3939 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.3633 - accuracy: 0.9990 - val_loss: 0.3776 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.3477 - accuracy: 0.9990 - val_loss: 0.3623 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.3328 - accuracy: 0.9990 - val_loss: 0.3473 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.3185 - accuracy: 0.9990 - val_loss: 0.3333 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.3050 - accuracy: 0.9990 - val_loss: 0.3196 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.2919 - accuracy: 0.9990 - val_loss: 0.3067 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.9990 - val_loss: 0.2941 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 607us/step - loss: 0.2676 - accuracy: 0.9990 - val_loss: 0.2823 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 695us/step - loss: 0.2563 - accuracy: 0.9990 - val_loss: 0.2708 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.2455 - accuracy: 0.9990 - val_loss: 0.2600 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 929us/step - loss: 0.2351 - accuracy: 0.9990 - val_loss: 0.2495 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.2252 - accuracy: 0.9990 - val_loss: 0.2394 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.2157 - accuracy: 0.9990 - val_loss: 0.2297 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.2067 - accuracy: 0.9990 - val_loss: 0.2207 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1980 - accuracy: 0.9990 - val_loss: 0.2118 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1897 - accuracy: 0.9990 - val_loss: 0.2033 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.1818 - accuracy: 0.9990 - val_loss: 0.1952 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1743 - accuracy: 0.9990 - val_loss: 0.1876 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1671 - accuracy: 0.9990 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.1602 - accuracy: 0.9990 - val_loss: 0.1732 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.1536 - accuracy: 0.9990 - val_loss: 0.1664 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.1472 - accuracy: 0.9990 - val_loss: 0.1599 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.1412 - accuracy: 0.9990 - val_loss: 0.1536 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.1355 - accuracy: 0.9990 - val_loss: 0.1478 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1300 - accuracy: 0.9990 - val_loss: 0.1421 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1248 - accuracy: 0.9990 - val_loss: 0.1367 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1197 - accuracy: 0.9990 - val_loss: 0.1315 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.1150 - accuracy: 0.9990 - val_loss: 0.1265 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1104 - accuracy: 0.9990 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1060 - accuracy: 0.9990 - val_loss: 0.1172 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1019 - accuracy: 0.9990 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0978 - accuracy: 0.9990 - val_loss: 0.1086 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0940 - accuracy: 0.9990 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0904 - accuracy: 0.9990 - val_loss: 0.1008 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.0869 - accuracy: 0.9990 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0836 - accuracy: 0.9990 - val_loss: 0.0936 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0804 - accuracy: 0.9990 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0774 - accuracy: 0.9990 - val_loss: 0.0871 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0745 - accuracy: 0.9990 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0716 - accuracy: 0.9990 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0690 - accuracy: 0.9990 - val_loss: 0.0782 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0664 - accuracy: 0.9990 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0640 - accuracy: 0.9990 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0616 - accuracy: 0.9990 - val_loss: 0.0703 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0594 - accuracy: 0.9990 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0572 - accuracy: 0.9990 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0551 - accuracy: 0.9990 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0532 - accuracy: 0.9990 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0513 - accuracy: 0.9990 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0495 - accuracy: 0.9990 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0477 - accuracy: 0.9990 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0461 - accuracy: 0.9990 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0445 - accuracy: 0.9990 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0429 - accuracy: 0.9990 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0414 - accuracy: 0.9990 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0400 - accuracy: 0.9990 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0386 - accuracy: 0.9990 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0373 - accuracy: 0.9990 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 970us/step - loss: 0.0361 - accuracy: 0.9990 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0349 - accuracy: 0.9990 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0337 - accuracy: 0.9990 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0326 - accuracy: 0.9990 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0316 - accuracy: 0.9990 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0305 - accuracy: 0.9990 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.0295 - accuracy: 0.9990 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0285 - accuracy: 0.9990 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0276 - accuracy: 0.9990 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0259 - accuracy: 0.9990 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0251 - accuracy: 0.9990 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0243 - accuracy: 0.9990 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0235 - accuracy: 0.9990 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0228 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0208 - accuracy: 0.9990 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0201 - accuracy: 0.9990 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0195 - accuracy: 0.9990 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.0190 - accuracy: 0.9990 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0184 - accuracy: 0.9990 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.0178 - accuracy: 0.9990 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 121: early stopping\n",
      "29/29 - 0s - loss: 0.8165 - accuracy: 0.9978 - 98ms/epoch - 3ms/step\n",
      "5\n",
      "Epoch 1/500\n",
      "60/72 [========================>.....] - ETA: 0s - loss: 1.6186 - accuracy: 0.2068 INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.6197 - accuracy: 0.1996 - val_loss: 1.5915 - val_accuracy: 0.2037\n",
      "Epoch 2/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5525 - accuracy: 0.2593INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5646 - accuracy: 0.2063 - val_loss: 1.5469 - val_accuracy: 0.2454\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5579 - accuracy: 0.2222INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5223 - accuracy: 0.3218 - val_loss: 1.5086 - val_accuracy: 0.3657\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4508 - accuracy: 0.5185INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4842 - accuracy: 0.3914 - val_loss: 1.4730 - val_accuracy: 0.4167\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3976 - accuracy: 0.5185INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.4479 - accuracy: 0.4951 - val_loss: 1.4378 - val_accuracy: 0.5509\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3984 - accuracy: 0.5556INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4121 - accuracy: 0.6230 - val_loss: 1.4031 - val_accuracy: 0.6435\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4268 - accuracy: 0.6296INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3754 - accuracy: 0.6576 - val_loss: 1.3670 - val_accuracy: 0.6528\n",
      "Epoch 8/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2896 - accuracy: 0.8148INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3388 - accuracy: 0.7009 - val_loss: 1.3312 - val_accuracy: 0.7037\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3509 - accuracy: 0.5556INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3019 - accuracy: 0.7375 - val_loss: 1.2949 - val_accuracy: 0.7731\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2595 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2643 - accuracy: 0.8241 - val_loss: 1.2578 - val_accuracy: 0.8472\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2544 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2263 - accuracy: 0.8814 - val_loss: 1.2204 - val_accuracy: 0.9120\n",
      "Epoch 12/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2379 - accuracy: 0.8889INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.1881 - accuracy: 0.9371 - val_loss: 1.1828 - val_accuracy: 0.9583\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1704 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1491 - accuracy: 0.9670 - val_loss: 1.1450 - val_accuracy: 0.9769\n",
      "Epoch 14/500\n",
      "61/72 [========================>.....] - ETA: 0s - loss: 1.1084 - accuracy: 0.9806INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.1104 - accuracy: 0.9819 - val_loss: 1.1067 - val_accuracy: 0.9815\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 1.0714 - accuracy: 0.9881 - val_loss: 1.0685 - val_accuracy: 0.9815\n",
      "Epoch 16/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1199 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0325 - accuracy: 0.9912 - val_loss: 1.0304 - val_accuracy: 0.9907\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.9939 - accuracy: 0.9933 - val_loss: 0.9923 - val_accuracy: 0.9907\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.9555 - accuracy: 0.9959 - val_loss: 0.9549 - val_accuracy: 0.9907\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 0.9177 - accuracy: 0.9969 - val_loss: 0.9177 - val_accuracy: 0.9907\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.8807 - accuracy: 0.9985 - val_loss: 0.8816 - val_accuracy: 0.9907\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.8444 - accuracy: 0.9979 - val_loss: 0.8459 - val_accuracy: 0.9907\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8088 - accuracy: 0.9990 - val_loss: 0.8111 - val_accuracy: 0.9907\n",
      "Epoch 23/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 0.7203 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.7744 - accuracy: 0.9995 - val_loss: 0.7773 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7407 - accuracy: 0.9990 - val_loss: 0.7446 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7082 - accuracy: 0.9990 - val_loss: 0.7129 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6769 - accuracy: 0.9995 - val_loss: 0.6823 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6465 - accuracy: 0.9995 - val_loss: 0.6528 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.6175 - accuracy: 0.9995 - val_loss: 0.6241 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5896 - accuracy: 0.9995 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.5628 - accuracy: 0.9995 - val_loss: 0.5708 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5373 - accuracy: 0.9995 - val_loss: 0.5458 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5130 - accuracy: 0.9995 - val_loss: 0.5219 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 948us/step - loss: 0.4896 - accuracy: 0.9995 - val_loss: 0.4989 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.4673 - accuracy: 0.9995 - val_loss: 0.4772 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.4460 - accuracy: 0.9995 - val_loss: 0.4566 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.4260 - accuracy: 0.9990 - val_loss: 0.4366 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.4067 - accuracy: 0.9995 - val_loss: 0.4177 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 721us/step - loss: 0.3883 - accuracy: 0.9990 - val_loss: 0.3997 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 977us/step - loss: 0.3709 - accuracy: 0.9990 - val_loss: 0.3827 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.3543 - accuracy: 0.9990 - val_loss: 0.3663 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 868us/step - loss: 0.3386 - accuracy: 0.9990 - val_loss: 0.3507 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 771us/step - loss: 0.3235 - accuracy: 0.9990 - val_loss: 0.3358 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.3092 - accuracy: 0.9990 - val_loss: 0.3217 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.2956 - accuracy: 0.9990 - val_loss: 0.3082 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.2827 - accuracy: 0.9990 - val_loss: 0.2953 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.2704 - accuracy: 0.9990 - val_loss: 0.2831 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.9990 - val_loss: 0.2713 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 852us/step - loss: 0.2474 - accuracy: 0.9990 - val_loss: 0.2601 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.2367 - accuracy: 0.9990 - val_loss: 0.2495 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.2265 - accuracy: 0.9990 - val_loss: 0.2393 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.2168 - accuracy: 0.9990 - val_loss: 0.2295 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 947us/step - loss: 0.2076 - accuracy: 0.9990 - val_loss: 0.2203 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.1988 - accuracy: 0.9990 - val_loss: 0.2114 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.1903 - accuracy: 0.9990 - val_loss: 0.2029 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1824 - accuracy: 0.9990 - val_loss: 0.1950 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.1747 - accuracy: 0.9990 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.1674 - accuracy: 0.9990 - val_loss: 0.1797 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1604 - accuracy: 0.9990 - val_loss: 0.1726 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1538 - accuracy: 0.9990 - val_loss: 0.1658 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1474 - accuracy: 0.9990 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1414 - accuracy: 0.9990 - val_loss: 0.1532 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1356 - accuracy: 0.9990 - val_loss: 0.1472 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1301 - accuracy: 0.9990 - val_loss: 0.1416 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.1249 - accuracy: 0.9990 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1198 - accuracy: 0.9990 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1150 - accuracy: 0.9990 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.1104 - accuracy: 0.9990 - val_loss: 0.1212 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.1060 - accuracy: 0.9990 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.1018 - accuracy: 0.9990 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 841us/step - loss: 0.0978 - accuracy: 0.9990 - val_loss: 0.1081 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.0940 - accuracy: 0.9990 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.0903 - accuracy: 0.9990 - val_loss: 0.1003 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 998us/step - loss: 0.0868 - accuracy: 0.9990 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 618us/step - loss: 0.0835 - accuracy: 0.9990 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0803 - accuracy: 0.9990 - val_loss: 0.0898 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.0772 - accuracy: 0.9990 - val_loss: 0.0866 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.0743 - accuracy: 0.9990 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9990 - val_loss: 0.0806 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.0688 - accuracy: 0.9990 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0663 - accuracy: 0.9990 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 968us/step - loss: 0.0638 - accuracy: 0.9990 - val_loss: 0.0724 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.0614 - accuracy: 0.9990 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9990 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0570 - accuracy: 0.9990 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.0549 - accuracy: 0.9990 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0529 - accuracy: 0.9990 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0510 - accuracy: 0.9990 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0492 - accuracy: 0.9990 - val_loss: 0.0568 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0475 - accuracy: 0.9990 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0458 - accuracy: 0.9990 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0442 - accuracy: 0.9990 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0427 - accuracy: 0.9990 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 744us/step - loss: 0.0412 - accuracy: 0.9990 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.0398 - accuracy: 0.9990 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.0384 - accuracy: 0.9990 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.0371 - accuracy: 0.9990 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.0358 - accuracy: 0.9990 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0346 - accuracy: 0.9990 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.0335 - accuracy: 0.9990 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.0323 - accuracy: 0.9990 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9990 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 700us/step - loss: 0.0302 - accuracy: 0.9990 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.0292 - accuracy: 0.9990 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0283 - accuracy: 0.9990 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0274 - accuracy: 0.9990 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.0265 - accuracy: 0.9990 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0248 - accuracy: 0.9990 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.0240 - accuracy: 0.9990 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.0233 - accuracy: 0.9990 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0218 - accuracy: 0.9990 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0212 - accuracy: 0.9990 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.0205 - accuracy: 0.9990 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0199 - accuracy: 0.9990 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.0193 - accuracy: 0.9990 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.0187 - accuracy: 0.9990 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.0181 - accuracy: 0.9990 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0176 - accuracy: 0.9990 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0171 - accuracy: 0.9990 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.0166 - accuracy: 0.9990 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.0161 - accuracy: 0.9995 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.0156 - accuracy: 0.9995 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 123: early stopping\n",
      "29/29 - 0s - loss: 0.7249 - accuracy: 1.0000 - 106ms/epoch - 4ms/step\n",
      "6\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 19s - loss: 1.6592 - accuracy: 0.2222INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.6200 - accuracy: 0.2398 - val_loss: 1.5957 - val_accuracy: 0.2130\n",
      "Epoch 2/500\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 1.5745 - accuracy: 0.2560INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.5732 - accuracy: 0.2620 - val_loss: 1.5569 - val_accuracy: 0.3102\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5549 - accuracy: 0.2593INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.5347 - accuracy: 0.4569 - val_loss: 1.5227 - val_accuracy: 0.5370\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5085 - accuracy: 0.7407INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4996 - accuracy: 0.6570 - val_loss: 1.4898 - val_accuracy: 0.7083\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.4916 - accuracy: 0.5926INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4654 - accuracy: 0.7231 - val_loss: 1.4572 - val_accuracy: 0.7269\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.4467 - accuracy: 0.7037INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.4317 - accuracy: 0.7612 - val_loss: 1.4246 - val_accuracy: 0.7778\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.3954 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3976 - accuracy: 0.7875 - val_loss: 1.3913 - val_accuracy: 0.8148\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3633 - accuracy: 0.8422INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3633 - accuracy: 0.8422 - val_loss: 1.3578 - val_accuracy: 0.8657\n",
      "Epoch 9/500\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 1.3297 - accuracy: 0.8808INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3278 - accuracy: 0.8834 - val_loss: 1.3231 - val_accuracy: 0.9120\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2553 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2919 - accuracy: 0.9123 - val_loss: 1.2878 - val_accuracy: 0.9352\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3117 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.2554 - accuracy: 0.9505 - val_loss: 1.2519 - val_accuracy: 0.9537\n",
      "Epoch 12/500\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 1.2214 - accuracy: 0.9653INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2182 - accuracy: 0.9660 - val_loss: 1.2154 - val_accuracy: 0.9722\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1904 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1804 - accuracy: 0.9809 - val_loss: 1.1783 - val_accuracy: 0.9907\n",
      "Epoch 14/500\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 1.1435 - accuracy: 0.9773INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1420 - accuracy: 0.9783 - val_loss: 1.1408 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 1.1035 - accuracy: 0.9892 - val_loss: 1.1029 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 709us/step - loss: 1.0644 - accuracy: 0.9902 - val_loss: 1.0647 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 964us/step - loss: 1.0253 - accuracy: 0.9928 - val_loss: 1.0265 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 971us/step - loss: 0.9865 - accuracy: 0.9938 - val_loss: 0.9884 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.9480 - accuracy: 0.9943 - val_loss: 0.9509 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.9098 - accuracy: 0.9969 - val_loss: 0.9136 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.8725 - accuracy: 0.9974 - val_loss: 0.8769 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8358 - accuracy: 0.9990 - val_loss: 0.8413 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8002 - accuracy: 0.9990 - val_loss: 0.8064 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7655 - accuracy: 0.9990 - val_loss: 0.7726 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7317 - accuracy: 0.9990 - val_loss: 0.7398 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.6993 - accuracy: 0.9995 - val_loss: 0.7079 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6678 - accuracy: 0.9990 - val_loss: 0.6775 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6376 - accuracy: 0.9995 - val_loss: 0.6479 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 693us/step - loss: 0.6087 - accuracy: 0.9995 - val_loss: 0.6194 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5810 - accuracy: 0.9995 - val_loss: 0.5924 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5547 - accuracy: 0.9995 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5296 - accuracy: 0.9995 - val_loss: 0.5418 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 715us/step - loss: 0.5054 - accuracy: 0.9995 - val_loss: 0.5183 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.4824 - accuracy: 0.9995 - val_loss: 0.4958 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.4605 - accuracy: 0.9995 - val_loss: 0.4741 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.4398 - accuracy: 0.9995 - val_loss: 0.4537 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.4200 - accuracy: 0.9995 - val_loss: 0.4342 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.9995 - val_loss: 0.4155 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.3832 - accuracy: 0.9995 - val_loss: 0.3979 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.3661 - accuracy: 0.9995 - val_loss: 0.3810 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.3499 - accuracy: 0.9990 - val_loss: 0.3647 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.3345 - accuracy: 0.9990 - val_loss: 0.3492 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.3197 - accuracy: 0.9990 - val_loss: 0.3345 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3057 - accuracy: 0.9990 - val_loss: 0.3207 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.2924 - accuracy: 0.9990 - val_loss: 0.3073 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2797 - accuracy: 0.9990 - val_loss: 0.2945 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2675 - accuracy: 0.9990 - val_loss: 0.2824 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.2560 - accuracy: 0.9990 - val_loss: 0.2708 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.2450 - accuracy: 0.9990 - val_loss: 0.2600 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.2346 - accuracy: 0.9990 - val_loss: 0.2492 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2246 - accuracy: 0.9990 - val_loss: 0.2392 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.2151 - accuracy: 0.9990 - val_loss: 0.2295 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 706us/step - loss: 0.2060 - accuracy: 0.9990 - val_loss: 0.2203 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.1972 - accuracy: 0.9990 - val_loss: 0.2115 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.1889 - accuracy: 0.9990 - val_loss: 0.2031 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.1811 - accuracy: 0.9990 - val_loss: 0.1951 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.1735 - accuracy: 0.9990 - val_loss: 0.1874 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1664 - accuracy: 0.9990 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.1595 - accuracy: 0.9990 - val_loss: 0.1729 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 996us/step - loss: 0.1529 - accuracy: 0.9990 - val_loss: 0.1662 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.1467 - accuracy: 0.9990 - val_loss: 0.1598 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9990 - val_loss: 0.1536 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 589us/step - loss: 0.1350 - accuracy: 0.9990 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.1296 - accuracy: 0.9990 - val_loss: 0.1421 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.1243 - accuracy: 0.9990 - val_loss: 0.1368 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.1193 - accuracy: 0.9990 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.1146 - accuracy: 0.9990 - val_loss: 0.1267 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.1101 - accuracy: 0.9990 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9990 - val_loss: 0.1174 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.1016 - accuracy: 0.9990 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.0976 - accuracy: 0.9990 - val_loss: 0.1090 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 685us/step - loss: 0.0939 - accuracy: 0.9990 - val_loss: 0.1050 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.0902 - accuracy: 0.9990 - val_loss: 0.1011 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.0868 - accuracy: 0.9990 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.0835 - accuracy: 0.9990 - val_loss: 0.0940 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 623us/step - loss: 0.0803 - accuracy: 0.9990 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9990 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.0744 - accuracy: 0.9990 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0716 - accuracy: 0.9990 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.0689 - accuracy: 0.9990 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.0664 - accuracy: 0.9990 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.0639 - accuracy: 0.9990 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.0616 - accuracy: 0.9990 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0594 - accuracy: 0.9990 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 670us/step - loss: 0.0572 - accuracy: 0.9990 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 972us/step - loss: 0.0552 - accuracy: 0.9990 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.0532 - accuracy: 0.9990 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 731us/step - loss: 0.0513 - accuracy: 0.9990 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.0495 - accuracy: 0.9990 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0478 - accuracy: 0.9990 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0461 - accuracy: 0.9990 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0445 - accuracy: 0.9990 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0429 - accuracy: 0.9990 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0415 - accuracy: 0.9990 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 653us/step - loss: 0.0401 - accuracy: 0.9990 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.0387 - accuracy: 0.9990 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.0374 - accuracy: 0.9990 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 699us/step - loss: 0.0361 - accuracy: 0.9990 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 998us/step - loss: 0.0349 - accuracy: 0.9990 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.0338 - accuracy: 0.9990 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0326 - accuracy: 0.9990 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.0316 - accuracy: 0.9990 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 0.0305 - accuracy: 0.9990 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9990 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.0286 - accuracy: 0.9990 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 744us/step - loss: 0.0277 - accuracy: 0.9990 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0259 - accuracy: 0.9990 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.0251 - accuracy: 0.9990 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.0243 - accuracy: 0.9990 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.0235 - accuracy: 0.9990 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.0228 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 114: early stopping\n",
      "29/29 - 0s - loss: 1.0953 - accuracy: 0.9815 - 117ms/epoch - 4ms/step\n",
      "7\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 18s - loss: 1.6817 - accuracy: 0.0000e+00INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.6263 - accuracy: 0.0598 - val_loss: 1.6046 - val_accuracy: 0.1204\n",
      "Epoch 2/500\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.5896 - accuracy: 0.1616INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5877 - accuracy: 0.1655 - val_loss: 1.5696 - val_accuracy: 0.2361\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.6069 - accuracy: 0.1481INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5516 - accuracy: 0.2981 - val_loss: 1.5355 - val_accuracy: 0.3426\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.5313 - accuracy: 0.2963INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5165 - accuracy: 0.4234 - val_loss: 1.5020 - val_accuracy: 0.5046\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4826 - accuracy: 0.5185INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.4817 - accuracy: 0.5921 - val_loss: 1.4683 - val_accuracy: 0.6343\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.4470 - accuracy: 0.6509INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4470 - accuracy: 0.6509 - val_loss: 1.4342 - val_accuracy: 0.6713\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4348 - accuracy: 0.6667INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4118 - accuracy: 0.7055 - val_loss: 1.3993 - val_accuracy: 0.7130\n",
      "Epoch 8/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3517 - accuracy: 0.7407INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3759 - accuracy: 0.7323 - val_loss: 1.3646 - val_accuracy: 0.7639\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4069 - accuracy: 0.6296INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3398 - accuracy: 0.7932 - val_loss: 1.3287 - val_accuracy: 0.8056\n",
      "Epoch 10/500\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 1.3036 - accuracy: 0.8690INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3030 - accuracy: 0.8695 - val_loss: 1.2922 - val_accuracy: 0.8750\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2845 - accuracy: 0.8148INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2654 - accuracy: 0.9025 - val_loss: 1.2557 - val_accuracy: 0.9306\n",
      "Epoch 12/500\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 1.2317 - accuracy: 0.9279INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.2275 - accuracy: 0.9366 - val_loss: 1.2179 - val_accuracy: 0.9676\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2280 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1890 - accuracy: 0.9546 - val_loss: 1.1804 - val_accuracy: 0.9722\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 964us/step - loss: 1.1502 - accuracy: 0.9742 - val_loss: 1.1422 - val_accuracy: 0.9722\n",
      "Epoch 15/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1691 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1114 - accuracy: 0.9840 - val_loss: 1.1038 - val_accuracy: 0.9954\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 937us/step - loss: 1.0727 - accuracy: 0.9887 - val_loss: 1.0660 - val_accuracy: 0.9954\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 1.0342 - accuracy: 0.9912 - val_loss: 1.0280 - val_accuracy: 0.9954\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.9959 - accuracy: 0.9933 - val_loss: 0.9904 - val_accuracy: 0.9954\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 933us/step - loss: 0.9578 - accuracy: 0.9969 - val_loss: 0.9531 - val_accuracy: 0.9954\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 631us/step - loss: 0.9203 - accuracy: 0.9974 - val_loss: 0.9165 - val_accuracy: 0.9954\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8837 - accuracy: 0.9974 - val_loss: 0.8801 - val_accuracy: 0.9954\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.8473 - accuracy: 0.9969 - val_loss: 0.8449 - val_accuracy: 0.9954\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 958us/step - loss: 0.8120 - accuracy: 0.9974 - val_loss: 0.8104 - val_accuracy: 0.9954\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7776 - accuracy: 0.9974 - val_loss: 0.7767 - val_accuracy: 0.9954\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.7443 - accuracy: 0.9974 - val_loss: 0.7440 - val_accuracy: 0.9954\n",
      "Epoch 26/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 0.7708 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7118 - accuracy: 0.9979 - val_loss: 0.7126 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6807 - accuracy: 0.9985 - val_loss: 0.6821 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6506 - accuracy: 0.9985 - val_loss: 0.6527 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6217 - accuracy: 0.9985 - val_loss: 0.6246 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5938 - accuracy: 0.9990 - val_loss: 0.5976 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 739us/step - loss: 0.5671 - accuracy: 0.9990 - val_loss: 0.5714 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.5416 - accuracy: 0.9990 - val_loss: 0.5464 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.5171 - accuracy: 0.9990 - val_loss: 0.5224 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.4939 - accuracy: 0.9990 - val_loss: 0.4996 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.4713 - accuracy: 0.9990 - val_loss: 0.4776 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.4499 - accuracy: 0.9990 - val_loss: 0.4568 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.4295 - accuracy: 0.9990 - val_loss: 0.4369 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.4101 - accuracy: 0.9990 - val_loss: 0.4178 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.3915 - accuracy: 0.9990 - val_loss: 0.3998 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.3739 - accuracy: 0.9990 - val_loss: 0.3824 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.3570 - accuracy: 0.9990 - val_loss: 0.3660 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.3409 - accuracy: 0.9990 - val_loss: 0.3501 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3257 - accuracy: 0.9990 - val_loss: 0.3351 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.3112 - accuracy: 0.9990 - val_loss: 0.3206 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.2973 - accuracy: 0.9990 - val_loss: 0.3071 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.2841 - accuracy: 0.9990 - val_loss: 0.2941 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.2715 - accuracy: 0.9990 - val_loss: 0.2816 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.2596 - accuracy: 0.9990 - val_loss: 0.2696 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 875us/step - loss: 0.2481 - accuracy: 0.9990 - val_loss: 0.2584 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.2373 - accuracy: 0.9990 - val_loss: 0.2476 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.2269 - accuracy: 0.9990 - val_loss: 0.2373 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.2170 - accuracy: 0.9990 - val_loss: 0.2275 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9990 - val_loss: 0.2180 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.1987 - accuracy: 0.9990 - val_loss: 0.2091 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.1901 - accuracy: 0.9990 - val_loss: 0.2005 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.1820 - accuracy: 0.9990 - val_loss: 0.1924 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.1743 - accuracy: 0.9990 - val_loss: 0.1846 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.1669 - accuracy: 0.9990 - val_loss: 0.1771 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.1598 - accuracy: 0.9990 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.1531 - accuracy: 0.9990 - val_loss: 0.1633 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.1467 - accuracy: 0.9990 - val_loss: 0.1569 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.1407 - accuracy: 0.9990 - val_loss: 0.1506 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.1348 - accuracy: 0.9990 - val_loss: 0.1447 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9990 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.1240 - accuracy: 0.9990 - val_loss: 0.1337 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.1189 - accuracy: 0.9990 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.1141 - accuracy: 0.9990 - val_loss: 0.1236 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.1095 - accuracy: 0.9990 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.1051 - accuracy: 0.9990 - val_loss: 0.1144 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1009 - accuracy: 0.9990 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.0969 - accuracy: 0.9990 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.0931 - accuracy: 0.9990 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.0894 - accuracy: 0.9990 - val_loss: 0.0982 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.0860 - accuracy: 0.9990 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.0826 - accuracy: 0.9990 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.0794 - accuracy: 0.9990 - val_loss: 0.0878 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.0764 - accuracy: 0.9990 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.0735 - accuracy: 0.9990 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 968us/step - loss: 0.0707 - accuracy: 0.9990 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0680 - accuracy: 0.9990 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0655 - accuracy: 0.9990 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0630 - accuracy: 0.9990 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0607 - accuracy: 0.9990 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0585 - accuracy: 0.9990 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0564 - accuracy: 0.9990 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.0543 - accuracy: 0.9990 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9990 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.0505 - accuracy: 0.9990 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.0487 - accuracy: 0.9990 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 887us/step - loss: 0.0470 - accuracy: 0.9990 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0453 - accuracy: 0.9990 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.0437 - accuracy: 0.9990 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0422 - accuracy: 0.9990 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0407 - accuracy: 0.9990 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0393 - accuracy: 0.9990 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0380 - accuracy: 0.9990 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 957us/step - loss: 0.0367 - accuracy: 0.9990 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0354 - accuracy: 0.9990 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0342 - accuracy: 0.9990 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0331 - accuracy: 0.9990 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0320 - accuracy: 0.9990 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0309 - accuracy: 0.9990 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.0299 - accuracy: 0.9990 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0289 - accuracy: 0.9990 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0280 - accuracy: 0.9990 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.0271 - accuracy: 0.9990 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.0262 - accuracy: 0.9990 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0254 - accuracy: 0.9990 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.0246 - accuracy: 0.9990 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.0238 - accuracy: 0.9990 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0223 - accuracy: 0.9990 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9990 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0210 - accuracy: 0.9990 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.0203 - accuracy: 0.9990 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.0197 - accuracy: 0.9990 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9990 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.0186 - accuracy: 0.9990 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 727us/step - loss: 0.0180 - accuracy: 0.9990 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.0175 - accuracy: 0.9990 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0170 - accuracy: 0.9990 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.0165 - accuracy: 0.9990 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.0160 - accuracy: 0.9990 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9990 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 850us/step - loss: 0.0151 - accuracy: 0.9990 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 126: early stopping\n",
      "29/29 - 0s - loss: 0.6612 - accuracy: 1.0000 - 116ms/epoch - 4ms/step\n",
      "8\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 19s - loss: 1.7638 - accuracy: 0.1481INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.6280 - accuracy: 0.2826 - val_loss: 1.5933 - val_accuracy: 0.3241\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 762us/step - loss: 1.5775 - accuracy: 0.2687 - val_loss: 1.5520 - val_accuracy: 0.3194\n",
      "Epoch 3/500\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 1.5384 - accuracy: 0.2928INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5358 - accuracy: 0.2986 - val_loss: 1.5159 - val_accuracy: 0.3657\n",
      "Epoch 4/500\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 1.5008 - accuracy: 0.3837INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4983 - accuracy: 0.3909 - val_loss: 1.4817 - val_accuracy: 0.4815\n",
      "Epoch 5/500\n",
      "58/72 [=======================>......] - ETA: 0s - loss: 1.4652 - accuracy: 0.5792INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.4627 - accuracy: 0.5859 - val_loss: 1.4484 - val_accuracy: 0.6435\n",
      "Epoch 6/500\n",
      "59/72 [=======================>......] - ETA: 0s - loss: 1.4296 - accuracy: 0.6930INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.4273 - accuracy: 0.6926 - val_loss: 1.4143 - val_accuracy: 0.7176\n",
      "Epoch 7/500\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 1.3930 - accuracy: 0.7320INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3917 - accuracy: 0.7344 - val_loss: 1.3802 - val_accuracy: 0.7778\n",
      "Epoch 8/500\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 1.3578 - accuracy: 0.7812INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.3555 - accuracy: 0.7818 - val_loss: 1.3450 - val_accuracy: 0.7870\n",
      "Epoch 9/500\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 1.3182 - accuracy: 0.8014INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3188 - accuracy: 0.8004 - val_loss: 1.3089 - val_accuracy: 0.8056\n",
      "Epoch 10/500\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 1.2837 - accuracy: 0.8225INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2811 - accuracy: 0.8252 - val_loss: 1.2725 - val_accuracy: 0.8241\n",
      "Epoch 11/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2382 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2427 - accuracy: 0.8504 - val_loss: 1.2350 - val_accuracy: 0.8472\n",
      "Epoch 12/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2229 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2040 - accuracy: 0.8582 - val_loss: 1.1971 - val_accuracy: 0.8843\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1552 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1648 - accuracy: 0.8948 - val_loss: 1.1587 - val_accuracy: 0.8981\n",
      "Epoch 14/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.1258 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.1251 - accuracy: 0.9067 - val_loss: 1.1198 - val_accuracy: 0.9259\n",
      "Epoch 15/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1037 - accuracy: 0.8519INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.0852 - accuracy: 0.9397 - val_loss: 1.0808 - val_accuracy: 0.9491\n",
      "Epoch 16/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.0965 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0456 - accuracy: 0.9546 - val_loss: 1.0424 - val_accuracy: 0.9583\n",
      "Epoch 17/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.0972 - accuracy: 0.9630INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0060 - accuracy: 0.9675 - val_loss: 1.0035 - val_accuracy: 0.9676\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 866us/step - loss: 0.9668 - accuracy: 0.9763 - val_loss: 0.9655 - val_accuracy: 0.9676\n",
      "Epoch 19/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 0.9849 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.9282 - accuracy: 0.9809 - val_loss: 0.9277 - val_accuracy: 0.9861\n",
      "Epoch 20/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 0.8100 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.8903 - accuracy: 0.9912 - val_loss: 0.8906 - val_accuracy: 0.9907\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.8530 - accuracy: 0.9938 - val_loss: 0.8544 - val_accuracy: 0.9907\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.8170 - accuracy: 0.9943 - val_loss: 0.8192 - val_accuracy: 0.9907\n",
      "Epoch 23/500\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.7836 - accuracy: 0.9954INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.7817 - accuracy: 0.9959 - val_loss: 0.7848 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.7477 - accuracy: 0.9964 - val_loss: 0.7515 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.7148 - accuracy: 0.9979 - val_loss: 0.7195 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.9990 - val_loss: 0.6887 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.6529 - accuracy: 0.9990 - val_loss: 0.6590 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.6238 - accuracy: 0.9990 - val_loss: 0.6307 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5960 - accuracy: 0.9990 - val_loss: 0.6034 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.5692 - accuracy: 0.9995 - val_loss: 0.5771 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.9995 - val_loss: 0.5523 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5195 - accuracy: 0.9995 - val_loss: 0.5284 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.4963 - accuracy: 0.9995 - val_loss: 0.5058 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.4742 - accuracy: 0.9995 - val_loss: 0.4839 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 967us/step - loss: 0.4533 - accuracy: 0.9995 - val_loss: 0.4634 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.4331 - accuracy: 0.9995 - val_loss: 0.4435 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.9995 - val_loss: 0.4247 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.3957 - accuracy: 0.9995 - val_loss: 0.4065 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.3783 - accuracy: 0.9995 - val_loss: 0.3894 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3617 - accuracy: 0.9995 - val_loss: 0.3731 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.3460 - accuracy: 0.9995 - val_loss: 0.3574 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.3309 - accuracy: 0.9990 - val_loss: 0.3425 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.3165 - accuracy: 0.9995 - val_loss: 0.3282 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.3028 - accuracy: 0.9990 - val_loss: 0.3145 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.2897 - accuracy: 0.9990 - val_loss: 0.3016 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 724us/step - loss: 0.2772 - accuracy: 0.9990 - val_loss: 0.2892 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.2654 - accuracy: 0.9990 - val_loss: 0.2773 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 728us/step - loss: 0.2540 - accuracy: 0.9990 - val_loss: 0.2659 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.2431 - accuracy: 0.9990 - val_loss: 0.2550 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.2327 - accuracy: 0.9990 - val_loss: 0.2446 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.2229 - accuracy: 0.9990 - val_loss: 0.2348 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.2134 - accuracy: 0.9990 - val_loss: 0.2253 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.2043 - accuracy: 0.9990 - val_loss: 0.2163 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.1957 - accuracy: 0.9990 - val_loss: 0.2075 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.1875 - accuracy: 0.9990 - val_loss: 0.1992 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.1797 - accuracy: 0.9990 - val_loss: 0.1913 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.1721 - accuracy: 0.9990 - val_loss: 0.1836 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.1649 - accuracy: 0.9990 - val_loss: 0.1764 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.1581 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 746us/step - loss: 0.1516 - accuracy: 0.9990 - val_loss: 0.1627 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.1453 - accuracy: 0.9990 - val_loss: 0.1564 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.1393 - accuracy: 0.9990 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1336 - accuracy: 0.9990 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1282 - accuracy: 0.9990 - val_loss: 0.1389 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 711us/step - loss: 0.1230 - accuracy: 0.9990 - val_loss: 0.1335 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.1180 - accuracy: 0.9990 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.1134 - accuracy: 0.9990 - val_loss: 0.1236 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1088 - accuracy: 0.9990 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.1044 - accuracy: 0.9990 - val_loss: 0.1144 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1003 - accuracy: 0.9990 - val_loss: 0.1102 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.0964 - accuracy: 0.9990 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.0926 - accuracy: 0.9990 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.0890 - accuracy: 0.9990 - val_loss: 0.0984 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.0855 - accuracy: 0.9990 - val_loss: 0.0948 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.0822 - accuracy: 0.9990 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 870us/step - loss: 0.0790 - accuracy: 0.9990 - val_loss: 0.0881 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0760 - accuracy: 0.9990 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.0731 - accuracy: 0.9990 - val_loss: 0.0818 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.0704 - accuracy: 0.9990 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9990 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.0652 - accuracy: 0.9990 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.0628 - accuracy: 0.9990 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 770us/step - loss: 0.0605 - accuracy: 0.9990 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.0582 - accuracy: 0.9990 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 743us/step - loss: 0.0561 - accuracy: 0.9990 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.0541 - accuracy: 0.9990 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0521 - accuracy: 0.9990 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.0502 - accuracy: 0.9990 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 661us/step - loss: 0.0484 - accuracy: 0.9990 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.0467 - accuracy: 0.9990 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.0451 - accuracy: 0.9990 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0435 - accuracy: 0.9990 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.0419 - accuracy: 0.9990 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 673us/step - loss: 0.0405 - accuracy: 0.9990 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.0391 - accuracy: 0.9990 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.0377 - accuracy: 0.9990 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9990 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.0352 - accuracy: 0.9990 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 688us/step - loss: 0.0340 - accuracy: 0.9990 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9990 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 751us/step - loss: 0.0318 - accuracy: 0.9990 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 887us/step - loss: 0.0307 - accuracy: 0.9990 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 730us/step - loss: 0.0297 - accuracy: 0.9990 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0287 - accuracy: 0.9990 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0278 - accuracy: 0.9990 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.0269 - accuracy: 0.9990 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 661us/step - loss: 0.0260 - accuracy: 0.9990 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.0252 - accuracy: 0.9990 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.0244 - accuracy: 0.9990 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0236 - accuracy: 0.9990 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 933us/step - loss: 0.0228 - accuracy: 0.9990 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 981us/step - loss: 0.0214 - accuracy: 0.9995 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.0208 - accuracy: 0.9995 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.0201 - accuracy: 0.9995 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.0195 - accuracy: 0.9995 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.0189 - accuracy: 0.9995 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.0183 - accuracy: 0.9995 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 664us/step - loss: 0.0178 - accuracy: 0.9995 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9995 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.0167 - accuracy: 0.9995 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.0162 - accuracy: 0.9995 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.0157 - accuracy: 0.9995 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 123: early stopping\n",
      "29/29 - 0s - loss: 0.7289 - accuracy: 1.0000 - 109ms/epoch - 4ms/step\n",
      "9\n",
      "Epoch 1/500\n",
      " 1/72 [..............................] - ETA: 19s - loss: 1.6124 - accuracy: 0.1852INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.5887 - accuracy: 0.2017 - val_loss: 1.5645 - val_accuracy: 0.1898\n",
      "Epoch 2/500\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 1.5453 - accuracy: 0.2496INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5429 - accuracy: 0.2615 - val_loss: 1.5244 - val_accuracy: 0.4074\n",
      "Epoch 3/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5152 - accuracy: 0.3704INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.5034 - accuracy: 0.5493 - val_loss: 1.4881 - val_accuracy: 0.6898\n",
      "Epoch 4/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.5005 - accuracy: 0.5926INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.4665 - accuracy: 0.7638 - val_loss: 1.4529 - val_accuracy: 0.7778\n",
      "Epoch 5/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4338 - accuracy: 0.7778INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4304 - accuracy: 0.7329 - val_loss: 1.4182 - val_accuracy: 0.7824\n",
      "Epoch 6/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.4283 - accuracy: 0.7407INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3946 - accuracy: 0.7715 - val_loss: 1.3830 - val_accuracy: 0.8102\n",
      "Epoch 7/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3629 - accuracy: 0.8889INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3584 - accuracy: 0.8412 - val_loss: 1.3478 - val_accuracy: 0.8843\n",
      "Epoch 8/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.2951 - accuracy: 0.8889INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3216 - accuracy: 0.8876 - val_loss: 1.3122 - val_accuracy: 0.9352\n",
      "Epoch 9/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.3500 - accuracy: 0.9259INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2844 - accuracy: 0.9201 - val_loss: 1.2753 - val_accuracy: 0.9583\n",
      "Epoch 10/500\n",
      " 1/72 [..............................] - ETA: 1s - loss: 1.2489 - accuracy: 0.8889INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2466 - accuracy: 0.9402 - val_loss: 1.2380 - val_accuracy: 0.9769\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 711us/step - loss: 1.2083 - accuracy: 0.9438 - val_loss: 1.2003 - val_accuracy: 0.9769\n",
      "Epoch 12/500\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 1.1716 - accuracy: 0.9751INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.1698 - accuracy: 0.9768 - val_loss: 1.1626 - val_accuracy: 0.9861\n",
      "Epoch 13/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1567 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.1305 - accuracy: 0.9789 - val_loss: 1.1240 - val_accuracy: 0.9954\n",
      "Epoch 14/500\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.1098 - accuracy: 1.0000INFO:tensorflow:Assets written to: model_name\\assets\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0912 - accuracy: 0.9809 - val_loss: 1.0853 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 1.0522 - accuracy: 0.9861 - val_loss: 1.0472 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 1.0132 - accuracy: 0.9876 - val_loss: 1.0088 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.9745 - accuracy: 0.9892 - val_loss: 0.9708 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 698us/step - loss: 0.9362 - accuracy: 0.9876 - val_loss: 0.9332 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8987 - accuracy: 0.9917 - val_loss: 0.8966 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8618 - accuracy: 0.9948 - val_loss: 0.8608 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.8261 - accuracy: 0.9948 - val_loss: 0.8257 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.7911 - accuracy: 0.9948 - val_loss: 0.7914 - val_accuracy: 0.9954\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.7573 - accuracy: 0.9948 - val_loss: 0.7584 - val_accuracy: 0.9954\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 688us/step - loss: 0.7247 - accuracy: 0.9964 - val_loss: 0.7267 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.6931 - accuracy: 0.9964 - val_loss: 0.6957 - val_accuracy: 0.9954\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.6628 - accuracy: 0.9974 - val_loss: 0.6662 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.9979 - val_loss: 0.6378 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.6058 - accuracy: 0.9974 - val_loss: 0.6106 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5792 - accuracy: 0.9985 - val_loss: 0.5846 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 688us/step - loss: 0.5537 - accuracy: 0.9985 - val_loss: 0.5593 - val_accuracy: 0.9954\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5292 - accuracy: 0.9985 - val_loss: 0.5356 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.5060 - accuracy: 0.9985 - val_loss: 0.5128 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.4838 - accuracy: 0.9990 - val_loss: 0.4910 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 957us/step - loss: 0.4626 - accuracy: 0.9990 - val_loss: 0.4705 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.4424 - accuracy: 0.9990 - val_loss: 0.4506 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 724us/step - loss: 0.4231 - accuracy: 0.9990 - val_loss: 0.4316 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 977us/step - loss: 0.4048 - accuracy: 0.9985 - val_loss: 0.4135 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.3873 - accuracy: 0.9990 - val_loss: 0.3965 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.3705 - accuracy: 0.9990 - val_loss: 0.3799 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.9990 - val_loss: 0.3641 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.3392 - accuracy: 0.9990 - val_loss: 0.3490 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.3247 - accuracy: 0.9990 - val_loss: 0.3346 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.9990 - val_loss: 0.3208 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.2975 - accuracy: 0.9990 - val_loss: 0.3076 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.2848 - accuracy: 0.9990 - val_loss: 0.2950 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.2726 - accuracy: 0.9990 - val_loss: 0.2828 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.2611 - accuracy: 0.9990 - val_loss: 0.2714 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.2500 - accuracy: 0.9990 - val_loss: 0.2602 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.2394 - accuracy: 0.9990 - val_loss: 0.2499 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.2293 - accuracy: 0.9990 - val_loss: 0.2398 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.2197 - accuracy: 0.9990 - val_loss: 0.2302 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 664us/step - loss: 0.2105 - accuracy: 0.9990 - val_loss: 0.2207 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.2016 - accuracy: 0.9990 - val_loss: 0.2119 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.1932 - accuracy: 0.9990 - val_loss: 0.2035 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.1851 - accuracy: 0.9990 - val_loss: 0.1952 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.1774 - accuracy: 0.9990 - val_loss: 0.1876 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.1701 - accuracy: 0.9990 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1630 - accuracy: 0.9990 - val_loss: 0.1729 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.1564 - accuracy: 0.9990 - val_loss: 0.1662 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 716us/step - loss: 0.1499 - accuracy: 0.9990 - val_loss: 0.1596 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.1438 - accuracy: 0.9990 - val_loss: 0.1534 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.1379 - accuracy: 0.9990 - val_loss: 0.1474 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9990 - val_loss: 0.1417 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.1269 - accuracy: 0.9990 - val_loss: 0.1362 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.1218 - accuracy: 0.9990 - val_loss: 0.1309 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.1169 - accuracy: 0.9990 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 729us/step - loss: 0.1122 - accuracy: 0.9990 - val_loss: 0.1211 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.1078 - accuracy: 0.9990 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.1035 - accuracy: 0.9990 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.0994 - accuracy: 0.9990 - val_loss: 0.1079 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0955 - accuracy: 0.9990 - val_loss: 0.1040 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 769us/step - loss: 0.0917 - accuracy: 0.9990 - val_loss: 0.1000 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 916us/step - loss: 0.0882 - accuracy: 0.9990 - val_loss: 0.0963 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 681us/step - loss: 0.0847 - accuracy: 0.9990 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0815 - accuracy: 0.9990 - val_loss: 0.0894 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.0783 - accuracy: 0.9990 - val_loss: 0.0861 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 657us/step - loss: 0.0754 - accuracy: 0.9990 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9990 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0698 - accuracy: 0.9990 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.0672 - accuracy: 0.9990 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 935us/step - loss: 0.0646 - accuracy: 0.9990 - val_loss: 0.0717 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.0622 - accuracy: 0.9990 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.0599 - accuracy: 0.9990 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.0577 - accuracy: 0.9990 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.0556 - accuracy: 0.9990 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.0536 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 712us/step - loss: 0.0516 - accuracy: 0.9990 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.0498 - accuracy: 0.9990 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.0480 - accuracy: 0.9990 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.0463 - accuracy: 0.9990 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.0447 - accuracy: 0.9990 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.0431 - accuracy: 0.9990 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.0416 - accuracy: 0.9990 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.0402 - accuracy: 0.9990 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9990 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 594us/step - loss: 0.0375 - accuracy: 0.9990 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.0362 - accuracy: 0.9990 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.0350 - accuracy: 0.9990 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.0338 - accuracy: 0.9990 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.0326 - accuracy: 0.9990 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.0316 - accuracy: 0.9990 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.0305 - accuracy: 0.9990 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9990 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 949us/step - loss: 0.0285 - accuracy: 0.9990 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0276 - accuracy: 0.9990 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0267 - accuracy: 0.9990 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0258 - accuracy: 0.9990 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0250 - accuracy: 0.9990 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0242 - accuracy: 0.9990 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.0234 - accuracy: 0.9990 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0227 - accuracy: 0.9990 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.0220 - accuracy: 0.9990 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.0213 - accuracy: 0.9990 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 114: early stopping\n",
      "29/29 - 0s - loss: 1.0394 - accuracy: 0.9837 - 98ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "# Number of classes\n",
    "myN=5;\n",
    "\n",
    "# Buidling neural network model\n",
    "def build_my_model(numberOfClasses):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=50, activation=\"tanh\"))\n",
    "    model.add(Dense(numberOfClasses))\n",
    "    #model.add(Dense(numberOfClasses, activation=\"softmax\"))\n",
    "    #model.compile(loss=\"categorical_crossentropy\",optimizer='adam', metrics=[\"accuracy\"]) \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-3 / 200)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "   # print(model.summary())\n",
    "    return model;\n",
    "\n",
    "\n",
    "t=[]\n",
    "a=[]\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    checkpoint_path='model_name'\n",
    "    keras_callbacks   = [EarlyStopping(monitor='val_accuracy', patience=100, verbose=1),\n",
    "                         ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "                        ]\n",
    "    model=build_my_model(myN);\n",
    "    \n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    history=model.fit(X_train, Y_train,epochs=500, batch_size=27, verbose=1, validation_split=0.1,callbacks=[keras_callbacks])\n",
    "    best_model = load_model(checkpoint_path)\n",
    "    model=best_model;\n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    \n",
    "    t.append(stop - start)\n",
    "    test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2) \n",
    "    a.append(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.173428899999635,\n",
       " 21.12407229999917,\n",
       " 17.7957374000016,\n",
       " 16.680735599999025,\n",
       " 18.95711130000018,\n",
       " 17.448785500000668,\n",
       " 15.859291799999482,\n",
       " 17.289060200000677,\n",
       " 19.260718699999416,\n",
       " 15.282274999999572]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9934782385826111,\n",
       " 0.998913049697876,\n",
       " 0.97826087474823,\n",
       " 0.9967391490936279,\n",
       " 0.997826099395752,\n",
       " 1.0,\n",
       " 0.981521725654602,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9836956262588501]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.687121669999943"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_1=np.mean(t) # average time\n",
    "t2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930434763431549"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2_1=np.mean(a) # average accuracy\n",
    "a2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results (for last run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 1.0394 - accuracy: 0.9837 - 27ms/epoch - 932us/step\n",
      "[1.0394160747528076, 0.9836956262588501]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=2) \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC1\\AppData\\Local\\Temp\\ipykernel_18564\\1357602405.py:19: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  plt.grid(b=None)\n",
      "C:\\Users\\PC1\\AppData\\Local\\Temp\\ipykernel_18564\\1357602405.py:27: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  plt.grid(b=None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 909us/step\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00       184\n",
      "       Inner       1.00      0.92      0.96       184\n",
      "       Outer       0.99      1.00      1.00       184\n",
      "        Ball       1.00      1.00      1.00       184\n",
      "        Comb       0.93      1.00      0.96       184\n",
      "\n",
      "    accuracy                           0.98       920\n",
      "   macro avg       0.98      0.98      0.98       920\n",
      "weighted avg       0.98      0.98      0.98       920\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Training and Validation Accuracy and  Training and Validation Loss\n",
    "plt.rc('axes',edgecolor='k')\n",
    "plt.rc('axes',linewidth='1')\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(history.history['loss']))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.subplot(121, facecolor='w')\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(b=None)\n",
    "\n",
    "plt.subplot(122, facecolor='w')\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.grid(b=None)\n",
    "plt.show()\n",
    "\n",
    "# Draw confusion matrix (It is only for the last trial)\n",
    "predictions=model.predict(X_test);\n",
    "confusion=confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(predictions,axis=1));\n",
    "\n",
    "dataset_labels=np.array(['Normal','Inner','Outer','Ball','Comb'])\n",
    "##\n",
    "df_cm = pd.DataFrame(confusion, \n",
    "              dataset_labels, \n",
    "              dataset_labels)\n",
    "\n",
    "sn.set(font_scale=1.2) # for label size\n",
    "plt.figure(figsize=(4,4))\n",
    "sn.heatmap(df_cm,annot=True,annot_kws={\"size\": 10},fmt = \"d\",linewidths=.5,cmap=\"YlGnBu\") \n",
    "plt.title('LPC')\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "\n",
    "# Print classification report\n",
    "print('CLASSIFICATION REPORT\\n',\n",
    "  classification_report(np.argmax(Y_test, axis=1), \n",
    "                        np.argmax(predictions, axis=1), \n",
    "                        target_names=dataset_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The end of LPC-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TDSIs-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PEAK</th>\n",
       "      <th>RMS_</th>\n",
       "      <th>CF</th>\n",
       "      <th>KUR</th>\n",
       "      <th>IF</th>\n",
       "      <th>SF</th>\n",
       "      <th>TALAF</th>\n",
       "      <th>THIKAT</th>\n",
       "      <th>KUCR</th>\n",
       "      <th>INTHAR</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512.27</td>\n",
       "      <td>212.32</td>\n",
       "      <td>2.4127</td>\n",
       "      <td>2.3997</td>\n",
       "      <td>2.9683</td>\n",
       "      <td>1.2303</td>\n",
       "      <td>1.2387</td>\n",
       "      <td>25.723</td>\n",
       "      <td>3.4921</td>\n",
       "      <td>-170.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>515.45</td>\n",
       "      <td>213.44</td>\n",
       "      <td>2.4149</td>\n",
       "      <td>2.4688</td>\n",
       "      <td>3.0085</td>\n",
       "      <td>1.2458</td>\n",
       "      <td>1.2601</td>\n",
       "      <td>28.598</td>\n",
       "      <td>3.5512</td>\n",
       "      <td>-171.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>515.45</td>\n",
       "      <td>207.33</td>\n",
       "      <td>2.4862</td>\n",
       "      <td>2.5111</td>\n",
       "      <td>3.0966</td>\n",
       "      <td>1.2455</td>\n",
       "      <td>1.2635</td>\n",
       "      <td>13.612</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>-172.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>584.25</td>\n",
       "      <td>208.89</td>\n",
       "      <td>2.7969</td>\n",
       "      <td>2.5036</td>\n",
       "      <td>3.4467</td>\n",
       "      <td>1.2323</td>\n",
       "      <td>1.2636</td>\n",
       "      <td>19.820</td>\n",
       "      <td>3.8262</td>\n",
       "      <td>-197.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>584.25</td>\n",
       "      <td>207.61</td>\n",
       "      <td>2.8142</td>\n",
       "      <td>2.7092</td>\n",
       "      <td>3.5088</td>\n",
       "      <td>1.2468</td>\n",
       "      <td>1.3184</td>\n",
       "      <td>16.223</td>\n",
       "      <td>3.9638</td>\n",
       "      <td>-196.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>687.79</td>\n",
       "      <td>225.74</td>\n",
       "      <td>3.0468</td>\n",
       "      <td>2.6194</td>\n",
       "      <td>3.7279</td>\n",
       "      <td>1.2235</td>\n",
       "      <td>1.3184</td>\n",
       "      <td>76.687</td>\n",
       "      <td>4.2969</td>\n",
       "      <td>-233.07</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>691.38</td>\n",
       "      <td>229.10</td>\n",
       "      <td>3.0178</td>\n",
       "      <td>2.6783</td>\n",
       "      <td>3.7249</td>\n",
       "      <td>1.2343</td>\n",
       "      <td>1.3384</td>\n",
       "      <td>87.305</td>\n",
       "      <td>4.3471</td>\n",
       "      <td>-234.22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>740.42</td>\n",
       "      <td>228.85</td>\n",
       "      <td>3.2353</td>\n",
       "      <td>2.9012</td>\n",
       "      <td>4.0912</td>\n",
       "      <td>1.2645</td>\n",
       "      <td>1.3949</td>\n",
       "      <td>92.695</td>\n",
       "      <td>4.6758</td>\n",
       "      <td>-248.13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>740.42</td>\n",
       "      <td>237.47</td>\n",
       "      <td>3.1180</td>\n",
       "      <td>2.9547</td>\n",
       "      <td>3.9944</td>\n",
       "      <td>1.2811</td>\n",
       "      <td>1.4185</td>\n",
       "      <td>120.050</td>\n",
       "      <td>4.7091</td>\n",
       "      <td>-249.14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>753.25</td>\n",
       "      <td>241.98</td>\n",
       "      <td>3.1128</td>\n",
       "      <td>2.9633</td>\n",
       "      <td>4.0098</td>\n",
       "      <td>1.2882</td>\n",
       "      <td>1.4259</td>\n",
       "      <td>136.330</td>\n",
       "      <td>4.7641</td>\n",
       "      <td>-253.76</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PEAK    RMS_      CF     KUR      IF      SF   TALAF   THIKAT    KUCR  \\\n",
       "0     512.27  212.32  2.4127  2.3997  2.9683  1.2303  1.2387   25.723  3.4921   \n",
       "1     515.45  213.44  2.4149  2.4688  3.0085  1.2458  1.2601   28.598  3.5512   \n",
       "2     515.45  207.33  2.4862  2.5111  3.0966  1.2455  1.2635   13.612  3.5808   \n",
       "3     584.25  208.89  2.7969  2.5036  3.4467  1.2323  1.2636   19.820  3.8262   \n",
       "4     584.25  207.61  2.8142  2.7092  3.5088  1.2468  1.3184   16.223  3.9638   \n",
       "...      ...     ...     ...     ...     ...     ...     ...      ...     ...   \n",
       "2150  687.79  225.74  3.0468  2.6194  3.7279  1.2235  1.3184   76.687  4.2969   \n",
       "2151  691.38  229.10  3.0178  2.6783  3.7249  1.2343  1.3384   87.305  4.3471   \n",
       "2152  740.42  228.85  3.2353  2.9012  4.0912  1.2645  1.3949   92.695  4.6758   \n",
       "2153  740.42  237.47  3.1180  2.9547  3.9944  1.2811  1.4185  120.050  4.7091   \n",
       "2154  753.25  241.98  3.1128  2.9633  4.0098  1.2882  1.4259  136.330  4.7641   \n",
       "\n",
       "      INTHAR  Status  \n",
       "0    -170.94       1  \n",
       "1    -171.67       1  \n",
       "2    -172.01       1  \n",
       "3    -197.66       1  \n",
       "4    -196.29       1  \n",
       "...      ...     ...  \n",
       "2150 -233.07       5  \n",
       "2151 -234.22       5  \n",
       "2152 -248.13       5  \n",
       "2153 -249.14       5  \n",
       "2154 -253.76       5  \n",
       "\n",
       "[2143 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder_= r'D:\\Mohammad paper\\LPC-NN\\to_submit_Trans_on_Ins_Meas\\CORRECTED\\cor_moh\\TDSIs';\n",
    "\n",
    "# Path to train\n",
    "path_to_train=root_folder_+\"\\SUSU_TDSIs_TRAIN.csv\"\n",
    "\n",
    "#Loading training data\n",
    "data_raw1 = pd.read_csv(path_to_train)\n",
    "data_raw=data_raw1.drop(['SIANA'], axis=1)\n",
    "data_raw=data_raw.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "data_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2143, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = data_raw.iloc[np.random.permutation(len(data_raw))]\n",
    "features=data[['PEAK','RMS_','CF','KUR','IF','SF','TALAF','THIKAT','KUCR','INTHAR']]\n",
    "labels = data['Status']\n",
    "X=features\n",
    "y=np.ravel(labels)\n",
    "X_train, y_train = shuffle(X, y)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to test\n",
    "path_to_test=root_folder_+\"\\SUSU_TDSIs_TEST.csv\"\n",
    "\n",
    "#Loading testing data\n",
    "data12 = pd.read_csv(path_to_test)\n",
    "data12=data12.drop(['SIANA'], axis=1)\n",
    "data12=data12.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "labels12=data12['Status']\n",
    "features12 = data12[['PEAK','RMS_','CF','KUR','IF','SF','TALAF','THIKAT','KUCR','INTHAR']]\n",
    "\n",
    "X12=features12\n",
    "y12=np.ravel(labels12)\n",
    "X_test=X12;\n",
    "y_test=y12;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "myN=5; #number of classes\n",
    "\n",
    "y_train=y_train-1;\n",
    "y_test=y_test-1;\n",
    "# Convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, myN) \n",
    "Y_test = np_utils.to_categorical(y_test, myN)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = MinMaxScaler()\n",
    "X_train = cs.fit_transform(X_train)\n",
    "X_test = cs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5413 - accuracy: 0.2505 - val_loss: 1.4422 - val_accuracy: 0.3628\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.3880 - accuracy: 0.4134 - val_loss: 1.3020 - val_accuracy: 0.4651\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 1.2854 - accuracy: 0.4445 - val_loss: 1.2330 - val_accuracy: 0.4651\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2341 - accuracy: 0.4652 - val_loss: 1.2026 - val_accuracy: 0.4791\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2078 - accuracy: 0.4710 - val_loss: 1.1777 - val_accuracy: 0.4930\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 923us/step - loss: 1.1829 - accuracy: 0.4907 - val_loss: 1.1630 - val_accuracy: 0.4930\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1606 - accuracy: 0.5067 - val_loss: 1.1403 - val_accuracy: 0.5256\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 1.1379 - accuracy: 0.5083 - val_loss: 1.1315 - val_accuracy: 0.5163\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1122 - accuracy: 0.5280 - val_loss: 1.0980 - val_accuracy: 0.5395\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 1.0887 - accuracy: 0.5379 - val_loss: 1.0875 - val_accuracy: 0.5163\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0688 - accuracy: 0.5513 - val_loss: 1.0542 - val_accuracy: 0.5581\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0490 - accuracy: 0.5560 - val_loss: 1.0455 - val_accuracy: 0.5767\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 1.0309 - accuracy: 0.5571 - val_loss: 1.0169 - val_accuracy: 0.5767\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 1.0068 - accuracy: 0.5737 - val_loss: 1.0100 - val_accuracy: 0.5721\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.9903 - accuracy: 0.5840 - val_loss: 0.9777 - val_accuracy: 0.5767\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9696 - accuracy: 0.5970 - val_loss: 0.9591 - val_accuracy: 0.6047\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.9538 - accuracy: 0.6089 - val_loss: 0.9570 - val_accuracy: 0.5860\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.9293 - accuracy: 0.6177 - val_loss: 0.9248 - val_accuracy: 0.5953\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.9138 - accuracy: 0.6338 - val_loss: 0.9207 - val_accuracy: 0.6000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8989 - accuracy: 0.6297 - val_loss: 0.9067 - val_accuracy: 0.6093\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8920 - accuracy: 0.6457 - val_loss: 0.8857 - val_accuracy: 0.6326\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8780 - accuracy: 0.6509 - val_loss: 0.8988 - val_accuracy: 0.6465\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 751us/step - loss: 0.8709 - accuracy: 0.6447 - val_loss: 0.8770 - val_accuracy: 0.6233\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.8623 - accuracy: 0.6535 - val_loss: 0.8653 - val_accuracy: 0.6233\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 714us/step - loss: 0.8599 - accuracy: 0.6463 - val_loss: 0.8612 - val_accuracy: 0.6419\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.8518 - accuracy: 0.6546 - val_loss: 0.8986 - val_accuracy: 0.6093\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.8500 - accuracy: 0.6582 - val_loss: 0.8715 - val_accuracy: 0.6093\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.8447 - accuracy: 0.6515 - val_loss: 0.8486 - val_accuracy: 0.6233\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.8429 - accuracy: 0.6618 - val_loss: 0.8672 - val_accuracy: 0.6326\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.8350 - accuracy: 0.6603 - val_loss: 0.8506 - val_accuracy: 0.6233\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.8391 - accuracy: 0.6629 - val_loss: 0.8418 - val_accuracy: 0.6233\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8341 - accuracy: 0.6582 - val_loss: 0.8601 - val_accuracy: 0.6186\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8267 - accuracy: 0.6592 - val_loss: 0.8487 - val_accuracy: 0.6233\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.8284 - accuracy: 0.6509 - val_loss: 0.8382 - val_accuracy: 0.6279\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 712us/step - loss: 0.8205 - accuracy: 0.6644 - val_loss: 0.8444 - val_accuracy: 0.6465\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 776us/step - loss: 0.8308 - accuracy: 0.6535 - val_loss: 0.8525 - val_accuracy: 0.6140\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 706us/step - loss: 0.8219 - accuracy: 0.6582 - val_loss: 0.8367 - val_accuracy: 0.6186\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.8200 - accuracy: 0.6655 - val_loss: 0.8299 - val_accuracy: 0.6279\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8143 - accuracy: 0.6592 - val_loss: 0.8437 - val_accuracy: 0.6233\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.8119 - accuracy: 0.6623 - val_loss: 0.8460 - val_accuracy: 0.6326\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8095 - accuracy: 0.6717 - val_loss: 0.8373 - val_accuracy: 0.6372\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.8070 - accuracy: 0.6655 - val_loss: 0.8337 - val_accuracy: 0.6186\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.8049 - accuracy: 0.6706 - val_loss: 0.8231 - val_accuracy: 0.6326\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.8002 - accuracy: 0.6738 - val_loss: 0.8325 - val_accuracy: 0.6326\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7999 - accuracy: 0.6696 - val_loss: 0.8271 - val_accuracy: 0.6372\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.8016 - accuracy: 0.6655 - val_loss: 0.8018 - val_accuracy: 0.6465\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8006 - accuracy: 0.6696 - val_loss: 0.8347 - val_accuracy: 0.6233\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.7960 - accuracy: 0.6758 - val_loss: 0.8081 - val_accuracy: 0.6419\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.7921 - accuracy: 0.6743 - val_loss: 0.8402 - val_accuracy: 0.6279\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7904 - accuracy: 0.6722 - val_loss: 0.8115 - val_accuracy: 0.6326\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 967us/step - loss: 0.7842 - accuracy: 0.6795 - val_loss: 0.8067 - val_accuracy: 0.6279\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.7809 - accuracy: 0.6805 - val_loss: 0.8095 - val_accuracy: 0.6465\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.7776 - accuracy: 0.6836 - val_loss: 0.8034 - val_accuracy: 0.6419\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.7758 - accuracy: 0.6826 - val_loss: 0.8049 - val_accuracy: 0.6419\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.7774 - accuracy: 0.6852 - val_loss: 0.7950 - val_accuracy: 0.6279\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7730 - accuracy: 0.6758 - val_loss: 0.7932 - val_accuracy: 0.6372\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.7687 - accuracy: 0.6841 - val_loss: 0.8008 - val_accuracy: 0.6419\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.7671 - accuracy: 0.6878 - val_loss: 0.7930 - val_accuracy: 0.6326\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 936us/step - loss: 0.7628 - accuracy: 0.6893 - val_loss: 0.8269 - val_accuracy: 0.6558\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7634 - accuracy: 0.6883 - val_loss: 0.7952 - val_accuracy: 0.6512\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.7614 - accuracy: 0.6836 - val_loss: 0.7787 - val_accuracy: 0.6605\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.7573 - accuracy: 0.6862 - val_loss: 0.7819 - val_accuracy: 0.6512\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 713us/step - loss: 0.7578 - accuracy: 0.6857 - val_loss: 0.7834 - val_accuracy: 0.6465\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7545 - accuracy: 0.6883 - val_loss: 0.7787 - val_accuracy: 0.6651\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.7521 - accuracy: 0.6857 - val_loss: 0.7727 - val_accuracy: 0.6419\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.7498 - accuracy: 0.6955 - val_loss: 0.7799 - val_accuracy: 0.6651\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 697us/step - loss: 0.7524 - accuracy: 0.6919 - val_loss: 0.7684 - val_accuracy: 0.6512\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.7525 - accuracy: 0.6862 - val_loss: 0.7718 - val_accuracy: 0.6372\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7521 - accuracy: 0.6888 - val_loss: 0.7780 - val_accuracy: 0.6419\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7416 - accuracy: 0.6987 - val_loss: 0.7885 - val_accuracy: 0.6419\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.7453 - accuracy: 0.6929 - val_loss: 0.7657 - val_accuracy: 0.6651\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7390 - accuracy: 0.6919 - val_loss: 0.7766 - val_accuracy: 0.6326\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.7336 - accuracy: 0.6904 - val_loss: 0.7636 - val_accuracy: 0.6465\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7323 - accuracy: 0.7038 - val_loss: 0.7614 - val_accuracy: 0.6651\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7321 - accuracy: 0.7012 - val_loss: 0.7591 - val_accuracy: 0.6372\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.7329 - accuracy: 0.7049 - val_loss: 0.7623 - val_accuracy: 0.6651\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.7379 - accuracy: 0.6966 - val_loss: 0.7641 - val_accuracy: 0.6558\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.7028 - val_loss: 0.7682 - val_accuracy: 0.6698\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.7264 - accuracy: 0.6976 - val_loss: 0.7812 - val_accuracy: 0.6326\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.7303 - accuracy: 0.6961 - val_loss: 0.7565 - val_accuracy: 0.6512\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 709us/step - loss: 0.7267 - accuracy: 0.7033 - val_loss: 0.7600 - val_accuracy: 0.6465\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.7176 - accuracy: 0.7075 - val_loss: 0.7586 - val_accuracy: 0.6419\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 855us/step - loss: 0.7173 - accuracy: 0.7054 - val_loss: 0.7462 - val_accuracy: 0.6605\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.7149 - accuracy: 0.7075 - val_loss: 0.7565 - val_accuracy: 0.6605\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7127 - accuracy: 0.7044 - val_loss: 0.7554 - val_accuracy: 0.6605\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.7111 - accuracy: 0.7090 - val_loss: 0.7510 - val_accuracy: 0.6605\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.7123 - accuracy: 0.7116 - val_loss: 0.7627 - val_accuracy: 0.6605\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.7070 - accuracy: 0.7116 - val_loss: 0.7418 - val_accuracy: 0.6605\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.7042 - accuracy: 0.7111 - val_loss: 0.7426 - val_accuracy: 0.6558\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7047 - accuracy: 0.7147 - val_loss: 0.7482 - val_accuracy: 0.6512\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.7049 - accuracy: 0.7132 - val_loss: 0.7582 - val_accuracy: 0.6326\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.7021 - accuracy: 0.7116 - val_loss: 0.7583 - val_accuracy: 0.6558\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.7103 - accuracy: 0.7127 - val_loss: 0.7489 - val_accuracy: 0.6465\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 767us/step - loss: 0.6981 - accuracy: 0.7090 - val_loss: 0.7282 - val_accuracy: 0.6651\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 879us/step - loss: 0.6995 - accuracy: 0.7106 - val_loss: 0.7492 - val_accuracy: 0.6512\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6984 - accuracy: 0.7132 - val_loss: 0.7474 - val_accuracy: 0.6465\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.6951 - accuracy: 0.7142 - val_loss: 0.7405 - val_accuracy: 0.6651\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 855us/step - loss: 0.6957 - accuracy: 0.7158 - val_loss: 0.7273 - val_accuracy: 0.6698\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6923 - accuracy: 0.7106 - val_loss: 0.7241 - val_accuracy: 0.6698\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.6932 - accuracy: 0.7168 - val_loss: 0.7349 - val_accuracy: 0.6419\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6899 - accuracy: 0.7225 - val_loss: 0.7311 - val_accuracy: 0.6558\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.7163 - val_loss: 0.7337 - val_accuracy: 0.6837\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.7189 - val_loss: 0.7250 - val_accuracy: 0.6558\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6919 - accuracy: 0.7184 - val_loss: 0.7447 - val_accuracy: 0.6512\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6855 - accuracy: 0.7199 - val_loss: 0.7213 - val_accuracy: 0.6744\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.6815 - accuracy: 0.7163 - val_loss: 0.7238 - val_accuracy: 0.6791\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6830 - accuracy: 0.7251 - val_loss: 0.7210 - val_accuracy: 0.6558\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.6845 - accuracy: 0.7210 - val_loss: 0.7178 - val_accuracy: 0.6605\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.6777 - accuracy: 0.7256 - val_loss: 0.7234 - val_accuracy: 0.6512\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 986us/step - loss: 0.6787 - accuracy: 0.7308 - val_loss: 0.7168 - val_accuracy: 0.6465\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.6769 - accuracy: 0.7256 - val_loss: 0.7180 - val_accuracy: 0.6744\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.6750 - accuracy: 0.7287 - val_loss: 0.7342 - val_accuracy: 0.6465\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 660us/step - loss: 0.6739 - accuracy: 0.7298 - val_loss: 0.7234 - val_accuracy: 0.6605\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.6766 - accuracy: 0.7225 - val_loss: 0.7146 - val_accuracy: 0.6558\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 660us/step - loss: 0.6734 - accuracy: 0.7272 - val_loss: 0.7329 - val_accuracy: 0.6465\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.6719 - accuracy: 0.7199 - val_loss: 0.7212 - val_accuracy: 0.6558\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.6705 - accuracy: 0.7246 - val_loss: 0.7172 - val_accuracy: 0.6744\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.6702 - accuracy: 0.7261 - val_loss: 0.7051 - val_accuracy: 0.6651\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 947us/step - loss: 0.6696 - accuracy: 0.7303 - val_loss: 0.7091 - val_accuracy: 0.6698\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.6694 - accuracy: 0.7277 - val_loss: 0.7035 - val_accuracy: 0.6698\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 993us/step - loss: 0.6660 - accuracy: 0.7298 - val_loss: 0.7282 - val_accuracy: 0.6884\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6690 - accuracy: 0.7318 - val_loss: 0.7061 - val_accuracy: 0.6651\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6678 - accuracy: 0.7230 - val_loss: 0.7142 - val_accuracy: 0.6512\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6639 - accuracy: 0.7298 - val_loss: 0.6992 - val_accuracy: 0.6837\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6635 - accuracy: 0.7287 - val_loss: 0.6980 - val_accuracy: 0.6791\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6675 - accuracy: 0.7339 - val_loss: 0.7099 - val_accuracy: 0.6605\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6641 - accuracy: 0.7251 - val_loss: 0.7024 - val_accuracy: 0.6651\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6597 - accuracy: 0.7344 - val_loss: 0.7046 - val_accuracy: 0.6744\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6621 - accuracy: 0.7241 - val_loss: 0.6971 - val_accuracy: 0.6791\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.6598 - accuracy: 0.7355 - val_loss: 0.6989 - val_accuracy: 0.6698\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.6597 - accuracy: 0.7298 - val_loss: 0.7057 - val_accuracy: 0.6558\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.7293 - val_loss: 0.6988 - val_accuracy: 0.6930\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.6588 - accuracy: 0.7277 - val_loss: 0.6898 - val_accuracy: 0.6884\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 727us/step - loss: 0.6524 - accuracy: 0.7272 - val_loss: 0.6997 - val_accuracy: 0.6930\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.7412 - val_loss: 0.6937 - val_accuracy: 0.6977\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.6568 - accuracy: 0.7287 - val_loss: 0.6968 - val_accuracy: 0.6744\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6558 - accuracy: 0.7324 - val_loss: 0.6972 - val_accuracy: 0.6651\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6534 - accuracy: 0.7365 - val_loss: 0.7085 - val_accuracy: 0.6651\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6512 - accuracy: 0.7277 - val_loss: 0.6869 - val_accuracy: 0.6930\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.6520 - accuracy: 0.7287 - val_loss: 0.6970 - val_accuracy: 0.6651\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6536 - accuracy: 0.7272 - val_loss: 0.7094 - val_accuracy: 0.6698\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6556 - accuracy: 0.7308 - val_loss: 0.6950 - val_accuracy: 0.6930\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6499 - accuracy: 0.7324 - val_loss: 0.6826 - val_accuracy: 0.6977\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 684us/step - loss: 0.6506 - accuracy: 0.7329 - val_loss: 0.6905 - val_accuracy: 0.6930\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 743us/step - loss: 0.6463 - accuracy: 0.7344 - val_loss: 0.7073 - val_accuracy: 0.6651\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.6508 - accuracy: 0.7324 - val_loss: 0.6927 - val_accuracy: 0.6930\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.6496 - accuracy: 0.7350 - val_loss: 0.6919 - val_accuracy: 0.6884\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6464 - accuracy: 0.7267 - val_loss: 0.7036 - val_accuracy: 0.6791\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6454 - accuracy: 0.7417 - val_loss: 0.6849 - val_accuracy: 0.6884\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6411 - accuracy: 0.7391 - val_loss: 0.7175 - val_accuracy: 0.6651\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6445 - accuracy: 0.7329 - val_loss: 0.6858 - val_accuracy: 0.6977\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6417 - accuracy: 0.7381 - val_loss: 0.6927 - val_accuracy: 0.6698\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6402 - accuracy: 0.7365 - val_loss: 0.6871 - val_accuracy: 0.6977\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6367 - accuracy: 0.7438 - val_loss: 0.6868 - val_accuracy: 0.6744\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6399 - accuracy: 0.7313 - val_loss: 0.6906 - val_accuracy: 0.6791\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6397 - accuracy: 0.7391 - val_loss: 0.6920 - val_accuracy: 0.6558\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6386 - accuracy: 0.7344 - val_loss: 0.6775 - val_accuracy: 0.6977\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 991us/step - loss: 0.6351 - accuracy: 0.7339 - val_loss: 0.6963 - val_accuracy: 0.7163\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 645us/step - loss: 0.6486 - accuracy: 0.7293 - val_loss: 0.6897 - val_accuracy: 0.6698\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.7313 - val_loss: 0.7005 - val_accuracy: 0.6930\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6418 - accuracy: 0.7344 - val_loss: 0.6845 - val_accuracy: 0.6744\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6369 - accuracy: 0.7360 - val_loss: 0.6842 - val_accuracy: 0.6744\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6363 - accuracy: 0.7339 - val_loss: 0.6715 - val_accuracy: 0.6930\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6336 - accuracy: 0.7318 - val_loss: 0.7016 - val_accuracy: 0.6698\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6318 - accuracy: 0.7339 - val_loss: 0.6789 - val_accuracy: 0.6837\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6347 - accuracy: 0.7386 - val_loss: 0.6691 - val_accuracy: 0.7070\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6341 - accuracy: 0.7303 - val_loss: 0.6708 - val_accuracy: 0.7023\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6331 - accuracy: 0.7355 - val_loss: 0.6848 - val_accuracy: 0.6791\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6316 - accuracy: 0.7360 - val_loss: 0.6984 - val_accuracy: 0.6837\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6320 - accuracy: 0.7282 - val_loss: 0.6914 - val_accuracy: 0.6791\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6312 - accuracy: 0.7391 - val_loss: 0.6840 - val_accuracy: 0.6930\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6279 - accuracy: 0.7365 - val_loss: 0.6760 - val_accuracy: 0.7023\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6262 - accuracy: 0.7453 - val_loss: 0.6953 - val_accuracy: 0.7023\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 713us/step - loss: 0.6274 - accuracy: 0.7422 - val_loss: 0.6704 - val_accuracy: 0.7023\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 936us/step - loss: 0.6273 - accuracy: 0.7401 - val_loss: 0.6902 - val_accuracy: 0.6791\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.6280 - accuracy: 0.7376 - val_loss: 0.6815 - val_accuracy: 0.6791\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6313 - accuracy: 0.7355 - val_loss: 0.6729 - val_accuracy: 0.6744\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.6241 - accuracy: 0.7386 - val_loss: 0.6819 - val_accuracy: 0.6884\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6262 - accuracy: 0.7339 - val_loss: 0.6807 - val_accuracy: 0.7116\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6250 - accuracy: 0.7370 - val_loss: 0.6697 - val_accuracy: 0.6791\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6236 - accuracy: 0.7412 - val_loss: 0.6727 - val_accuracy: 0.7070\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6231 - accuracy: 0.7334 - val_loss: 0.6648 - val_accuracy: 0.6930\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6208 - accuracy: 0.7386 - val_loss: 0.6658 - val_accuracy: 0.6977\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 591us/step - loss: 0.6207 - accuracy: 0.7386 - val_loss: 0.6784 - val_accuracy: 0.6977\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6182 - accuracy: 0.7412 - val_loss: 0.6592 - val_accuracy: 0.7116\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6221 - accuracy: 0.7396 - val_loss: 0.6792 - val_accuracy: 0.7023\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6193 - accuracy: 0.7391 - val_loss: 0.6700 - val_accuracy: 0.6930\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6206 - accuracy: 0.7376 - val_loss: 0.6810 - val_accuracy: 0.6791\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6159 - accuracy: 0.7386 - val_loss: 0.6794 - val_accuracy: 0.6930\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6195 - accuracy: 0.7339 - val_loss: 0.6663 - val_accuracy: 0.7070\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6159 - accuracy: 0.7381 - val_loss: 0.6846 - val_accuracy: 0.6837\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6167 - accuracy: 0.7407 - val_loss: 0.6722 - val_accuracy: 0.6977\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6169 - accuracy: 0.7350 - val_loss: 0.6774 - val_accuracy: 0.7209\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.6183 - accuracy: 0.7381 - val_loss: 0.6646 - val_accuracy: 0.7023\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6153 - accuracy: 0.7412 - val_loss: 0.6680 - val_accuracy: 0.6977\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.6127 - accuracy: 0.7370 - val_loss: 0.6675 - val_accuracy: 0.7070\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6156 - accuracy: 0.7381 - val_loss: 0.6745 - val_accuracy: 0.6977\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6127 - accuracy: 0.7438 - val_loss: 0.6753 - val_accuracy: 0.7023\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.6118 - accuracy: 0.7396 - val_loss: 0.6697 - val_accuracy: 0.6977\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6099 - accuracy: 0.7365 - val_loss: 0.6889 - val_accuracy: 0.6698\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 612us/step - loss: 0.6102 - accuracy: 0.7427 - val_loss: 0.6729 - val_accuracy: 0.6837\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6111 - accuracy: 0.7401 - val_loss: 0.6675 - val_accuracy: 0.6884\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.6116 - accuracy: 0.7376 - val_loss: 0.6769 - val_accuracy: 0.6791\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6113 - accuracy: 0.7422 - val_loss: 0.6625 - val_accuracy: 0.7209\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 610us/step - loss: 0.6069 - accuracy: 0.7459 - val_loss: 0.6683 - val_accuracy: 0.6791\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6065 - accuracy: 0.7391 - val_loss: 0.6857 - val_accuracy: 0.6977\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6098 - accuracy: 0.7448 - val_loss: 0.6787 - val_accuracy: 0.6884\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6073 - accuracy: 0.7422 - val_loss: 0.6516 - val_accuracy: 0.7116\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.6061 - accuracy: 0.7417 - val_loss: 0.6676 - val_accuracy: 0.6930\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6127 - accuracy: 0.7360 - val_loss: 0.6777 - val_accuracy: 0.6977\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6042 - accuracy: 0.7531 - val_loss: 0.7061 - val_accuracy: 0.6698\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6070 - accuracy: 0.7479 - val_loss: 0.6738 - val_accuracy: 0.7023\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6059 - accuracy: 0.7438 - val_loss: 0.6692 - val_accuracy: 0.7023\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6078 - accuracy: 0.7433 - val_loss: 0.6594 - val_accuracy: 0.6884\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6032 - accuracy: 0.7484 - val_loss: 0.6763 - val_accuracy: 0.6977\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6045 - accuracy: 0.7490 - val_loss: 0.6604 - val_accuracy: 0.7116\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6008 - accuracy: 0.7464 - val_loss: 0.6579 - val_accuracy: 0.7116\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.5996 - accuracy: 0.7459 - val_loss: 0.6935 - val_accuracy: 0.6977\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6069 - accuracy: 0.7417 - val_loss: 0.6577 - val_accuracy: 0.7163\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.6007 - accuracy: 0.7495 - val_loss: 0.6535 - val_accuracy: 0.7116\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6030 - accuracy: 0.7469 - val_loss: 0.6655 - val_accuracy: 0.7070\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6011 - accuracy: 0.7464 - val_loss: 0.6707 - val_accuracy: 0.7070\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5982 - accuracy: 0.7469 - val_loss: 0.6534 - val_accuracy: 0.7116\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5977 - accuracy: 0.7469 - val_loss: 0.6669 - val_accuracy: 0.6977\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.5978 - accuracy: 0.7479 - val_loss: 0.6713 - val_accuracy: 0.7070\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.5951 - accuracy: 0.7536 - val_loss: 0.6648 - val_accuracy: 0.7116\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 681us/step - loss: 0.5969 - accuracy: 0.7448 - val_loss: 0.6807 - val_accuracy: 0.6884\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.7479 - val_loss: 0.6597 - val_accuracy: 0.7256\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 629us/step - loss: 0.5955 - accuracy: 0.7453 - val_loss: 0.6684 - val_accuracy: 0.7116\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.7495 - val_loss: 0.6643 - val_accuracy: 0.6930\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5980 - accuracy: 0.7479 - val_loss: 0.6563 - val_accuracy: 0.7023\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5942 - accuracy: 0.7495 - val_loss: 0.6518 - val_accuracy: 0.7256\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5933 - accuracy: 0.7510 - val_loss: 0.6789 - val_accuracy: 0.6884\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5929 - accuracy: 0.7536 - val_loss: 0.6569 - val_accuracy: 0.7163\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5928 - accuracy: 0.7531 - val_loss: 0.6633 - val_accuracy: 0.7209\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.5943 - accuracy: 0.7490 - val_loss: 0.6661 - val_accuracy: 0.7163\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.5885 - accuracy: 0.7552 - val_loss: 0.6687 - val_accuracy: 0.7116\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 685us/step - loss: 0.5912 - accuracy: 0.7526 - val_loss: 0.6581 - val_accuracy: 0.7023\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5900 - accuracy: 0.7479 - val_loss: 0.6524 - val_accuracy: 0.6930\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5951 - accuracy: 0.7531 - val_loss: 0.6735 - val_accuracy: 0.6884\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5912 - accuracy: 0.7490 - val_loss: 0.6501 - val_accuracy: 0.7163\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5882 - accuracy: 0.7531 - val_loss: 0.6711 - val_accuracy: 0.6977\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5933 - accuracy: 0.7526 - val_loss: 0.6564 - val_accuracy: 0.7163\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5895 - accuracy: 0.7516 - val_loss: 0.6493 - val_accuracy: 0.6977\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5875 - accuracy: 0.7516 - val_loss: 0.6535 - val_accuracy: 0.7070\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5872 - accuracy: 0.7547 - val_loss: 0.6614 - val_accuracy: 0.6977\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5943 - accuracy: 0.7562 - val_loss: 0.6571 - val_accuracy: 0.6930\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5869 - accuracy: 0.7557 - val_loss: 0.6533 - val_accuracy: 0.7116\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.5864 - accuracy: 0.7500 - val_loss: 0.6581 - val_accuracy: 0.6977\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.5859 - accuracy: 0.7588 - val_loss: 0.6599 - val_accuracy: 0.6884\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.5879 - accuracy: 0.7505 - val_loss: 0.6582 - val_accuracy: 0.7116\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5861 - accuracy: 0.7516 - val_loss: 0.6664 - val_accuracy: 0.6977\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5876 - accuracy: 0.7526 - val_loss: 0.6785 - val_accuracy: 0.7116\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.5853 - accuracy: 0.7536 - val_loss: 0.6662 - val_accuracy: 0.7116\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.5915 - accuracy: 0.7521 - val_loss: 0.6666 - val_accuracy: 0.7023\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 694us/step - loss: 0.5857 - accuracy: 0.7599 - val_loss: 0.6458 - val_accuracy: 0.7163\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 951us/step - loss: 0.5837 - accuracy: 0.7619 - val_loss: 0.6542 - val_accuracy: 0.6884\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.5827 - accuracy: 0.7510 - val_loss: 0.6583 - val_accuracy: 0.7023\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5828 - accuracy: 0.7573 - val_loss: 0.6573 - val_accuracy: 0.7209\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.5799 - accuracy: 0.7531 - val_loss: 0.6481 - val_accuracy: 0.6930\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.5822 - accuracy: 0.7516 - val_loss: 0.6501 - val_accuracy: 0.6884\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5783 - accuracy: 0.7609 - val_loss: 0.6448 - val_accuracy: 0.6884\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 878us/step - loss: 0.5811 - accuracy: 0.7599 - val_loss: 0.6659 - val_accuracy: 0.6884\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5795 - accuracy: 0.7583 - val_loss: 0.6563 - val_accuracy: 0.7209\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5769 - accuracy: 0.7547 - val_loss: 0.6645 - val_accuracy: 0.7116\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5828 - accuracy: 0.7567 - val_loss: 0.6667 - val_accuracy: 0.7116\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5788 - accuracy: 0.7557 - val_loss: 0.6457 - val_accuracy: 0.6930\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5816 - accuracy: 0.7490 - val_loss: 0.6824 - val_accuracy: 0.7070\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 850us/step - loss: 0.5837 - accuracy: 0.7547 - val_loss: 0.6737 - val_accuracy: 0.7070\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5795 - accuracy: 0.7562 - val_loss: 0.6548 - val_accuracy: 0.7023\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 688us/step - loss: 0.5819 - accuracy: 0.7541 - val_loss: 0.6605 - val_accuracy: 0.6744\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5802 - accuracy: 0.7578 - val_loss: 0.6532 - val_accuracy: 0.6977\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5825 - accuracy: 0.7557 - val_loss: 0.6435 - val_accuracy: 0.7070\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.5768 - accuracy: 0.7536 - val_loss: 0.6530 - val_accuracy: 0.6977\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.5794 - accuracy: 0.7562 - val_loss: 0.6475 - val_accuracy: 0.6884\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7599 - val_loss: 0.6563 - val_accuracy: 0.7302\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5774 - accuracy: 0.7593 - val_loss: 0.6508 - val_accuracy: 0.6977\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5762 - accuracy: 0.7562 - val_loss: 0.6546 - val_accuracy: 0.6977\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.5742 - accuracy: 0.7599 - val_loss: 0.6738 - val_accuracy: 0.7070\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 923us/step - loss: 0.5768 - accuracy: 0.7588 - val_loss: 0.6517 - val_accuracy: 0.6930\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 695us/step - loss: 0.5759 - accuracy: 0.7562 - val_loss: 0.6662 - val_accuracy: 0.6744\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 948us/step - loss: 0.5813 - accuracy: 0.7505 - val_loss: 0.6541 - val_accuracy: 0.6977\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5765 - accuracy: 0.7614 - val_loss: 0.6565 - val_accuracy: 0.6837\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5791 - accuracy: 0.7557 - val_loss: 0.6614 - val_accuracy: 0.7070\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 654us/step - loss: 0.5744 - accuracy: 0.7645 - val_loss: 0.6399 - val_accuracy: 0.6744\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.5752 - accuracy: 0.7510 - val_loss: 0.6486 - val_accuracy: 0.7209\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.5777 - accuracy: 0.7609 - val_loss: 0.6474 - val_accuracy: 0.6884\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 707us/step - loss: 0.5732 - accuracy: 0.7510 - val_loss: 0.6649 - val_accuracy: 0.7302\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 933us/step - loss: 0.5774 - accuracy: 0.7531 - val_loss: 0.6743 - val_accuracy: 0.7023\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 762us/step - loss: 0.5754 - accuracy: 0.7557 - val_loss: 0.6560 - val_accuracy: 0.6837\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.5745 - accuracy: 0.7635 - val_loss: 0.6743 - val_accuracy: 0.7163\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5723 - accuracy: 0.7573 - val_loss: 0.6507 - val_accuracy: 0.7116\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5726 - accuracy: 0.7562 - val_loss: 0.6648 - val_accuracy: 0.6744\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 712us/step - loss: 0.5721 - accuracy: 0.7583 - val_loss: 0.6744 - val_accuracy: 0.6791\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 919us/step - loss: 0.5755 - accuracy: 0.7599 - val_loss: 0.6459 - val_accuracy: 0.7116\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.5733 - accuracy: 0.7624 - val_loss: 0.6603 - val_accuracy: 0.6884\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.5715 - accuracy: 0.7583 - val_loss: 0.6601 - val_accuracy: 0.6884\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.5698 - accuracy: 0.7573 - val_loss: 0.6574 - val_accuracy: 0.7209\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 728us/step - loss: 0.5739 - accuracy: 0.7552 - val_loss: 0.6594 - val_accuracy: 0.7116\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.5744 - accuracy: 0.7557 - val_loss: 0.6597 - val_accuracy: 0.7116\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 726us/step - loss: 0.5680 - accuracy: 0.7578 - val_loss: 0.6541 - val_accuracy: 0.6930\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.5687 - accuracy: 0.7604 - val_loss: 0.6419 - val_accuracy: 0.6977\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5709 - accuracy: 0.7573 - val_loss: 0.6461 - val_accuracy: 0.7023\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.5714 - accuracy: 0.7567 - val_loss: 0.6482 - val_accuracy: 0.7163\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.5705 - accuracy: 0.7526 - val_loss: 0.6483 - val_accuracy: 0.7070\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 937us/step - loss: 0.5705 - accuracy: 0.7562 - val_loss: 0.6548 - val_accuracy: 0.7302\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 860us/step - loss: 0.5699 - accuracy: 0.7578 - val_loss: 0.6403 - val_accuracy: 0.6930\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5689 - accuracy: 0.7583 - val_loss: 0.6916 - val_accuracy: 0.6791\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 839us/step - loss: 0.5675 - accuracy: 0.7583 - val_loss: 0.6707 - val_accuracy: 0.6744\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 737us/step - loss: 0.5709 - accuracy: 0.7609 - val_loss: 0.6561 - val_accuracy: 0.6977\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.5674 - accuracy: 0.7573 - val_loss: 0.6591 - val_accuracy: 0.7023\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 739us/step - loss: 0.5654 - accuracy: 0.7609 - val_loss: 0.6607 - val_accuracy: 0.7070\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 890us/step - loss: 0.5663 - accuracy: 0.7588 - val_loss: 0.6924 - val_accuracy: 0.6884\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 740us/step - loss: 0.5737 - accuracy: 0.7562 - val_loss: 0.6526 - val_accuracy: 0.6930\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.5641 - accuracy: 0.7619 - val_loss: 0.6742 - val_accuracy: 0.6791\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5667 - accuracy: 0.7599 - val_loss: 0.6603 - val_accuracy: 0.7070\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 868us/step - loss: 0.5635 - accuracy: 0.7593 - val_loss: 0.6470 - val_accuracy: 0.7070\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.5673 - accuracy: 0.7583 - val_loss: 0.6442 - val_accuracy: 0.7070\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5651 - accuracy: 0.7578 - val_loss: 0.6602 - val_accuracy: 0.6930\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5661 - accuracy: 0.7593 - val_loss: 0.6628 - val_accuracy: 0.7070\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 768us/step - loss: 0.5653 - accuracy: 0.7557 - val_loss: 0.6401 - val_accuracy: 0.6930\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.5638 - accuracy: 0.7630 - val_loss: 0.6421 - val_accuracy: 0.6977\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.5647 - accuracy: 0.7676 - val_loss: 0.6560 - val_accuracy: 0.6977\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.5696 - accuracy: 0.7578 - val_loss: 0.6497 - val_accuracy: 0.7070\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 769us/step - loss: 0.5631 - accuracy: 0.7619 - val_loss: 0.6627 - val_accuracy: 0.6837\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.5640 - accuracy: 0.7578 - val_loss: 0.6565 - val_accuracy: 0.7070\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.5650 - accuracy: 0.7583 - val_loss: 0.6496 - val_accuracy: 0.7209\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 858us/step - loss: 0.5661 - accuracy: 0.7557 - val_loss: 0.6498 - val_accuracy: 0.7070\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 752us/step - loss: 0.5642 - accuracy: 0.7573 - val_loss: 0.6515 - val_accuracy: 0.6977\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 762us/step - loss: 0.5667 - accuracy: 0.7624 - val_loss: 0.6510 - val_accuracy: 0.7023\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5601 - accuracy: 0.7599 - val_loss: 0.6456 - val_accuracy: 0.7023\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 762us/step - loss: 0.5612 - accuracy: 0.7656 - val_loss: 0.6460 - val_accuracy: 0.7116\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 868us/step - loss: 0.5623 - accuracy: 0.7588 - val_loss: 0.6546 - val_accuracy: 0.7070\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.5665 - accuracy: 0.7562 - val_loss: 0.6425 - val_accuracy: 0.6977\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.5610 - accuracy: 0.7599 - val_loss: 0.6597 - val_accuracy: 0.6884\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 709us/step - loss: 0.5643 - accuracy: 0.7578 - val_loss: 0.6543 - val_accuracy: 0.6884\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.5627 - accuracy: 0.7645 - val_loss: 0.6515 - val_accuracy: 0.7209\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.5628 - accuracy: 0.7624 - val_loss: 0.6578 - val_accuracy: 0.7209\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 865us/step - loss: 0.5642 - accuracy: 0.7552 - val_loss: 0.6611 - val_accuracy: 0.6930\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.5608 - accuracy: 0.7588 - val_loss: 0.6508 - val_accuracy: 0.6977\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 848us/step - loss: 0.5626 - accuracy: 0.7604 - val_loss: 0.6605 - val_accuracy: 0.6837\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5610 - accuracy: 0.7588 - val_loss: 0.6499 - val_accuracy: 0.6884\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5629 - accuracy: 0.7578 - val_loss: 0.6451 - val_accuracy: 0.7116\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5630 - accuracy: 0.7609 - val_loss: 0.6875 - val_accuracy: 0.6837\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.5616 - accuracy: 0.7645 - val_loss: 0.6490 - val_accuracy: 0.7023\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5603 - accuracy: 0.7614 - val_loss: 0.6534 - val_accuracy: 0.7163\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5593 - accuracy: 0.7593 - val_loss: 0.6562 - val_accuracy: 0.7023\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5635 - accuracy: 0.7578 - val_loss: 0.6609 - val_accuracy: 0.6930\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5654 - accuracy: 0.7609 - val_loss: 0.6450 - val_accuracy: 0.6977\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5608 - accuracy: 0.7599 - val_loss: 0.6418 - val_accuracy: 0.6977\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5598 - accuracy: 0.7604 - val_loss: 0.6585 - val_accuracy: 0.7070\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5628 - accuracy: 0.7614 - val_loss: 0.6475 - val_accuracy: 0.7256\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5583 - accuracy: 0.7635 - val_loss: 0.6487 - val_accuracy: 0.7023\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5616 - accuracy: 0.7578 - val_loss: 0.6602 - val_accuracy: 0.6930\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5604 - accuracy: 0.7604 - val_loss: 0.6529 - val_accuracy: 0.7023\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.5592 - accuracy: 0.7650 - val_loss: 0.6774 - val_accuracy: 0.6744\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - 0s 847us/step - loss: 0.5554 - accuracy: 0.7599 - val_loss: 0.6599 - val_accuracy: 0.6930\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.5566 - accuracy: 0.7619 - val_loss: 0.6595 - val_accuracy: 0.7023\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5545 - accuracy: 0.7697 - val_loss: 0.6365 - val_accuracy: 0.6977\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.5569 - accuracy: 0.7588 - val_loss: 0.6428 - val_accuracy: 0.7023\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.5590 - accuracy: 0.7635 - val_loss: 0.6477 - val_accuracy: 0.7116\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - 0s 757us/step - loss: 0.5600 - accuracy: 0.7635 - val_loss: 0.6496 - val_accuracy: 0.6977\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.5580 - accuracy: 0.7609 - val_loss: 0.6476 - val_accuracy: 0.6977\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5583 - accuracy: 0.7521 - val_loss: 0.6582 - val_accuracy: 0.7023\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - 0s 780us/step - loss: 0.5570 - accuracy: 0.7614 - val_loss: 0.6555 - val_accuracy: 0.6977\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - 0s 851us/step - loss: 0.5576 - accuracy: 0.7583 - val_loss: 0.6499 - val_accuracy: 0.7023\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5548 - accuracy: 0.7609 - val_loss: 0.6567 - val_accuracy: 0.7209\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.5555 - accuracy: 0.7567 - val_loss: 0.6490 - val_accuracy: 0.7163\n",
      "Epoch 369/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.5554 - accuracy: 0.7541 - val_loss: 0.6599 - val_accuracy: 0.6884\n",
      "Epoch 370/500\n",
      "72/72 [==============================] - 0s 869us/step - loss: 0.5594 - accuracy: 0.7588 - val_loss: 0.6490 - val_accuracy: 0.7163\n",
      "Epoch 371/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.5553 - accuracy: 0.7604 - val_loss: 0.6619 - val_accuracy: 0.7209\n",
      "Epoch 372/500\n",
      "72/72 [==============================] - 0s 879us/step - loss: 0.5553 - accuracy: 0.7630 - val_loss: 0.6466 - val_accuracy: 0.7256\n",
      "Epoch 373/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.7599 - val_loss: 0.6555 - val_accuracy: 0.7395\n",
      "Epoch 374/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.5564 - accuracy: 0.7619 - val_loss: 0.6397 - val_accuracy: 0.7116\n",
      "Epoch 375/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5564 - accuracy: 0.7619 - val_loss: 0.6495 - val_accuracy: 0.7070\n",
      "Epoch 376/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5580 - accuracy: 0.7593 - val_loss: 0.6566 - val_accuracy: 0.7023\n",
      "Epoch 377/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5571 - accuracy: 0.7578 - val_loss: 0.6404 - val_accuracy: 0.7116\n",
      "Epoch 378/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5599 - accuracy: 0.7567 - val_loss: 0.6394 - val_accuracy: 0.7070\n",
      "Epoch 379/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5517 - accuracy: 0.7583 - val_loss: 0.6564 - val_accuracy: 0.7116\n",
      "Epoch 380/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5555 - accuracy: 0.7578 - val_loss: 0.6672 - val_accuracy: 0.6884\n",
      "Epoch 381/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5600 - accuracy: 0.7624 - val_loss: 0.6396 - val_accuracy: 0.7070\n",
      "Epoch 382/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.5515 - accuracy: 0.7661 - val_loss: 0.6668 - val_accuracy: 0.6744\n",
      "Epoch 383/500\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.5528 - accuracy: 0.7645 - val_loss: 0.6636 - val_accuracy: 0.7302\n",
      "Epoch 384/500\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.5568 - accuracy: 0.7567 - val_loss: 0.6412 - val_accuracy: 0.7209\n",
      "Epoch 385/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5546 - accuracy: 0.7676 - val_loss: 0.6439 - val_accuracy: 0.7116\n",
      "Epoch 386/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5543 - accuracy: 0.7604 - val_loss: 0.6469 - val_accuracy: 0.7163\n",
      "Epoch 387/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5516 - accuracy: 0.7635 - val_loss: 0.6462 - val_accuracy: 0.7023\n",
      "Epoch 388/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5539 - accuracy: 0.7640 - val_loss: 0.6404 - val_accuracy: 0.6977\n",
      "Epoch 389/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5519 - accuracy: 0.7650 - val_loss: 0.6461 - val_accuracy: 0.7070\n",
      "Epoch 390/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5559 - accuracy: 0.7640 - val_loss: 0.6465 - val_accuracy: 0.7070\n",
      "Epoch 391/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5530 - accuracy: 0.7650 - val_loss: 0.6516 - val_accuracy: 0.6977\n",
      "Epoch 392/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5508 - accuracy: 0.7645 - val_loss: 0.6553 - val_accuracy: 0.6884\n",
      "Epoch 393/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5517 - accuracy: 0.7609 - val_loss: 0.6563 - val_accuracy: 0.6977\n",
      "Epoch 394/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5572 - accuracy: 0.7640 - val_loss: 0.6523 - val_accuracy: 0.6977\n",
      "Epoch 395/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5567 - accuracy: 0.7604 - val_loss: 0.6441 - val_accuracy: 0.7163\n",
      "Epoch 396/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5528 - accuracy: 0.7671 - val_loss: 0.6558 - val_accuracy: 0.7023\n",
      "Epoch 397/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5573 - accuracy: 0.7541 - val_loss: 0.6356 - val_accuracy: 0.6977\n",
      "Epoch 398/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5507 - accuracy: 0.7656 - val_loss: 0.6493 - val_accuracy: 0.7163\n",
      "Epoch 399/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5516 - accuracy: 0.7666 - val_loss: 0.6531 - val_accuracy: 0.7116\n",
      "Epoch 400/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5497 - accuracy: 0.7630 - val_loss: 0.6525 - val_accuracy: 0.6930\n",
      "Epoch 401/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5555 - accuracy: 0.7599 - val_loss: 0.6551 - val_accuracy: 0.7116\n",
      "Epoch 402/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5497 - accuracy: 0.7635 - val_loss: 0.6505 - val_accuracy: 0.7256\n",
      "Epoch 403/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5510 - accuracy: 0.7583 - val_loss: 0.6487 - val_accuracy: 0.7116\n",
      "Epoch 404/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5556 - accuracy: 0.7557 - val_loss: 0.6490 - val_accuracy: 0.7070\n",
      "Epoch 405/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5572 - accuracy: 0.7573 - val_loss: 0.6478 - val_accuracy: 0.7070\n",
      "Epoch 406/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5504 - accuracy: 0.7702 - val_loss: 0.6850 - val_accuracy: 0.6837\n",
      "Epoch 407/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5496 - accuracy: 0.7630 - val_loss: 0.6526 - val_accuracy: 0.7070\n",
      "Epoch 408/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5507 - accuracy: 0.7650 - val_loss: 0.6578 - val_accuracy: 0.7256\n",
      "Epoch 409/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5519 - accuracy: 0.7656 - val_loss: 0.6498 - val_accuracy: 0.7163\n",
      "Epoch 410/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5469 - accuracy: 0.7671 - val_loss: 0.6429 - val_accuracy: 0.7070\n",
      "Epoch 411/500\n",
      "72/72 [==============================] - 0s 700us/step - loss: 0.5478 - accuracy: 0.7671 - val_loss: 0.6651 - val_accuracy: 0.7116\n",
      "Epoch 412/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5495 - accuracy: 0.7656 - val_loss: 0.6514 - val_accuracy: 0.7023\n",
      "Epoch 413/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5496 - accuracy: 0.7614 - val_loss: 0.6450 - val_accuracy: 0.7070\n",
      "Epoch 414/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5495 - accuracy: 0.7619 - val_loss: 0.6534 - val_accuracy: 0.7256\n",
      "Epoch 415/500\n",
      "72/72 [==============================] - 0s 731us/step - loss: 0.5479 - accuracy: 0.7682 - val_loss: 0.6499 - val_accuracy: 0.7256\n",
      "Epoch 416/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5488 - accuracy: 0.7656 - val_loss: 0.6388 - val_accuracy: 0.7070\n",
      "Epoch 417/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5513 - accuracy: 0.7635 - val_loss: 0.6339 - val_accuracy: 0.7209\n",
      "Epoch 418/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5475 - accuracy: 0.7656 - val_loss: 0.6416 - val_accuracy: 0.7302\n",
      "Epoch 419/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5512 - accuracy: 0.7656 - val_loss: 0.6408 - val_accuracy: 0.7256\n",
      "Epoch 420/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5466 - accuracy: 0.7687 - val_loss: 0.6444 - val_accuracy: 0.7116\n",
      "Epoch 421/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5475 - accuracy: 0.7682 - val_loss: 0.6435 - val_accuracy: 0.6977\n",
      "Epoch 422/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5456 - accuracy: 0.7656 - val_loss: 0.6513 - val_accuracy: 0.7116\n",
      "Epoch 423/500\n",
      "72/72 [==============================] - 0s 679us/step - loss: 0.5482 - accuracy: 0.7640 - val_loss: 0.6569 - val_accuracy: 0.7023\n",
      "Epoch 424/500\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.5465 - accuracy: 0.7666 - val_loss: 0.6366 - val_accuracy: 0.7116\n",
      "Epoch 425/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5463 - accuracy: 0.7614 - val_loss: 0.6449 - val_accuracy: 0.7070\n",
      "Epoch 426/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5481 - accuracy: 0.7661 - val_loss: 0.6429 - val_accuracy: 0.7209\n",
      "Epoch 427/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5520 - accuracy: 0.7640 - val_loss: 0.6520 - val_accuracy: 0.7023\n",
      "Epoch 428/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5440 - accuracy: 0.7671 - val_loss: 0.6434 - val_accuracy: 0.7023\n",
      "Epoch 429/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5457 - accuracy: 0.7661 - val_loss: 0.6669 - val_accuracy: 0.7023\n",
      "Epoch 430/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.5521 - accuracy: 0.7661 - val_loss: 0.6549 - val_accuracy: 0.7070\n",
      "Epoch 431/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5456 - accuracy: 0.7692 - val_loss: 0.6449 - val_accuracy: 0.7256\n",
      "Epoch 432/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5452 - accuracy: 0.7676 - val_loss: 0.6437 - val_accuracy: 0.7023\n",
      "Epoch 433/500\n",
      "72/72 [==============================] - 0s 661us/step - loss: 0.5498 - accuracy: 0.7650 - val_loss: 0.6456 - val_accuracy: 0.7116\n",
      "Epoch 434/500\n",
      "72/72 [==============================] - 0s 987us/step - loss: 0.5456 - accuracy: 0.7635 - val_loss: 0.6660 - val_accuracy: 0.7023\n",
      "Epoch 435/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5487 - accuracy: 0.7630 - val_loss: 0.6430 - val_accuracy: 0.7395\n",
      "Epoch 436/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5443 - accuracy: 0.7661 - val_loss: 0.6412 - val_accuracy: 0.7163\n",
      "Epoch 437/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5455 - accuracy: 0.7624 - val_loss: 0.6502 - val_accuracy: 0.7023\n",
      "Epoch 438/500\n",
      "72/72 [==============================] - 0s 741us/step - loss: 0.5469 - accuracy: 0.7661 - val_loss: 0.6505 - val_accuracy: 0.7070\n",
      "Epoch 439/500\n",
      "72/72 [==============================] - 0s 921us/step - loss: 0.5441 - accuracy: 0.7640 - val_loss: 0.6532 - val_accuracy: 0.7116\n",
      "Epoch 440/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5453 - accuracy: 0.7630 - val_loss: 0.6717 - val_accuracy: 0.6837\n",
      "Epoch 441/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5468 - accuracy: 0.7697 - val_loss: 0.6461 - val_accuracy: 0.7070\n",
      "Epoch 442/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5415 - accuracy: 0.7682 - val_loss: 0.6354 - val_accuracy: 0.7163\n",
      "Epoch 443/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5461 - accuracy: 0.7661 - val_loss: 0.6542 - val_accuracy: 0.7023\n",
      "Epoch 444/500\n",
      "72/72 [==============================] - 0s 656us/step - loss: 0.5427 - accuracy: 0.7713 - val_loss: 0.6596 - val_accuracy: 0.7023\n",
      "Epoch 445/500\n",
      "72/72 [==============================] - 0s 685us/step - loss: 0.5432 - accuracy: 0.7650 - val_loss: 0.6449 - val_accuracy: 0.7209\n",
      "Epoch 446/500\n",
      "72/72 [==============================] - 0s 973us/step - loss: 0.5469 - accuracy: 0.7588 - val_loss: 0.6564 - val_accuracy: 0.7070\n",
      "Epoch 447/500\n",
      "72/72 [==============================] - 0s 773us/step - loss: 0.5450 - accuracy: 0.7624 - val_loss: 0.6449 - val_accuracy: 0.7163\n",
      "Epoch 448/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5475 - accuracy: 0.7661 - val_loss: 0.6254 - val_accuracy: 0.7256\n",
      "Epoch 449/500\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.5435 - accuracy: 0.7687 - val_loss: 0.6494 - val_accuracy: 0.7070\n",
      "Epoch 450/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5432 - accuracy: 0.7702 - val_loss: 0.6429 - val_accuracy: 0.7163\n",
      "Epoch 451/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5421 - accuracy: 0.7702 - val_loss: 0.6429 - val_accuracy: 0.7116\n",
      "Epoch 452/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.5415 - accuracy: 0.7661 - val_loss: 0.6503 - val_accuracy: 0.7023\n",
      "Epoch 453/500\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.5454 - accuracy: 0.7624 - val_loss: 0.6542 - val_accuracy: 0.7116\n",
      "Epoch 454/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5471 - accuracy: 0.7619 - val_loss: 0.6309 - val_accuracy: 0.7070\n",
      "Epoch 455/500\n",
      "72/72 [==============================] - 0s 858us/step - loss: 0.5450 - accuracy: 0.7682 - val_loss: 0.6502 - val_accuracy: 0.7116\n",
      "Epoch 456/500\n",
      "72/72 [==============================] - 0s 638us/step - loss: 0.5418 - accuracy: 0.7707 - val_loss: 0.6430 - val_accuracy: 0.7209\n",
      "Epoch 457/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.5411 - accuracy: 0.7635 - val_loss: 0.6302 - val_accuracy: 0.7163\n",
      "Epoch 458/500\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.5435 - accuracy: 0.7650 - val_loss: 0.6435 - val_accuracy: 0.7349\n",
      "Epoch 459/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5438 - accuracy: 0.7666 - val_loss: 0.6666 - val_accuracy: 0.7070\n",
      "Epoch 460/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5471 - accuracy: 0.7671 - val_loss: 0.6305 - val_accuracy: 0.7209\n",
      "Epoch 461/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5400 - accuracy: 0.7609 - val_loss: 0.6427 - val_accuracy: 0.7256\n",
      "Epoch 462/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5415 - accuracy: 0.7650 - val_loss: 0.6495 - val_accuracy: 0.6930\n",
      "Epoch 463/500\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.5396 - accuracy: 0.7697 - val_loss: 0.6408 - val_accuracy: 0.7302\n",
      "Epoch 464/500\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.5418 - accuracy: 0.7682 - val_loss: 0.6503 - val_accuracy: 0.7070\n",
      "Epoch 465/500\n",
      "72/72 [==============================] - 0s 846us/step - loss: 0.5444 - accuracy: 0.7650 - val_loss: 0.6286 - val_accuracy: 0.7395\n",
      "Epoch 466/500\n",
      "72/72 [==============================] - 0s 930us/step - loss: 0.5466 - accuracy: 0.7645 - val_loss: 0.6493 - val_accuracy: 0.7163\n",
      "Epoch 467/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5414 - accuracy: 0.7676 - val_loss: 0.6348 - val_accuracy: 0.7209\n",
      "Epoch 468/500\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.5374 - accuracy: 0.7728 - val_loss: 0.6547 - val_accuracy: 0.7209\n",
      "Epoch 469/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5420 - accuracy: 0.7676 - val_loss: 0.6480 - val_accuracy: 0.7070\n",
      "Epoch 470/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5414 - accuracy: 0.7692 - val_loss: 0.6303 - val_accuracy: 0.7163\n",
      "Epoch 471/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.5397 - accuracy: 0.7671 - val_loss: 0.6494 - val_accuracy: 0.7023\n",
      "Epoch 472/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5394 - accuracy: 0.7650 - val_loss: 0.6354 - val_accuracy: 0.7070\n",
      "Epoch 473/500\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.5375 - accuracy: 0.7687 - val_loss: 0.6520 - val_accuracy: 0.7209\n",
      "Epoch 473: early stopping\n",
      "29/29 - 0s - loss: 0.5284 - accuracy: 0.7801 - 100ms/epoch - 3ms/step\n",
      "1\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 1s 3ms/step - loss: 1.4892 - accuracy: 0.3548 - val_loss: 1.3854 - val_accuracy: 0.4465\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.3358 - accuracy: 0.4471 - val_loss: 1.2900 - val_accuracy: 0.4512\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2656 - accuracy: 0.4538 - val_loss: 1.2406 - val_accuracy: 0.4558\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2289 - accuracy: 0.4652 - val_loss: 1.2112 - val_accuracy: 0.4605\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2035 - accuracy: 0.4839 - val_loss: 1.1916 - val_accuracy: 0.4744\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1794 - accuracy: 0.4938 - val_loss: 1.1776 - val_accuracy: 0.4884\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 894us/step - loss: 1.1610 - accuracy: 0.5026 - val_loss: 1.1542 - val_accuracy: 0.4884\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1374 - accuracy: 0.5228 - val_loss: 1.1344 - val_accuracy: 0.5163\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1093 - accuracy: 0.5373 - val_loss: 1.1007 - val_accuracy: 0.5302\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0824 - accuracy: 0.5430 - val_loss: 1.0798 - val_accuracy: 0.5535\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 848us/step - loss: 1.0572 - accuracy: 0.5571 - val_loss: 1.0670 - val_accuracy: 0.5488\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0298 - accuracy: 0.5742 - val_loss: 1.0199 - val_accuracy: 0.5767\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 1.0046 - accuracy: 0.5721 - val_loss: 1.0170 - val_accuracy: 0.5581\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9819 - accuracy: 0.5902 - val_loss: 0.9852 - val_accuracy: 0.5907\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9587 - accuracy: 0.5970 - val_loss: 0.9566 - val_accuracy: 0.6233\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.9348 - accuracy: 0.6146 - val_loss: 0.9467 - val_accuracy: 0.5953\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.9196 - accuracy: 0.6245 - val_loss: 0.9242 - val_accuracy: 0.5907\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.9125 - accuracy: 0.6286 - val_loss: 0.9033 - val_accuracy: 0.6093\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8996 - accuracy: 0.6271 - val_loss: 0.9061 - val_accuracy: 0.6000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8831 - accuracy: 0.6385 - val_loss: 0.8812 - val_accuracy: 0.6186\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.8667 - accuracy: 0.6395 - val_loss: 0.8777 - val_accuracy: 0.6140\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.8665 - accuracy: 0.6416 - val_loss: 0.8698 - val_accuracy: 0.6140\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.8534 - accuracy: 0.6489 - val_loss: 0.8968 - val_accuracy: 0.5814\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8518 - accuracy: 0.6400 - val_loss: 0.8526 - val_accuracy: 0.6326\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.8504 - accuracy: 0.6546 - val_loss: 0.8654 - val_accuracy: 0.6372\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 949us/step - loss: 0.8391 - accuracy: 0.6509 - val_loss: 0.8652 - val_accuracy: 0.5860\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.8301 - accuracy: 0.6556 - val_loss: 0.8510 - val_accuracy: 0.6186\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.8295 - accuracy: 0.6587 - val_loss: 0.8718 - val_accuracy: 0.6186\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.8268 - accuracy: 0.6551 - val_loss: 0.8423 - val_accuracy: 0.6233\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8264 - accuracy: 0.6556 - val_loss: 0.8471 - val_accuracy: 0.6047\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.8169 - accuracy: 0.6551 - val_loss: 0.8220 - val_accuracy: 0.6233\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.8216 - accuracy: 0.6535 - val_loss: 0.8463 - val_accuracy: 0.6047\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8107 - accuracy: 0.6753 - val_loss: 0.8205 - val_accuracy: 0.6186\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.8072 - accuracy: 0.6613 - val_loss: 0.8216 - val_accuracy: 0.6279\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.7994 - accuracy: 0.6706 - val_loss: 0.8166 - val_accuracy: 0.6186\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 870us/step - loss: 0.7967 - accuracy: 0.6732 - val_loss: 0.8136 - val_accuracy: 0.6279\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.7906 - accuracy: 0.6712 - val_loss: 0.8175 - val_accuracy: 0.6279\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.7949 - accuracy: 0.6727 - val_loss: 0.8218 - val_accuracy: 0.6279\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.7920 - accuracy: 0.6623 - val_loss: 0.8074 - val_accuracy: 0.6279\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7820 - accuracy: 0.6763 - val_loss: 0.8319 - val_accuracy: 0.6372\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.7798 - accuracy: 0.6784 - val_loss: 0.8005 - val_accuracy: 0.6233\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7757 - accuracy: 0.6779 - val_loss: 0.8283 - val_accuracy: 0.6093\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.7775 - accuracy: 0.6795 - val_loss: 0.8250 - val_accuracy: 0.6140\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.7732 - accuracy: 0.6821 - val_loss: 0.8100 - val_accuracy: 0.6233\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.7665 - accuracy: 0.6872 - val_loss: 0.8014 - val_accuracy: 0.6233\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.7643 - accuracy: 0.6821 - val_loss: 0.8041 - val_accuracy: 0.6279\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7612 - accuracy: 0.6872 - val_loss: 0.8036 - val_accuracy: 0.6233\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7621 - accuracy: 0.6867 - val_loss: 0.7908 - val_accuracy: 0.6279\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7540 - accuracy: 0.6846 - val_loss: 0.7991 - val_accuracy: 0.6233\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7553 - accuracy: 0.6872 - val_loss: 0.7997 - val_accuracy: 0.6279\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7569 - accuracy: 0.6883 - val_loss: 0.7975 - val_accuracy: 0.6233\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7540 - accuracy: 0.6893 - val_loss: 0.7898 - val_accuracy: 0.6233\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7497 - accuracy: 0.6919 - val_loss: 0.7966 - val_accuracy: 0.6233\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7497 - accuracy: 0.6800 - val_loss: 0.8154 - val_accuracy: 0.6093\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7510 - accuracy: 0.6888 - val_loss: 0.7887 - val_accuracy: 0.6465\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7493 - accuracy: 0.6909 - val_loss: 0.7877 - val_accuracy: 0.6419\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7412 - accuracy: 0.6961 - val_loss: 0.7942 - val_accuracy: 0.6186\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7399 - accuracy: 0.6955 - val_loss: 0.8014 - val_accuracy: 0.6558\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.7516 - accuracy: 0.6909 - val_loss: 0.7827 - val_accuracy: 0.6279\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.7365 - accuracy: 0.6987 - val_loss: 0.7810 - val_accuracy: 0.6326\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7424 - accuracy: 0.6955 - val_loss: 0.7842 - val_accuracy: 0.6326\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7289 - accuracy: 0.7033 - val_loss: 0.7879 - val_accuracy: 0.6186\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7334 - accuracy: 0.6955 - val_loss: 0.7750 - val_accuracy: 0.6326\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.7291 - accuracy: 0.7007 - val_loss: 0.7764 - val_accuracy: 0.6326\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7284 - accuracy: 0.6945 - val_loss: 0.7730 - val_accuracy: 0.6419\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7330 - accuracy: 0.6955 - val_loss: 0.7820 - val_accuracy: 0.6279\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7244 - accuracy: 0.6992 - val_loss: 0.7730 - val_accuracy: 0.6465\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7250 - accuracy: 0.6966 - val_loss: 0.8069 - val_accuracy: 0.6186\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.7298 - accuracy: 0.6950 - val_loss: 0.7766 - val_accuracy: 0.6326\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7237 - accuracy: 0.7049 - val_loss: 0.7725 - val_accuracy: 0.6465\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.7177 - accuracy: 0.7054 - val_loss: 0.7705 - val_accuracy: 0.6465\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7162 - accuracy: 0.7090 - val_loss: 0.7832 - val_accuracy: 0.6465\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6976 - val_loss: 0.7728 - val_accuracy: 0.6744\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.7167 - accuracy: 0.7070 - val_loss: 0.7834 - val_accuracy: 0.6279\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.7157 - accuracy: 0.6987 - val_loss: 0.7721 - val_accuracy: 0.6465\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7143 - accuracy: 0.7033 - val_loss: 0.7730 - val_accuracy: 0.6558\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.7094 - accuracy: 0.7059 - val_loss: 0.7757 - val_accuracy: 0.6372\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.7028 - val_loss: 0.7889 - val_accuracy: 0.6791\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.7084 - accuracy: 0.7023 - val_loss: 0.7656 - val_accuracy: 0.6465\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.7067 - accuracy: 0.7090 - val_loss: 0.7756 - val_accuracy: 0.6372\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7066 - accuracy: 0.7054 - val_loss: 0.7577 - val_accuracy: 0.6605\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7051 - accuracy: 0.7090 - val_loss: 0.7673 - val_accuracy: 0.6419\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.7055 - accuracy: 0.7002 - val_loss: 0.7632 - val_accuracy: 0.6419\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7042 - accuracy: 0.7080 - val_loss: 0.7639 - val_accuracy: 0.6558\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.7037 - accuracy: 0.7142 - val_loss: 0.7657 - val_accuracy: 0.6651\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 674us/step - loss: 0.7028 - accuracy: 0.7116 - val_loss: 0.7563 - val_accuracy: 0.6512\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.6970 - accuracy: 0.7132 - val_loss: 0.7552 - val_accuracy: 0.6605\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6961 - accuracy: 0.7132 - val_loss: 0.7689 - val_accuracy: 0.6465\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6968 - accuracy: 0.7116 - val_loss: 0.7665 - val_accuracy: 0.6558\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6972 - accuracy: 0.7080 - val_loss: 0.7576 - val_accuracy: 0.6558\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6949 - accuracy: 0.7106 - val_loss: 0.7549 - val_accuracy: 0.6465\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6932 - accuracy: 0.7075 - val_loss: 0.7499 - val_accuracy: 0.6558\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.6929 - accuracy: 0.7116 - val_loss: 0.7479 - val_accuracy: 0.6698\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6902 - accuracy: 0.7152 - val_loss: 0.7527 - val_accuracy: 0.6512\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6928 - accuracy: 0.7168 - val_loss: 0.7582 - val_accuracy: 0.6651\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6916 - accuracy: 0.7178 - val_loss: 0.7450 - val_accuracy: 0.6558\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6892 - accuracy: 0.7111 - val_loss: 0.7410 - val_accuracy: 0.6744\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6898 - accuracy: 0.7194 - val_loss: 0.7489 - val_accuracy: 0.6512\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6935 - accuracy: 0.7111 - val_loss: 0.7516 - val_accuracy: 0.6558\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6838 - accuracy: 0.7225 - val_loss: 0.7526 - val_accuracy: 0.6558\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.6926 - accuracy: 0.7049 - val_loss: 0.7588 - val_accuracy: 0.6744\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6881 - accuracy: 0.7142 - val_loss: 0.7478 - val_accuracy: 0.6512\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6824 - accuracy: 0.7152 - val_loss: 0.7332 - val_accuracy: 0.6791\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6794 - accuracy: 0.7246 - val_loss: 0.7394 - val_accuracy: 0.6651\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6825 - accuracy: 0.7121 - val_loss: 0.7392 - val_accuracy: 0.6698\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6811 - accuracy: 0.7220 - val_loss: 0.7808 - val_accuracy: 0.6512\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 700us/step - loss: 0.6793 - accuracy: 0.7142 - val_loss: 0.7401 - val_accuracy: 0.6651\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.6777 - accuracy: 0.7147 - val_loss: 0.7344 - val_accuracy: 0.6791\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.6763 - accuracy: 0.7235 - val_loss: 0.7314 - val_accuracy: 0.6698\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.7158 - val_loss: 0.7313 - val_accuracy: 0.6930\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.6792 - accuracy: 0.7215 - val_loss: 0.7398 - val_accuracy: 0.6698\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6762 - accuracy: 0.7235 - val_loss: 0.7269 - val_accuracy: 0.6698\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.7189 - val_loss: 0.7191 - val_accuracy: 0.6977\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.6767 - accuracy: 0.7251 - val_loss: 0.7347 - val_accuracy: 0.6791\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.7225 - val_loss: 0.7299 - val_accuracy: 0.7116\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.6700 - accuracy: 0.7230 - val_loss: 0.7363 - val_accuracy: 0.6744\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.6698 - accuracy: 0.7204 - val_loss: 0.7400 - val_accuracy: 0.6884\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.6686 - accuracy: 0.7178 - val_loss: 0.7431 - val_accuracy: 0.6605\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 884us/step - loss: 0.6691 - accuracy: 0.7178 - val_loss: 0.7276 - val_accuracy: 0.6698\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.6671 - accuracy: 0.7272 - val_loss: 0.7330 - val_accuracy: 0.6605\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6676 - accuracy: 0.7261 - val_loss: 0.7377 - val_accuracy: 0.6651\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6675 - accuracy: 0.7184 - val_loss: 0.7289 - val_accuracy: 0.6698\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.6749 - accuracy: 0.7225 - val_loss: 0.7337 - val_accuracy: 0.6837\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6659 - accuracy: 0.7225 - val_loss: 0.7392 - val_accuracy: 0.6605\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6658 - accuracy: 0.7256 - val_loss: 0.7343 - val_accuracy: 0.7023\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6612 - accuracy: 0.7256 - val_loss: 0.7193 - val_accuracy: 0.6930\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6608 - accuracy: 0.7235 - val_loss: 0.7199 - val_accuracy: 0.6837\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.6619 - accuracy: 0.7204 - val_loss: 0.7262 - val_accuracy: 0.6744\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6597 - accuracy: 0.7235 - val_loss: 0.7279 - val_accuracy: 0.6744\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6584 - accuracy: 0.7303 - val_loss: 0.7297 - val_accuracy: 0.6884\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6579 - accuracy: 0.7204 - val_loss: 0.7244 - val_accuracy: 0.6884\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6560 - accuracy: 0.7313 - val_loss: 0.7303 - val_accuracy: 0.6791\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.6599 - accuracy: 0.7303 - val_loss: 0.7147 - val_accuracy: 0.6837\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.6523 - accuracy: 0.7303 - val_loss: 0.7187 - val_accuracy: 0.6698\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6580 - accuracy: 0.7235 - val_loss: 0.7166 - val_accuracy: 0.7070\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6536 - accuracy: 0.7267 - val_loss: 0.7166 - val_accuracy: 0.6837\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6543 - accuracy: 0.7256 - val_loss: 0.7149 - val_accuracy: 0.6930\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6528 - accuracy: 0.7277 - val_loss: 0.7178 - val_accuracy: 0.6744\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6545 - accuracy: 0.7277 - val_loss: 0.7279 - val_accuracy: 0.6977\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.6543 - accuracy: 0.7256 - val_loss: 0.7107 - val_accuracy: 0.6698\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6490 - accuracy: 0.7287 - val_loss: 0.7236 - val_accuracy: 0.6744\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6522 - accuracy: 0.7344 - val_loss: 0.7073 - val_accuracy: 0.6977\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6498 - accuracy: 0.7282 - val_loss: 0.7146 - val_accuracy: 0.7023\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6538 - accuracy: 0.7313 - val_loss: 0.7073 - val_accuracy: 0.6884\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6472 - accuracy: 0.7272 - val_loss: 0.7250 - val_accuracy: 0.6837\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6463 - accuracy: 0.7308 - val_loss: 0.7448 - val_accuracy: 0.6558\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6488 - accuracy: 0.7293 - val_loss: 0.6987 - val_accuracy: 0.6791\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.6442 - accuracy: 0.7324 - val_loss: 0.7065 - val_accuracy: 0.6977\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.6435 - accuracy: 0.7318 - val_loss: 0.7168 - val_accuracy: 0.6930\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6421 - accuracy: 0.7318 - val_loss: 0.7097 - val_accuracy: 0.6884\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.6437 - accuracy: 0.7318 - val_loss: 0.7060 - val_accuracy: 0.6791\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6443 - accuracy: 0.7287 - val_loss: 0.7054 - val_accuracy: 0.6930\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.6385 - accuracy: 0.7329 - val_loss: 0.7104 - val_accuracy: 0.6791\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6426 - accuracy: 0.7324 - val_loss: 0.7219 - val_accuracy: 0.6977\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.6392 - accuracy: 0.7318 - val_loss: 0.7056 - val_accuracy: 0.7070\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6410 - accuracy: 0.7334 - val_loss: 0.7098 - val_accuracy: 0.6884\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6393 - accuracy: 0.7318 - val_loss: 0.7193 - val_accuracy: 0.6837\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6377 - accuracy: 0.7318 - val_loss: 0.7145 - val_accuracy: 0.6884\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6432 - accuracy: 0.7313 - val_loss: 0.7304 - val_accuracy: 0.6791\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6370 - accuracy: 0.7298 - val_loss: 0.7120 - val_accuracy: 0.6930\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6366 - accuracy: 0.7339 - val_loss: 0.7146 - val_accuracy: 0.6837\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6363 - accuracy: 0.7324 - val_loss: 0.6974 - val_accuracy: 0.7023\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 698us/step - loss: 0.6419 - accuracy: 0.7329 - val_loss: 0.6975 - val_accuracy: 0.7023\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 963us/step - loss: 0.6333 - accuracy: 0.7355 - val_loss: 0.7099 - val_accuracy: 0.6837\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6419 - accuracy: 0.7334 - val_loss: 0.6949 - val_accuracy: 0.6837\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6312 - accuracy: 0.7339 - val_loss: 0.7239 - val_accuracy: 0.6837\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6324 - accuracy: 0.7350 - val_loss: 0.7011 - val_accuracy: 0.6837\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6325 - accuracy: 0.7334 - val_loss: 0.6990 - val_accuracy: 0.6837\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.6322 - accuracy: 0.7344 - val_loss: 0.7007 - val_accuracy: 0.7023\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6310 - accuracy: 0.7381 - val_loss: 0.6898 - val_accuracy: 0.7023\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6282 - accuracy: 0.7350 - val_loss: 0.7162 - val_accuracy: 0.6977\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.6276 - accuracy: 0.7381 - val_loss: 0.6943 - val_accuracy: 0.7023\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.6262 - accuracy: 0.7412 - val_loss: 0.7026 - val_accuracy: 0.6791\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6244 - accuracy: 0.7396 - val_loss: 0.7261 - val_accuracy: 0.6698\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6294 - accuracy: 0.7334 - val_loss: 0.6961 - val_accuracy: 0.6977\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6271 - accuracy: 0.7407 - val_loss: 0.7151 - val_accuracy: 0.6791\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6275 - accuracy: 0.7334 - val_loss: 0.6902 - val_accuracy: 0.7023\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6238 - accuracy: 0.7360 - val_loss: 0.6939 - val_accuracy: 0.6884\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6280 - accuracy: 0.7308 - val_loss: 0.6943 - val_accuracy: 0.6930\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 916us/step - loss: 0.6208 - accuracy: 0.7391 - val_loss: 0.6973 - val_accuracy: 0.7023\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6247 - accuracy: 0.7376 - val_loss: 0.6947 - val_accuracy: 0.6977\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.6222 - accuracy: 0.7370 - val_loss: 0.6975 - val_accuracy: 0.6977\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.6201 - accuracy: 0.7417 - val_loss: 0.7054 - val_accuracy: 0.6884\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6204 - accuracy: 0.7407 - val_loss: 0.7060 - val_accuracy: 0.7116\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.6213 - accuracy: 0.7376 - val_loss: 0.6943 - val_accuracy: 0.6930\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.6265 - accuracy: 0.7272 - val_loss: 0.7046 - val_accuracy: 0.6930\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6179 - accuracy: 0.7360 - val_loss: 0.6959 - val_accuracy: 0.6884\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.6180 - accuracy: 0.7376 - val_loss: 0.6905 - val_accuracy: 0.6930\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6234 - accuracy: 0.7376 - val_loss: 0.6968 - val_accuracy: 0.6977\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6230 - accuracy: 0.7329 - val_loss: 0.6916 - val_accuracy: 0.6977\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6149 - accuracy: 0.7427 - val_loss: 0.6905 - val_accuracy: 0.7023\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6141 - accuracy: 0.7438 - val_loss: 0.6896 - val_accuracy: 0.6977\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6161 - accuracy: 0.7448 - val_loss: 0.6983 - val_accuracy: 0.6837\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6114 - accuracy: 0.7427 - val_loss: 0.6958 - val_accuracy: 0.7116\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6130 - accuracy: 0.7448 - val_loss: 0.6971 - val_accuracy: 0.7116\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 851us/step - loss: 0.6145 - accuracy: 0.7427 - val_loss: 0.6876 - val_accuracy: 0.7023\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6130 - accuracy: 0.7438 - val_loss: 0.6891 - val_accuracy: 0.7116\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6126 - accuracy: 0.7350 - val_loss: 0.6891 - val_accuracy: 0.7116\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 733us/step - loss: 0.6139 - accuracy: 0.7412 - val_loss: 0.6944 - val_accuracy: 0.6977\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 908us/step - loss: 0.6115 - accuracy: 0.7360 - val_loss: 0.6833 - val_accuracy: 0.7023\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6093 - accuracy: 0.7469 - val_loss: 0.6938 - val_accuracy: 0.7116\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6096 - accuracy: 0.7495 - val_loss: 0.6840 - val_accuracy: 0.7023\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.6095 - accuracy: 0.7433 - val_loss: 0.6940 - val_accuracy: 0.6930\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6074 - accuracy: 0.7459 - val_loss: 0.6900 - val_accuracy: 0.6977\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6059 - accuracy: 0.7495 - val_loss: 0.6919 - val_accuracy: 0.6837\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.6103 - accuracy: 0.7448 - val_loss: 0.6878 - val_accuracy: 0.6837\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6028 - accuracy: 0.7438 - val_loss: 0.6894 - val_accuracy: 0.7116\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.7453 - val_loss: 0.6986 - val_accuracy: 0.7256\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6064 - accuracy: 0.7516 - val_loss: 0.6882 - val_accuracy: 0.6977\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 761us/step - loss: 0.6062 - accuracy: 0.7391 - val_loss: 0.6899 - val_accuracy: 0.6884\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 920us/step - loss: 0.6043 - accuracy: 0.7474 - val_loss: 0.6797 - val_accuracy: 0.7070\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.6049 - accuracy: 0.7401 - val_loss: 0.6937 - val_accuracy: 0.6884\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6052 - accuracy: 0.7479 - val_loss: 0.7017 - val_accuracy: 0.6791\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6047 - accuracy: 0.7464 - val_loss: 0.6960 - val_accuracy: 0.6930\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6041 - accuracy: 0.7417 - val_loss: 0.6856 - val_accuracy: 0.7116\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6007 - accuracy: 0.7448 - val_loss: 0.6906 - val_accuracy: 0.7023\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6008 - accuracy: 0.7479 - val_loss: 0.7027 - val_accuracy: 0.6744\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6032 - accuracy: 0.7464 - val_loss: 0.6898 - val_accuracy: 0.6977\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5969 - accuracy: 0.7448 - val_loss: 0.6949 - val_accuracy: 0.6977\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5980 - accuracy: 0.7526 - val_loss: 0.6844 - val_accuracy: 0.6977\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5977 - accuracy: 0.7474 - val_loss: 0.7023 - val_accuracy: 0.7023\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6020 - accuracy: 0.7547 - val_loss: 0.7027 - val_accuracy: 0.6744\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5975 - accuracy: 0.7495 - val_loss: 0.6841 - val_accuracy: 0.7163\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5960 - accuracy: 0.7500 - val_loss: 0.6876 - val_accuracy: 0.7023\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5928 - accuracy: 0.7516 - val_loss: 0.6855 - val_accuracy: 0.7070\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5951 - accuracy: 0.7500 - val_loss: 0.6854 - val_accuracy: 0.7116\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 668us/step - loss: 0.5998 - accuracy: 0.7443 - val_loss: 0.6988 - val_accuracy: 0.7163\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 975us/step - loss: 0.5964 - accuracy: 0.7474 - val_loss: 0.6778 - val_accuracy: 0.7023\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5940 - accuracy: 0.7453 - val_loss: 0.6975 - val_accuracy: 0.6884\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5914 - accuracy: 0.7526 - val_loss: 0.6844 - val_accuracy: 0.7163\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 716us/step - loss: 0.5950 - accuracy: 0.7510 - val_loss: 0.6991 - val_accuracy: 0.6837\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5957 - accuracy: 0.7510 - val_loss: 0.6909 - val_accuracy: 0.6884\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5925 - accuracy: 0.7469 - val_loss: 0.6827 - val_accuracy: 0.7116\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5908 - accuracy: 0.7495 - val_loss: 0.6757 - val_accuracy: 0.7023\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5913 - accuracy: 0.7490 - val_loss: 0.6896 - val_accuracy: 0.6977\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5916 - accuracy: 0.7500 - val_loss: 0.6903 - val_accuracy: 0.6930\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.5912 - accuracy: 0.7526 - val_loss: 0.6753 - val_accuracy: 0.7163\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 688us/step - loss: 0.5927 - accuracy: 0.7495 - val_loss: 0.6871 - val_accuracy: 0.6930\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.5894 - accuracy: 0.7552 - val_loss: 0.6866 - val_accuracy: 0.6837\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.7459 - val_loss: 0.6861 - val_accuracy: 0.7302\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5895 - accuracy: 0.7516 - val_loss: 0.6716 - val_accuracy: 0.7116\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5853 - accuracy: 0.7521 - val_loss: 0.6783 - val_accuracy: 0.7116\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 726us/step - loss: 0.5869 - accuracy: 0.7557 - val_loss: 0.6793 - val_accuracy: 0.7163\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 780us/step - loss: 0.5888 - accuracy: 0.7557 - val_loss: 0.6823 - val_accuracy: 0.7070\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.5865 - accuracy: 0.7469 - val_loss: 0.6823 - val_accuracy: 0.6884\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 957us/step - loss: 0.5860 - accuracy: 0.7541 - val_loss: 0.6764 - val_accuracy: 0.7070\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5841 - accuracy: 0.7557 - val_loss: 0.6722 - val_accuracy: 0.7163\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.5821 - accuracy: 0.7567 - val_loss: 0.6813 - val_accuracy: 0.6930\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 846us/step - loss: 0.5871 - accuracy: 0.7541 - val_loss: 0.6765 - val_accuracy: 0.7023\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5838 - accuracy: 0.7552 - val_loss: 0.6824 - val_accuracy: 0.6977\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5826 - accuracy: 0.7552 - val_loss: 0.6822 - val_accuracy: 0.6977\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5812 - accuracy: 0.7583 - val_loss: 0.6755 - val_accuracy: 0.7256\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5829 - accuracy: 0.7547 - val_loss: 0.6751 - val_accuracy: 0.7256\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5806 - accuracy: 0.7505 - val_loss: 0.6803 - val_accuracy: 0.6884\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5830 - accuracy: 0.7526 - val_loss: 0.6792 - val_accuracy: 0.6930\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5818 - accuracy: 0.7557 - val_loss: 0.6783 - val_accuracy: 0.6977\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5819 - accuracy: 0.7567 - val_loss: 0.6897 - val_accuracy: 0.6930\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5826 - accuracy: 0.7552 - val_loss: 0.6768 - val_accuracy: 0.7209\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5801 - accuracy: 0.7547 - val_loss: 0.6739 - val_accuracy: 0.7023\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.5798 - accuracy: 0.7588 - val_loss: 0.6878 - val_accuracy: 0.6930\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5799 - accuracy: 0.7531 - val_loss: 0.6732 - val_accuracy: 0.7116\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5838 - accuracy: 0.7510 - val_loss: 0.6831 - val_accuracy: 0.7116\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.5770 - accuracy: 0.7541 - val_loss: 0.6701 - val_accuracy: 0.6930\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.5748 - accuracy: 0.7583 - val_loss: 0.6727 - val_accuracy: 0.6930\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 672us/step - loss: 0.5769 - accuracy: 0.7536 - val_loss: 0.6882 - val_accuracy: 0.7116\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.5756 - accuracy: 0.7583 - val_loss: 0.6878 - val_accuracy: 0.6884\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5807 - accuracy: 0.7557 - val_loss: 0.6699 - val_accuracy: 0.7209\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7614 - val_loss: 0.6771 - val_accuracy: 0.7442\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5788 - accuracy: 0.7557 - val_loss: 0.6793 - val_accuracy: 0.7209\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5818 - accuracy: 0.7541 - val_loss: 0.6833 - val_accuracy: 0.6884\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5762 - accuracy: 0.7583 - val_loss: 0.6868 - val_accuracy: 0.7116\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 876us/step - loss: 0.5736 - accuracy: 0.7593 - val_loss: 0.6733 - val_accuracy: 0.6930\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5729 - accuracy: 0.7604 - val_loss: 0.6785 - val_accuracy: 0.7256\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.5757 - accuracy: 0.7583 - val_loss: 0.6799 - val_accuracy: 0.7023\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5726 - accuracy: 0.7547 - val_loss: 0.6711 - val_accuracy: 0.7209\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5749 - accuracy: 0.7541 - val_loss: 0.6752 - val_accuracy: 0.7070\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.5736 - accuracy: 0.7541 - val_loss: 0.6773 - val_accuracy: 0.7209\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.5693 - accuracy: 0.7593 - val_loss: 0.6872 - val_accuracy: 0.7023\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5728 - accuracy: 0.7578 - val_loss: 0.6761 - val_accuracy: 0.7349\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5761 - accuracy: 0.7619 - val_loss: 0.6890 - val_accuracy: 0.6977\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5743 - accuracy: 0.7531 - val_loss: 0.6671 - val_accuracy: 0.7256\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5701 - accuracy: 0.7619 - val_loss: 0.6781 - val_accuracy: 0.7023\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5710 - accuracy: 0.7567 - val_loss: 0.6751 - val_accuracy: 0.6930\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5700 - accuracy: 0.7593 - val_loss: 0.6919 - val_accuracy: 0.7116\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5697 - accuracy: 0.7541 - val_loss: 0.6729 - val_accuracy: 0.7023\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5678 - accuracy: 0.7588 - val_loss: 0.6783 - val_accuracy: 0.7302\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5710 - accuracy: 0.7645 - val_loss: 0.6695 - val_accuracy: 0.7116\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5671 - accuracy: 0.7593 - val_loss: 0.6867 - val_accuracy: 0.6837\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5675 - accuracy: 0.7593 - val_loss: 0.6781 - val_accuracy: 0.7256\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5695 - accuracy: 0.7609 - val_loss: 0.6959 - val_accuracy: 0.6791\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5725 - accuracy: 0.7583 - val_loss: 0.6768 - val_accuracy: 0.7256\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5678 - accuracy: 0.7573 - val_loss: 0.6669 - val_accuracy: 0.7163\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5746 - accuracy: 0.7541 - val_loss: 0.6783 - val_accuracy: 0.7023\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5680 - accuracy: 0.7609 - val_loss: 0.6804 - val_accuracy: 0.6977\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5699 - accuracy: 0.7656 - val_loss: 0.6663 - val_accuracy: 0.7116\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5653 - accuracy: 0.7588 - val_loss: 0.6633 - val_accuracy: 0.7163\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5644 - accuracy: 0.7599 - val_loss: 0.6887 - val_accuracy: 0.6930\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5680 - accuracy: 0.7562 - val_loss: 0.6829 - val_accuracy: 0.7023\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5648 - accuracy: 0.7614 - val_loss: 0.6794 - val_accuracy: 0.6884\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.5671 - accuracy: 0.7650 - val_loss: 0.6687 - val_accuracy: 0.7209\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5678 - accuracy: 0.7583 - val_loss: 0.6879 - val_accuracy: 0.6977\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5635 - accuracy: 0.7619 - val_loss: 0.6805 - val_accuracy: 0.7209\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5637 - accuracy: 0.7614 - val_loss: 0.6990 - val_accuracy: 0.7116\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5675 - accuracy: 0.7609 - val_loss: 0.6806 - val_accuracy: 0.6884\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5616 - accuracy: 0.7552 - val_loss: 0.6955 - val_accuracy: 0.6930\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5679 - accuracy: 0.7614 - val_loss: 0.6796 - val_accuracy: 0.7256\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5604 - accuracy: 0.7609 - val_loss: 0.6834 - val_accuracy: 0.6977\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5607 - accuracy: 0.7599 - val_loss: 0.6666 - val_accuracy: 0.7116\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5613 - accuracy: 0.7619 - val_loss: 0.6755 - val_accuracy: 0.7163\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5657 - accuracy: 0.7609 - val_loss: 0.6700 - val_accuracy: 0.6977\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5621 - accuracy: 0.7656 - val_loss: 0.6715 - val_accuracy: 0.7116\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.5603 - accuracy: 0.7588 - val_loss: 0.6718 - val_accuracy: 0.7256\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5608 - accuracy: 0.7635 - val_loss: 0.6716 - val_accuracy: 0.7209\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5598 - accuracy: 0.7676 - val_loss: 0.6637 - val_accuracy: 0.7209\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5613 - accuracy: 0.7567 - val_loss: 0.6790 - val_accuracy: 0.7302\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5634 - accuracy: 0.7661 - val_loss: 0.6666 - val_accuracy: 0.7163\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5597 - accuracy: 0.7604 - val_loss: 0.6832 - val_accuracy: 0.7209\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 733us/step - loss: 0.5602 - accuracy: 0.7624 - val_loss: 0.6802 - val_accuracy: 0.7302\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.5607 - accuracy: 0.7645 - val_loss: 0.6723 - val_accuracy: 0.7023\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 694us/step - loss: 0.5581 - accuracy: 0.7609 - val_loss: 0.6621 - val_accuracy: 0.7116\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.5584 - accuracy: 0.7599 - val_loss: 0.6743 - val_accuracy: 0.7302\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 744us/step - loss: 0.5590 - accuracy: 0.7614 - val_loss: 0.6748 - val_accuracy: 0.6884\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 898us/step - loss: 0.5611 - accuracy: 0.7583 - val_loss: 0.6685 - val_accuracy: 0.7163\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5605 - accuracy: 0.7656 - val_loss: 0.6770 - val_accuracy: 0.6930\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5567 - accuracy: 0.7609 - val_loss: 0.6624 - val_accuracy: 0.7116\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5540 - accuracy: 0.7728 - val_loss: 0.6660 - val_accuracy: 0.7209\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5604 - accuracy: 0.7645 - val_loss: 0.6658 - val_accuracy: 0.7302\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5564 - accuracy: 0.7635 - val_loss: 0.6733 - val_accuracy: 0.7163\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5603 - accuracy: 0.7573 - val_loss: 0.6669 - val_accuracy: 0.7209\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5560 - accuracy: 0.7640 - val_loss: 0.6718 - val_accuracy: 0.7116\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5557 - accuracy: 0.7687 - val_loss: 0.6733 - val_accuracy: 0.7349\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5557 - accuracy: 0.7666 - val_loss: 0.6703 - val_accuracy: 0.7116\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5558 - accuracy: 0.7645 - val_loss: 0.6656 - val_accuracy: 0.7302\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 911us/step - loss: 0.5549 - accuracy: 0.7676 - val_loss: 0.6709 - val_accuracy: 0.7256\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5535 - accuracy: 0.7702 - val_loss: 0.6695 - val_accuracy: 0.7209\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5556 - accuracy: 0.7604 - val_loss: 0.6591 - val_accuracy: 0.7163\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5581 - accuracy: 0.7619 - val_loss: 0.6658 - val_accuracy: 0.7302\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.5520 - accuracy: 0.7661 - val_loss: 0.6835 - val_accuracy: 0.6884\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.5548 - accuracy: 0.7640 - val_loss: 0.6589 - val_accuracy: 0.7163\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5532 - accuracy: 0.7656 - val_loss: 0.6607 - val_accuracy: 0.7256\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5516 - accuracy: 0.7687 - val_loss: 0.6708 - val_accuracy: 0.6930\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5562 - accuracy: 0.7588 - val_loss: 0.6592 - val_accuracy: 0.7209\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5554 - accuracy: 0.7583 - val_loss: 0.6668 - val_accuracy: 0.7209\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5536 - accuracy: 0.7640 - val_loss: 0.6627 - val_accuracy: 0.7256\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5522 - accuracy: 0.7619 - val_loss: 0.6678 - val_accuracy: 0.6930\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5570 - accuracy: 0.7599 - val_loss: 0.6872 - val_accuracy: 0.6977\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5509 - accuracy: 0.7640 - val_loss: 0.6720 - val_accuracy: 0.7023\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.5542 - accuracy: 0.7640 - val_loss: 0.6673 - val_accuracy: 0.7395\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5520 - accuracy: 0.7624 - val_loss: 0.6638 - val_accuracy: 0.7023\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5511 - accuracy: 0.7645 - val_loss: 0.6585 - val_accuracy: 0.7349\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5485 - accuracy: 0.7687 - val_loss: 0.6785 - val_accuracy: 0.7395\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5575 - accuracy: 0.7666 - val_loss: 0.6651 - val_accuracy: 0.6977\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5503 - accuracy: 0.7692 - val_loss: 0.6569 - val_accuracy: 0.7256\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5484 - accuracy: 0.7645 - val_loss: 0.6631 - val_accuracy: 0.7442\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5488 - accuracy: 0.7656 - val_loss: 0.6588 - val_accuracy: 0.7349\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5509 - accuracy: 0.7661 - val_loss: 0.6702 - val_accuracy: 0.7395\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5530 - accuracy: 0.7609 - val_loss: 0.6610 - val_accuracy: 0.7163\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5515 - accuracy: 0.7661 - val_loss: 0.6830 - val_accuracy: 0.6977\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5538 - accuracy: 0.7624 - val_loss: 0.6611 - val_accuracy: 0.7209\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5487 - accuracy: 0.7671 - val_loss: 0.6680 - val_accuracy: 0.7302\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.5472 - accuracy: 0.7671 - val_loss: 0.6692 - val_accuracy: 0.6930\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5493 - accuracy: 0.7630 - val_loss: 0.6668 - val_accuracy: 0.7302\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5468 - accuracy: 0.7661 - val_loss: 0.7084 - val_accuracy: 0.7116\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5496 - accuracy: 0.7630 - val_loss: 0.6549 - val_accuracy: 0.7209\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5476 - accuracy: 0.7604 - val_loss: 0.6570 - val_accuracy: 0.7349\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5503 - accuracy: 0.7682 - val_loss: 0.6734 - val_accuracy: 0.7395\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - 0s 693us/step - loss: 0.5475 - accuracy: 0.7692 - val_loss: 0.6685 - val_accuracy: 0.7302\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.5464 - accuracy: 0.7650 - val_loss: 0.6575 - val_accuracy: 0.7070\n",
      "Epoch 368: early stopping\n",
      "29/29 - 0s - loss: 0.5595 - accuracy: 0.7615 - 111ms/epoch - 4ms/step\n",
      "2\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.5596 - accuracy: 0.2645 - val_loss: 1.4924 - val_accuracy: 0.3860\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.4473 - accuracy: 0.3553 - val_loss: 1.3904 - val_accuracy: 0.4419\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 1.3508 - accuracy: 0.4212 - val_loss: 1.3061 - val_accuracy: 0.4372\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 1.2877 - accuracy: 0.4253 - val_loss: 1.2636 - val_accuracy: 0.4372\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2477 - accuracy: 0.4409 - val_loss: 1.2357 - val_accuracy: 0.4558\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 1.2235 - accuracy: 0.4606 - val_loss: 1.2270 - val_accuracy: 0.4465\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 1.2049 - accuracy: 0.4772 - val_loss: 1.2147 - val_accuracy: 0.4372\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1840 - accuracy: 0.4803 - val_loss: 1.1908 - val_accuracy: 0.4605\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1661 - accuracy: 0.4870 - val_loss: 1.1567 - val_accuracy: 0.5070\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 1.1435 - accuracy: 0.5067 - val_loss: 1.1457 - val_accuracy: 0.5023\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 1.1249 - accuracy: 0.5130 - val_loss: 1.1319 - val_accuracy: 0.5023\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1032 - accuracy: 0.5244 - val_loss: 1.1138 - val_accuracy: 0.5349\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 1.0880 - accuracy: 0.5249 - val_loss: 1.0967 - val_accuracy: 0.5209\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0680 - accuracy: 0.5410 - val_loss: 1.0786 - val_accuracy: 0.5395\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0521 - accuracy: 0.5467 - val_loss: 1.0514 - val_accuracy: 0.5628\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 944us/step - loss: 1.0331 - accuracy: 0.5591 - val_loss: 1.0381 - val_accuracy: 0.5535\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 1.0159 - accuracy: 0.5664 - val_loss: 1.0287 - val_accuracy: 0.5581\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.9935 - accuracy: 0.5752 - val_loss: 0.9929 - val_accuracy: 0.5628\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.9765 - accuracy: 0.5892 - val_loss: 0.9847 - val_accuracy: 0.5581\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9678 - accuracy: 0.5731 - val_loss: 0.9546 - val_accuracy: 0.5953\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9409 - accuracy: 0.6100 - val_loss: 0.9384 - val_accuracy: 0.6047\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.9309 - accuracy: 0.6131 - val_loss: 0.9239 - val_accuracy: 0.5907\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.9089 - accuracy: 0.6333 - val_loss: 0.9270 - val_accuracy: 0.6000\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.8959 - accuracy: 0.6260 - val_loss: 0.8990 - val_accuracy: 0.6047\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8831 - accuracy: 0.6369 - val_loss: 0.9001 - val_accuracy: 0.6093\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8699 - accuracy: 0.6473 - val_loss: 0.8816 - val_accuracy: 0.6186\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8605 - accuracy: 0.6515 - val_loss: 0.8742 - val_accuracy: 0.6093\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.8568 - accuracy: 0.6478 - val_loss: 0.9224 - val_accuracy: 0.5721\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8468 - accuracy: 0.6540 - val_loss: 0.8537 - val_accuracy: 0.6326\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8399 - accuracy: 0.6592 - val_loss: 0.8582 - val_accuracy: 0.6419\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.8374 - accuracy: 0.6530 - val_loss: 0.8475 - val_accuracy: 0.6326\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8337 - accuracy: 0.6556 - val_loss: 0.8508 - val_accuracy: 0.6186\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.8209 - accuracy: 0.6634 - val_loss: 0.8470 - val_accuracy: 0.6093\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.8168 - accuracy: 0.6634 - val_loss: 0.8433 - val_accuracy: 0.6186\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.8188 - accuracy: 0.6592 - val_loss: 0.8350 - val_accuracy: 0.6326\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 629us/step - loss: 0.8144 - accuracy: 0.6566 - val_loss: 0.8261 - val_accuracy: 0.6372\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8070 - accuracy: 0.6696 - val_loss: 0.8402 - val_accuracy: 0.6233\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.8056 - accuracy: 0.6717 - val_loss: 0.8204 - val_accuracy: 0.6372\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.8021 - accuracy: 0.6753 - val_loss: 0.8304 - val_accuracy: 0.6140\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.7955 - accuracy: 0.6779 - val_loss: 0.8185 - val_accuracy: 0.6419\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.7945 - accuracy: 0.6805 - val_loss: 0.8069 - val_accuracy: 0.6326\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.7941 - accuracy: 0.6738 - val_loss: 0.8091 - val_accuracy: 0.6279\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7897 - accuracy: 0.6774 - val_loss: 0.8123 - val_accuracy: 0.6326\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7824 - accuracy: 0.6748 - val_loss: 0.8120 - val_accuracy: 0.6465\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.7840 - accuracy: 0.6753 - val_loss: 0.8238 - val_accuracy: 0.6279\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7794 - accuracy: 0.6810 - val_loss: 0.8138 - val_accuracy: 0.6326\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.7801 - accuracy: 0.6810 - val_loss: 0.8291 - val_accuracy: 0.6047\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.7695 - accuracy: 0.6867 - val_loss: 0.8131 - val_accuracy: 0.6279\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.7745 - accuracy: 0.6795 - val_loss: 0.8068 - val_accuracy: 0.6372\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7695 - accuracy: 0.6862 - val_loss: 0.8098 - val_accuracy: 0.6372\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7766 - accuracy: 0.6784 - val_loss: 0.8073 - val_accuracy: 0.6233\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.7694 - accuracy: 0.6826 - val_loss: 0.7997 - val_accuracy: 0.6186\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7654 - accuracy: 0.6857 - val_loss: 0.8085 - val_accuracy: 0.6186\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.7595 - accuracy: 0.6878 - val_loss: 0.7972 - val_accuracy: 0.6326\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7526 - accuracy: 0.6878 - val_loss: 0.7895 - val_accuracy: 0.6233\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7550 - accuracy: 0.6831 - val_loss: 0.8052 - val_accuracy: 0.6186\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7512 - accuracy: 0.6862 - val_loss: 0.7953 - val_accuracy: 0.6326\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7458 - accuracy: 0.6883 - val_loss: 0.8077 - val_accuracy: 0.6279\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7461 - accuracy: 0.6841 - val_loss: 0.7950 - val_accuracy: 0.6419\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7462 - accuracy: 0.6815 - val_loss: 0.7824 - val_accuracy: 0.6465\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7385 - accuracy: 0.6955 - val_loss: 0.7846 - val_accuracy: 0.6558\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.7397 - accuracy: 0.6950 - val_loss: 0.8173 - val_accuracy: 0.6512\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7406 - accuracy: 0.6987 - val_loss: 0.7875 - val_accuracy: 0.6465\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.7317 - accuracy: 0.6940 - val_loss: 0.7797 - val_accuracy: 0.6558\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7327 - accuracy: 0.6992 - val_loss: 0.8099 - val_accuracy: 0.6140\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.7279 - accuracy: 0.6992 - val_loss: 0.7809 - val_accuracy: 0.6419\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 733us/step - loss: 0.7279 - accuracy: 0.6966 - val_loss: 0.7893 - val_accuracy: 0.6326\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.7278 - accuracy: 0.7012 - val_loss: 0.7793 - val_accuracy: 0.6512\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 773us/step - loss: 0.7305 - accuracy: 0.6935 - val_loss: 0.7831 - val_accuracy: 0.6558\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.7209 - accuracy: 0.7095 - val_loss: 0.7718 - val_accuracy: 0.6512\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7202 - accuracy: 0.7049 - val_loss: 0.7814 - val_accuracy: 0.6512\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.7279 - accuracy: 0.6997 - val_loss: 0.7848 - val_accuracy: 0.6419\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.7169 - accuracy: 0.7012 - val_loss: 0.7652 - val_accuracy: 0.6558\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7157 - accuracy: 0.7023 - val_loss: 0.7855 - val_accuracy: 0.6233\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7097 - accuracy: 0.7054 - val_loss: 0.7656 - val_accuracy: 0.6419\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.7106 - val_loss: 0.7610 - val_accuracy: 0.6698\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.7112 - accuracy: 0.7059 - val_loss: 0.7628 - val_accuracy: 0.6465\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.7037 - accuracy: 0.7116 - val_loss: 0.7735 - val_accuracy: 0.6465\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7085 - accuracy: 0.7116 - val_loss: 0.7703 - val_accuracy: 0.6419\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7030 - accuracy: 0.7127 - val_loss: 0.7639 - val_accuracy: 0.6512\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.7024 - accuracy: 0.7075 - val_loss: 0.7646 - val_accuracy: 0.6605\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.7018 - accuracy: 0.7121 - val_loss: 0.7630 - val_accuracy: 0.6512\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6986 - accuracy: 0.7127 - val_loss: 0.7533 - val_accuracy: 0.6465\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6988 - accuracy: 0.7137 - val_loss: 0.7517 - val_accuracy: 0.6698\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.6916 - accuracy: 0.7152 - val_loss: 0.7680 - val_accuracy: 0.6326\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.7158 - val_loss: 0.7589 - val_accuracy: 0.6465\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6899 - accuracy: 0.7210 - val_loss: 0.7555 - val_accuracy: 0.6651\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.6934 - accuracy: 0.7137 - val_loss: 0.7505 - val_accuracy: 0.6605\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.6841 - accuracy: 0.7189 - val_loss: 0.7499 - val_accuracy: 0.6837\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.7173 - val_loss: 0.7523 - val_accuracy: 0.6698\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 624us/step - loss: 0.6853 - accuracy: 0.7132 - val_loss: 0.7366 - val_accuracy: 0.6837\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.6790 - accuracy: 0.7210 - val_loss: 0.7519 - val_accuracy: 0.6698\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6827 - accuracy: 0.7235 - val_loss: 0.7308 - val_accuracy: 0.6791\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6756 - accuracy: 0.7173 - val_loss: 0.7504 - val_accuracy: 0.6558\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6769 - accuracy: 0.7121 - val_loss: 0.7448 - val_accuracy: 0.6651\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.6753 - accuracy: 0.7230 - val_loss: 0.7279 - val_accuracy: 0.6884\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6734 - accuracy: 0.7230 - val_loss: 0.7278 - val_accuracy: 0.6791\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6745 - accuracy: 0.7163 - val_loss: 0.7401 - val_accuracy: 0.6884\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.7241 - val_loss: 0.7217 - val_accuracy: 0.6977\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6723 - accuracy: 0.7246 - val_loss: 0.7353 - val_accuracy: 0.6605\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6660 - accuracy: 0.7235 - val_loss: 0.7315 - val_accuracy: 0.6930\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 652us/step - loss: 0.6653 - accuracy: 0.7267 - val_loss: 0.7282 - val_accuracy: 0.6884\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.6628 - accuracy: 0.7293 - val_loss: 0.7254 - val_accuracy: 0.6698\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.6625 - accuracy: 0.7272 - val_loss: 0.7367 - val_accuracy: 0.6791\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.7241 - val_loss: 0.7232 - val_accuracy: 0.7116\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6617 - accuracy: 0.7230 - val_loss: 0.7148 - val_accuracy: 0.6791\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.6561 - accuracy: 0.7303 - val_loss: 0.7169 - val_accuracy: 0.6837\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6585 - accuracy: 0.7210 - val_loss: 0.7288 - val_accuracy: 0.6744\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6584 - accuracy: 0.7277 - val_loss: 0.7225 - val_accuracy: 0.6558\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6518 - accuracy: 0.7324 - val_loss: 0.7201 - val_accuracy: 0.6930\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6561 - accuracy: 0.7246 - val_loss: 0.7051 - val_accuracy: 0.6977\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6555 - accuracy: 0.7298 - val_loss: 0.7153 - val_accuracy: 0.6558\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6482 - accuracy: 0.7298 - val_loss: 0.7368 - val_accuracy: 0.6651\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 707us/step - loss: 0.6536 - accuracy: 0.7287 - val_loss: 0.7183 - val_accuracy: 0.6791\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.7267 - val_loss: 0.6927 - val_accuracy: 0.7163\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6425 - accuracy: 0.7360 - val_loss: 0.6977 - val_accuracy: 0.7070\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.6412 - accuracy: 0.7334 - val_loss: 0.6913 - val_accuracy: 0.7070\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.6464 - accuracy: 0.7355 - val_loss: 0.7014 - val_accuracy: 0.7023\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6411 - accuracy: 0.7293 - val_loss: 0.6959 - val_accuracy: 0.7023\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.7376 - val_loss: 0.7023 - val_accuracy: 0.7209\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.7318 - val_loss: 0.6849 - val_accuracy: 0.7256\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6370 - accuracy: 0.7365 - val_loss: 0.7083 - val_accuracy: 0.6884\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6354 - accuracy: 0.7381 - val_loss: 0.6998 - val_accuracy: 0.7116\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6371 - accuracy: 0.7344 - val_loss: 0.6938 - val_accuracy: 0.7023\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.6353 - accuracy: 0.7324 - val_loss: 0.6874 - val_accuracy: 0.7023\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6330 - accuracy: 0.7318 - val_loss: 0.6944 - val_accuracy: 0.7023\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6308 - accuracy: 0.7355 - val_loss: 0.6937 - val_accuracy: 0.6930\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6301 - accuracy: 0.7329 - val_loss: 0.6853 - val_accuracy: 0.6977\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6314 - accuracy: 0.7370 - val_loss: 0.6902 - val_accuracy: 0.7023\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.6332 - accuracy: 0.7355 - val_loss: 0.6812 - val_accuracy: 0.7163\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6263 - accuracy: 0.7376 - val_loss: 0.6817 - val_accuracy: 0.6977\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6248 - accuracy: 0.7365 - val_loss: 0.6911 - val_accuracy: 0.6977\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6255 - accuracy: 0.7443 - val_loss: 0.6867 - val_accuracy: 0.7070\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6235 - accuracy: 0.7303 - val_loss: 0.6809 - val_accuracy: 0.6977\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6238 - accuracy: 0.7386 - val_loss: 0.6943 - val_accuracy: 0.6977\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6293 - accuracy: 0.7298 - val_loss: 0.6809 - val_accuracy: 0.7023\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6230 - accuracy: 0.7401 - val_loss: 0.6967 - val_accuracy: 0.6977\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6221 - accuracy: 0.7355 - val_loss: 0.6731 - val_accuracy: 0.7116\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 753us/step - loss: 0.6227 - accuracy: 0.7422 - val_loss: 0.6960 - val_accuracy: 0.6698\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.6224 - accuracy: 0.7417 - val_loss: 0.6891 - val_accuracy: 0.6884\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.7407 - val_loss: 0.6695 - val_accuracy: 0.7302\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.6170 - accuracy: 0.7427 - val_loss: 0.6843 - val_accuracy: 0.7070\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.6207 - accuracy: 0.7417 - val_loss: 0.6686 - val_accuracy: 0.7116\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 757us/step - loss: 0.6149 - accuracy: 0.7329 - val_loss: 0.6807 - val_accuracy: 0.6884\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6132 - accuracy: 0.7438 - val_loss: 0.6707 - val_accuracy: 0.6884\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6159 - accuracy: 0.7412 - val_loss: 0.6845 - val_accuracy: 0.7023\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6121 - accuracy: 0.7448 - val_loss: 0.6791 - val_accuracy: 0.7256\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.6161 - accuracy: 0.7417 - val_loss: 0.7156 - val_accuracy: 0.6744\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.6143 - accuracy: 0.7417 - val_loss: 0.6972 - val_accuracy: 0.6884\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.6110 - accuracy: 0.7433 - val_loss: 0.6812 - val_accuracy: 0.7023\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.6089 - accuracy: 0.7433 - val_loss: 0.6624 - val_accuracy: 0.7116\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.6099 - accuracy: 0.7422 - val_loss: 0.6582 - val_accuracy: 0.7070\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.6071 - accuracy: 0.7469 - val_loss: 0.6659 - val_accuracy: 0.6977\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.7427 - val_loss: 0.6900 - val_accuracy: 0.7070\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6070 - accuracy: 0.7427 - val_loss: 0.6808 - val_accuracy: 0.7116\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.6049 - accuracy: 0.7505 - val_loss: 0.6736 - val_accuracy: 0.7209\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.6048 - accuracy: 0.7474 - val_loss: 0.6747 - val_accuracy: 0.6977\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 689us/step - loss: 0.6032 - accuracy: 0.7459 - val_loss: 0.6849 - val_accuracy: 0.6977\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.6061 - accuracy: 0.7479 - val_loss: 0.6611 - val_accuracy: 0.7070\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6036 - accuracy: 0.7438 - val_loss: 0.6753 - val_accuracy: 0.6977\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6022 - accuracy: 0.7484 - val_loss: 0.6891 - val_accuracy: 0.6837\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 635us/step - loss: 0.6044 - accuracy: 0.7464 - val_loss: 0.6601 - val_accuracy: 0.6977\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 979us/step - loss: 0.6037 - accuracy: 0.7417 - val_loss: 0.6954 - val_accuracy: 0.6977\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 638us/step - loss: 0.6002 - accuracy: 0.7448 - val_loss: 0.6629 - val_accuracy: 0.7116\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.6029 - accuracy: 0.7453 - val_loss: 0.6647 - val_accuracy: 0.7116\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.6002 - accuracy: 0.7531 - val_loss: 0.6725 - val_accuracy: 0.7023\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.5956 - accuracy: 0.7573 - val_loss: 0.6791 - val_accuracy: 0.6884\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5993 - accuracy: 0.7484 - val_loss: 0.6618 - val_accuracy: 0.7116\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 716us/step - loss: 0.5936 - accuracy: 0.7516 - val_loss: 0.6755 - val_accuracy: 0.7163\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5987 - accuracy: 0.7479 - val_loss: 0.6562 - val_accuracy: 0.7256\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.5966 - accuracy: 0.7464 - val_loss: 0.6691 - val_accuracy: 0.7302\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 769us/step - loss: 0.5945 - accuracy: 0.7521 - val_loss: 0.6555 - val_accuracy: 0.7116\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5951 - accuracy: 0.7510 - val_loss: 0.6560 - val_accuracy: 0.7070\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5928 - accuracy: 0.7541 - val_loss: 0.6649 - val_accuracy: 0.7116\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.5941 - accuracy: 0.7490 - val_loss: 0.6942 - val_accuracy: 0.6884\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 973us/step - loss: 0.5931 - accuracy: 0.7536 - val_loss: 0.6594 - val_accuracy: 0.7070\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 643us/step - loss: 0.5925 - accuracy: 0.7541 - val_loss: 0.6705 - val_accuracy: 0.7256\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.7505 - val_loss: 0.6633 - val_accuracy: 0.7023\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.5904 - accuracy: 0.7521 - val_loss: 0.6622 - val_accuracy: 0.7070\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.5875 - accuracy: 0.7578 - val_loss: 0.6560 - val_accuracy: 0.7116\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5866 - accuracy: 0.7578 - val_loss: 0.6716 - val_accuracy: 0.7302\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5919 - accuracy: 0.7490 - val_loss: 0.6625 - val_accuracy: 0.7116\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5885 - accuracy: 0.7526 - val_loss: 0.6608 - val_accuracy: 0.7163\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 948us/step - loss: 0.5951 - accuracy: 0.7552 - val_loss: 0.6720 - val_accuracy: 0.7023\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 732us/step - loss: 0.5856 - accuracy: 0.7516 - val_loss: 0.6640 - val_accuracy: 0.7070\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 930us/step - loss: 0.5846 - accuracy: 0.7567 - val_loss: 0.6635 - val_accuracy: 0.7256\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.5841 - accuracy: 0.7567 - val_loss: 0.6709 - val_accuracy: 0.6977\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 716us/step - loss: 0.5846 - accuracy: 0.7510 - val_loss: 0.6731 - val_accuracy: 0.6884\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5888 - accuracy: 0.7547 - val_loss: 0.6598 - val_accuracy: 0.7302\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5869 - accuracy: 0.7583 - val_loss: 0.6573 - val_accuracy: 0.7116\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5820 - accuracy: 0.7521 - val_loss: 0.6545 - val_accuracy: 0.7116\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5898 - accuracy: 0.7521 - val_loss: 0.6833 - val_accuracy: 0.7070\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5834 - accuracy: 0.7557 - val_loss: 0.6587 - val_accuracy: 0.7023\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5840 - accuracy: 0.7578 - val_loss: 0.6645 - val_accuracy: 0.6977\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.5841 - accuracy: 0.7604 - val_loss: 0.6654 - val_accuracy: 0.7116\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.5800 - accuracy: 0.7562 - val_loss: 0.6650 - val_accuracy: 0.7070\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 964us/step - loss: 0.5806 - accuracy: 0.7588 - val_loss: 0.6527 - val_accuracy: 0.7302\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5792 - accuracy: 0.7578 - val_loss: 0.6544 - val_accuracy: 0.6977\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.5820 - accuracy: 0.7500 - val_loss: 0.6508 - val_accuracy: 0.7116\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5809 - accuracy: 0.7624 - val_loss: 0.6439 - val_accuracy: 0.7070\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5817 - accuracy: 0.7552 - val_loss: 0.6723 - val_accuracy: 0.7023\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 774us/step - loss: 0.5813 - accuracy: 0.7578 - val_loss: 0.6663 - val_accuracy: 0.6930\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5769 - accuracy: 0.7510 - val_loss: 0.6553 - val_accuracy: 0.7302\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5765 - accuracy: 0.7578 - val_loss: 0.6734 - val_accuracy: 0.6930\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 663us/step - loss: 0.5778 - accuracy: 0.7604 - val_loss: 0.6683 - val_accuracy: 0.7163\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.5740 - accuracy: 0.7604 - val_loss: 0.6781 - val_accuracy: 0.6930\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.5750 - accuracy: 0.7573 - val_loss: 0.6667 - val_accuracy: 0.7302\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.5808 - accuracy: 0.7609 - val_loss: 0.6978 - val_accuracy: 0.6744\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5747 - accuracy: 0.7614 - val_loss: 0.6608 - val_accuracy: 0.7070\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5725 - accuracy: 0.7599 - val_loss: 0.6528 - val_accuracy: 0.7070\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5709 - accuracy: 0.7604 - val_loss: 0.6609 - val_accuracy: 0.6930\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 741us/step - loss: 0.5698 - accuracy: 0.7645 - val_loss: 0.6492 - val_accuracy: 0.6977\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5733 - accuracy: 0.7609 - val_loss: 0.6859 - val_accuracy: 0.6791\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7562 - val_loss: 0.6683 - val_accuracy: 0.6884\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.5703 - accuracy: 0.7640 - val_loss: 0.6680 - val_accuracy: 0.6977\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5702 - accuracy: 0.7583 - val_loss: 0.6586 - val_accuracy: 0.7070\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5700 - accuracy: 0.7552 - val_loss: 0.6462 - val_accuracy: 0.6977\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.5705 - accuracy: 0.7562 - val_loss: 0.6539 - val_accuracy: 0.6930\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 951us/step - loss: 0.5695 - accuracy: 0.7578 - val_loss: 0.6594 - val_accuracy: 0.7302\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.5718 - accuracy: 0.7604 - val_loss: 0.6562 - val_accuracy: 0.7116\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 934us/step - loss: 0.5691 - accuracy: 0.7619 - val_loss: 0.6470 - val_accuracy: 0.7163\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5700 - accuracy: 0.7604 - val_loss: 0.6668 - val_accuracy: 0.7023\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.5716 - accuracy: 0.7547 - val_loss: 0.6601 - val_accuracy: 0.6884\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5665 - accuracy: 0.7624 - val_loss: 0.6693 - val_accuracy: 0.6884\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.5686 - accuracy: 0.7619 - val_loss: 0.6498 - val_accuracy: 0.7023\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.5683 - accuracy: 0.7614 - val_loss: 0.6555 - val_accuracy: 0.7116\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5678 - accuracy: 0.7614 - val_loss: 0.6432 - val_accuracy: 0.6977\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.5645 - accuracy: 0.7630 - val_loss: 0.6488 - val_accuracy: 0.6884\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.5698 - accuracy: 0.7609 - val_loss: 0.6856 - val_accuracy: 0.6837\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5676 - accuracy: 0.7624 - val_loss: 0.6808 - val_accuracy: 0.6930\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.5676 - accuracy: 0.7604 - val_loss: 0.6831 - val_accuracy: 0.6977\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 875us/step - loss: 0.5660 - accuracy: 0.7635 - val_loss: 0.6609 - val_accuracy: 0.6930\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5663 - accuracy: 0.7624 - val_loss: 0.6603 - val_accuracy: 0.7209\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.5637 - accuracy: 0.7593 - val_loss: 0.6616 - val_accuracy: 0.7023\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.5644 - accuracy: 0.7604 - val_loss: 0.6484 - val_accuracy: 0.7116\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.5627 - accuracy: 0.7624 - val_loss: 0.6466 - val_accuracy: 0.7209\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 947us/step - loss: 0.5641 - accuracy: 0.7604 - val_loss: 0.6596 - val_accuracy: 0.7023\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.5645 - accuracy: 0.7593 - val_loss: 0.6399 - val_accuracy: 0.7023\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.5609 - accuracy: 0.7624 - val_loss: 0.6642 - val_accuracy: 0.7302\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5606 - accuracy: 0.7614 - val_loss: 0.6519 - val_accuracy: 0.6837\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5611 - accuracy: 0.7650 - val_loss: 0.6544 - val_accuracy: 0.7116\n",
      "Epoch 241: early stopping\n",
      "29/29 - 0s - loss: 0.5868 - accuracy: 0.7637 - 97ms/epoch - 3ms/step\n",
      "3\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5281 - accuracy: 0.2635 - val_loss: 1.4544 - val_accuracy: 0.3116\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.3973 - accuracy: 0.3636 - val_loss: 1.3383 - val_accuracy: 0.4698\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 748us/step - loss: 1.3089 - accuracy: 0.4331 - val_loss: 1.2794 - val_accuracy: 0.4698\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 1.2577 - accuracy: 0.4487 - val_loss: 1.2462 - val_accuracy: 0.4512\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 1.2290 - accuracy: 0.4606 - val_loss: 1.2073 - val_accuracy: 0.4837\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2081 - accuracy: 0.4678 - val_loss: 1.1909 - val_accuracy: 0.5023\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 724us/step - loss: 1.1868 - accuracy: 0.4907 - val_loss: 1.1715 - val_accuracy: 0.4977\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 908us/step - loss: 1.1610 - accuracy: 0.4979 - val_loss: 1.1600 - val_accuracy: 0.4744\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1365 - accuracy: 0.5249 - val_loss: 1.1268 - val_accuracy: 0.5209\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1098 - accuracy: 0.5280 - val_loss: 1.1072 - val_accuracy: 0.5256\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0839 - accuracy: 0.5430 - val_loss: 1.0792 - val_accuracy: 0.5535\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 1.0625 - accuracy: 0.5539 - val_loss: 1.0577 - val_accuracy: 0.5488\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0369 - accuracy: 0.5648 - val_loss: 1.0351 - val_accuracy: 0.5674\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 1.0134 - accuracy: 0.5742 - val_loss: 1.0168 - val_accuracy: 0.5581\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.9925 - accuracy: 0.5887 - val_loss: 1.0058 - val_accuracy: 0.6000\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9727 - accuracy: 0.5954 - val_loss: 0.9570 - val_accuracy: 0.6093\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.9487 - accuracy: 0.6089 - val_loss: 0.9594 - val_accuracy: 0.5860\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 782us/step - loss: 0.9344 - accuracy: 0.6141 - val_loss: 0.9362 - val_accuracy: 0.5860\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9190 - accuracy: 0.6240 - val_loss: 0.9073 - val_accuracy: 0.6233\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.9066 - accuracy: 0.6255 - val_loss: 0.9075 - val_accuracy: 0.6372\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.8939 - accuracy: 0.6333 - val_loss: 0.8979 - val_accuracy: 0.6000\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.8842 - accuracy: 0.6395 - val_loss: 0.8879 - val_accuracy: 0.6186\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 961us/step - loss: 0.8733 - accuracy: 0.6494 - val_loss: 0.8929 - val_accuracy: 0.6233\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 655us/step - loss: 0.8737 - accuracy: 0.6411 - val_loss: 0.8918 - val_accuracy: 0.6186\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8669 - accuracy: 0.6411 - val_loss: 0.8628 - val_accuracy: 0.6047\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.8555 - accuracy: 0.6551 - val_loss: 0.8790 - val_accuracy: 0.6093\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 667us/step - loss: 0.8507 - accuracy: 0.6452 - val_loss: 0.8529 - val_accuracy: 0.6186\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8507 - accuracy: 0.6483 - val_loss: 0.8691 - val_accuracy: 0.5953\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 600us/step - loss: 0.8481 - accuracy: 0.6504 - val_loss: 0.8651 - val_accuracy: 0.6186\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8420 - accuracy: 0.6572 - val_loss: 0.8482 - val_accuracy: 0.6186\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.8378 - accuracy: 0.6572 - val_loss: 0.8494 - val_accuracy: 0.6186\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8415 - accuracy: 0.6556 - val_loss: 0.8505 - val_accuracy: 0.6047\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.8363 - accuracy: 0.6535 - val_loss: 0.8375 - val_accuracy: 0.6093\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8314 - accuracy: 0.6546 - val_loss: 0.8743 - val_accuracy: 0.6233\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.8258 - accuracy: 0.6649 - val_loss: 0.8345 - val_accuracy: 0.6279\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.8242 - accuracy: 0.6587 - val_loss: 0.8446 - val_accuracy: 0.6140\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.8243 - accuracy: 0.6582 - val_loss: 0.8362 - val_accuracy: 0.6186\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.8290 - accuracy: 0.6530 - val_loss: 0.8437 - val_accuracy: 0.6047\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.8206 - accuracy: 0.6639 - val_loss: 0.8524 - val_accuracy: 0.6093\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.8227 - accuracy: 0.6577 - val_loss: 0.8382 - val_accuracy: 0.6186\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.8166 - accuracy: 0.6530 - val_loss: 0.8261 - val_accuracy: 0.6047\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8101 - accuracy: 0.6639 - val_loss: 0.8211 - val_accuracy: 0.6326\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.8106 - accuracy: 0.6722 - val_loss: 0.8304 - val_accuracy: 0.6279\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 889us/step - loss: 0.8062 - accuracy: 0.6644 - val_loss: 0.8288 - val_accuracy: 0.6279\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.8105 - accuracy: 0.6623 - val_loss: 0.8198 - val_accuracy: 0.6233\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.8099 - accuracy: 0.6598 - val_loss: 0.8152 - val_accuracy: 0.6326\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.8028 - accuracy: 0.6649 - val_loss: 0.8206 - val_accuracy: 0.6326\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.7948 - accuracy: 0.6665 - val_loss: 0.8184 - val_accuracy: 0.6233\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.7946 - accuracy: 0.6738 - val_loss: 0.8206 - val_accuracy: 0.6279\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.7947 - accuracy: 0.6670 - val_loss: 0.8129 - val_accuracy: 0.6093\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7902 - accuracy: 0.6696 - val_loss: 0.8222 - val_accuracy: 0.6233\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7889 - accuracy: 0.6706 - val_loss: 0.8238 - val_accuracy: 0.6233\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.7852 - accuracy: 0.6660 - val_loss: 0.8013 - val_accuracy: 0.6419\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 782us/step - loss: 0.7777 - accuracy: 0.6743 - val_loss: 0.8385 - val_accuracy: 0.6233\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7772 - accuracy: 0.6748 - val_loss: 0.8270 - val_accuracy: 0.6186\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.7740 - accuracy: 0.6753 - val_loss: 0.8446 - val_accuracy: 0.6047\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7778 - accuracy: 0.6738 - val_loss: 0.8042 - val_accuracy: 0.6186\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 668us/step - loss: 0.7703 - accuracy: 0.6805 - val_loss: 0.7967 - val_accuracy: 0.6279\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 945us/step - loss: 0.7674 - accuracy: 0.6841 - val_loss: 0.7979 - val_accuracy: 0.6186\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 697us/step - loss: 0.7645 - accuracy: 0.6841 - val_loss: 0.8014 - val_accuracy: 0.6326\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.7651 - accuracy: 0.6857 - val_loss: 0.8041 - val_accuracy: 0.6279\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 590us/step - loss: 0.7597 - accuracy: 0.6826 - val_loss: 0.8100 - val_accuracy: 0.6233\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.7590 - accuracy: 0.6862 - val_loss: 0.7897 - val_accuracy: 0.6372\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7555 - accuracy: 0.6883 - val_loss: 0.7930 - val_accuracy: 0.6186\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7575 - accuracy: 0.6893 - val_loss: 0.8109 - val_accuracy: 0.6000\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.7518 - accuracy: 0.6924 - val_loss: 0.7985 - val_accuracy: 0.6186\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.6893 - val_loss: 0.7888 - val_accuracy: 0.6233\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7520 - accuracy: 0.6852 - val_loss: 0.7945 - val_accuracy: 0.6233\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 726us/step - loss: 0.7478 - accuracy: 0.6878 - val_loss: 0.7920 - val_accuracy: 0.6326\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7502 - accuracy: 0.6857 - val_loss: 0.7766 - val_accuracy: 0.6279\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.7410 - accuracy: 0.6981 - val_loss: 0.7834 - val_accuracy: 0.6326\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.7451 - accuracy: 0.6867 - val_loss: 0.7858 - val_accuracy: 0.6279\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 991us/step - loss: 0.7470 - accuracy: 0.6888 - val_loss: 0.7934 - val_accuracy: 0.6279\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 626us/step - loss: 0.7415 - accuracy: 0.6872 - val_loss: 0.7950 - val_accuracy: 0.6279\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.7331 - accuracy: 0.6929 - val_loss: 0.7815 - val_accuracy: 0.6326\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7347 - accuracy: 0.6971 - val_loss: 0.7673 - val_accuracy: 0.6605\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 691us/step - loss: 0.7342 - accuracy: 0.7002 - val_loss: 0.7663 - val_accuracy: 0.6326\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.7367 - accuracy: 0.6971 - val_loss: 0.7847 - val_accuracy: 0.6372\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.7316 - accuracy: 0.6976 - val_loss: 0.7703 - val_accuracy: 0.6372\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.7281 - accuracy: 0.7012 - val_loss: 0.7768 - val_accuracy: 0.6233\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.7248 - accuracy: 0.7038 - val_loss: 0.7685 - val_accuracy: 0.6279\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.7234 - accuracy: 0.7023 - val_loss: 0.7679 - val_accuracy: 0.6512\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.7178 - accuracy: 0.7038 - val_loss: 0.7646 - val_accuracy: 0.6558\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.7224 - accuracy: 0.7023 - val_loss: 0.7728 - val_accuracy: 0.6233\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.7173 - accuracy: 0.6971 - val_loss: 0.7695 - val_accuracy: 0.6279\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.7196 - accuracy: 0.7075 - val_loss: 0.7634 - val_accuracy: 0.6419\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7153 - accuracy: 0.7023 - val_loss: 0.7742 - val_accuracy: 0.6419\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.7137 - accuracy: 0.7049 - val_loss: 0.7657 - val_accuracy: 0.6372\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.7130 - accuracy: 0.6981 - val_loss: 0.7666 - val_accuracy: 0.6558\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.7094 - accuracy: 0.7080 - val_loss: 0.7668 - val_accuracy: 0.6512\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.7056 - accuracy: 0.7095 - val_loss: 0.7848 - val_accuracy: 0.6651\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.7072 - accuracy: 0.7054 - val_loss: 0.7569 - val_accuracy: 0.6558\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 700us/step - loss: 0.7051 - accuracy: 0.7044 - val_loss: 0.7586 - val_accuracy: 0.6419\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.7101 - val_loss: 0.7518 - val_accuracy: 0.6837\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.7104 - accuracy: 0.7080 - val_loss: 0.7552 - val_accuracy: 0.6512\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.7000 - accuracy: 0.7090 - val_loss: 0.7539 - val_accuracy: 0.6558\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.7100 - accuracy: 0.7095 - val_loss: 0.7610 - val_accuracy: 0.6512\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 678us/step - loss: 0.6994 - accuracy: 0.7127 - val_loss: 0.7639 - val_accuracy: 0.6419\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 964us/step - loss: 0.7059 - accuracy: 0.7101 - val_loss: 0.7563 - val_accuracy: 0.6791\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 652us/step - loss: 0.6947 - accuracy: 0.7090 - val_loss: 0.7501 - val_accuracy: 0.6651\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 957us/step - loss: 0.6974 - accuracy: 0.7152 - val_loss: 0.7603 - val_accuracy: 0.6419\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.6906 - accuracy: 0.7142 - val_loss: 0.7437 - val_accuracy: 0.6651\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6952 - accuracy: 0.7095 - val_loss: 0.7418 - val_accuracy: 0.6605\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.6935 - accuracy: 0.7173 - val_loss: 0.7449 - val_accuracy: 0.6698\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.6868 - accuracy: 0.7163 - val_loss: 0.7410 - val_accuracy: 0.6605\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 865us/step - loss: 0.6944 - accuracy: 0.7085 - val_loss: 0.7546 - val_accuracy: 0.6605\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 741us/step - loss: 0.6923 - accuracy: 0.7178 - val_loss: 0.7672 - val_accuracy: 0.6419\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6837 - accuracy: 0.7168 - val_loss: 0.7564 - val_accuracy: 0.6698\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.6850 - accuracy: 0.7147 - val_loss: 0.7478 - val_accuracy: 0.6651\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.6822 - accuracy: 0.7184 - val_loss: 0.7607 - val_accuracy: 0.6465\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.6911 - accuracy: 0.7111 - val_loss: 0.7419 - val_accuracy: 0.6791\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.6799 - accuracy: 0.7178 - val_loss: 0.7380 - val_accuracy: 0.6651\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 998us/step - loss: 0.6811 - accuracy: 0.7168 - val_loss: 0.7449 - val_accuracy: 0.6791\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6789 - accuracy: 0.7152 - val_loss: 0.7396 - val_accuracy: 0.6651\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 744us/step - loss: 0.6797 - accuracy: 0.7194 - val_loss: 0.7403 - val_accuracy: 0.6698\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6798 - accuracy: 0.7225 - val_loss: 0.7340 - val_accuracy: 0.6651\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.6776 - accuracy: 0.7230 - val_loss: 0.7507 - val_accuracy: 0.6512\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.6757 - accuracy: 0.7199 - val_loss: 0.7352 - val_accuracy: 0.6512\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.6758 - accuracy: 0.7194 - val_loss: 0.7407 - val_accuracy: 0.6791\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.6711 - accuracy: 0.7225 - val_loss: 0.7372 - val_accuracy: 0.6512\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 993us/step - loss: 0.6709 - accuracy: 0.7256 - val_loss: 0.7298 - val_accuracy: 0.6837\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 623us/step - loss: 0.6721 - accuracy: 0.7204 - val_loss: 0.7362 - val_accuracy: 0.6558\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.7194 - val_loss: 0.7418 - val_accuracy: 0.6651\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 724us/step - loss: 0.6727 - accuracy: 0.7204 - val_loss: 0.7238 - val_accuracy: 0.6698\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6689 - accuracy: 0.7287 - val_loss: 0.7346 - val_accuracy: 0.6605\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.6677 - accuracy: 0.7204 - val_loss: 0.7308 - val_accuracy: 0.6512\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 605us/step - loss: 0.6664 - accuracy: 0.7251 - val_loss: 0.7376 - val_accuracy: 0.6744\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.7184 - val_loss: 0.7392 - val_accuracy: 0.6884\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.6656 - accuracy: 0.7163 - val_loss: 0.7266 - val_accuracy: 0.6605\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6684 - accuracy: 0.7241 - val_loss: 0.7251 - val_accuracy: 0.6605\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6654 - accuracy: 0.7184 - val_loss: 0.7290 - val_accuracy: 0.6884\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.7256 - val_loss: 0.7327 - val_accuracy: 0.7023\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 735us/step - loss: 0.6653 - accuracy: 0.7199 - val_loss: 0.7253 - val_accuracy: 0.6698\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6590 - accuracy: 0.7287 - val_loss: 0.7235 - val_accuracy: 0.6744\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.6580 - accuracy: 0.7261 - val_loss: 0.7361 - val_accuracy: 0.6698\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6580 - accuracy: 0.7261 - val_loss: 0.7126 - val_accuracy: 0.6837\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.6580 - accuracy: 0.7298 - val_loss: 0.7322 - val_accuracy: 0.6977\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 687us/step - loss: 0.6612 - accuracy: 0.7225 - val_loss: 0.7165 - val_accuracy: 0.6744\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.6555 - accuracy: 0.7256 - val_loss: 0.7233 - val_accuracy: 0.6605\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 645us/step - loss: 0.6561 - accuracy: 0.7235 - val_loss: 0.7188 - val_accuracy: 0.6698\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.6512 - accuracy: 0.7199 - val_loss: 0.7271 - val_accuracy: 0.6698\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.6603 - accuracy: 0.7256 - val_loss: 0.7222 - val_accuracy: 0.6744\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 715us/step - loss: 0.6545 - accuracy: 0.7313 - val_loss: 0.7113 - val_accuracy: 0.6744\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.6530 - accuracy: 0.7261 - val_loss: 0.7254 - val_accuracy: 0.6791\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.6521 - accuracy: 0.7282 - val_loss: 0.7184 - val_accuracy: 0.6837\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.6517 - accuracy: 0.7272 - val_loss: 0.7088 - val_accuracy: 0.6977\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.6494 - accuracy: 0.7329 - val_loss: 0.7122 - val_accuracy: 0.6837\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6495 - accuracy: 0.7282 - val_loss: 0.7055 - val_accuracy: 0.6930\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 737us/step - loss: 0.6489 - accuracy: 0.7308 - val_loss: 0.7110 - val_accuracy: 0.6884\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.6470 - accuracy: 0.7298 - val_loss: 0.7187 - val_accuracy: 0.6698\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.6461 - accuracy: 0.7329 - val_loss: 0.7100 - val_accuracy: 0.6977\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6485 - accuracy: 0.7318 - val_loss: 0.7100 - val_accuracy: 0.6930\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 961us/step - loss: 0.6471 - accuracy: 0.7334 - val_loss: 0.7023 - val_accuracy: 0.6930\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 655us/step - loss: 0.6455 - accuracy: 0.7324 - val_loss: 0.7289 - val_accuracy: 0.6651\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 960us/step - loss: 0.6449 - accuracy: 0.7329 - val_loss: 0.7031 - val_accuracy: 0.6930\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 723us/step - loss: 0.6445 - accuracy: 0.7303 - val_loss: 0.7121 - val_accuracy: 0.6791\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 884us/step - loss: 0.6455 - accuracy: 0.7329 - val_loss: 0.7103 - val_accuracy: 0.6977\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6448 - accuracy: 0.7298 - val_loss: 0.7083 - val_accuracy: 0.6791\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 996us/step - loss: 0.6407 - accuracy: 0.7324 - val_loss: 0.6999 - val_accuracy: 0.6884\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.6406 - accuracy: 0.7287 - val_loss: 0.7000 - val_accuracy: 0.6791\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.7329 - val_loss: 0.7229 - val_accuracy: 0.6698\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.6422 - accuracy: 0.7287 - val_loss: 0.7043 - val_accuracy: 0.6791\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.7376 - val_loss: 0.7050 - val_accuracy: 0.6930\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.6389 - accuracy: 0.7381 - val_loss: 0.6953 - val_accuracy: 0.6977\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.6355 - accuracy: 0.7376 - val_loss: 0.6982 - val_accuracy: 0.6930\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.6384 - accuracy: 0.7324 - val_loss: 0.7139 - val_accuracy: 0.6837\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.6346 - accuracy: 0.7318 - val_loss: 0.6963 - val_accuracy: 0.7116\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6343 - accuracy: 0.7376 - val_loss: 0.7019 - val_accuracy: 0.6791\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.6356 - accuracy: 0.7313 - val_loss: 0.7008 - val_accuracy: 0.6884\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6363 - accuracy: 0.7370 - val_loss: 0.7001 - val_accuracy: 0.6884\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 945us/step - loss: 0.6353 - accuracy: 0.7401 - val_loss: 0.6997 - val_accuracy: 0.6977\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 664us/step - loss: 0.6309 - accuracy: 0.7360 - val_loss: 0.6951 - val_accuracy: 0.6837\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 974us/step - loss: 0.6368 - accuracy: 0.7344 - val_loss: 0.7019 - val_accuracy: 0.6930\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.7313 - val_loss: 0.6985 - val_accuracy: 0.7209\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6289 - accuracy: 0.7422 - val_loss: 0.7061 - val_accuracy: 0.6930\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6308 - accuracy: 0.7355 - val_loss: 0.7049 - val_accuracy: 0.6837\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.6348 - accuracy: 0.7350 - val_loss: 0.7005 - val_accuracy: 0.6698\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.6341 - accuracy: 0.7370 - val_loss: 0.6979 - val_accuracy: 0.6977\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 883us/step - loss: 0.6308 - accuracy: 0.7459 - val_loss: 0.6968 - val_accuracy: 0.6744\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.6293 - accuracy: 0.7350 - val_loss: 0.7004 - val_accuracy: 0.7070\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6331 - accuracy: 0.7381 - val_loss: 0.6933 - val_accuracy: 0.7070\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6282 - accuracy: 0.7355 - val_loss: 0.6899 - val_accuracy: 0.7070\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6240 - accuracy: 0.7391 - val_loss: 0.6880 - val_accuracy: 0.6977\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.6275 - accuracy: 0.7339 - val_loss: 0.6897 - val_accuracy: 0.6791\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 761us/step - loss: 0.6279 - accuracy: 0.7412 - val_loss: 0.6940 - val_accuracy: 0.6884\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.6260 - accuracy: 0.7422 - val_loss: 0.6929 - val_accuracy: 0.6884\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.6262 - accuracy: 0.7396 - val_loss: 0.6930 - val_accuracy: 0.6744\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6223 - accuracy: 0.7417 - val_loss: 0.6953 - val_accuracy: 0.6837\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6244 - accuracy: 0.7433 - val_loss: 0.6999 - val_accuracy: 0.6791\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6255 - accuracy: 0.7365 - val_loss: 0.6920 - val_accuracy: 0.6930\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6209 - accuracy: 0.7459 - val_loss: 0.6880 - val_accuracy: 0.7023\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6199 - accuracy: 0.7459 - val_loss: 0.7044 - val_accuracy: 0.6930\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6211 - accuracy: 0.7474 - val_loss: 0.6916 - val_accuracy: 0.6977\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.6173 - accuracy: 0.7427 - val_loss: 0.6934 - val_accuracy: 0.6791\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.7484 - val_loss: 0.6859 - val_accuracy: 0.6977\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 717us/step - loss: 0.6206 - accuracy: 0.7438 - val_loss: 0.6980 - val_accuracy: 0.6837\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.6203 - accuracy: 0.7433 - val_loss: 0.7023 - val_accuracy: 0.7023\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.6189 - accuracy: 0.7427 - val_loss: 0.7138 - val_accuracy: 0.6744\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6186 - accuracy: 0.7500 - val_loss: 0.6787 - val_accuracy: 0.7023\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6187 - accuracy: 0.7453 - val_loss: 0.6943 - val_accuracy: 0.6837\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.6174 - accuracy: 0.7391 - val_loss: 0.6851 - val_accuracy: 0.6930\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6163 - accuracy: 0.7459 - val_loss: 0.6989 - val_accuracy: 0.6884\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6191 - accuracy: 0.7448 - val_loss: 0.6886 - val_accuracy: 0.7163\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6154 - accuracy: 0.7433 - val_loss: 0.6930 - val_accuracy: 0.6977\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6138 - accuracy: 0.7459 - val_loss: 0.6973 - val_accuracy: 0.6930\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.6147 - accuracy: 0.7443 - val_loss: 0.6859 - val_accuracy: 0.6930\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.6187 - accuracy: 0.7438 - val_loss: 0.7093 - val_accuracy: 0.7116\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6137 - accuracy: 0.7469 - val_loss: 0.6915 - val_accuracy: 0.7070\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.6109 - accuracy: 0.7484 - val_loss: 0.6803 - val_accuracy: 0.6977\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 855us/step - loss: 0.6136 - accuracy: 0.7490 - val_loss: 0.6876 - val_accuracy: 0.7163\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 731us/step - loss: 0.6130 - accuracy: 0.7474 - val_loss: 0.6962 - val_accuracy: 0.7209\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 758us/step - loss: 0.6183 - accuracy: 0.7438 - val_loss: 0.6905 - val_accuracy: 0.6837\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 971us/step - loss: 0.6108 - accuracy: 0.7484 - val_loss: 0.6901 - val_accuracy: 0.7070\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6090 - accuracy: 0.7469 - val_loss: 0.6934 - val_accuracy: 0.6884\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 748us/step - loss: 0.6083 - accuracy: 0.7516 - val_loss: 0.6843 - val_accuracy: 0.6977\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 893us/step - loss: 0.6097 - accuracy: 0.7422 - val_loss: 0.6978 - val_accuracy: 0.7209\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6104 - accuracy: 0.7427 - val_loss: 0.6888 - val_accuracy: 0.7023\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6101 - accuracy: 0.7479 - val_loss: 0.6965 - val_accuracy: 0.6930\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6044 - accuracy: 0.7500 - val_loss: 0.6981 - val_accuracy: 0.6977\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6141 - accuracy: 0.7453 - val_loss: 0.7157 - val_accuracy: 0.7209\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 747us/step - loss: 0.6080 - accuracy: 0.7453 - val_loss: 0.7057 - val_accuracy: 0.6837\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.6094 - accuracy: 0.7459 - val_loss: 0.6973 - val_accuracy: 0.6977\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.6064 - accuracy: 0.7495 - val_loss: 0.6957 - val_accuracy: 0.6930\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6071 - accuracy: 0.7495 - val_loss: 0.6917 - val_accuracy: 0.7302\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6078 - accuracy: 0.7433 - val_loss: 0.6961 - val_accuracy: 0.6837\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.6037 - accuracy: 0.7495 - val_loss: 0.6895 - val_accuracy: 0.6837\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6049 - accuracy: 0.7464 - val_loss: 0.6928 - val_accuracy: 0.7209\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.6024 - accuracy: 0.7510 - val_loss: 0.6876 - val_accuracy: 0.7163\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.6033 - accuracy: 0.7479 - val_loss: 0.6762 - val_accuracy: 0.7023\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.6141 - accuracy: 0.7469 - val_loss: 0.6895 - val_accuracy: 0.6791\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6022 - accuracy: 0.7536 - val_loss: 0.6878 - val_accuracy: 0.6977\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 868us/step - loss: 0.6000 - accuracy: 0.7536 - val_loss: 0.6836 - val_accuracy: 0.7256\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.6055 - accuracy: 0.7500 - val_loss: 0.7032 - val_accuracy: 0.6884\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 850us/step - loss: 0.6052 - accuracy: 0.7391 - val_loss: 0.6989 - val_accuracy: 0.6977\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5995 - accuracy: 0.7547 - val_loss: 0.7098 - val_accuracy: 0.6791\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.6020 - accuracy: 0.7484 - val_loss: 0.6930 - val_accuracy: 0.6930\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5988 - accuracy: 0.7484 - val_loss: 0.6979 - val_accuracy: 0.6698\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5981 - accuracy: 0.7573 - val_loss: 0.6809 - val_accuracy: 0.6884\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5992 - accuracy: 0.7490 - val_loss: 0.7034 - val_accuracy: 0.7070\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5985 - accuracy: 0.7541 - val_loss: 0.6913 - val_accuracy: 0.7116\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5964 - accuracy: 0.7521 - val_loss: 0.6818 - val_accuracy: 0.7163\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 755us/step - loss: 0.5965 - accuracy: 0.7490 - val_loss: 0.6822 - val_accuracy: 0.7163\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.5947 - accuracy: 0.7604 - val_loss: 0.6845 - val_accuracy: 0.7163\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.5952 - accuracy: 0.7500 - val_loss: 0.6942 - val_accuracy: 0.7023\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.5959 - accuracy: 0.7583 - val_loss: 0.6884 - val_accuracy: 0.7023\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.5974 - accuracy: 0.7495 - val_loss: 0.6834 - val_accuracy: 0.7116\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.5951 - accuracy: 0.7500 - val_loss: 0.6769 - val_accuracy: 0.7116\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5938 - accuracy: 0.7500 - val_loss: 0.6857 - val_accuracy: 0.6930\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.5981 - accuracy: 0.7469 - val_loss: 0.6924 - val_accuracy: 0.6977\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5918 - accuracy: 0.7521 - val_loss: 0.6873 - val_accuracy: 0.7023\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.5926 - accuracy: 0.7567 - val_loss: 0.6854 - val_accuracy: 0.6977\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5885 - accuracy: 0.7567 - val_loss: 0.6824 - val_accuracy: 0.7023\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.5907 - accuracy: 0.7495 - val_loss: 0.7159 - val_accuracy: 0.6884\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.5943 - accuracy: 0.7510 - val_loss: 0.6864 - val_accuracy: 0.7070\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.5885 - accuracy: 0.7557 - val_loss: 0.6867 - val_accuracy: 0.7070\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 768us/step - loss: 0.5890 - accuracy: 0.7573 - val_loss: 0.6920 - val_accuracy: 0.6977\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.5916 - accuracy: 0.7521 - val_loss: 0.6764 - val_accuracy: 0.7116\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.5886 - accuracy: 0.7516 - val_loss: 0.6793 - val_accuracy: 0.7256\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 887us/step - loss: 0.5870 - accuracy: 0.7567 - val_loss: 0.6902 - val_accuracy: 0.6930\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5854 - accuracy: 0.7557 - val_loss: 0.6936 - val_accuracy: 0.7209\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 771us/step - loss: 0.5876 - accuracy: 0.7583 - val_loss: 0.6823 - val_accuracy: 0.6977\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.5881 - accuracy: 0.7599 - val_loss: 0.6786 - val_accuracy: 0.7256\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.5886 - accuracy: 0.7484 - val_loss: 0.6934 - val_accuracy: 0.6977\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.5874 - accuracy: 0.7521 - val_loss: 0.6897 - val_accuracy: 0.7256\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 773us/step - loss: 0.5903 - accuracy: 0.7583 - val_loss: 0.6933 - val_accuracy: 0.7209\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.5880 - accuracy: 0.7573 - val_loss: 0.6949 - val_accuracy: 0.6977\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.5832 - accuracy: 0.7541 - val_loss: 0.6822 - val_accuracy: 0.7116\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.5815 - accuracy: 0.7567 - val_loss: 0.6792 - val_accuracy: 0.7070\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.7552 - val_loss: 0.6849 - val_accuracy: 0.7023\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.5854 - accuracy: 0.7583 - val_loss: 0.6930 - val_accuracy: 0.7256\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.7500 - val_loss: 0.6801 - val_accuracy: 0.7116\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5838 - accuracy: 0.7510 - val_loss: 0.6794 - val_accuracy: 0.7116\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5819 - accuracy: 0.7536 - val_loss: 0.6817 - val_accuracy: 0.7163\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.5815 - accuracy: 0.7536 - val_loss: 0.6860 - val_accuracy: 0.7163\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.7573 - val_loss: 0.6815 - val_accuracy: 0.7116\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5792 - accuracy: 0.7583 - val_loss: 0.6834 - val_accuracy: 0.7070\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5793 - accuracy: 0.7562 - val_loss: 0.6907 - val_accuracy: 0.7023\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.5798 - accuracy: 0.7557 - val_loss: 0.6895 - val_accuracy: 0.7163\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.5802 - accuracy: 0.7635 - val_loss: 0.6866 - val_accuracy: 0.7116\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.5769 - accuracy: 0.7593 - val_loss: 0.7005 - val_accuracy: 0.7023\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5774 - accuracy: 0.7583 - val_loss: 0.6821 - val_accuracy: 0.6837\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 653us/step - loss: 0.5782 - accuracy: 0.7547 - val_loss: 0.7014 - val_accuracy: 0.7116\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5778 - accuracy: 0.7588 - val_loss: 0.6818 - val_accuracy: 0.6837\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5770 - accuracy: 0.7526 - val_loss: 0.6949 - val_accuracy: 0.7302\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5768 - accuracy: 0.7562 - val_loss: 0.6943 - val_accuracy: 0.7209\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.5771 - accuracy: 0.7573 - val_loss: 0.6977 - val_accuracy: 0.6930\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 728us/step - loss: 0.5766 - accuracy: 0.7666 - val_loss: 0.6766 - val_accuracy: 0.7302\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.5789 - accuracy: 0.7599 - val_loss: 0.6743 - val_accuracy: 0.7163\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5744 - accuracy: 0.7604 - val_loss: 0.6788 - val_accuracy: 0.7256\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 782us/step - loss: 0.5749 - accuracy: 0.7630 - val_loss: 0.6874 - val_accuracy: 0.7163\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5730 - accuracy: 0.7604 - val_loss: 0.6904 - val_accuracy: 0.7209\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 961us/step - loss: 0.5771 - accuracy: 0.7609 - val_loss: 0.6805 - val_accuracy: 0.7116\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5732 - accuracy: 0.7593 - val_loss: 0.6967 - val_accuracy: 0.7116\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 778us/step - loss: 0.5767 - accuracy: 0.7599 - val_loss: 0.6887 - val_accuracy: 0.7116\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5731 - accuracy: 0.7593 - val_loss: 0.6929 - val_accuracy: 0.7116\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.5726 - accuracy: 0.7630 - val_loss: 0.6820 - val_accuracy: 0.6977\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.5727 - accuracy: 0.7588 - val_loss: 0.6805 - val_accuracy: 0.7256\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7578 - val_loss: 0.6828 - val_accuracy: 0.7163\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.5727 - accuracy: 0.7604 - val_loss: 0.6846 - val_accuracy: 0.7023\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5684 - accuracy: 0.7640 - val_loss: 0.6776 - val_accuracy: 0.7256\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5714 - accuracy: 0.7604 - val_loss: 0.6749 - val_accuracy: 0.7302\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.5709 - accuracy: 0.7588 - val_loss: 0.6694 - val_accuracy: 0.7302\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5681 - accuracy: 0.7578 - val_loss: 0.6799 - val_accuracy: 0.7163\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.5702 - accuracy: 0.7578 - val_loss: 0.6767 - val_accuracy: 0.7302\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 711us/step - loss: 0.5678 - accuracy: 0.7599 - val_loss: 0.6917 - val_accuracy: 0.6884\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.5694 - accuracy: 0.7604 - val_loss: 0.7113 - val_accuracy: 0.6977\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 774us/step - loss: 0.5696 - accuracy: 0.7573 - val_loss: 0.7007 - val_accuracy: 0.6977\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 869us/step - loss: 0.5656 - accuracy: 0.7682 - val_loss: 0.6747 - val_accuracy: 0.7256\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 693us/step - loss: 0.5663 - accuracy: 0.7650 - val_loss: 0.6837 - val_accuracy: 0.7256\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5646 - accuracy: 0.7609 - val_loss: 0.6782 - val_accuracy: 0.7256\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.5644 - accuracy: 0.7635 - val_loss: 0.7032 - val_accuracy: 0.6977\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.5641 - accuracy: 0.7599 - val_loss: 0.6818 - val_accuracy: 0.7163\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 679us/step - loss: 0.5635 - accuracy: 0.7624 - val_loss: 0.6928 - val_accuracy: 0.7302\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.5654 - accuracy: 0.7635 - val_loss: 0.6761 - val_accuracy: 0.7256\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 664us/step - loss: 0.5641 - accuracy: 0.7635 - val_loss: 0.6775 - val_accuracy: 0.7302\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.5651 - accuracy: 0.7624 - val_loss: 0.6764 - val_accuracy: 0.7302\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 670us/step - loss: 0.5647 - accuracy: 0.7619 - val_loss: 0.6883 - val_accuracy: 0.6977\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 964us/step - loss: 0.5600 - accuracy: 0.7692 - val_loss: 0.6708 - val_accuracy: 0.7302\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 692us/step - loss: 0.5636 - accuracy: 0.7599 - val_loss: 0.6787 - val_accuracy: 0.7070\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5657 - accuracy: 0.7619 - val_loss: 0.6749 - val_accuracy: 0.7302\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5624 - accuracy: 0.7661 - val_loss: 0.6893 - val_accuracy: 0.6884\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.7578 - val_loss: 0.6679 - val_accuracy: 0.7395\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5654 - accuracy: 0.7650 - val_loss: 0.6947 - val_accuracy: 0.7302\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5639 - accuracy: 0.7645 - val_loss: 0.6975 - val_accuracy: 0.7070\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.5588 - accuracy: 0.7702 - val_loss: 0.6880 - val_accuracy: 0.7209\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5622 - accuracy: 0.7619 - val_loss: 0.6775 - val_accuracy: 0.7163\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 949us/step - loss: 0.5659 - accuracy: 0.7604 - val_loss: 0.6855 - val_accuracy: 0.7256\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.5590 - accuracy: 0.7666 - val_loss: 0.6768 - val_accuracy: 0.7256\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 856us/step - loss: 0.5607 - accuracy: 0.7609 - val_loss: 0.6831 - val_accuracy: 0.7163\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5617 - accuracy: 0.7656 - val_loss: 0.6790 - val_accuracy: 0.7116\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 744us/step - loss: 0.5598 - accuracy: 0.7635 - val_loss: 0.6702 - val_accuracy: 0.7349\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 876us/step - loss: 0.5650 - accuracy: 0.7578 - val_loss: 0.6899 - val_accuracy: 0.6930\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5611 - accuracy: 0.7676 - val_loss: 0.6883 - val_accuracy: 0.7116\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.5563 - accuracy: 0.7656 - val_loss: 0.6683 - val_accuracy: 0.7395\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.7635 - val_loss: 0.6821 - val_accuracy: 0.7070\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.5560 - accuracy: 0.7682 - val_loss: 0.6818 - val_accuracy: 0.7163\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7687 - val_loss: 0.6812 - val_accuracy: 0.7209\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 659us/step - loss: 0.5610 - accuracy: 0.7624 - val_loss: 0.6728 - val_accuracy: 0.7070\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.5584 - accuracy: 0.7573 - val_loss: 0.6862 - val_accuracy: 0.7070\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5590 - accuracy: 0.7687 - val_loss: 0.6915 - val_accuracy: 0.7302\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.5561 - accuracy: 0.7640 - val_loss: 0.6796 - val_accuracy: 0.7209\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5549 - accuracy: 0.7671 - val_loss: 0.6702 - val_accuracy: 0.7349\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5589 - accuracy: 0.7588 - val_loss: 0.6798 - val_accuracy: 0.7163\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 687us/step - loss: 0.5539 - accuracy: 0.7676 - val_loss: 0.6780 - val_accuracy: 0.7116\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.5537 - accuracy: 0.7671 - val_loss: 0.6842 - val_accuracy: 0.6884\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.5545 - accuracy: 0.7718 - val_loss: 0.6816 - val_accuracy: 0.7116\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7645 - val_loss: 0.6867 - val_accuracy: 0.7116\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 656us/step - loss: 0.5549 - accuracy: 0.7682 - val_loss: 0.6801 - val_accuracy: 0.7163\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.5535 - accuracy: 0.7702 - val_loss: 0.7014 - val_accuracy: 0.6930\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5545 - accuracy: 0.7687 - val_loss: 0.6726 - val_accuracy: 0.7256\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 717us/step - loss: 0.5521 - accuracy: 0.7650 - val_loss: 0.6776 - val_accuracy: 0.7209\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.5531 - accuracy: 0.7676 - val_loss: 0.6837 - val_accuracy: 0.7116\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 747us/step - loss: 0.5547 - accuracy: 0.7733 - val_loss: 0.6740 - val_accuracy: 0.7116\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 960us/step - loss: 0.5551 - accuracy: 0.7671 - val_loss: 0.6930 - val_accuracy: 0.7023\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5519 - accuracy: 0.7697 - val_loss: 0.6928 - val_accuracy: 0.7023\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 716us/step - loss: 0.5523 - accuracy: 0.7692 - val_loss: 0.6775 - val_accuracy: 0.7349\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5526 - accuracy: 0.7702 - val_loss: 0.6949 - val_accuracy: 0.7256\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7661 - val_loss: 0.6807 - val_accuracy: 0.7256\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5537 - accuracy: 0.7645 - val_loss: 0.6969 - val_accuracy: 0.7256\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - 0s 752us/step - loss: 0.5501 - accuracy: 0.7707 - val_loss: 0.6822 - val_accuracy: 0.7163\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.5564 - accuracy: 0.7676 - val_loss: 0.6687 - val_accuracy: 0.7209\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5541 - accuracy: 0.7650 - val_loss: 0.6677 - val_accuracy: 0.7256\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5546 - accuracy: 0.7661 - val_loss: 0.6749 - val_accuracy: 0.7256\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.5557 - accuracy: 0.7645 - val_loss: 0.6680 - val_accuracy: 0.7302\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - 0s 702us/step - loss: 0.5490 - accuracy: 0.7661 - val_loss: 0.6778 - val_accuracy: 0.7302\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.5472 - accuracy: 0.7645 - val_loss: 0.6753 - val_accuracy: 0.7209\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7676 - val_loss: 0.6810 - val_accuracy: 0.7349\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5520 - accuracy: 0.7619 - val_loss: 0.6765 - val_accuracy: 0.7163\n",
      "Epoch 369/500\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.5497 - accuracy: 0.7614 - val_loss: 0.6787 - val_accuracy: 0.7163\n",
      "Epoch 370/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7713 - val_loss: 0.6723 - val_accuracy: 0.7256\n",
      "Epoch 371/500\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.5537 - accuracy: 0.7718 - val_loss: 0.6851 - val_accuracy: 0.7209\n",
      "Epoch 372/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7697 - val_loss: 0.6939 - val_accuracy: 0.6977\n",
      "Epoch 373/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5491 - accuracy: 0.7614 - val_loss: 0.6751 - val_accuracy: 0.7256\n",
      "Epoch 374/500\n",
      "72/72 [==============================] - 0s 742us/step - loss: 0.5480 - accuracy: 0.7661 - val_loss: 0.6676 - val_accuracy: 0.7349\n",
      "Epoch 375/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.5501 - accuracy: 0.7676 - val_loss: 0.6844 - val_accuracy: 0.7349\n",
      "Epoch 376/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.5491 - accuracy: 0.7739 - val_loss: 0.7080 - val_accuracy: 0.7209\n",
      "Epoch 377/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.5473 - accuracy: 0.7702 - val_loss: 0.6887 - val_accuracy: 0.7116\n",
      "Epoch 378/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.5485 - accuracy: 0.7650 - val_loss: 0.6781 - val_accuracy: 0.7163\n",
      "Epoch 379/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.5498 - accuracy: 0.7593 - val_loss: 0.6822 - val_accuracy: 0.7256\n",
      "Epoch 380/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5453 - accuracy: 0.7713 - val_loss: 0.6747 - val_accuracy: 0.7209\n",
      "Epoch 381/500\n",
      "72/72 [==============================] - 0s 929us/step - loss: 0.5472 - accuracy: 0.7713 - val_loss: 0.6837 - val_accuracy: 0.6977\n",
      "Epoch 382/500\n",
      "72/72 [==============================] - 0s 677us/step - loss: 0.5452 - accuracy: 0.7671 - val_loss: 0.6728 - val_accuracy: 0.7302\n",
      "Epoch 383/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.7671 - val_loss: 0.6770 - val_accuracy: 0.7535\n",
      "Epoch 384/500\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.5461 - accuracy: 0.7645 - val_loss: 0.6748 - val_accuracy: 0.7395\n",
      "Epoch 385/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5496 - accuracy: 0.7692 - val_loss: 0.6750 - val_accuracy: 0.7256\n",
      "Epoch 386/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5455 - accuracy: 0.7676 - val_loss: 0.6746 - val_accuracy: 0.7349\n",
      "Epoch 387/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5488 - accuracy: 0.7666 - val_loss: 0.6761 - val_accuracy: 0.7070\n",
      "Epoch 388/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5447 - accuracy: 0.7687 - val_loss: 0.7021 - val_accuracy: 0.6930\n",
      "Epoch 389/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5454 - accuracy: 0.7697 - val_loss: 0.6815 - val_accuracy: 0.7349\n",
      "Epoch 390/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5464 - accuracy: 0.7656 - val_loss: 0.6663 - val_accuracy: 0.7302\n",
      "Epoch 391/500\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.5421 - accuracy: 0.7749 - val_loss: 0.6671 - val_accuracy: 0.7302\n",
      "Epoch 392/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5436 - accuracy: 0.7682 - val_loss: 0.6744 - val_accuracy: 0.7349\n",
      "Epoch 393/500\n",
      "72/72 [==============================] - 0s 970us/step - loss: 0.5449 - accuracy: 0.7744 - val_loss: 0.6873 - val_accuracy: 0.6837\n",
      "Epoch 394/500\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.5451 - accuracy: 0.7624 - val_loss: 0.6864 - val_accuracy: 0.7256\n",
      "Epoch 395/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.5463 - accuracy: 0.7718 - val_loss: 0.6724 - val_accuracy: 0.7070\n",
      "Epoch 396/500\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.5446 - accuracy: 0.7723 - val_loss: 0.6772 - val_accuracy: 0.7163\n",
      "Epoch 397/500\n",
      "72/72 [==============================] - 0s 990us/step - loss: 0.5413 - accuracy: 0.7692 - val_loss: 0.6635 - val_accuracy: 0.7302\n",
      "Epoch 398/500\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.5430 - accuracy: 0.7707 - val_loss: 0.6739 - val_accuracy: 0.7163\n",
      "Epoch 399/500\n",
      "72/72 [==============================] - 0s 989us/step - loss: 0.5437 - accuracy: 0.7713 - val_loss: 0.6804 - val_accuracy: 0.7116\n",
      "Epoch 400/500\n",
      "72/72 [==============================] - 0s 628us/step - loss: 0.5420 - accuracy: 0.7650 - val_loss: 0.6731 - val_accuracy: 0.7209\n",
      "Epoch 401/500\n",
      "72/72 [==============================] - 0s 982us/step - loss: 0.5456 - accuracy: 0.7718 - val_loss: 0.6706 - val_accuracy: 0.7209\n",
      "Epoch 402/500\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.5421 - accuracy: 0.7635 - val_loss: 0.6723 - val_accuracy: 0.7163\n",
      "Epoch 403/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5415 - accuracy: 0.7697 - val_loss: 0.6725 - val_accuracy: 0.7256\n",
      "Epoch 404/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.5473 - accuracy: 0.7692 - val_loss: 0.6616 - val_accuracy: 0.7256\n",
      "Epoch 405/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.5410 - accuracy: 0.7718 - val_loss: 0.6864 - val_accuracy: 0.7349\n",
      "Epoch 406/500\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.5418 - accuracy: 0.7661 - val_loss: 0.6989 - val_accuracy: 0.6977\n",
      "Epoch 407/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.5422 - accuracy: 0.7682 - val_loss: 0.6638 - val_accuracy: 0.7302\n",
      "Epoch 408/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.5448 - accuracy: 0.7676 - val_loss: 0.6741 - val_accuracy: 0.7302\n",
      "Epoch 409/500\n",
      "72/72 [==============================] - 0s 970us/step - loss: 0.5399 - accuracy: 0.7676 - val_loss: 0.6718 - val_accuracy: 0.7209\n",
      "Epoch 410/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5419 - accuracy: 0.7718 - val_loss: 0.6600 - val_accuracy: 0.7395\n",
      "Epoch 411/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5420 - accuracy: 0.7682 - val_loss: 0.6700 - val_accuracy: 0.7163\n",
      "Epoch 412/500\n",
      "72/72 [==============================] - 0s 697us/step - loss: 0.5391 - accuracy: 0.7733 - val_loss: 0.6982 - val_accuracy: 0.7163\n",
      "Epoch 413/500\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.5396 - accuracy: 0.7749 - val_loss: 0.6715 - val_accuracy: 0.7302\n",
      "Epoch 414/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.5420 - accuracy: 0.7790 - val_loss: 0.6696 - val_accuracy: 0.7209\n",
      "Epoch 415/500\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.5390 - accuracy: 0.7687 - val_loss: 0.6652 - val_accuracy: 0.7209\n",
      "Epoch 416/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5384 - accuracy: 0.7713 - val_loss: 0.6753 - val_accuracy: 0.7070\n",
      "Epoch 417/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5384 - accuracy: 0.7702 - val_loss: 0.6603 - val_accuracy: 0.7163\n",
      "Epoch 418/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5413 - accuracy: 0.7692 - val_loss: 0.6802 - val_accuracy: 0.7302\n",
      "Epoch 419/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5382 - accuracy: 0.7713 - val_loss: 0.6844 - val_accuracy: 0.7116\n",
      "Epoch 420/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5384 - accuracy: 0.7770 - val_loss: 0.6755 - val_accuracy: 0.7116\n",
      "Epoch 421/500\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.5398 - accuracy: 0.7718 - val_loss: 0.6772 - val_accuracy: 0.7395\n",
      "Epoch 422/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5396 - accuracy: 0.7728 - val_loss: 0.6802 - val_accuracy: 0.7116\n",
      "Epoch 423/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5422 - accuracy: 0.7702 - val_loss: 0.6804 - val_accuracy: 0.7488\n",
      "Epoch 424/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5366 - accuracy: 0.7723 - val_loss: 0.6647 - val_accuracy: 0.7256\n",
      "Epoch 425/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5358 - accuracy: 0.7775 - val_loss: 0.6783 - val_accuracy: 0.7302\n",
      "Epoch 426/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5355 - accuracy: 0.7733 - val_loss: 0.6723 - val_accuracy: 0.7023\n",
      "Epoch 427/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5386 - accuracy: 0.7749 - val_loss: 0.6796 - val_accuracy: 0.7023\n",
      "Epoch 428/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5358 - accuracy: 0.7713 - val_loss: 0.6873 - val_accuracy: 0.6977\n",
      "Epoch 429/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5344 - accuracy: 0.7744 - val_loss: 0.6870 - val_accuracy: 0.7163\n",
      "Epoch 430/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5404 - accuracy: 0.7718 - val_loss: 0.6698 - val_accuracy: 0.7023\n",
      "Epoch 431/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5368 - accuracy: 0.7770 - val_loss: 0.6658 - val_accuracy: 0.7256\n",
      "Epoch 432/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5389 - accuracy: 0.7759 - val_loss: 0.6919 - val_accuracy: 0.7163\n",
      "Epoch 433/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5364 - accuracy: 0.7739 - val_loss: 0.6711 - val_accuracy: 0.7163\n",
      "Epoch 434/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5394 - accuracy: 0.7718 - val_loss: 0.6744 - val_accuracy: 0.7070\n",
      "Epoch 435/500\n",
      "72/72 [==============================] - 0s 710us/step - loss: 0.5343 - accuracy: 0.7702 - val_loss: 0.6655 - val_accuracy: 0.7163\n",
      "Epoch 436/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.5405 - accuracy: 0.7749 - val_loss: 0.6720 - val_accuracy: 0.7116\n",
      "Epoch 437/500\n",
      "72/72 [==============================] - 0s 663us/step - loss: 0.5365 - accuracy: 0.7697 - val_loss: 0.6634 - val_accuracy: 0.7349\n",
      "Epoch 438/500\n",
      "72/72 [==============================] - 0s 968us/step - loss: 0.5370 - accuracy: 0.7744 - val_loss: 0.6710 - val_accuracy: 0.7209\n",
      "Epoch 439/500\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.5354 - accuracy: 0.7759 - val_loss: 0.6953 - val_accuracy: 0.7070\n",
      "Epoch 440/500\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.5370 - accuracy: 0.7770 - val_loss: 0.6668 - val_accuracy: 0.7070\n",
      "Epoch 441/500\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.5321 - accuracy: 0.7707 - val_loss: 0.6680 - val_accuracy: 0.7395\n",
      "Epoch 442/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5351 - accuracy: 0.7744 - val_loss: 0.6650 - val_accuracy: 0.7209\n",
      "Epoch 443/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.5318 - accuracy: 0.7785 - val_loss: 0.6909 - val_accuracy: 0.7349\n",
      "Epoch 444/500\n",
      "72/72 [==============================] - 0s 960us/step - loss: 0.5346 - accuracy: 0.7749 - val_loss: 0.6655 - val_accuracy: 0.7256\n",
      "Epoch 445/500\n",
      "72/72 [==============================] - 0s 684us/step - loss: 0.5342 - accuracy: 0.7759 - val_loss: 0.6825 - val_accuracy: 0.7023\n",
      "Epoch 446/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5370 - accuracy: 0.7723 - val_loss: 0.6718 - val_accuracy: 0.7349\n",
      "Epoch 447/500\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.5367 - accuracy: 0.7739 - val_loss: 0.6613 - val_accuracy: 0.7256\n",
      "Epoch 448/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7739 - val_loss: 0.6681 - val_accuracy: 0.7209\n",
      "Epoch 449/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5346 - accuracy: 0.7765 - val_loss: 0.6715 - val_accuracy: 0.7163\n",
      "Epoch 450/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.5327 - accuracy: 0.7780 - val_loss: 0.6683 - val_accuracy: 0.7302\n",
      "Epoch 451/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.5309 - accuracy: 0.7744 - val_loss: 0.6611 - val_accuracy: 0.7302\n",
      "Epoch 452/500\n",
      "72/72 [==============================] - 0s 947us/step - loss: 0.5288 - accuracy: 0.7723 - val_loss: 0.6587 - val_accuracy: 0.7256\n",
      "Epoch 453/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5330 - accuracy: 0.7723 - val_loss: 0.6802 - val_accuracy: 0.7023\n",
      "Epoch 454/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.5323 - accuracy: 0.7806 - val_loss: 0.6596 - val_accuracy: 0.7209\n",
      "Epoch 455/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.5325 - accuracy: 0.7692 - val_loss: 0.6660 - val_accuracy: 0.7209\n",
      "Epoch 456/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5293 - accuracy: 0.7785 - val_loss: 0.6826 - val_accuracy: 0.7349\n",
      "Epoch 457/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5317 - accuracy: 0.7759 - val_loss: 0.6596 - val_accuracy: 0.7302\n",
      "Epoch 458/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.5315 - accuracy: 0.7707 - val_loss: 0.6598 - val_accuracy: 0.7442\n",
      "Epoch 459/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5314 - accuracy: 0.7702 - val_loss: 0.6621 - val_accuracy: 0.7395\n",
      "Epoch 460/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5326 - accuracy: 0.7775 - val_loss: 0.6549 - val_accuracy: 0.7302\n",
      "Epoch 461/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.5299 - accuracy: 0.7780 - val_loss: 0.6700 - val_accuracy: 0.7209\n",
      "Epoch 462/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5332 - accuracy: 0.7775 - val_loss: 0.6653 - val_accuracy: 0.7163\n",
      "Epoch 463/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5333 - accuracy: 0.7697 - val_loss: 0.6587 - val_accuracy: 0.7302\n",
      "Epoch 464/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5324 - accuracy: 0.7775 - val_loss: 0.6711 - val_accuracy: 0.7209\n",
      "Epoch 465/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5324 - accuracy: 0.7733 - val_loss: 0.6664 - val_accuracy: 0.7256\n",
      "Epoch 466/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5311 - accuracy: 0.7754 - val_loss: 0.6673 - val_accuracy: 0.7256\n",
      "Epoch 467/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5313 - accuracy: 0.7728 - val_loss: 0.6787 - val_accuracy: 0.7070\n",
      "Epoch 468/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.5293 - accuracy: 0.7775 - val_loss: 0.6657 - val_accuracy: 0.7395\n",
      "Epoch 469/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.5310 - accuracy: 0.7759 - val_loss: 0.6728 - val_accuracy: 0.7535\n",
      "Epoch 470/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7775 - val_loss: 0.6790 - val_accuracy: 0.7163\n",
      "Epoch 471/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5282 - accuracy: 0.7816 - val_loss: 0.6616 - val_accuracy: 0.7209\n",
      "Epoch 472/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5253 - accuracy: 0.7832 - val_loss: 0.6677 - val_accuracy: 0.7302\n",
      "Epoch 473/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5362 - accuracy: 0.7728 - val_loss: 0.6636 - val_accuracy: 0.7256\n",
      "Epoch 474/500\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.5312 - accuracy: 0.7687 - val_loss: 0.6637 - val_accuracy: 0.7349\n",
      "Epoch 475/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5277 - accuracy: 0.7723 - val_loss: 0.6666 - val_accuracy: 0.7209\n",
      "Epoch 476/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5278 - accuracy: 0.7780 - val_loss: 0.6628 - val_accuracy: 0.7256\n",
      "Epoch 477/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5288 - accuracy: 0.7801 - val_loss: 0.6573 - val_accuracy: 0.7442\n",
      "Epoch 478/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5281 - accuracy: 0.7728 - val_loss: 0.6612 - val_accuracy: 0.7209\n",
      "Epoch 479/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5265 - accuracy: 0.7806 - val_loss: 0.6639 - val_accuracy: 0.7302\n",
      "Epoch 480/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5311 - accuracy: 0.7744 - val_loss: 0.6758 - val_accuracy: 0.7209\n",
      "Epoch 481/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5289 - accuracy: 0.7765 - val_loss: 0.6664 - val_accuracy: 0.7256\n",
      "Epoch 482/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5280 - accuracy: 0.7707 - val_loss: 0.6561 - val_accuracy: 0.7535\n",
      "Epoch 483/500\n",
      "72/72 [==============================] - 0s 589us/step - loss: 0.5284 - accuracy: 0.7822 - val_loss: 0.6707 - val_accuracy: 0.7302\n",
      "Epoch 483: early stopping\n",
      "29/29 - 0s - loss: 0.5309 - accuracy: 0.7746 - 109ms/epoch - 4ms/step\n",
      "4\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 1s 6ms/step - loss: 1.5427 - accuracy: 0.3408 - val_loss: 1.4369 - val_accuracy: 0.4093\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.3636 - accuracy: 0.4404 - val_loss: 1.2786 - val_accuracy: 0.4465\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2654 - accuracy: 0.4492 - val_loss: 1.2297 - val_accuracy: 0.4744\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2276 - accuracy: 0.4616 - val_loss: 1.2005 - val_accuracy: 0.4884\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 1.2025 - accuracy: 0.4647 - val_loss: 1.1745 - val_accuracy: 0.4884\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1836 - accuracy: 0.4834 - val_loss: 1.1643 - val_accuracy: 0.4930\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1634 - accuracy: 0.4984 - val_loss: 1.1487 - val_accuracy: 0.5116\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1403 - accuracy: 0.5140 - val_loss: 1.1226 - val_accuracy: 0.5256\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1137 - accuracy: 0.5259 - val_loss: 1.0844 - val_accuracy: 0.5395\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0854 - accuracy: 0.5482 - val_loss: 1.0637 - val_accuracy: 0.5581\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 740us/step - loss: 1.0545 - accuracy: 0.5607 - val_loss: 1.0627 - val_accuracy: 0.5256\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0265 - accuracy: 0.5674 - val_loss: 1.0204 - val_accuracy: 0.5814\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 697us/step - loss: 1.0014 - accuracy: 0.5877 - val_loss: 0.9980 - val_accuracy: 0.5767\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 911us/step - loss: 0.9739 - accuracy: 0.5960 - val_loss: 0.9762 - val_accuracy: 0.5674\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9535 - accuracy: 0.6058 - val_loss: 0.9498 - val_accuracy: 0.6047\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9324 - accuracy: 0.6162 - val_loss: 0.9291 - val_accuracy: 0.6233\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.9199 - accuracy: 0.6209 - val_loss: 0.9249 - val_accuracy: 0.5907\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 699us/step - loss: 0.9038 - accuracy: 0.6333 - val_loss: 0.9019 - val_accuracy: 0.6186\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.8903 - accuracy: 0.6395 - val_loss: 0.9153 - val_accuracy: 0.6000\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.8869 - accuracy: 0.6307 - val_loss: 0.8955 - val_accuracy: 0.6000\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8792 - accuracy: 0.6385 - val_loss: 0.9392 - val_accuracy: 0.6093\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.8697 - accuracy: 0.6421 - val_loss: 0.8670 - val_accuracy: 0.6186\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.8598 - accuracy: 0.6483 - val_loss: 0.8656 - val_accuracy: 0.6233\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.8545 - accuracy: 0.6447 - val_loss: 0.8727 - val_accuracy: 0.6186\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 758us/step - loss: 0.8558 - accuracy: 0.6494 - val_loss: 0.8661 - val_accuracy: 0.6093\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 858us/step - loss: 0.8468 - accuracy: 0.6494 - val_loss: 0.8638 - val_accuracy: 0.6140\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.8408 - accuracy: 0.6639 - val_loss: 0.8860 - val_accuracy: 0.6093\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.8454 - accuracy: 0.6551 - val_loss: 0.8512 - val_accuracy: 0.6140\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8357 - accuracy: 0.6520 - val_loss: 0.8513 - val_accuracy: 0.6233\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 649us/step - loss: 0.8331 - accuracy: 0.6515 - val_loss: 0.8413 - val_accuracy: 0.6186\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.8299 - accuracy: 0.6540 - val_loss: 0.8465 - val_accuracy: 0.6186\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.8267 - accuracy: 0.6551 - val_loss: 0.8481 - val_accuracy: 0.6233\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 929us/step - loss: 0.8247 - accuracy: 0.6499 - val_loss: 0.8287 - val_accuracy: 0.6279\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.8187 - accuracy: 0.6660 - val_loss: 0.8386 - val_accuracy: 0.6093\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.8198 - accuracy: 0.6639 - val_loss: 0.8430 - val_accuracy: 0.6233\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.8159 - accuracy: 0.6618 - val_loss: 0.8320 - val_accuracy: 0.6233\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.8099 - accuracy: 0.6587 - val_loss: 0.8241 - val_accuracy: 0.6279\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.8043 - accuracy: 0.6722 - val_loss: 0.8306 - val_accuracy: 0.6186\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.8031 - accuracy: 0.6629 - val_loss: 0.8332 - val_accuracy: 0.6186\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8064 - accuracy: 0.6670 - val_loss: 0.8137 - val_accuracy: 0.6326\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.7980 - accuracy: 0.6665 - val_loss: 0.8147 - val_accuracy: 0.6233\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7966 - accuracy: 0.6701 - val_loss: 0.8306 - val_accuracy: 0.6372\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.7964 - accuracy: 0.6706 - val_loss: 0.8163 - val_accuracy: 0.6279\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.7899 - accuracy: 0.6732 - val_loss: 0.8095 - val_accuracy: 0.6140\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7882 - accuracy: 0.6727 - val_loss: 0.8096 - val_accuracy: 0.6186\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 960us/step - loss: 0.7843 - accuracy: 0.6748 - val_loss: 0.8206 - val_accuracy: 0.6279\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.7864 - accuracy: 0.6763 - val_loss: 0.8129 - val_accuracy: 0.6233\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.7829 - accuracy: 0.6769 - val_loss: 0.8057 - val_accuracy: 0.6186\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.7774 - accuracy: 0.6763 - val_loss: 0.7988 - val_accuracy: 0.6233\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7771 - accuracy: 0.6815 - val_loss: 0.7997 - val_accuracy: 0.6372\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7767 - accuracy: 0.6769 - val_loss: 0.8092 - val_accuracy: 0.6233\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.7714 - accuracy: 0.6810 - val_loss: 0.8095 - val_accuracy: 0.6326\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 697us/step - loss: 0.7677 - accuracy: 0.6821 - val_loss: 0.7998 - val_accuracy: 0.6372\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 988us/step - loss: 0.7693 - accuracy: 0.6821 - val_loss: 0.7948 - val_accuracy: 0.6233\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7626 - accuracy: 0.6846 - val_loss: 0.7923 - val_accuracy: 0.6233\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.7617 - accuracy: 0.6955 - val_loss: 0.8113 - val_accuracy: 0.6372\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7589 - accuracy: 0.6852 - val_loss: 0.7862 - val_accuracy: 0.6419\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.7574 - accuracy: 0.6867 - val_loss: 0.7815 - val_accuracy: 0.6326\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.7545 - accuracy: 0.6852 - val_loss: 0.7953 - val_accuracy: 0.6326\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7513 - accuracy: 0.6893 - val_loss: 0.7848 - val_accuracy: 0.6372\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 658us/step - loss: 0.7539 - accuracy: 0.6929 - val_loss: 0.7873 - val_accuracy: 0.6279\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 982us/step - loss: 0.7494 - accuracy: 0.6904 - val_loss: 0.7970 - val_accuracy: 0.6372\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.7494 - accuracy: 0.6888 - val_loss: 0.7919 - val_accuracy: 0.6233\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.7467 - accuracy: 0.6961 - val_loss: 0.7895 - val_accuracy: 0.6186\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7446 - accuracy: 0.7012 - val_loss: 0.7870 - val_accuracy: 0.6651\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.7405 - accuracy: 0.6924 - val_loss: 0.7772 - val_accuracy: 0.6558\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7453 - accuracy: 0.6914 - val_loss: 0.7939 - val_accuracy: 0.6093\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 630us/step - loss: 0.7422 - accuracy: 0.6976 - val_loss: 0.7805 - val_accuracy: 0.6465\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.7345 - accuracy: 0.7012 - val_loss: 0.7829 - val_accuracy: 0.6512\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 893us/step - loss: 0.7366 - accuracy: 0.7038 - val_loss: 0.7888 - val_accuracy: 0.6419\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 724us/step - loss: 0.7399 - accuracy: 0.6904 - val_loss: 0.7741 - val_accuracy: 0.6558\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 970us/step - loss: 0.7371 - accuracy: 0.6992 - val_loss: 0.7784 - val_accuracy: 0.6512\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7331 - accuracy: 0.7007 - val_loss: 0.7803 - val_accuracy: 0.6465\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.7280 - accuracy: 0.6971 - val_loss: 0.7814 - val_accuracy: 0.6233\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7339 - accuracy: 0.6940 - val_loss: 0.7738 - val_accuracy: 0.6419\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7280 - accuracy: 0.7028 - val_loss: 0.7780 - val_accuracy: 0.6465\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.7257 - accuracy: 0.7070 - val_loss: 0.7785 - val_accuracy: 0.6279\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.7306 - accuracy: 0.7033 - val_loss: 0.7674 - val_accuracy: 0.6512\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.7294 - accuracy: 0.7038 - val_loss: 0.7844 - val_accuracy: 0.6233\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.7228 - accuracy: 0.6997 - val_loss: 0.7666 - val_accuracy: 0.6558\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.7023 - val_loss: 0.7647 - val_accuracy: 0.6419\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7191 - accuracy: 0.7012 - val_loss: 0.7674 - val_accuracy: 0.6558\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7220 - accuracy: 0.7044 - val_loss: 0.7854 - val_accuracy: 0.6233\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7207 - accuracy: 0.7054 - val_loss: 0.7740 - val_accuracy: 0.6140\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.7180 - accuracy: 0.7106 - val_loss: 0.7789 - val_accuracy: 0.6186\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7170 - accuracy: 0.7012 - val_loss: 0.7651 - val_accuracy: 0.6558\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 758us/step - loss: 0.7132 - accuracy: 0.7111 - val_loss: 0.7723 - val_accuracy: 0.6279\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 758us/step - loss: 0.7167 - accuracy: 0.7111 - val_loss: 0.7652 - val_accuracy: 0.6558\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.7121 - accuracy: 0.7121 - val_loss: 0.7865 - val_accuracy: 0.6140\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7162 - accuracy: 0.7090 - val_loss: 0.7716 - val_accuracy: 0.6279\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.7098 - accuracy: 0.7085 - val_loss: 0.7621 - val_accuracy: 0.6698\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.7104 - accuracy: 0.7147 - val_loss: 0.7601 - val_accuracy: 0.6791\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 970us/step - loss: 0.7093 - accuracy: 0.7173 - val_loss: 0.7647 - val_accuracy: 0.6512\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.7067 - accuracy: 0.7054 - val_loss: 0.7608 - val_accuracy: 0.6512\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.7049 - accuracy: 0.7132 - val_loss: 0.7569 - val_accuracy: 0.6419\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.7051 - accuracy: 0.7121 - val_loss: 0.7568 - val_accuracy: 0.6419\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.7068 - accuracy: 0.7137 - val_loss: 0.7609 - val_accuracy: 0.6419\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.7040 - accuracy: 0.7080 - val_loss: 0.7578 - val_accuracy: 0.6558\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.7034 - accuracy: 0.7101 - val_loss: 0.7560 - val_accuracy: 0.6372\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7039 - accuracy: 0.7147 - val_loss: 0.7612 - val_accuracy: 0.6558\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7036 - accuracy: 0.7090 - val_loss: 0.7659 - val_accuracy: 0.6233\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.6986 - accuracy: 0.7075 - val_loss: 0.7473 - val_accuracy: 0.6651\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6988 - accuracy: 0.7220 - val_loss: 0.7622 - val_accuracy: 0.6326\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6997 - accuracy: 0.7137 - val_loss: 0.7540 - val_accuracy: 0.6698\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6967 - accuracy: 0.7101 - val_loss: 0.7536 - val_accuracy: 0.6465\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6930 - accuracy: 0.7152 - val_loss: 0.7479 - val_accuracy: 0.6512\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.6965 - accuracy: 0.7142 - val_loss: 0.7507 - val_accuracy: 0.6744\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.6976 - accuracy: 0.7085 - val_loss: 0.7397 - val_accuracy: 0.6744\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.6959 - accuracy: 0.7137 - val_loss: 0.7493 - val_accuracy: 0.6558\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.7173 - val_loss: 0.7680 - val_accuracy: 0.6558\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6908 - accuracy: 0.7184 - val_loss: 0.7427 - val_accuracy: 0.6605\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6908 - accuracy: 0.7158 - val_loss: 0.7417 - val_accuracy: 0.6558\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6902 - accuracy: 0.7173 - val_loss: 0.7461 - val_accuracy: 0.6605\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 841us/step - loss: 0.6885 - accuracy: 0.7210 - val_loss: 0.7349 - val_accuracy: 0.6605\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6852 - accuracy: 0.7220 - val_loss: 0.7504 - val_accuracy: 0.6558\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6872 - accuracy: 0.7132 - val_loss: 0.7342 - val_accuracy: 0.6698\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6837 - accuracy: 0.7184 - val_loss: 0.7379 - val_accuracy: 0.6651\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 714us/step - loss: 0.6842 - accuracy: 0.7230 - val_loss: 0.7377 - val_accuracy: 0.6651\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.7132 - val_loss: 0.7264 - val_accuracy: 0.6837\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.7220 - val_loss: 0.7276 - val_accuracy: 0.6884\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.6791 - accuracy: 0.7080 - val_loss: 0.7252 - val_accuracy: 0.6791\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6777 - accuracy: 0.7184 - val_loss: 0.7222 - val_accuracy: 0.6884\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 982us/step - loss: 0.6780 - accuracy: 0.7147 - val_loss: 0.7305 - val_accuracy: 0.6837\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6828 - accuracy: 0.7241 - val_loss: 0.7233 - val_accuracy: 0.6698\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.7204 - val_loss: 0.7310 - val_accuracy: 0.6930\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6804 - accuracy: 0.7220 - val_loss: 0.7184 - val_accuracy: 0.6791\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.6743 - accuracy: 0.7220 - val_loss: 0.7169 - val_accuracy: 0.6651\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6729 - accuracy: 0.7225 - val_loss: 0.7297 - val_accuracy: 0.6744\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6766 - accuracy: 0.7241 - val_loss: 0.7175 - val_accuracy: 0.6651\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6714 - accuracy: 0.7184 - val_loss: 0.7153 - val_accuracy: 0.6791\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6677 - accuracy: 0.7267 - val_loss: 0.7327 - val_accuracy: 0.6884\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.6721 - accuracy: 0.7235 - val_loss: 0.7148 - val_accuracy: 0.6791\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6689 - accuracy: 0.7298 - val_loss: 0.7219 - val_accuracy: 0.6791\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6632 - accuracy: 0.7256 - val_loss: 0.7171 - val_accuracy: 0.6558\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.6678 - accuracy: 0.7210 - val_loss: 0.7108 - val_accuracy: 0.6884\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 762us/step - loss: 0.6642 - accuracy: 0.7246 - val_loss: 0.7238 - val_accuracy: 0.6651\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6647 - accuracy: 0.7298 - val_loss: 0.7145 - val_accuracy: 0.6698\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.6607 - accuracy: 0.7246 - val_loss: 0.7032 - val_accuracy: 0.6791\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.6623 - accuracy: 0.7334 - val_loss: 0.7090 - val_accuracy: 0.6791\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6628 - accuracy: 0.7251 - val_loss: 0.6958 - val_accuracy: 0.6791\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.7267 - val_loss: 0.7008 - val_accuracy: 0.6977\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 656us/step - loss: 0.6588 - accuracy: 0.7308 - val_loss: 0.6975 - val_accuracy: 0.6837\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.7277 - val_loss: 0.6959 - val_accuracy: 0.7023\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.7204 - val_loss: 0.6999 - val_accuracy: 0.7070\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.7287 - val_loss: 0.6992 - val_accuracy: 0.6791\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6537 - accuracy: 0.7282 - val_loss: 0.6900 - val_accuracy: 0.7023\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 752us/step - loss: 0.6580 - accuracy: 0.7251 - val_loss: 0.6992 - val_accuracy: 0.6930\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.6508 - accuracy: 0.7282 - val_loss: 0.7007 - val_accuracy: 0.6791\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 737us/step - loss: 0.6512 - accuracy: 0.7350 - val_loss: 0.7026 - val_accuracy: 0.6884\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 884us/step - loss: 0.6502 - accuracy: 0.7230 - val_loss: 0.6900 - val_accuracy: 0.6791\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 733us/step - loss: 0.6477 - accuracy: 0.7303 - val_loss: 0.6959 - val_accuracy: 0.6884\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.7344 - val_loss: 0.6978 - val_accuracy: 0.7116\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.6509 - accuracy: 0.7204 - val_loss: 0.6849 - val_accuracy: 0.7023\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 839us/step - loss: 0.6457 - accuracy: 0.7313 - val_loss: 0.6853 - val_accuracy: 0.6930\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6469 - accuracy: 0.7334 - val_loss: 0.7013 - val_accuracy: 0.6837\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 671us/step - loss: 0.6451 - accuracy: 0.7360 - val_loss: 0.6841 - val_accuracy: 0.6930\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.7298 - val_loss: 0.6958 - val_accuracy: 0.6791\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.6420 - accuracy: 0.7365 - val_loss: 0.6873 - val_accuracy: 0.6977\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.6404 - accuracy: 0.7324 - val_loss: 0.6874 - val_accuracy: 0.7070\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.6384 - accuracy: 0.7350 - val_loss: 0.6863 - val_accuracy: 0.7023\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.7376 - val_loss: 0.6835 - val_accuracy: 0.7163\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.6376 - accuracy: 0.7287 - val_loss: 0.6928 - val_accuracy: 0.6837\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6368 - accuracy: 0.7433 - val_loss: 0.6756 - val_accuracy: 0.7116\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6411 - accuracy: 0.7329 - val_loss: 0.6879 - val_accuracy: 0.6884\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.6333 - accuracy: 0.7459 - val_loss: 0.6769 - val_accuracy: 0.6930\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6357 - accuracy: 0.7396 - val_loss: 0.6830 - val_accuracy: 0.6977\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.7438 - val_loss: 0.6717 - val_accuracy: 0.7256\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.6303 - accuracy: 0.7360 - val_loss: 0.6713 - val_accuracy: 0.7070\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6349 - accuracy: 0.7401 - val_loss: 0.6982 - val_accuracy: 0.7256\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.7308 - val_loss: 0.6770 - val_accuracy: 0.7395\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.6317 - accuracy: 0.7376 - val_loss: 0.6713 - val_accuracy: 0.7116\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6303 - accuracy: 0.7381 - val_loss: 0.6679 - val_accuracy: 0.7163\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6281 - accuracy: 0.7318 - val_loss: 0.6762 - val_accuracy: 0.7163\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6313 - accuracy: 0.7370 - val_loss: 0.6877 - val_accuracy: 0.6977\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 699us/step - loss: 0.6310 - accuracy: 0.7386 - val_loss: 0.6781 - val_accuracy: 0.6837\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.6259 - accuracy: 0.7381 - val_loss: 0.6859 - val_accuracy: 0.7070\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 693us/step - loss: 0.6310 - accuracy: 0.7339 - val_loss: 0.6747 - val_accuracy: 0.7116\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.6289 - accuracy: 0.7313 - val_loss: 0.6744 - val_accuracy: 0.7023\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.6214 - accuracy: 0.7422 - val_loss: 0.6702 - val_accuracy: 0.7163\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.6218 - accuracy: 0.7417 - val_loss: 0.6647 - val_accuracy: 0.7163\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 707us/step - loss: 0.6229 - accuracy: 0.7396 - val_loss: 0.6854 - val_accuracy: 0.7023\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.6244 - accuracy: 0.7360 - val_loss: 0.6793 - val_accuracy: 0.7023\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.6216 - accuracy: 0.7401 - val_loss: 0.6642 - val_accuracy: 0.7209\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.7433 - val_loss: 0.6737 - val_accuracy: 0.7116\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6185 - accuracy: 0.7443 - val_loss: 0.6676 - val_accuracy: 0.7116\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.6180 - accuracy: 0.7422 - val_loss: 0.6719 - val_accuracy: 0.7395\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.6169 - accuracy: 0.7401 - val_loss: 0.6767 - val_accuracy: 0.7023\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6176 - accuracy: 0.7417 - val_loss: 0.6651 - val_accuracy: 0.7163\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.6133 - accuracy: 0.7412 - val_loss: 0.6657 - val_accuracy: 0.7070\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.6135 - accuracy: 0.7443 - val_loss: 0.6559 - val_accuracy: 0.7256\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.6157 - accuracy: 0.7438 - val_loss: 0.6631 - val_accuracy: 0.7116\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 974us/step - loss: 0.6152 - accuracy: 0.7381 - val_loss: 0.6623 - val_accuracy: 0.7209\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.6134 - accuracy: 0.7407 - val_loss: 0.6656 - val_accuracy: 0.7349\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.6121 - accuracy: 0.7412 - val_loss: 0.6647 - val_accuracy: 0.7209\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6122 - accuracy: 0.7464 - val_loss: 0.6738 - val_accuracy: 0.7256\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.6109 - accuracy: 0.7459 - val_loss: 0.6573 - val_accuracy: 0.7116\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.6115 - accuracy: 0.7412 - val_loss: 0.6642 - val_accuracy: 0.7116\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 758us/step - loss: 0.6079 - accuracy: 0.7433 - val_loss: 0.6678 - val_accuracy: 0.7209\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6126 - accuracy: 0.7469 - val_loss: 0.6639 - val_accuracy: 0.7116\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.6079 - accuracy: 0.7453 - val_loss: 0.6585 - val_accuracy: 0.7302\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.6086 - accuracy: 0.7396 - val_loss: 0.6719 - val_accuracy: 0.7302\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 744us/step - loss: 0.6096 - accuracy: 0.7417 - val_loss: 0.6684 - val_accuracy: 0.7070\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.6060 - accuracy: 0.7453 - val_loss: 0.6602 - val_accuracy: 0.7302\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.6062 - accuracy: 0.7417 - val_loss: 0.6673 - val_accuracy: 0.7163\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.6062 - accuracy: 0.7417 - val_loss: 0.6659 - val_accuracy: 0.7116\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 749us/step - loss: 0.6097 - accuracy: 0.7427 - val_loss: 0.6800 - val_accuracy: 0.7256\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 879us/step - loss: 0.6053 - accuracy: 0.7417 - val_loss: 0.6662 - val_accuracy: 0.7163\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.6050 - accuracy: 0.7490 - val_loss: 0.6656 - val_accuracy: 0.7116\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6029 - accuracy: 0.7469 - val_loss: 0.6579 - val_accuracy: 0.7395\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.7443 - val_loss: 0.6653 - val_accuracy: 0.7209\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5980 - accuracy: 0.7490 - val_loss: 0.6618 - val_accuracy: 0.7256\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.6001 - accuracy: 0.7526 - val_loss: 0.6654 - val_accuracy: 0.7116\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5969 - accuracy: 0.7443 - val_loss: 0.6658 - val_accuracy: 0.7209\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.5967 - accuracy: 0.7459 - val_loss: 0.6624 - val_accuracy: 0.7256\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6025 - accuracy: 0.7396 - val_loss: 0.6620 - val_accuracy: 0.7209\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5959 - accuracy: 0.7479 - val_loss: 0.6637 - val_accuracy: 0.7395\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.7531 - val_loss: 0.6612 - val_accuracy: 0.7488\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.5948 - accuracy: 0.7521 - val_loss: 0.6620 - val_accuracy: 0.7070\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5969 - accuracy: 0.7490 - val_loss: 0.6563 - val_accuracy: 0.7442\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 742us/step - loss: 0.5955 - accuracy: 0.7505 - val_loss: 0.6583 - val_accuracy: 0.7395\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.5920 - accuracy: 0.7459 - val_loss: 0.6724 - val_accuracy: 0.7209\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5926 - accuracy: 0.7479 - val_loss: 0.6604 - val_accuracy: 0.7302\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.5955 - accuracy: 0.7443 - val_loss: 0.6589 - val_accuracy: 0.7302\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5928 - accuracy: 0.7500 - val_loss: 0.6683 - val_accuracy: 0.7256\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6006 - accuracy: 0.7453 - val_loss: 0.6666 - val_accuracy: 0.7395\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5898 - accuracy: 0.7459 - val_loss: 0.6638 - val_accuracy: 0.7395\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5884 - accuracy: 0.7453 - val_loss: 0.6742 - val_accuracy: 0.7116\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 658us/step - loss: 0.5906 - accuracy: 0.7531 - val_loss: 0.6636 - val_accuracy: 0.7442\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.5887 - accuracy: 0.7547 - val_loss: 0.6625 - val_accuracy: 0.7302\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5916 - accuracy: 0.7495 - val_loss: 0.6521 - val_accuracy: 0.7302\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5912 - accuracy: 0.7464 - val_loss: 0.6531 - val_accuracy: 0.7302\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5885 - accuracy: 0.7490 - val_loss: 0.6546 - val_accuracy: 0.7349\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 743us/step - loss: 0.5857 - accuracy: 0.7536 - val_loss: 0.6522 - val_accuracy: 0.7395\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.5883 - accuracy: 0.7541 - val_loss: 0.6556 - val_accuracy: 0.7349\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5855 - accuracy: 0.7510 - val_loss: 0.6705 - val_accuracy: 0.7209\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5885 - accuracy: 0.7510 - val_loss: 0.6507 - val_accuracy: 0.7395\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 727us/step - loss: 0.5828 - accuracy: 0.7490 - val_loss: 0.6659 - val_accuracy: 0.7349\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 894us/step - loss: 0.5832 - accuracy: 0.7510 - val_loss: 0.6692 - val_accuracy: 0.7209\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.5866 - accuracy: 0.7495 - val_loss: 0.6658 - val_accuracy: 0.7256\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 900us/step - loss: 0.5817 - accuracy: 0.7500 - val_loss: 0.6627 - val_accuracy: 0.7349\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 717us/step - loss: 0.5863 - accuracy: 0.7573 - val_loss: 0.6617 - val_accuracy: 0.7163\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 727us/step - loss: 0.5804 - accuracy: 0.7536 - val_loss: 0.6599 - val_accuracy: 0.7395\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5825 - accuracy: 0.7474 - val_loss: 0.6581 - val_accuracy: 0.7256\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.7510 - val_loss: 0.6548 - val_accuracy: 0.7535\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 960us/step - loss: 0.5815 - accuracy: 0.7516 - val_loss: 0.6645 - val_accuracy: 0.7256\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.5787 - accuracy: 0.7578 - val_loss: 0.6486 - val_accuracy: 0.7442\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.5802 - accuracy: 0.7541 - val_loss: 0.6461 - val_accuracy: 0.7442\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 744us/step - loss: 0.5787 - accuracy: 0.7547 - val_loss: 0.6584 - val_accuracy: 0.7349\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 964us/step - loss: 0.5790 - accuracy: 0.7531 - val_loss: 0.6697 - val_accuracy: 0.7116\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.5816 - accuracy: 0.7500 - val_loss: 0.6446 - val_accuracy: 0.7442\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5793 - accuracy: 0.7541 - val_loss: 0.6612 - val_accuracy: 0.7395\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5755 - accuracy: 0.7583 - val_loss: 0.6533 - val_accuracy: 0.7395\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5751 - accuracy: 0.7510 - val_loss: 0.6524 - val_accuracy: 0.7349\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5777 - accuracy: 0.7547 - val_loss: 0.6566 - val_accuracy: 0.7349\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5738 - accuracy: 0.7630 - val_loss: 0.6505 - val_accuracy: 0.7442\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5758 - accuracy: 0.7567 - val_loss: 0.6492 - val_accuracy: 0.7302\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5782 - accuracy: 0.7536 - val_loss: 0.6532 - val_accuracy: 0.7302\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5734 - accuracy: 0.7588 - val_loss: 0.6476 - val_accuracy: 0.7302\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5722 - accuracy: 0.7604 - val_loss: 0.6506 - val_accuracy: 0.7442\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5736 - accuracy: 0.7619 - val_loss: 0.6632 - val_accuracy: 0.7070\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5713 - accuracy: 0.7573 - val_loss: 0.6588 - val_accuracy: 0.7488\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5736 - accuracy: 0.7604 - val_loss: 0.6471 - val_accuracy: 0.7395\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5714 - accuracy: 0.7583 - val_loss: 0.6461 - val_accuracy: 0.7302\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5680 - accuracy: 0.7557 - val_loss: 0.6435 - val_accuracy: 0.7395\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5751 - accuracy: 0.7510 - val_loss: 0.6572 - val_accuracy: 0.7302\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5685 - accuracy: 0.7567 - val_loss: 0.6567 - val_accuracy: 0.7442\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5678 - accuracy: 0.7599 - val_loss: 0.6509 - val_accuracy: 0.7395\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5681 - accuracy: 0.7588 - val_loss: 0.6604 - val_accuracy: 0.7256\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5693 - accuracy: 0.7573 - val_loss: 0.6562 - val_accuracy: 0.7395\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.5640 - accuracy: 0.7619 - val_loss: 0.6499 - val_accuracy: 0.7302\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.5704 - accuracy: 0.7521 - val_loss: 0.6556 - val_accuracy: 0.7395\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5697 - accuracy: 0.7567 - val_loss: 0.6461 - val_accuracy: 0.7302\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.5709 - accuracy: 0.7588 - val_loss: 0.6562 - val_accuracy: 0.7395\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5714 - accuracy: 0.7635 - val_loss: 0.6534 - val_accuracy: 0.7442\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5674 - accuracy: 0.7573 - val_loss: 0.6431 - val_accuracy: 0.7256\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5662 - accuracy: 0.7635 - val_loss: 0.6554 - val_accuracy: 0.7395\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5676 - accuracy: 0.7640 - val_loss: 0.6736 - val_accuracy: 0.7256\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5669 - accuracy: 0.7599 - val_loss: 0.6438 - val_accuracy: 0.7442\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 657us/step - loss: 0.5668 - accuracy: 0.7583 - val_loss: 0.6524 - val_accuracy: 0.7209\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7645 - val_loss: 0.6518 - val_accuracy: 0.7395\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5657 - accuracy: 0.7609 - val_loss: 0.6586 - val_accuracy: 0.7349\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5619 - accuracy: 0.7599 - val_loss: 0.6460 - val_accuracy: 0.7302\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5658 - accuracy: 0.7557 - val_loss: 0.6458 - val_accuracy: 0.7302\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5615 - accuracy: 0.7614 - val_loss: 0.6736 - val_accuracy: 0.7256\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.5630 - accuracy: 0.7599 - val_loss: 0.6643 - val_accuracy: 0.7349\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.5616 - accuracy: 0.7630 - val_loss: 0.6525 - val_accuracy: 0.7302\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.5619 - accuracy: 0.7593 - val_loss: 0.6620 - val_accuracy: 0.7395\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.5618 - accuracy: 0.7614 - val_loss: 0.6493 - val_accuracy: 0.7488\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5632 - accuracy: 0.7614 - val_loss: 0.6515 - val_accuracy: 0.7395\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5590 - accuracy: 0.7599 - val_loss: 0.6504 - val_accuracy: 0.7395\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 768us/step - loss: 0.5585 - accuracy: 0.7656 - val_loss: 0.6523 - val_accuracy: 0.7349\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5601 - accuracy: 0.7578 - val_loss: 0.6439 - val_accuracy: 0.7442\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5631 - accuracy: 0.7609 - val_loss: 0.6610 - val_accuracy: 0.7395\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5603 - accuracy: 0.7619 - val_loss: 0.6503 - val_accuracy: 0.7302\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5593 - accuracy: 0.7567 - val_loss: 0.6513 - val_accuracy: 0.7349\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5577 - accuracy: 0.7687 - val_loss: 0.6583 - val_accuracy: 0.7256\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5616 - accuracy: 0.7656 - val_loss: 0.6578 - val_accuracy: 0.7256\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5586 - accuracy: 0.7599 - val_loss: 0.6619 - val_accuracy: 0.7395\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.5586 - accuracy: 0.7624 - val_loss: 0.6462 - val_accuracy: 0.7442\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 774us/step - loss: 0.5543 - accuracy: 0.7640 - val_loss: 0.6908 - val_accuracy: 0.7209\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.5585 - accuracy: 0.7635 - val_loss: 0.6556 - val_accuracy: 0.7302\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 0.5616 - accuracy: 0.7599 - val_loss: 0.6683 - val_accuracy: 0.7070\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.5625 - accuracy: 0.7599 - val_loss: 0.6517 - val_accuracy: 0.7442\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 876us/step - loss: 0.5535 - accuracy: 0.7676 - val_loss: 0.6455 - val_accuracy: 0.7302\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.5554 - accuracy: 0.7666 - val_loss: 0.6581 - val_accuracy: 0.7535\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.5535 - accuracy: 0.7604 - val_loss: 0.6548 - val_accuracy: 0.7442\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 683us/step - loss: 0.5539 - accuracy: 0.7661 - val_loss: 0.6460 - val_accuracy: 0.7395\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.5537 - accuracy: 0.7630 - val_loss: 0.6688 - val_accuracy: 0.7070\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.5556 - accuracy: 0.7614 - val_loss: 0.6659 - val_accuracy: 0.7395\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5541 - accuracy: 0.7650 - val_loss: 0.6423 - val_accuracy: 0.7395\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5525 - accuracy: 0.7624 - val_loss: 0.6489 - val_accuracy: 0.7349\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.5548 - accuracy: 0.7676 - val_loss: 0.6459 - val_accuracy: 0.7302\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.5540 - accuracy: 0.7609 - val_loss: 0.6478 - val_accuracy: 0.7349\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5504 - accuracy: 0.7604 - val_loss: 0.6495 - val_accuracy: 0.7395\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5547 - accuracy: 0.7650 - val_loss: 0.6542 - val_accuracy: 0.7209\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5516 - accuracy: 0.7682 - val_loss: 0.6624 - val_accuracy: 0.7442\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5533 - accuracy: 0.7692 - val_loss: 0.6438 - val_accuracy: 0.7256\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 758us/step - loss: 0.5495 - accuracy: 0.7640 - val_loss: 0.6431 - val_accuracy: 0.7349\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.5526 - accuracy: 0.7619 - val_loss: 0.6401 - val_accuracy: 0.7302\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5514 - accuracy: 0.7624 - val_loss: 0.6520 - val_accuracy: 0.7302\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5523 - accuracy: 0.7640 - val_loss: 0.6560 - val_accuracy: 0.7302\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5503 - accuracy: 0.7650 - val_loss: 0.6537 - val_accuracy: 0.7442\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 735us/step - loss: 0.5477 - accuracy: 0.7650 - val_loss: 0.6538 - val_accuracy: 0.7256\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.5517 - accuracy: 0.7666 - val_loss: 0.6467 - val_accuracy: 0.7349\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5496 - accuracy: 0.7640 - val_loss: 0.6428 - val_accuracy: 0.7395\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 714us/step - loss: 0.5507 - accuracy: 0.7645 - val_loss: 0.6399 - val_accuracy: 0.7302\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.5497 - accuracy: 0.7645 - val_loss: 0.6537 - val_accuracy: 0.7395\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7692 - val_loss: 0.6498 - val_accuracy: 0.7302\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.5478 - accuracy: 0.7650 - val_loss: 0.6395 - val_accuracy: 0.7395\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 951us/step - loss: 0.5509 - accuracy: 0.7671 - val_loss: 0.6483 - val_accuracy: 0.7256\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5465 - accuracy: 0.7604 - val_loss: 0.6511 - val_accuracy: 0.7442\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 776us/step - loss: 0.5489 - accuracy: 0.7624 - val_loss: 0.6593 - val_accuracy: 0.7349\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5445 - accuracy: 0.7687 - val_loss: 0.6446 - val_accuracy: 0.7349\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5451 - accuracy: 0.7661 - val_loss: 0.6689 - val_accuracy: 0.7163\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5455 - accuracy: 0.7676 - val_loss: 0.6624 - val_accuracy: 0.7349\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5442 - accuracy: 0.7656 - val_loss: 0.6515 - val_accuracy: 0.7349\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5440 - accuracy: 0.7702 - val_loss: 0.6501 - val_accuracy: 0.7442\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.5474 - accuracy: 0.7619 - val_loss: 0.6579 - val_accuracy: 0.7349\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 678us/step - loss: 0.5451 - accuracy: 0.7656 - val_loss: 0.6541 - val_accuracy: 0.7302\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.5443 - accuracy: 0.7661 - val_loss: 0.6445 - val_accuracy: 0.7442\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.5468 - accuracy: 0.7656 - val_loss: 0.6482 - val_accuracy: 0.7302\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.5478 - accuracy: 0.7697 - val_loss: 0.6477 - val_accuracy: 0.7442\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5467 - accuracy: 0.7718 - val_loss: 0.6547 - val_accuracy: 0.7488\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5435 - accuracy: 0.7765 - val_loss: 0.6473 - val_accuracy: 0.7302\n",
      "Epoch 344: early stopping\n",
      "29/29 - 0s - loss: 0.5729 - accuracy: 0.7473 - 116ms/epoch - 4ms/step\n",
      "5\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.5083 - accuracy: 0.3387 - val_loss: 1.4251 - val_accuracy: 0.3860\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.3551 - accuracy: 0.4528 - val_loss: 1.3088 - val_accuracy: 0.4698\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 957us/step - loss: 1.2718 - accuracy: 0.4730 - val_loss: 1.2524 - val_accuracy: 0.4465\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 893us/step - loss: 1.2306 - accuracy: 0.4772 - val_loss: 1.2352 - val_accuracy: 0.4744\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2074 - accuracy: 0.4756 - val_loss: 1.2008 - val_accuracy: 0.4884\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1872 - accuracy: 0.4912 - val_loss: 1.1843 - val_accuracy: 0.4930\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 1.1660 - accuracy: 0.5031 - val_loss: 1.1676 - val_accuracy: 0.4930\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1508 - accuracy: 0.5057 - val_loss: 1.1529 - val_accuracy: 0.5023\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1318 - accuracy: 0.5239 - val_loss: 1.1266 - val_accuracy: 0.5302\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1134 - accuracy: 0.5285 - val_loss: 1.1030 - val_accuracy: 0.5442\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 951us/step - loss: 1.0894 - accuracy: 0.5399 - val_loss: 1.1024 - val_accuracy: 0.5395\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 1.0716 - accuracy: 0.5415 - val_loss: 1.0755 - val_accuracy: 0.5395\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 1.0519 - accuracy: 0.5596 - val_loss: 1.0606 - val_accuracy: 0.5395\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0262 - accuracy: 0.5705 - val_loss: 1.0351 - val_accuracy: 0.5581\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0059 - accuracy: 0.5788 - val_loss: 1.0148 - val_accuracy: 0.5721\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 887us/step - loss: 0.9863 - accuracy: 0.5908 - val_loss: 0.9943 - val_accuracy: 0.5628\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9643 - accuracy: 0.5975 - val_loss: 0.9622 - val_accuracy: 0.5860\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9490 - accuracy: 0.6105 - val_loss: 0.9436 - val_accuracy: 0.6047\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 964us/step - loss: 0.9302 - accuracy: 0.6183 - val_loss: 0.9438 - val_accuracy: 0.5814\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 667us/step - loss: 0.9151 - accuracy: 0.6286 - val_loss: 0.9553 - val_accuracy: 0.5767\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 966us/step - loss: 0.9013 - accuracy: 0.6343 - val_loss: 0.9141 - val_accuracy: 0.5860\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8883 - accuracy: 0.6421 - val_loss: 0.9037 - val_accuracy: 0.6233\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 693us/step - loss: 0.8822 - accuracy: 0.6349 - val_loss: 0.9035 - val_accuracy: 0.6140\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8754 - accuracy: 0.6483 - val_loss: 0.8836 - val_accuracy: 0.6279\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.8698 - accuracy: 0.6463 - val_loss: 0.8715 - val_accuracy: 0.6233\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8619 - accuracy: 0.6551 - val_loss: 0.8915 - val_accuracy: 0.6047\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.8573 - accuracy: 0.6463 - val_loss: 0.8690 - val_accuracy: 0.6093\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.8523 - accuracy: 0.6546 - val_loss: 0.8605 - val_accuracy: 0.6233\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8496 - accuracy: 0.6525 - val_loss: 0.8694 - val_accuracy: 0.6186\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.8452 - accuracy: 0.6499 - val_loss: 0.8935 - val_accuracy: 0.6047\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.8460 - accuracy: 0.6520 - val_loss: 0.8552 - val_accuracy: 0.6186\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.8410 - accuracy: 0.6608 - val_loss: 0.8538 - val_accuracy: 0.6093\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.8346 - accuracy: 0.6546 - val_loss: 0.8484 - val_accuracy: 0.6233\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8326 - accuracy: 0.6546 - val_loss: 0.8518 - val_accuracy: 0.6186\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8366 - accuracy: 0.6530 - val_loss: 0.8703 - val_accuracy: 0.6186\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.8262 - accuracy: 0.6603 - val_loss: 0.8416 - val_accuracy: 0.6233\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.8302 - accuracy: 0.6587 - val_loss: 0.8516 - val_accuracy: 0.6279\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 713us/step - loss: 0.8278 - accuracy: 0.6598 - val_loss: 0.8478 - val_accuracy: 0.6140\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.8230 - accuracy: 0.6566 - val_loss: 0.8443 - val_accuracy: 0.6047\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.8189 - accuracy: 0.6613 - val_loss: 0.8403 - val_accuracy: 0.6186\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 749us/step - loss: 0.8252 - accuracy: 0.6551 - val_loss: 0.8559 - val_accuracy: 0.6000\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 868us/step - loss: 0.8167 - accuracy: 0.6639 - val_loss: 0.8370 - val_accuracy: 0.6140\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 749us/step - loss: 0.8137 - accuracy: 0.6644 - val_loss: 0.8451 - val_accuracy: 0.6233\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.8100 - accuracy: 0.6686 - val_loss: 0.8403 - val_accuracy: 0.6186\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.8132 - accuracy: 0.6655 - val_loss: 0.8259 - val_accuracy: 0.6233\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8075 - accuracy: 0.6660 - val_loss: 0.8224 - val_accuracy: 0.6326\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.8051 - accuracy: 0.6696 - val_loss: 0.8312 - val_accuracy: 0.6093\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.8004 - accuracy: 0.6587 - val_loss: 0.8331 - val_accuracy: 0.6186\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8003 - accuracy: 0.6701 - val_loss: 0.8363 - val_accuracy: 0.6233\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7935 - accuracy: 0.6738 - val_loss: 0.8198 - val_accuracy: 0.6140\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.7951 - accuracy: 0.6712 - val_loss: 0.8248 - val_accuracy: 0.6186\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.7945 - accuracy: 0.6732 - val_loss: 0.8187 - val_accuracy: 0.6140\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7864 - accuracy: 0.6738 - val_loss: 0.8116 - val_accuracy: 0.6186\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7854 - accuracy: 0.6717 - val_loss: 0.8423 - val_accuracy: 0.6047\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.7814 - accuracy: 0.6784 - val_loss: 0.8084 - val_accuracy: 0.6186\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.7760 - accuracy: 0.6805 - val_loss: 0.8049 - val_accuracy: 0.6326\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.7747 - accuracy: 0.6738 - val_loss: 0.8083 - val_accuracy: 0.6279\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.7729 - accuracy: 0.6810 - val_loss: 0.8133 - val_accuracy: 0.6279\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.7700 - accuracy: 0.6789 - val_loss: 0.7998 - val_accuracy: 0.6419\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7763 - accuracy: 0.6763 - val_loss: 0.8138 - val_accuracy: 0.6419\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.7734 - accuracy: 0.6784 - val_loss: 0.8200 - val_accuracy: 0.6093\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7656 - accuracy: 0.6872 - val_loss: 0.8059 - val_accuracy: 0.6465\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7637 - accuracy: 0.6914 - val_loss: 0.7940 - val_accuracy: 0.6279\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.7544 - accuracy: 0.6883 - val_loss: 0.8158 - val_accuracy: 0.6233\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7599 - accuracy: 0.6878 - val_loss: 0.8157 - val_accuracy: 0.6093\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7546 - accuracy: 0.6919 - val_loss: 0.7953 - val_accuracy: 0.6279\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.7507 - accuracy: 0.6862 - val_loss: 0.7939 - val_accuracy: 0.6326\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.7498 - accuracy: 0.6841 - val_loss: 0.7864 - val_accuracy: 0.6372\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.7473 - accuracy: 0.6888 - val_loss: 0.7861 - val_accuracy: 0.6326\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 749us/step - loss: 0.7440 - accuracy: 0.6945 - val_loss: 0.7827 - val_accuracy: 0.6279\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7443 - accuracy: 0.6878 - val_loss: 0.7824 - val_accuracy: 0.6605\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.7361 - accuracy: 0.6966 - val_loss: 0.7961 - val_accuracy: 0.6093\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.7345 - accuracy: 0.6966 - val_loss: 0.7880 - val_accuracy: 0.6233\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.7341 - accuracy: 0.6966 - val_loss: 0.7829 - val_accuracy: 0.6512\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.7339 - accuracy: 0.6955 - val_loss: 0.7718 - val_accuracy: 0.6465\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.7316 - accuracy: 0.7012 - val_loss: 0.7813 - val_accuracy: 0.6279\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 736us/step - loss: 0.7268 - accuracy: 0.6976 - val_loss: 0.7757 - val_accuracy: 0.6279\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 866us/step - loss: 0.7254 - accuracy: 0.7044 - val_loss: 0.7702 - val_accuracy: 0.6186\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7193 - accuracy: 0.7007 - val_loss: 0.7731 - val_accuracy: 0.6279\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 652us/step - loss: 0.7195 - accuracy: 0.7033 - val_loss: 0.7823 - val_accuracy: 0.6233\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 993us/step - loss: 0.7197 - accuracy: 0.7044 - val_loss: 0.7732 - val_accuracy: 0.6279\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.7146 - accuracy: 0.7064 - val_loss: 0.7629 - val_accuracy: 0.6512\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.7147 - accuracy: 0.7070 - val_loss: 0.7665 - val_accuracy: 0.6279\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.7138 - accuracy: 0.7090 - val_loss: 0.7774 - val_accuracy: 0.6140\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7086 - accuracy: 0.7059 - val_loss: 0.7629 - val_accuracy: 0.6326\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7068 - accuracy: 0.7095 - val_loss: 0.7517 - val_accuracy: 0.6465\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.7058 - accuracy: 0.7095 - val_loss: 0.7532 - val_accuracy: 0.6558\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.7081 - accuracy: 0.7033 - val_loss: 0.7444 - val_accuracy: 0.6465\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7040 - accuracy: 0.7038 - val_loss: 0.7623 - val_accuracy: 0.6326\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7003 - accuracy: 0.7095 - val_loss: 0.7420 - val_accuracy: 0.6558\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.6968 - accuracy: 0.7121 - val_loss: 0.7742 - val_accuracy: 0.6279\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 848us/step - loss: 0.6940 - accuracy: 0.7106 - val_loss: 0.7362 - val_accuracy: 0.6651\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 981us/step - loss: 0.6969 - accuracy: 0.7158 - val_loss: 0.7561 - val_accuracy: 0.6233\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6950 - accuracy: 0.7111 - val_loss: 0.7453 - val_accuracy: 0.6605\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 988us/step - loss: 0.6911 - accuracy: 0.7106 - val_loss: 0.7280 - val_accuracy: 0.6744\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6935 - accuracy: 0.7147 - val_loss: 0.7435 - val_accuracy: 0.6465\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6872 - accuracy: 0.7106 - val_loss: 0.7322 - val_accuracy: 0.6651\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6873 - accuracy: 0.7152 - val_loss: 0.7367 - val_accuracy: 0.6558\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.6832 - accuracy: 0.7220 - val_loss: 0.7292 - val_accuracy: 0.6558\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6868 - accuracy: 0.7235 - val_loss: 0.7407 - val_accuracy: 0.6326\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.7189 - val_loss: 0.7344 - val_accuracy: 0.6837\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 687us/step - loss: 0.6851 - accuracy: 0.7106 - val_loss: 0.7347 - val_accuracy: 0.6512\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.7178 - val_loss: 0.7166 - val_accuracy: 0.6698\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 841us/step - loss: 0.6753 - accuracy: 0.7210 - val_loss: 0.7139 - val_accuracy: 0.6744\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6803 - accuracy: 0.7204 - val_loss: 0.7141 - val_accuracy: 0.6744\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6761 - accuracy: 0.7184 - val_loss: 0.7351 - val_accuracy: 0.6558\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.6728 - accuracy: 0.7215 - val_loss: 0.7322 - val_accuracy: 0.6512\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 875us/step - loss: 0.6756 - accuracy: 0.7199 - val_loss: 0.7229 - val_accuracy: 0.6605\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6720 - accuracy: 0.7235 - val_loss: 0.7133 - val_accuracy: 0.6791\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.6691 - accuracy: 0.7251 - val_loss: 0.7127 - val_accuracy: 0.6744\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.6682 - accuracy: 0.7287 - val_loss: 0.7230 - val_accuracy: 0.6791\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.6698 - accuracy: 0.7225 - val_loss: 0.7053 - val_accuracy: 0.6837\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.7251 - val_loss: 0.7116 - val_accuracy: 0.6698\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6704 - accuracy: 0.7230 - val_loss: 0.7155 - val_accuracy: 0.6651\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.7256 - val_loss: 0.7156 - val_accuracy: 0.6930\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6648 - accuracy: 0.7261 - val_loss: 0.6981 - val_accuracy: 0.6884\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6599 - accuracy: 0.7261 - val_loss: 0.7127 - val_accuracy: 0.6558\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6564 - accuracy: 0.7272 - val_loss: 0.6928 - val_accuracy: 0.6884\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6574 - accuracy: 0.7303 - val_loss: 0.7059 - val_accuracy: 0.6744\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6572 - accuracy: 0.7235 - val_loss: 0.6990 - val_accuracy: 0.6558\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6587 - accuracy: 0.7246 - val_loss: 0.7094 - val_accuracy: 0.6930\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.6555 - accuracy: 0.7241 - val_loss: 0.7075 - val_accuracy: 0.6744\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.6560 - accuracy: 0.7241 - val_loss: 0.6933 - val_accuracy: 0.6884\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.6531 - accuracy: 0.7324 - val_loss: 0.6902 - val_accuracy: 0.6884\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 705us/step - loss: 0.6536 - accuracy: 0.7329 - val_loss: 0.6955 - val_accuracy: 0.6791\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 887us/step - loss: 0.6509 - accuracy: 0.7230 - val_loss: 0.6965 - val_accuracy: 0.6884\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 730us/step - loss: 0.6485 - accuracy: 0.7344 - val_loss: 0.7026 - val_accuracy: 0.6930\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.6508 - accuracy: 0.7287 - val_loss: 0.7090 - val_accuracy: 0.6698\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 970us/step - loss: 0.6485 - accuracy: 0.7360 - val_loss: 0.6868 - val_accuracy: 0.7070\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 936us/step - loss: 0.6509 - accuracy: 0.7282 - val_loss: 0.6945 - val_accuracy: 0.6791\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.6500 - accuracy: 0.7235 - val_loss: 0.6916 - val_accuracy: 0.6791\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6517 - accuracy: 0.7293 - val_loss: 0.6817 - val_accuracy: 0.6930\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6512 - accuracy: 0.7318 - val_loss: 0.6775 - val_accuracy: 0.6837\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 663us/step - loss: 0.6492 - accuracy: 0.7277 - val_loss: 0.6989 - val_accuracy: 0.6791\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.6482 - accuracy: 0.7251 - val_loss: 0.6805 - val_accuracy: 0.7023\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.6456 - accuracy: 0.7396 - val_loss: 0.6730 - val_accuracy: 0.6977\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.7339 - val_loss: 0.6784 - val_accuracy: 0.7116\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.6434 - accuracy: 0.7256 - val_loss: 0.6913 - val_accuracy: 0.6977\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6406 - accuracy: 0.7365 - val_loss: 0.6858 - val_accuracy: 0.6977\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6430 - accuracy: 0.7339 - val_loss: 0.6957 - val_accuracy: 0.6837\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6470 - accuracy: 0.7287 - val_loss: 0.7048 - val_accuracy: 0.6837\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.6380 - accuracy: 0.7350 - val_loss: 0.6831 - val_accuracy: 0.7070\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.7303 - val_loss: 0.6812 - val_accuracy: 0.7163\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 726us/step - loss: 0.6376 - accuracy: 0.7386 - val_loss: 0.6775 - val_accuracy: 0.6884\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.6359 - accuracy: 0.7344 - val_loss: 0.6908 - val_accuracy: 0.7023\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6376 - accuracy: 0.7360 - val_loss: 0.6804 - val_accuracy: 0.6977\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.6332 - accuracy: 0.7417 - val_loss: 0.6791 - val_accuracy: 0.6977\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.6318 - accuracy: 0.7417 - val_loss: 0.6761 - val_accuracy: 0.6977\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.6346 - accuracy: 0.7303 - val_loss: 0.6890 - val_accuracy: 0.7070\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 847us/step - loss: 0.6315 - accuracy: 0.7422 - val_loss: 0.6841 - val_accuracy: 0.7070\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 769us/step - loss: 0.6331 - accuracy: 0.7350 - val_loss: 0.6756 - val_accuracy: 0.6977\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 847us/step - loss: 0.6396 - accuracy: 0.7355 - val_loss: 0.6934 - val_accuracy: 0.6744\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.6283 - accuracy: 0.7355 - val_loss: 0.6992 - val_accuracy: 0.6651\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6323 - accuracy: 0.7417 - val_loss: 0.6806 - val_accuracy: 0.7070\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 774us/step - loss: 0.6310 - accuracy: 0.7324 - val_loss: 0.6814 - val_accuracy: 0.7023\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.7386 - val_loss: 0.6772 - val_accuracy: 0.7209\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.6238 - accuracy: 0.7422 - val_loss: 0.6849 - val_accuracy: 0.6977\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6302 - accuracy: 0.7391 - val_loss: 0.6807 - val_accuracy: 0.6930\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.6255 - accuracy: 0.7396 - val_loss: 0.6856 - val_accuracy: 0.6930\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.6272 - accuracy: 0.7417 - val_loss: 0.6775 - val_accuracy: 0.7163\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 750us/step - loss: 0.6246 - accuracy: 0.7422 - val_loss: 0.6745 - val_accuracy: 0.7023\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 855us/step - loss: 0.6204 - accuracy: 0.7433 - val_loss: 0.6640 - val_accuracy: 0.7116\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 762us/step - loss: 0.6216 - accuracy: 0.7417 - val_loss: 0.6781 - val_accuracy: 0.7070\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 714us/step - loss: 0.6200 - accuracy: 0.7422 - val_loss: 0.6679 - val_accuracy: 0.7116\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 998us/step - loss: 0.6230 - accuracy: 0.7474 - val_loss: 0.6685 - val_accuracy: 0.7070\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 0.6230 - accuracy: 0.7427 - val_loss: 0.6684 - val_accuracy: 0.7070\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.6206 - accuracy: 0.7407 - val_loss: 0.6863 - val_accuracy: 0.6977\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6197 - accuracy: 0.7443 - val_loss: 0.6591 - val_accuracy: 0.7256\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 846us/step - loss: 0.6204 - accuracy: 0.7459 - val_loss: 0.6734 - val_accuracy: 0.7256\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6178 - accuracy: 0.7412 - val_loss: 0.6610 - val_accuracy: 0.7070\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6172 - accuracy: 0.7443 - val_loss: 0.6689 - val_accuracy: 0.7070\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.7386 - val_loss: 0.6694 - val_accuracy: 0.7070\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.7427 - val_loss: 0.6563 - val_accuracy: 0.7302\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.6195 - accuracy: 0.7407 - val_loss: 0.6782 - val_accuracy: 0.7116\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.6151 - accuracy: 0.7484 - val_loss: 0.6753 - val_accuracy: 0.7116\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.6138 - accuracy: 0.7464 - val_loss: 0.6597 - val_accuracy: 0.7163\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.6157 - accuracy: 0.7438 - val_loss: 0.6799 - val_accuracy: 0.7163\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6210 - accuracy: 0.7360 - val_loss: 0.6661 - val_accuracy: 0.7070\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.6105 - accuracy: 0.7422 - val_loss: 0.6701 - val_accuracy: 0.7163\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6182 - accuracy: 0.7376 - val_loss: 0.6542 - val_accuracy: 0.7116\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.6107 - accuracy: 0.7453 - val_loss: 0.6551 - val_accuracy: 0.7163\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6124 - accuracy: 0.7438 - val_loss: 0.6545 - val_accuracy: 0.7209\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6088 - accuracy: 0.7464 - val_loss: 0.6555 - val_accuracy: 0.7116\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.6082 - accuracy: 0.7495 - val_loss: 0.6852 - val_accuracy: 0.7023\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.6060 - accuracy: 0.7443 - val_loss: 0.6556 - val_accuracy: 0.7209\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 864us/step - loss: 0.6068 - accuracy: 0.7484 - val_loss: 0.6541 - val_accuracy: 0.7163\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.6063 - accuracy: 0.7448 - val_loss: 0.6705 - val_accuracy: 0.7302\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.6083 - accuracy: 0.7510 - val_loss: 0.6831 - val_accuracy: 0.6930\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.6061 - accuracy: 0.7401 - val_loss: 0.6559 - val_accuracy: 0.7209\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.6043 - accuracy: 0.7541 - val_loss: 0.6549 - val_accuracy: 0.7256\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 839us/step - loss: 0.6098 - accuracy: 0.7438 - val_loss: 0.6833 - val_accuracy: 0.7070\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.6065 - accuracy: 0.7474 - val_loss: 0.6585 - val_accuracy: 0.7209\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.6043 - accuracy: 0.7484 - val_loss: 0.6691 - val_accuracy: 0.7256\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6031 - accuracy: 0.7438 - val_loss: 0.6533 - val_accuracy: 0.7302\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.7490 - val_loss: 0.6572 - val_accuracy: 0.7395\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.6035 - accuracy: 0.7433 - val_loss: 0.6640 - val_accuracy: 0.7256\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 992us/step - loss: 0.6064 - accuracy: 0.7505 - val_loss: 0.6546 - val_accuracy: 0.7256\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 878us/step - loss: 0.5996 - accuracy: 0.7536 - val_loss: 0.6747 - val_accuracy: 0.7070\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 908us/step - loss: 0.5992 - accuracy: 0.7505 - val_loss: 0.6486 - val_accuracy: 0.7209\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.6002 - accuracy: 0.7500 - val_loss: 0.6712 - val_accuracy: 0.7256\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 778us/step - loss: 0.6010 - accuracy: 0.7521 - val_loss: 0.6857 - val_accuracy: 0.7209\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 852us/step - loss: 0.5986 - accuracy: 0.7510 - val_loss: 0.6527 - val_accuracy: 0.7209\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 736us/step - loss: 0.6011 - accuracy: 0.7469 - val_loss: 0.6743 - val_accuracy: 0.7302\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.6050 - accuracy: 0.7422 - val_loss: 0.6612 - val_accuracy: 0.7302\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.5995 - accuracy: 0.7474 - val_loss: 0.6777 - val_accuracy: 0.6977\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 709us/step - loss: 0.5985 - accuracy: 0.7495 - val_loss: 0.6567 - val_accuracy: 0.7395\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 934us/step - loss: 0.5964 - accuracy: 0.7531 - val_loss: 0.6708 - val_accuracy: 0.7070\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5960 - accuracy: 0.7531 - val_loss: 0.6660 - val_accuracy: 0.7023\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 968us/step - loss: 0.5973 - accuracy: 0.7505 - val_loss: 0.6476 - val_accuracy: 0.7163\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5947 - accuracy: 0.7521 - val_loss: 0.6469 - val_accuracy: 0.7209\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5968 - accuracy: 0.7490 - val_loss: 0.6561 - val_accuracy: 0.7209\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5927 - accuracy: 0.7541 - val_loss: 0.6737 - val_accuracy: 0.7209\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5925 - accuracy: 0.7495 - val_loss: 0.6544 - val_accuracy: 0.7116\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.5955 - accuracy: 0.7479 - val_loss: 0.6546 - val_accuracy: 0.7256\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5944 - accuracy: 0.7474 - val_loss: 0.6525 - val_accuracy: 0.7256\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.7557 - val_loss: 0.6489 - val_accuracy: 0.7442\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5912 - accuracy: 0.7521 - val_loss: 0.6587 - val_accuracy: 0.7395\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.5920 - accuracy: 0.7552 - val_loss: 0.6508 - val_accuracy: 0.7442\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 852us/step - loss: 0.5916 - accuracy: 0.7531 - val_loss: 0.6540 - val_accuracy: 0.7256\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.5902 - accuracy: 0.7510 - val_loss: 0.6597 - val_accuracy: 0.7116\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 989us/step - loss: 0.5885 - accuracy: 0.7536 - val_loss: 0.6626 - val_accuracy: 0.7116\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 653us/step - loss: 0.5909 - accuracy: 0.7578 - val_loss: 0.6603 - val_accuracy: 0.7163\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5896 - accuracy: 0.7593 - val_loss: 0.6492 - val_accuracy: 0.7349\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5862 - accuracy: 0.7541 - val_loss: 0.6518 - val_accuracy: 0.7116\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.5873 - accuracy: 0.7510 - val_loss: 0.6541 - val_accuracy: 0.7163\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.5850 - accuracy: 0.7521 - val_loss: 0.6633 - val_accuracy: 0.7116\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 735us/step - loss: 0.5846 - accuracy: 0.7536 - val_loss: 0.6612 - val_accuracy: 0.7256\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.5888 - accuracy: 0.7557 - val_loss: 0.6452 - val_accuracy: 0.7163\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 754us/step - loss: 0.5863 - accuracy: 0.7552 - val_loss: 0.6527 - val_accuracy: 0.7163\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.5845 - accuracy: 0.7531 - val_loss: 0.6598 - val_accuracy: 0.7023\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 763us/step - loss: 0.5852 - accuracy: 0.7573 - val_loss: 0.6547 - val_accuracy: 0.7070\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 770us/step - loss: 0.5824 - accuracy: 0.7567 - val_loss: 0.6809 - val_accuracy: 0.6930\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.5832 - accuracy: 0.7578 - val_loss: 0.6550 - val_accuracy: 0.7070\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.7578 - val_loss: 0.6556 - val_accuracy: 0.7488\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 681us/step - loss: 0.5838 - accuracy: 0.7521 - val_loss: 0.6496 - val_accuracy: 0.7070\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5842 - accuracy: 0.7562 - val_loss: 0.6592 - val_accuracy: 0.7116\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5796 - accuracy: 0.7588 - val_loss: 0.6740 - val_accuracy: 0.7163\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5791 - accuracy: 0.7536 - val_loss: 0.6720 - val_accuracy: 0.7209\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5813 - accuracy: 0.7562 - val_loss: 0.6562 - val_accuracy: 0.7116\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5819 - accuracy: 0.7583 - val_loss: 0.6452 - val_accuracy: 0.7163\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.5815 - accuracy: 0.7588 - val_loss: 0.6615 - val_accuracy: 0.7023\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 770us/step - loss: 0.5789 - accuracy: 0.7604 - val_loss: 0.6554 - val_accuracy: 0.7395\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.5791 - accuracy: 0.7578 - val_loss: 0.6506 - val_accuracy: 0.7256\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.5772 - accuracy: 0.7578 - val_loss: 0.6647 - val_accuracy: 0.6930\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 742us/step - loss: 0.5848 - accuracy: 0.7495 - val_loss: 0.6431 - val_accuracy: 0.7116\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.5770 - accuracy: 0.7588 - val_loss: 0.6583 - val_accuracy: 0.7023\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5794 - accuracy: 0.7609 - val_loss: 0.6611 - val_accuracy: 0.7256\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5792 - accuracy: 0.7588 - val_loss: 0.6657 - val_accuracy: 0.7395\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5784 - accuracy: 0.7557 - val_loss: 0.6518 - val_accuracy: 0.7116\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5789 - accuracy: 0.7650 - val_loss: 0.6555 - val_accuracy: 0.7163\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5736 - accuracy: 0.7578 - val_loss: 0.6624 - val_accuracy: 0.6977\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5753 - accuracy: 0.7666 - val_loss: 0.6513 - val_accuracy: 0.7070\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5764 - accuracy: 0.7593 - val_loss: 0.6523 - val_accuracy: 0.7023\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5735 - accuracy: 0.7609 - val_loss: 0.6658 - val_accuracy: 0.7256\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5768 - accuracy: 0.7604 - val_loss: 0.6645 - val_accuracy: 0.7023\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5783 - accuracy: 0.7562 - val_loss: 0.6468 - val_accuracy: 0.7116\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5732 - accuracy: 0.7635 - val_loss: 0.6851 - val_accuracy: 0.6791\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5753 - accuracy: 0.7650 - val_loss: 0.6465 - val_accuracy: 0.7163\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5728 - accuracy: 0.7588 - val_loss: 0.6700 - val_accuracy: 0.6930\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5745 - accuracy: 0.7630 - val_loss: 0.6475 - val_accuracy: 0.7163\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5737 - accuracy: 0.7573 - val_loss: 0.6580 - val_accuracy: 0.7488\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5702 - accuracy: 0.7661 - val_loss: 0.6998 - val_accuracy: 0.7163\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5728 - accuracy: 0.7583 - val_loss: 0.6766 - val_accuracy: 0.7163\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5706 - accuracy: 0.7645 - val_loss: 0.6411 - val_accuracy: 0.7395\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5720 - accuracy: 0.7599 - val_loss: 0.6728 - val_accuracy: 0.7256\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5700 - accuracy: 0.7573 - val_loss: 0.6509 - val_accuracy: 0.7209\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5681 - accuracy: 0.7609 - val_loss: 0.6452 - val_accuracy: 0.7256\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5667 - accuracy: 0.7671 - val_loss: 0.6594 - val_accuracy: 0.7116\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5704 - accuracy: 0.7588 - val_loss: 0.6566 - val_accuracy: 0.7116\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5725 - accuracy: 0.7687 - val_loss: 0.6446 - val_accuracy: 0.7302\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.5684 - accuracy: 0.7687 - val_loss: 0.6546 - val_accuracy: 0.7163\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5657 - accuracy: 0.7640 - val_loss: 0.6448 - val_accuracy: 0.7395\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5687 - accuracy: 0.7614 - val_loss: 0.6467 - val_accuracy: 0.7256\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5681 - accuracy: 0.7656 - val_loss: 0.6577 - val_accuracy: 0.7023\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5665 - accuracy: 0.7661 - val_loss: 0.6483 - val_accuracy: 0.7116\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5719 - accuracy: 0.7619 - val_loss: 0.6540 - val_accuracy: 0.7302\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5669 - accuracy: 0.7656 - val_loss: 0.6513 - val_accuracy: 0.7116\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.5665 - accuracy: 0.7599 - val_loss: 0.6422 - val_accuracy: 0.7442\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5668 - accuracy: 0.7682 - val_loss: 0.6456 - val_accuracy: 0.7163\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5658 - accuracy: 0.7645 - val_loss: 0.6544 - val_accuracy: 0.7023\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 777us/step - loss: 0.5675 - accuracy: 0.7593 - val_loss: 0.6665 - val_accuracy: 0.7256\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 717us/step - loss: 0.5688 - accuracy: 0.7614 - val_loss: 0.6552 - val_accuracy: 0.7070\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.5666 - accuracy: 0.7609 - val_loss: 0.6462 - val_accuracy: 0.7442\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 769us/step - loss: 0.5654 - accuracy: 0.7640 - val_loss: 0.6590 - val_accuracy: 0.7302\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.5654 - accuracy: 0.7635 - val_loss: 0.6662 - val_accuracy: 0.7209\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5674 - accuracy: 0.7661 - val_loss: 0.6426 - val_accuracy: 0.7116\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5622 - accuracy: 0.7656 - val_loss: 0.6551 - val_accuracy: 0.7349\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5619 - accuracy: 0.7682 - val_loss: 0.6481 - val_accuracy: 0.7302\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5636 - accuracy: 0.7593 - val_loss: 0.6465 - val_accuracy: 0.7070\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 967us/step - loss: 0.5661 - accuracy: 0.7562 - val_loss: 0.6519 - val_accuracy: 0.6977\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5586 - accuracy: 0.7661 - val_loss: 0.6508 - val_accuracy: 0.7070\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5621 - accuracy: 0.7661 - val_loss: 0.6475 - val_accuracy: 0.7256\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5612 - accuracy: 0.7609 - val_loss: 0.6637 - val_accuracy: 0.6930\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 719us/step - loss: 0.5638 - accuracy: 0.7697 - val_loss: 0.6467 - val_accuracy: 0.7302\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.5596 - accuracy: 0.7656 - val_loss: 0.6506 - val_accuracy: 0.7209\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5616 - accuracy: 0.7619 - val_loss: 0.6474 - val_accuracy: 0.7070\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5616 - accuracy: 0.7609 - val_loss: 0.6508 - val_accuracy: 0.7349\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5642 - accuracy: 0.7687 - val_loss: 0.6516 - val_accuracy: 0.7163\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5625 - accuracy: 0.7687 - val_loss: 0.6514 - val_accuracy: 0.7070\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5605 - accuracy: 0.7630 - val_loss: 0.6491 - val_accuracy: 0.7395\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.5605 - accuracy: 0.7692 - val_loss: 0.6529 - val_accuracy: 0.7395\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.5623 - accuracy: 0.7707 - val_loss: 0.6448 - val_accuracy: 0.7488\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5632 - accuracy: 0.7697 - val_loss: 0.6615 - val_accuracy: 0.7349\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5579 - accuracy: 0.7754 - val_loss: 0.6553 - val_accuracy: 0.7302\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5570 - accuracy: 0.7692 - val_loss: 0.6517 - val_accuracy: 0.7163\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5589 - accuracy: 0.7682 - val_loss: 0.6455 - val_accuracy: 0.7163\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5558 - accuracy: 0.7682 - val_loss: 0.6575 - val_accuracy: 0.7116\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5561 - accuracy: 0.7707 - val_loss: 0.6390 - val_accuracy: 0.7163\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 773us/step - loss: 0.5629 - accuracy: 0.7630 - val_loss: 0.6475 - val_accuracy: 0.7488\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7645 - val_loss: 0.6390 - val_accuracy: 0.7535\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5597 - accuracy: 0.7645 - val_loss: 0.6460 - val_accuracy: 0.7256\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5613 - accuracy: 0.7671 - val_loss: 0.6562 - val_accuracy: 0.7070\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5580 - accuracy: 0.7645 - val_loss: 0.6389 - val_accuracy: 0.7256\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5553 - accuracy: 0.7682 - val_loss: 0.6466 - val_accuracy: 0.7116\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5560 - accuracy: 0.7702 - val_loss: 0.6578 - val_accuracy: 0.7116\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5575 - accuracy: 0.7682 - val_loss: 0.6407 - val_accuracy: 0.7442\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 839us/step - loss: 0.5570 - accuracy: 0.7676 - val_loss: 0.6511 - val_accuracy: 0.7116\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5562 - accuracy: 0.7682 - val_loss: 0.6510 - val_accuracy: 0.7163\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5522 - accuracy: 0.7718 - val_loss: 0.6682 - val_accuracy: 0.6930\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5575 - accuracy: 0.7656 - val_loss: 0.6633 - val_accuracy: 0.6930\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.5522 - accuracy: 0.7676 - val_loss: 0.6366 - val_accuracy: 0.7302\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5548 - accuracy: 0.7671 - val_loss: 0.6441 - val_accuracy: 0.7116\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5552 - accuracy: 0.7676 - val_loss: 0.6366 - val_accuracy: 0.7488\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5557 - accuracy: 0.7645 - val_loss: 0.6445 - val_accuracy: 0.7163\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5525 - accuracy: 0.7666 - val_loss: 0.6525 - val_accuracy: 0.7442\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5538 - accuracy: 0.7697 - val_loss: 0.6503 - val_accuracy: 0.7395\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5563 - accuracy: 0.7676 - val_loss: 0.6538 - val_accuracy: 0.7023\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5540 - accuracy: 0.7682 - val_loss: 0.6725 - val_accuracy: 0.6977\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.5532 - accuracy: 0.7702 - val_loss: 0.6495 - val_accuracy: 0.7023\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.5507 - accuracy: 0.7676 - val_loss: 0.6387 - val_accuracy: 0.7163\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.5512 - accuracy: 0.7702 - val_loss: 0.6625 - val_accuracy: 0.7302\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 707us/step - loss: 0.5505 - accuracy: 0.7692 - val_loss: 0.6511 - val_accuracy: 0.7349\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.5521 - accuracy: 0.7723 - val_loss: 0.6433 - val_accuracy: 0.7209\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.5532 - accuracy: 0.7650 - val_loss: 0.6557 - val_accuracy: 0.7070\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.5530 - accuracy: 0.7765 - val_loss: 0.6462 - val_accuracy: 0.7116\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5498 - accuracy: 0.7635 - val_loss: 0.6785 - val_accuracy: 0.6837\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5545 - accuracy: 0.7702 - val_loss: 0.6873 - val_accuracy: 0.6884\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.5550 - accuracy: 0.7687 - val_loss: 0.6520 - val_accuracy: 0.7070\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5508 - accuracy: 0.7635 - val_loss: 0.6595 - val_accuracy: 0.7116\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5523 - accuracy: 0.7666 - val_loss: 0.6415 - val_accuracy: 0.7163\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5518 - accuracy: 0.7707 - val_loss: 0.6470 - val_accuracy: 0.7116\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5490 - accuracy: 0.7697 - val_loss: 0.6510 - val_accuracy: 0.7116\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5492 - accuracy: 0.7687 - val_loss: 0.6555 - val_accuracy: 0.7349\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5525 - accuracy: 0.7692 - val_loss: 0.6538 - val_accuracy: 0.7209\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.5500 - accuracy: 0.7733 - val_loss: 0.6438 - val_accuracy: 0.7395\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5515 - accuracy: 0.7645 - val_loss: 0.6495 - val_accuracy: 0.7395\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5507 - accuracy: 0.7692 - val_loss: 0.6314 - val_accuracy: 0.7256\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5499 - accuracy: 0.7754 - val_loss: 0.6601 - val_accuracy: 0.7209\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5537 - accuracy: 0.7656 - val_loss: 0.6452 - val_accuracy: 0.7395\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5466 - accuracy: 0.7713 - val_loss: 0.6707 - val_accuracy: 0.7209\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5486 - accuracy: 0.7728 - val_loss: 0.6539 - val_accuracy: 0.7488\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5488 - accuracy: 0.7687 - val_loss: 0.6785 - val_accuracy: 0.6884\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5500 - accuracy: 0.7713 - val_loss: 0.6502 - val_accuracy: 0.7070\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5471 - accuracy: 0.7692 - val_loss: 0.6493 - val_accuracy: 0.7070\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5485 - accuracy: 0.7739 - val_loss: 0.6543 - val_accuracy: 0.7349\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5509 - accuracy: 0.7718 - val_loss: 0.6652 - val_accuracy: 0.7023\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5496 - accuracy: 0.7765 - val_loss: 0.6403 - val_accuracy: 0.7488\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5479 - accuracy: 0.7733 - val_loss: 0.6405 - val_accuracy: 0.7395\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5466 - accuracy: 0.7723 - val_loss: 0.6407 - val_accuracy: 0.7349\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5509 - accuracy: 0.7744 - val_loss: 0.6448 - val_accuracy: 0.7395\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5463 - accuracy: 0.7702 - val_loss: 0.6656 - val_accuracy: 0.7116\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5440 - accuracy: 0.7697 - val_loss: 0.6610 - val_accuracy: 0.7256\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5508 - accuracy: 0.7728 - val_loss: 0.6506 - val_accuracy: 0.7209\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5450 - accuracy: 0.7713 - val_loss: 0.6719 - val_accuracy: 0.7163\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5463 - accuracy: 0.7713 - val_loss: 0.6482 - val_accuracy: 0.7116\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5478 - accuracy: 0.7702 - val_loss: 0.6491 - val_accuracy: 0.7209\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5483 - accuracy: 0.7775 - val_loss: 0.6502 - val_accuracy: 0.7395\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5481 - accuracy: 0.7661 - val_loss: 0.6489 - val_accuracy: 0.7256\n",
      "Epoch 369/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5495 - accuracy: 0.7671 - val_loss: 0.6572 - val_accuracy: 0.7163\n",
      "Epoch 370/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5467 - accuracy: 0.7749 - val_loss: 0.6446 - val_accuracy: 0.7302\n",
      "Epoch 371/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5443 - accuracy: 0.7759 - val_loss: 0.6677 - val_accuracy: 0.6977\n",
      "Epoch 372/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5482 - accuracy: 0.7676 - val_loss: 0.6479 - val_accuracy: 0.7116\n",
      "Epoch 373/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5440 - accuracy: 0.7713 - val_loss: 0.6597 - val_accuracy: 0.7209\n",
      "Epoch 374/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5462 - accuracy: 0.7692 - val_loss: 0.6745 - val_accuracy: 0.7209\n",
      "Epoch 375/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5488 - accuracy: 0.7723 - val_loss: 0.6699 - val_accuracy: 0.7256\n",
      "Epoch 376/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5448 - accuracy: 0.7707 - val_loss: 0.6505 - val_accuracy: 0.7302\n",
      "Epoch 377/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.5470 - accuracy: 0.7713 - val_loss: 0.6548 - val_accuracy: 0.7163\n",
      "Epoch 378/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5426 - accuracy: 0.7749 - val_loss: 0.6458 - val_accuracy: 0.7395\n",
      "Epoch 379/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5436 - accuracy: 0.7770 - val_loss: 0.6411 - val_accuracy: 0.7349\n",
      "Epoch 380/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.5417 - accuracy: 0.7785 - val_loss: 0.6534 - val_accuracy: 0.7116\n",
      "Epoch 381/500\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.5443 - accuracy: 0.7728 - val_loss: 0.6593 - val_accuracy: 0.7256\n",
      "Epoch 382/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.5445 - accuracy: 0.7759 - val_loss: 0.6458 - val_accuracy: 0.7116\n",
      "Epoch 383/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5447 - accuracy: 0.7733 - val_loss: 0.6430 - val_accuracy: 0.7442\n",
      "Epoch 384/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5437 - accuracy: 0.7785 - val_loss: 0.6579 - val_accuracy: 0.6977\n",
      "Epoch 385/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5448 - accuracy: 0.7697 - val_loss: 0.6780 - val_accuracy: 0.7023\n",
      "Epoch 386/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5475 - accuracy: 0.7707 - val_loss: 0.6558 - val_accuracy: 0.7116\n",
      "Epoch 387/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5418 - accuracy: 0.7713 - val_loss: 0.6405 - val_accuracy: 0.7395\n",
      "Epoch 388/500\n",
      "72/72 [==============================] - 0s 700us/step - loss: 0.5437 - accuracy: 0.7744 - val_loss: 0.6381 - val_accuracy: 0.7256\n",
      "Epoch 389/500\n",
      "72/72 [==============================] - 0s 963us/step - loss: 0.5446 - accuracy: 0.7697 - val_loss: 0.6628 - val_accuracy: 0.7302\n",
      "Epoch 390/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5416 - accuracy: 0.7765 - val_loss: 0.6336 - val_accuracy: 0.7256\n",
      "Epoch 391/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5442 - accuracy: 0.7718 - val_loss: 0.6489 - val_accuracy: 0.7302\n",
      "Epoch 392/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5446 - accuracy: 0.7759 - val_loss: 0.6405 - val_accuracy: 0.7116\n",
      "Epoch 393/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5430 - accuracy: 0.7744 - val_loss: 0.6577 - val_accuracy: 0.7256\n",
      "Epoch 394/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5400 - accuracy: 0.7728 - val_loss: 0.6429 - val_accuracy: 0.7209\n",
      "Epoch 395/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.5406 - accuracy: 0.7744 - val_loss: 0.6536 - val_accuracy: 0.7395\n",
      "Epoch 396/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5425 - accuracy: 0.7780 - val_loss: 0.6394 - val_accuracy: 0.7256\n",
      "Epoch 397/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5417 - accuracy: 0.7765 - val_loss: 0.6378 - val_accuracy: 0.7395\n",
      "Epoch 398/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5457 - accuracy: 0.7749 - val_loss: 0.6506 - val_accuracy: 0.7395\n",
      "Epoch 399/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5415 - accuracy: 0.7723 - val_loss: 0.6304 - val_accuracy: 0.7302\n",
      "Epoch 400/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5413 - accuracy: 0.7697 - val_loss: 0.6485 - val_accuracy: 0.7488\n",
      "Epoch 401/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5421 - accuracy: 0.7790 - val_loss: 0.6499 - val_accuracy: 0.7163\n",
      "Epoch 402/500\n",
      "72/72 [==============================] - 0s 780us/step - loss: 0.5412 - accuracy: 0.7759 - val_loss: 0.6630 - val_accuracy: 0.7302\n",
      "Epoch 403/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5393 - accuracy: 0.7728 - val_loss: 0.6466 - val_accuracy: 0.7256\n",
      "Epoch 404/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5398 - accuracy: 0.7775 - val_loss: 0.6441 - val_accuracy: 0.7116\n",
      "Epoch 405/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5396 - accuracy: 0.7754 - val_loss: 0.6344 - val_accuracy: 0.7116\n",
      "Epoch 406/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5428 - accuracy: 0.7713 - val_loss: 0.6403 - val_accuracy: 0.7535\n",
      "Epoch 407/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5391 - accuracy: 0.7754 - val_loss: 0.6708 - val_accuracy: 0.7302\n",
      "Epoch 408/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5395 - accuracy: 0.7785 - val_loss: 0.6542 - val_accuracy: 0.7209\n",
      "Epoch 409/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5421 - accuracy: 0.7759 - val_loss: 0.6841 - val_accuracy: 0.7070\n",
      "Epoch 410/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5440 - accuracy: 0.7801 - val_loss: 0.6478 - val_accuracy: 0.7302\n",
      "Epoch 410: early stopping\n",
      "29/29 - 0s - loss: 0.5337 - accuracy: 0.7713 - 111ms/epoch - 4ms/step\n",
      "6\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 1s 4ms/step - loss: 1.5644 - accuracy: 0.2614 - val_loss: 1.4685 - val_accuracy: 0.4558\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.4075 - accuracy: 0.4398 - val_loss: 1.3366 - val_accuracy: 0.4744\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 1.3029 - accuracy: 0.4585 - val_loss: 1.2656 - val_accuracy: 0.4512\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 1.2493 - accuracy: 0.4730 - val_loss: 1.2364 - val_accuracy: 0.4512\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2213 - accuracy: 0.4808 - val_loss: 1.1952 - val_accuracy: 0.4791\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1940 - accuracy: 0.4876 - val_loss: 1.1856 - val_accuracy: 0.4837\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1723 - accuracy: 0.4927 - val_loss: 1.1582 - val_accuracy: 0.4977\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1483 - accuracy: 0.5130 - val_loss: 1.1561 - val_accuracy: 0.5116\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1208 - accuracy: 0.5296 - val_loss: 1.1218 - val_accuracy: 0.5256\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 1.0977 - accuracy: 0.5446 - val_loss: 1.1034 - val_accuracy: 0.5209\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0750 - accuracy: 0.5519 - val_loss: 1.0671 - val_accuracy: 0.5628\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0519 - accuracy: 0.5607 - val_loss: 1.0519 - val_accuracy: 0.5674\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 1.0276 - accuracy: 0.5731 - val_loss: 1.0403 - val_accuracy: 0.5302\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0038 - accuracy: 0.5882 - val_loss: 1.0025 - val_accuracy: 0.5907\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.9814 - accuracy: 0.5913 - val_loss: 0.9769 - val_accuracy: 0.5907\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.9593 - accuracy: 0.6074 - val_loss: 0.9798 - val_accuracy: 0.5814\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9485 - accuracy: 0.6089 - val_loss: 0.9505 - val_accuracy: 0.6233\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.9271 - accuracy: 0.6141 - val_loss: 0.9251 - val_accuracy: 0.6047\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.9121 - accuracy: 0.6193 - val_loss: 0.9094 - val_accuracy: 0.6093\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8932 - accuracy: 0.6343 - val_loss: 0.8927 - val_accuracy: 0.6093\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.8845 - accuracy: 0.6338 - val_loss: 0.8952 - val_accuracy: 0.6233\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.8708 - accuracy: 0.6494 - val_loss: 0.9026 - val_accuracy: 0.6047\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8584 - accuracy: 0.6525 - val_loss: 0.8713 - val_accuracy: 0.6093\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8576 - accuracy: 0.6442 - val_loss: 0.8568 - val_accuracy: 0.6186\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8461 - accuracy: 0.6546 - val_loss: 0.8491 - val_accuracy: 0.6186\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.8382 - accuracy: 0.6556 - val_loss: 0.8702 - val_accuracy: 0.6093\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8339 - accuracy: 0.6546 - val_loss: 0.8468 - val_accuracy: 0.6233\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.8245 - accuracy: 0.6582 - val_loss: 0.8409 - val_accuracy: 0.6186\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8291 - accuracy: 0.6530 - val_loss: 0.8283 - val_accuracy: 0.6326\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8173 - accuracy: 0.6655 - val_loss: 0.8351 - val_accuracy: 0.6186\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.8174 - accuracy: 0.6598 - val_loss: 0.8363 - val_accuracy: 0.6093\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.8104 - accuracy: 0.6665 - val_loss: 0.8388 - val_accuracy: 0.6140\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8035 - accuracy: 0.6623 - val_loss: 0.8178 - val_accuracy: 0.6372\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8025 - accuracy: 0.6623 - val_loss: 0.8158 - val_accuracy: 0.6419\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.8062 - accuracy: 0.6680 - val_loss: 0.8178 - val_accuracy: 0.6140\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7977 - accuracy: 0.6722 - val_loss: 0.8220 - val_accuracy: 0.6186\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.7905 - accuracy: 0.6696 - val_loss: 0.8270 - val_accuracy: 0.6233\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 769us/step - loss: 0.7895 - accuracy: 0.6748 - val_loss: 0.8128 - val_accuracy: 0.6233\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.7831 - accuracy: 0.6732 - val_loss: 0.8167 - val_accuracy: 0.6419\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 700us/step - loss: 0.7865 - accuracy: 0.6769 - val_loss: 0.8196 - val_accuracy: 0.6372\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 751us/step - loss: 0.7801 - accuracy: 0.6738 - val_loss: 0.8023 - val_accuracy: 0.6326\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 921us/step - loss: 0.7782 - accuracy: 0.6763 - val_loss: 0.8073 - val_accuracy: 0.6326\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.7771 - accuracy: 0.6748 - val_loss: 0.8084 - val_accuracy: 0.6372\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7771 - accuracy: 0.6732 - val_loss: 0.8337 - val_accuracy: 0.6279\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7745 - accuracy: 0.6800 - val_loss: 0.8076 - val_accuracy: 0.6233\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 771us/step - loss: 0.7656 - accuracy: 0.6810 - val_loss: 0.8433 - val_accuracy: 0.6093\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 878us/step - loss: 0.7692 - accuracy: 0.6810 - val_loss: 0.7996 - val_accuracy: 0.6372\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 934us/step - loss: 0.7635 - accuracy: 0.6815 - val_loss: 0.8188 - val_accuracy: 0.6419\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.7668 - accuracy: 0.6763 - val_loss: 0.8037 - val_accuracy: 0.6372\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.7592 - accuracy: 0.6872 - val_loss: 0.7937 - val_accuracy: 0.6372\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7554 - accuracy: 0.6883 - val_loss: 0.7970 - val_accuracy: 0.6186\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7555 - accuracy: 0.6893 - val_loss: 0.8005 - val_accuracy: 0.6326\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7502 - accuracy: 0.6852 - val_loss: 0.8057 - val_accuracy: 0.6233\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7530 - accuracy: 0.6826 - val_loss: 0.7999 - val_accuracy: 0.6465\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.7505 - accuracy: 0.6789 - val_loss: 0.8038 - val_accuracy: 0.6233\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 715us/step - loss: 0.7530 - accuracy: 0.6821 - val_loss: 0.8025 - val_accuracy: 0.6372\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 949us/step - loss: 0.7503 - accuracy: 0.6924 - val_loss: 0.8009 - val_accuracy: 0.6279\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7430 - accuracy: 0.6935 - val_loss: 0.7927 - val_accuracy: 0.6233\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7416 - accuracy: 0.6914 - val_loss: 0.7892 - val_accuracy: 0.6233\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7422 - accuracy: 0.6950 - val_loss: 0.7919 - val_accuracy: 0.6326\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7427 - accuracy: 0.6935 - val_loss: 0.7952 - val_accuracy: 0.6279\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7447 - accuracy: 0.6898 - val_loss: 0.7913 - val_accuracy: 0.6326\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7325 - accuracy: 0.6950 - val_loss: 0.8145 - val_accuracy: 0.6140\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 721us/step - loss: 0.7388 - accuracy: 0.6893 - val_loss: 0.8073 - val_accuracy: 0.6233\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.7341 - accuracy: 0.6971 - val_loss: 0.7797 - val_accuracy: 0.6279\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.7289 - accuracy: 0.6966 - val_loss: 0.7792 - val_accuracy: 0.6326\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.7274 - accuracy: 0.7033 - val_loss: 0.7861 - val_accuracy: 0.6279\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7292 - accuracy: 0.6981 - val_loss: 0.7819 - val_accuracy: 0.6372\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.7288 - accuracy: 0.7018 - val_loss: 0.7831 - val_accuracy: 0.6326\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7236 - accuracy: 0.6971 - val_loss: 0.7899 - val_accuracy: 0.6233\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7240 - accuracy: 0.6987 - val_loss: 0.7913 - val_accuracy: 0.6419\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7188 - accuracy: 0.7033 - val_loss: 0.7834 - val_accuracy: 0.6372\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.7186 - accuracy: 0.7038 - val_loss: 0.7820 - val_accuracy: 0.6372\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7179 - accuracy: 0.7018 - val_loss: 0.8053 - val_accuracy: 0.6233\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7199 - accuracy: 0.6966 - val_loss: 0.7765 - val_accuracy: 0.6465\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.7059 - val_loss: 0.7656 - val_accuracy: 0.6512\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.7159 - accuracy: 0.7012 - val_loss: 0.7723 - val_accuracy: 0.6698\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7138 - accuracy: 0.7038 - val_loss: 0.7807 - val_accuracy: 0.6326\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.7138 - accuracy: 0.7075 - val_loss: 0.7639 - val_accuracy: 0.6512\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.7095 - accuracy: 0.7033 - val_loss: 0.7721 - val_accuracy: 0.6372\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7087 - accuracy: 0.7044 - val_loss: 0.7743 - val_accuracy: 0.6558\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.7093 - accuracy: 0.7075 - val_loss: 0.7751 - val_accuracy: 0.6419\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.7040 - accuracy: 0.7090 - val_loss: 0.7838 - val_accuracy: 0.6651\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7046 - accuracy: 0.7038 - val_loss: 0.7663 - val_accuracy: 0.6465\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 928us/step - loss: 0.7021 - accuracy: 0.7070 - val_loss: 0.7624 - val_accuracy: 0.6558\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7004 - accuracy: 0.7095 - val_loss: 0.7618 - val_accuracy: 0.6605\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7036 - accuracy: 0.7132 - val_loss: 0.7553 - val_accuracy: 0.6651\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6982 - accuracy: 0.7111 - val_loss: 0.7582 - val_accuracy: 0.6605\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6970 - accuracy: 0.7064 - val_loss: 0.7595 - val_accuracy: 0.6512\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.7012 - accuracy: 0.7085 - val_loss: 0.7631 - val_accuracy: 0.6558\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.6950 - accuracy: 0.7173 - val_loss: 0.7687 - val_accuracy: 0.6326\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6958 - accuracy: 0.7132 - val_loss: 0.7582 - val_accuracy: 0.6512\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6944 - accuracy: 0.7137 - val_loss: 0.7901 - val_accuracy: 0.6279\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 674us/step - loss: 0.6947 - accuracy: 0.7184 - val_loss: 0.7620 - val_accuracy: 0.6465\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6925 - accuracy: 0.7095 - val_loss: 0.7594 - val_accuracy: 0.6651\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6882 - accuracy: 0.7184 - val_loss: 0.7582 - val_accuracy: 0.6512\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6854 - accuracy: 0.7137 - val_loss: 0.7562 - val_accuracy: 0.6558\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 757us/step - loss: 0.6897 - accuracy: 0.7132 - val_loss: 0.7514 - val_accuracy: 0.6512\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.6866 - accuracy: 0.7246 - val_loss: 0.7726 - val_accuracy: 0.6419\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.6824 - accuracy: 0.7132 - val_loss: 0.7413 - val_accuracy: 0.6651\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6860 - accuracy: 0.7220 - val_loss: 0.7732 - val_accuracy: 0.6651\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6927 - accuracy: 0.7090 - val_loss: 0.7403 - val_accuracy: 0.6605\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.6784 - accuracy: 0.7127 - val_loss: 0.7521 - val_accuracy: 0.6419\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.6817 - accuracy: 0.7158 - val_loss: 0.7387 - val_accuracy: 0.6605\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.7189 - val_loss: 0.7754 - val_accuracy: 0.6744\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.6812 - accuracy: 0.7230 - val_loss: 0.7462 - val_accuracy: 0.6605\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.7152 - val_loss: 0.7377 - val_accuracy: 0.6791\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.6710 - accuracy: 0.7173 - val_loss: 0.7712 - val_accuracy: 0.6605\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.6737 - accuracy: 0.7235 - val_loss: 0.7525 - val_accuracy: 0.6372\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.6739 - accuracy: 0.7241 - val_loss: 0.7365 - val_accuracy: 0.6744\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.7298 - val_loss: 0.7349 - val_accuracy: 0.6837\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 691us/step - loss: 0.6752 - accuracy: 0.7230 - val_loss: 0.7395 - val_accuracy: 0.6651\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.6714 - accuracy: 0.7204 - val_loss: 0.7398 - val_accuracy: 0.6651\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6682 - accuracy: 0.7204 - val_loss: 0.7313 - val_accuracy: 0.6744\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 752us/step - loss: 0.6664 - accuracy: 0.7225 - val_loss: 0.7276 - val_accuracy: 0.6791\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 883us/step - loss: 0.6662 - accuracy: 0.7298 - val_loss: 0.7326 - val_accuracy: 0.6837\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.7230 - val_loss: 0.7272 - val_accuracy: 0.6884\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6659 - accuracy: 0.7256 - val_loss: 0.7347 - val_accuracy: 0.6791\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 987us/step - loss: 0.6644 - accuracy: 0.7220 - val_loss: 0.7293 - val_accuracy: 0.6791\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.6619 - accuracy: 0.7287 - val_loss: 0.7356 - val_accuracy: 0.6744\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 683us/step - loss: 0.6604 - accuracy: 0.7282 - val_loss: 0.7345 - val_accuracy: 0.6698\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 770us/step - loss: 0.6575 - accuracy: 0.7251 - val_loss: 0.7245 - val_accuracy: 0.6884\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 879us/step - loss: 0.6670 - accuracy: 0.7261 - val_loss: 0.7197 - val_accuracy: 0.6791\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.6582 - accuracy: 0.7303 - val_loss: 0.7290 - val_accuracy: 0.6744\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.6570 - accuracy: 0.7365 - val_loss: 0.7219 - val_accuracy: 0.6791\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 717us/step - loss: 0.6553 - accuracy: 0.7230 - val_loss: 0.7279 - val_accuracy: 0.6698\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 973us/step - loss: 0.6548 - accuracy: 0.7308 - val_loss: 0.7238 - val_accuracy: 0.6698\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.7230 - val_loss: 0.7422 - val_accuracy: 0.6930\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6549 - accuracy: 0.7272 - val_loss: 0.7219 - val_accuracy: 0.6884\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6537 - accuracy: 0.7251 - val_loss: 0.7133 - val_accuracy: 0.6930\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6520 - accuracy: 0.7282 - val_loss: 0.7141 - val_accuracy: 0.6884\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6495 - accuracy: 0.7334 - val_loss: 0.7116 - val_accuracy: 0.6791\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6533 - accuracy: 0.7293 - val_loss: 0.7142 - val_accuracy: 0.6837\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.6499 - accuracy: 0.7287 - val_loss: 0.7156 - val_accuracy: 0.6884\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.7350 - val_loss: 0.7122 - val_accuracy: 0.6837\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.6479 - accuracy: 0.7329 - val_loss: 0.7164 - val_accuracy: 0.6884\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6465 - accuracy: 0.7287 - val_loss: 0.7036 - val_accuracy: 0.6791\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6463 - accuracy: 0.7293 - val_loss: 0.7064 - val_accuracy: 0.6791\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6449 - accuracy: 0.7303 - val_loss: 0.7130 - val_accuracy: 0.6930\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6439 - accuracy: 0.7308 - val_loss: 0.7496 - val_accuracy: 0.6558\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.7313 - val_loss: 0.7118 - val_accuracy: 0.7070\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 858us/step - loss: 0.6412 - accuracy: 0.7313 - val_loss: 0.7122 - val_accuracy: 0.6837\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6428 - accuracy: 0.7230 - val_loss: 0.7119 - val_accuracy: 0.6837\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 742us/step - loss: 0.6435 - accuracy: 0.7344 - val_loss: 0.7075 - val_accuracy: 0.6837\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 884us/step - loss: 0.6398 - accuracy: 0.7370 - val_loss: 0.7161 - val_accuracy: 0.6837\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.6392 - accuracy: 0.7339 - val_loss: 0.7145 - val_accuracy: 0.6977\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 883us/step - loss: 0.6445 - accuracy: 0.7308 - val_loss: 0.7249 - val_accuracy: 0.6791\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6379 - accuracy: 0.7261 - val_loss: 0.7063 - val_accuracy: 0.6837\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6330 - accuracy: 0.7401 - val_loss: 0.7087 - val_accuracy: 0.6884\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6423 - accuracy: 0.7350 - val_loss: 0.6966 - val_accuracy: 0.6837\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6365 - accuracy: 0.7370 - val_loss: 0.7124 - val_accuracy: 0.6791\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6397 - accuracy: 0.7355 - val_loss: 0.7268 - val_accuracy: 0.6744\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6342 - accuracy: 0.7350 - val_loss: 0.7042 - val_accuracy: 0.6884\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.6322 - accuracy: 0.7324 - val_loss: 0.7065 - val_accuracy: 0.6930\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6313 - accuracy: 0.7350 - val_loss: 0.7096 - val_accuracy: 0.6837\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6365 - accuracy: 0.7339 - val_loss: 0.6896 - val_accuracy: 0.7070\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6329 - accuracy: 0.7350 - val_loss: 0.7215 - val_accuracy: 0.6698\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6347 - accuracy: 0.7360 - val_loss: 0.7219 - val_accuracy: 0.6791\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6316 - accuracy: 0.7365 - val_loss: 0.6965 - val_accuracy: 0.6837\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6281 - accuracy: 0.7438 - val_loss: 0.6877 - val_accuracy: 0.6930\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6347 - accuracy: 0.7386 - val_loss: 0.7023 - val_accuracy: 0.7070\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 698us/step - loss: 0.6296 - accuracy: 0.7407 - val_loss: 0.6894 - val_accuracy: 0.6930\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.6268 - accuracy: 0.7401 - val_loss: 0.6849 - val_accuracy: 0.6884\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 710us/step - loss: 0.6263 - accuracy: 0.7376 - val_loss: 0.6978 - val_accuracy: 0.6605\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 930us/step - loss: 0.6298 - accuracy: 0.7365 - val_loss: 0.6918 - val_accuracy: 0.6977\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 861us/step - loss: 0.6230 - accuracy: 0.7381 - val_loss: 0.6804 - val_accuracy: 0.7023\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6209 - accuracy: 0.7500 - val_loss: 0.6990 - val_accuracy: 0.6884\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6238 - accuracy: 0.7448 - val_loss: 0.6874 - val_accuracy: 0.6930\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.6219 - accuracy: 0.7448 - val_loss: 0.6858 - val_accuracy: 0.6884\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6240 - accuracy: 0.7412 - val_loss: 0.6907 - val_accuracy: 0.6930\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6214 - accuracy: 0.7350 - val_loss: 0.6930 - val_accuracy: 0.6744\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.7417 - val_loss: 0.6794 - val_accuracy: 0.7209\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6199 - accuracy: 0.7365 - val_loss: 0.6836 - val_accuracy: 0.6930\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6227 - accuracy: 0.7396 - val_loss: 0.7058 - val_accuracy: 0.6791\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6207 - accuracy: 0.7412 - val_loss: 0.6905 - val_accuracy: 0.6930\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6176 - accuracy: 0.7401 - val_loss: 0.6936 - val_accuracy: 0.7209\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6203 - accuracy: 0.7427 - val_loss: 0.6780 - val_accuracy: 0.6977\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6202 - accuracy: 0.7427 - val_loss: 0.6774 - val_accuracy: 0.7070\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6172 - accuracy: 0.7433 - val_loss: 0.6825 - val_accuracy: 0.7070\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.6164 - accuracy: 0.7453 - val_loss: 0.6870 - val_accuracy: 0.6791\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6172 - accuracy: 0.7350 - val_loss: 0.6734 - val_accuracy: 0.7023\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6163 - accuracy: 0.7427 - val_loss: 0.6952 - val_accuracy: 0.6698\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6141 - accuracy: 0.7396 - val_loss: 0.6905 - val_accuracy: 0.6884\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.6174 - accuracy: 0.7459 - val_loss: 0.6902 - val_accuracy: 0.6837\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6133 - accuracy: 0.7443 - val_loss: 0.6803 - val_accuracy: 0.6930\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6152 - accuracy: 0.7407 - val_loss: 0.6900 - val_accuracy: 0.6884\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6168 - accuracy: 0.7479 - val_loss: 0.6871 - val_accuracy: 0.6930\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.6130 - accuracy: 0.7459 - val_loss: 0.6830 - val_accuracy: 0.7023\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.6095 - accuracy: 0.7438 - val_loss: 0.7058 - val_accuracy: 0.7070\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6137 - accuracy: 0.7412 - val_loss: 0.6709 - val_accuracy: 0.7209\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6093 - accuracy: 0.7510 - val_loss: 0.6801 - val_accuracy: 0.7023\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6080 - accuracy: 0.7469 - val_loss: 0.6775 - val_accuracy: 0.6930\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6088 - accuracy: 0.7427 - val_loss: 0.6720 - val_accuracy: 0.7070\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6106 - accuracy: 0.7459 - val_loss: 0.6751 - val_accuracy: 0.7023\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.6074 - accuracy: 0.7448 - val_loss: 0.6692 - val_accuracy: 0.7023\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.6033 - accuracy: 0.7448 - val_loss: 0.6755 - val_accuracy: 0.6884\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6031 - accuracy: 0.7484 - val_loss: 0.7230 - val_accuracy: 0.6791\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6037 - accuracy: 0.7479 - val_loss: 0.6756 - val_accuracy: 0.7023\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.6022 - accuracy: 0.7422 - val_loss: 0.6780 - val_accuracy: 0.6930\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 752us/step - loss: 0.6074 - accuracy: 0.7407 - val_loss: 0.6742 - val_accuracy: 0.6977\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6056 - accuracy: 0.7453 - val_loss: 0.6774 - val_accuracy: 0.6977\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.6006 - accuracy: 0.7464 - val_loss: 0.6809 - val_accuracy: 0.6930\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.7526 - val_loss: 0.6722 - val_accuracy: 0.7302\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 982us/step - loss: 0.6019 - accuracy: 0.7448 - val_loss: 0.6949 - val_accuracy: 0.6791\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6013 - accuracy: 0.7479 - val_loss: 0.6715 - val_accuracy: 0.7070\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5972 - accuracy: 0.7500 - val_loss: 0.6832 - val_accuracy: 0.6884\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.6007 - accuracy: 0.7464 - val_loss: 0.6741 - val_accuracy: 0.7070\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.5975 - accuracy: 0.7510 - val_loss: 0.6649 - val_accuracy: 0.7163\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5997 - accuracy: 0.7448 - val_loss: 0.6810 - val_accuracy: 0.6884\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.6080 - accuracy: 0.7448 - val_loss: 0.6804 - val_accuracy: 0.6884\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.5981 - accuracy: 0.7422 - val_loss: 0.6734 - val_accuracy: 0.7209\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5932 - accuracy: 0.7516 - val_loss: 0.6650 - val_accuracy: 0.7163\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5981 - accuracy: 0.7521 - val_loss: 0.6645 - val_accuracy: 0.7209\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5922 - accuracy: 0.7541 - val_loss: 0.6964 - val_accuracy: 0.6930\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5936 - accuracy: 0.7484 - val_loss: 0.6737 - val_accuracy: 0.7209\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5968 - accuracy: 0.7474 - val_loss: 0.6877 - val_accuracy: 0.7023\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5978 - accuracy: 0.7505 - val_loss: 0.6802 - val_accuracy: 0.6930\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5930 - accuracy: 0.7464 - val_loss: 0.6662 - val_accuracy: 0.7023\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5933 - accuracy: 0.7541 - val_loss: 0.6682 - val_accuracy: 0.6884\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6005 - accuracy: 0.7500 - val_loss: 0.6652 - val_accuracy: 0.7070\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 778us/step - loss: 0.5910 - accuracy: 0.7541 - val_loss: 0.6718 - val_accuracy: 0.7070\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.5908 - accuracy: 0.7536 - val_loss: 0.6705 - val_accuracy: 0.7023\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.5893 - accuracy: 0.7521 - val_loss: 0.6658 - val_accuracy: 0.7116\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5892 - accuracy: 0.7547 - val_loss: 0.6573 - val_accuracy: 0.7256\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5898 - accuracy: 0.7547 - val_loss: 0.6665 - val_accuracy: 0.7023\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5859 - accuracy: 0.7510 - val_loss: 0.6985 - val_accuracy: 0.6837\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 771us/step - loss: 0.5865 - accuracy: 0.7583 - val_loss: 0.6703 - val_accuracy: 0.7023\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 740us/step - loss: 0.5874 - accuracy: 0.7516 - val_loss: 0.6783 - val_accuracy: 0.7023\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 959us/step - loss: 0.5888 - accuracy: 0.7536 - val_loss: 0.6684 - val_accuracy: 0.7023\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 848us/step - loss: 0.5849 - accuracy: 0.7557 - val_loss: 0.6836 - val_accuracy: 0.7163\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5844 - accuracy: 0.7562 - val_loss: 0.6648 - val_accuracy: 0.7163\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5833 - accuracy: 0.7479 - val_loss: 0.6671 - val_accuracy: 0.7070\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5830 - accuracy: 0.7541 - val_loss: 0.6663 - val_accuracy: 0.7302\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5808 - accuracy: 0.7541 - val_loss: 0.6710 - val_accuracy: 0.7116\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.5818 - accuracy: 0.7567 - val_loss: 0.6658 - val_accuracy: 0.7023\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 996us/step - loss: 0.5866 - accuracy: 0.7516 - val_loss: 0.6697 - val_accuracy: 0.7070\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5812 - accuracy: 0.7557 - val_loss: 0.6585 - val_accuracy: 0.7256\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5757 - accuracy: 0.7541 - val_loss: 0.7024 - val_accuracy: 0.7023\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5821 - accuracy: 0.7614 - val_loss: 0.6799 - val_accuracy: 0.7116\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.5837 - accuracy: 0.7516 - val_loss: 0.6621 - val_accuracy: 0.7163\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5788 - accuracy: 0.7593 - val_loss: 0.6860 - val_accuracy: 0.7209\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 721us/step - loss: 0.5765 - accuracy: 0.7599 - val_loss: 0.6627 - val_accuracy: 0.7116\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.5846 - accuracy: 0.7505 - val_loss: 0.6671 - val_accuracy: 0.7302\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.7552 - val_loss: 0.6794 - val_accuracy: 0.6977\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 677us/step - loss: 0.5776 - accuracy: 0.7609 - val_loss: 0.6576 - val_accuracy: 0.7209\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5812 - accuracy: 0.7552 - val_loss: 0.6649 - val_accuracy: 0.7302\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5813 - accuracy: 0.7593 - val_loss: 0.6610 - val_accuracy: 0.7209\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5748 - accuracy: 0.7552 - val_loss: 0.6669 - val_accuracy: 0.7256\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7541 - val_loss: 0.6608 - val_accuracy: 0.7349\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 852us/step - loss: 0.5767 - accuracy: 0.7604 - val_loss: 0.6924 - val_accuracy: 0.6837\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5766 - accuracy: 0.7557 - val_loss: 0.6672 - val_accuracy: 0.7023\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5735 - accuracy: 0.7567 - val_loss: 0.6648 - val_accuracy: 0.7302\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5774 - accuracy: 0.7583 - val_loss: 0.6687 - val_accuracy: 0.7256\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.5709 - accuracy: 0.7557 - val_loss: 0.6705 - val_accuracy: 0.7256\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5751 - accuracy: 0.7624 - val_loss: 0.6648 - val_accuracy: 0.7256\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7630 - val_loss: 0.6676 - val_accuracy: 0.7442\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5710 - accuracy: 0.7588 - val_loss: 0.6870 - val_accuracy: 0.6977\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5736 - accuracy: 0.7588 - val_loss: 0.6803 - val_accuracy: 0.6977\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 716us/step - loss: 0.5706 - accuracy: 0.7562 - val_loss: 0.6697 - val_accuracy: 0.7256\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.5711 - accuracy: 0.7619 - val_loss: 0.6660 - val_accuracy: 0.7163\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5716 - accuracy: 0.7567 - val_loss: 0.6692 - val_accuracy: 0.7163\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5704 - accuracy: 0.7609 - val_loss: 0.6579 - val_accuracy: 0.7163\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5697 - accuracy: 0.7599 - val_loss: 0.6944 - val_accuracy: 0.6744\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5700 - accuracy: 0.7583 - val_loss: 0.6960 - val_accuracy: 0.6930\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5748 - accuracy: 0.7567 - val_loss: 0.6841 - val_accuracy: 0.6977\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5705 - accuracy: 0.7593 - val_loss: 0.6653 - val_accuracy: 0.7349\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 773us/step - loss: 0.5673 - accuracy: 0.7599 - val_loss: 0.6627 - val_accuracy: 0.7256\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5691 - accuracy: 0.7588 - val_loss: 0.6734 - val_accuracy: 0.6977\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5669 - accuracy: 0.7650 - val_loss: 0.6677 - val_accuracy: 0.7302\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5705 - accuracy: 0.7630 - val_loss: 0.6680 - val_accuracy: 0.7302\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5685 - accuracy: 0.7630 - val_loss: 0.6994 - val_accuracy: 0.7023\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5692 - accuracy: 0.7599 - val_loss: 0.6934 - val_accuracy: 0.7070\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5657 - accuracy: 0.7573 - val_loss: 0.6584 - val_accuracy: 0.7116\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5635 - accuracy: 0.7583 - val_loss: 0.6667 - val_accuracy: 0.7023\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5652 - accuracy: 0.7635 - val_loss: 0.6735 - val_accuracy: 0.7302\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5642 - accuracy: 0.7614 - val_loss: 0.6679 - val_accuracy: 0.7163\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5663 - accuracy: 0.7619 - val_loss: 0.6695 - val_accuracy: 0.7163\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5652 - accuracy: 0.7593 - val_loss: 0.6715 - val_accuracy: 0.7023\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5629 - accuracy: 0.7640 - val_loss: 0.6649 - val_accuracy: 0.7163\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5623 - accuracy: 0.7697 - val_loss: 0.6717 - val_accuracy: 0.7256\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.5643 - accuracy: 0.7624 - val_loss: 0.6676 - val_accuracy: 0.7116\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5623 - accuracy: 0.7604 - val_loss: 0.6723 - val_accuracy: 0.7070\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5616 - accuracy: 0.7713 - val_loss: 0.6697 - val_accuracy: 0.7349\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5598 - accuracy: 0.7676 - val_loss: 0.6618 - val_accuracy: 0.7209\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5650 - accuracy: 0.7718 - val_loss: 0.6639 - val_accuracy: 0.7349\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.5604 - accuracy: 0.7624 - val_loss: 0.6942 - val_accuracy: 0.7070\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 701us/step - loss: 0.5663 - accuracy: 0.7661 - val_loss: 0.6709 - val_accuracy: 0.7070\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5622 - accuracy: 0.7624 - val_loss: 0.7021 - val_accuracy: 0.7116\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5623 - accuracy: 0.7682 - val_loss: 0.6751 - val_accuracy: 0.7256\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5567 - accuracy: 0.7640 - val_loss: 0.6640 - val_accuracy: 0.7302\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5592 - accuracy: 0.7676 - val_loss: 0.6687 - val_accuracy: 0.7209\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5594 - accuracy: 0.7661 - val_loss: 0.6687 - val_accuracy: 0.7163\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5632 - accuracy: 0.7624 - val_loss: 0.6877 - val_accuracy: 0.7023\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 778us/step - loss: 0.5647 - accuracy: 0.7656 - val_loss: 0.6858 - val_accuracy: 0.7116\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.5620 - accuracy: 0.7661 - val_loss: 0.6854 - val_accuracy: 0.6884\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 764us/step - loss: 0.5612 - accuracy: 0.7650 - val_loss: 0.6683 - val_accuracy: 0.7395\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 890us/step - loss: 0.5570 - accuracy: 0.7645 - val_loss: 0.6692 - val_accuracy: 0.7395\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.5569 - accuracy: 0.7661 - val_loss: 0.6655 - val_accuracy: 0.7070\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5623 - accuracy: 0.7687 - val_loss: 0.6979 - val_accuracy: 0.6884\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 961us/step - loss: 0.5589 - accuracy: 0.7619 - val_loss: 0.6688 - val_accuracy: 0.7070\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.5589 - accuracy: 0.7635 - val_loss: 0.6816 - val_accuracy: 0.7116\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5574 - accuracy: 0.7671 - val_loss: 0.6656 - val_accuracy: 0.7070\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5593 - accuracy: 0.7599 - val_loss: 0.6762 - val_accuracy: 0.7023\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 776us/step - loss: 0.5536 - accuracy: 0.7692 - val_loss: 0.7009 - val_accuracy: 0.7070\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5571 - accuracy: 0.7676 - val_loss: 0.6655 - val_accuracy: 0.7256\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.5580 - accuracy: 0.7635 - val_loss: 0.6596 - val_accuracy: 0.7256\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5550 - accuracy: 0.7650 - val_loss: 0.6840 - val_accuracy: 0.7209\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5554 - accuracy: 0.7640 - val_loss: 0.6672 - val_accuracy: 0.6977\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5560 - accuracy: 0.7635 - val_loss: 0.6828 - val_accuracy: 0.7023\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5583 - accuracy: 0.7650 - val_loss: 0.7125 - val_accuracy: 0.6698\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5556 - accuracy: 0.7692 - val_loss: 0.6794 - val_accuracy: 0.7023\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 629us/step - loss: 0.5535 - accuracy: 0.7671 - val_loss: 0.6704 - val_accuracy: 0.7302\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5535 - accuracy: 0.7661 - val_loss: 0.6988 - val_accuracy: 0.6977\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5554 - accuracy: 0.7604 - val_loss: 0.6905 - val_accuracy: 0.7209\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5538 - accuracy: 0.7744 - val_loss: 0.6732 - val_accuracy: 0.6977\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5517 - accuracy: 0.7702 - val_loss: 0.6706 - val_accuracy: 0.7302\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5557 - accuracy: 0.7645 - val_loss: 0.6909 - val_accuracy: 0.6977\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.5547 - accuracy: 0.7676 - val_loss: 0.6632 - val_accuracy: 0.7302\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5534 - accuracy: 0.7707 - val_loss: 0.6715 - val_accuracy: 0.7395\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5525 - accuracy: 0.7650 - val_loss: 0.7098 - val_accuracy: 0.6698\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5540 - accuracy: 0.7650 - val_loss: 0.6528 - val_accuracy: 0.7256\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5540 - accuracy: 0.7635 - val_loss: 0.6627 - val_accuracy: 0.7163\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 900us/step - loss: 0.5498 - accuracy: 0.7682 - val_loss: 0.6645 - val_accuracy: 0.7163\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5519 - accuracy: 0.7661 - val_loss: 0.6634 - val_accuracy: 0.7070\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5577 - accuracy: 0.7640 - val_loss: 0.6670 - val_accuracy: 0.7302\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5575 - accuracy: 0.7650 - val_loss: 0.6876 - val_accuracy: 0.7023\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5549 - accuracy: 0.7682 - val_loss: 0.6628 - val_accuracy: 0.7256\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 776us/step - loss: 0.5500 - accuracy: 0.7656 - val_loss: 0.6560 - val_accuracy: 0.7209\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 858us/step - loss: 0.5506 - accuracy: 0.7718 - val_loss: 0.7054 - val_accuracy: 0.6837\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 850us/step - loss: 0.5531 - accuracy: 0.7697 - val_loss: 0.6677 - val_accuracy: 0.7163\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5478 - accuracy: 0.7656 - val_loss: 0.6577 - val_accuracy: 0.7442\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5449 - accuracy: 0.7682 - val_loss: 0.6770 - val_accuracy: 0.7302\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5469 - accuracy: 0.7666 - val_loss: 0.6719 - val_accuracy: 0.7256\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5471 - accuracy: 0.7702 - val_loss: 0.6664 - val_accuracy: 0.7349\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.5479 - accuracy: 0.7682 - val_loss: 0.6738 - val_accuracy: 0.7070\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.5514 - accuracy: 0.7656 - val_loss: 0.6607 - val_accuracy: 0.7302\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5492 - accuracy: 0.7676 - val_loss: 0.6612 - val_accuracy: 0.7209\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 851us/step - loss: 0.5502 - accuracy: 0.7713 - val_loss: 0.6626 - val_accuracy: 0.7163\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5472 - accuracy: 0.7682 - val_loss: 0.6702 - val_accuracy: 0.7442\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5537 - accuracy: 0.7666 - val_loss: 0.6669 - val_accuracy: 0.7116\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.5471 - accuracy: 0.7687 - val_loss: 0.6989 - val_accuracy: 0.6977\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5445 - accuracy: 0.7749 - val_loss: 0.6522 - val_accuracy: 0.7256\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5555 - accuracy: 0.7630 - val_loss: 0.6854 - val_accuracy: 0.7116\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5442 - accuracy: 0.7692 - val_loss: 0.6715 - val_accuracy: 0.7256\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5460 - accuracy: 0.7687 - val_loss: 0.6712 - val_accuracy: 0.7395\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5459 - accuracy: 0.7718 - val_loss: 0.6666 - val_accuracy: 0.7256\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5435 - accuracy: 0.7676 - val_loss: 0.6625 - val_accuracy: 0.7349\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5425 - accuracy: 0.7702 - val_loss: 0.6724 - val_accuracy: 0.7209\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.5472 - accuracy: 0.7713 - val_loss: 0.6635 - val_accuracy: 0.7395\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.5457 - accuracy: 0.7697 - val_loss: 0.6814 - val_accuracy: 0.7070\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5472 - accuracy: 0.7656 - val_loss: 0.6780 - val_accuracy: 0.7209\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5438 - accuracy: 0.7739 - val_loss: 0.6675 - val_accuracy: 0.7116\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5442 - accuracy: 0.7702 - val_loss: 0.6705 - val_accuracy: 0.7209\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5434 - accuracy: 0.7718 - val_loss: 0.6869 - val_accuracy: 0.7070\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 717us/step - loss: 0.5458 - accuracy: 0.7666 - val_loss: 0.6781 - val_accuracy: 0.7209\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5470 - accuracy: 0.7723 - val_loss: 0.6642 - val_accuracy: 0.7116\n",
      "Epoch 356: early stopping\n",
      "29/29 - 0s - loss: 0.5418 - accuracy: 0.7757 - 108ms/epoch - 4ms/step\n",
      "7\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4500 - accuracy: 0.4232 - val_loss: 1.3602 - val_accuracy: 0.4744\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 1.3144 - accuracy: 0.4352 - val_loss: 1.2737 - val_accuracy: 0.4651\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 1.2463 - accuracy: 0.4544 - val_loss: 1.2337 - val_accuracy: 0.4558\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 1.2067 - accuracy: 0.4860 - val_loss: 1.2209 - val_accuracy: 0.4605\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1808 - accuracy: 0.4922 - val_loss: 1.1801 - val_accuracy: 0.4977\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1543 - accuracy: 0.5073 - val_loss: 1.1513 - val_accuracy: 0.5023\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 1.1296 - accuracy: 0.5202 - val_loss: 1.1452 - val_accuracy: 0.4977\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1115 - accuracy: 0.5192 - val_loss: 1.1057 - val_accuracy: 0.5302\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0884 - accuracy: 0.5290 - val_loss: 1.0851 - val_accuracy: 0.5581\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 1.0712 - accuracy: 0.5420 - val_loss: 1.0828 - val_accuracy: 0.5209\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 1.0526 - accuracy: 0.5555 - val_loss: 1.0532 - val_accuracy: 0.5442\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 877us/step - loss: 1.0381 - accuracy: 0.5539 - val_loss: 1.0353 - val_accuracy: 0.5488\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0177 - accuracy: 0.5705 - val_loss: 1.0175 - val_accuracy: 0.5814\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.9976 - accuracy: 0.5835 - val_loss: 1.0115 - val_accuracy: 0.5721\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.9841 - accuracy: 0.5918 - val_loss: 0.9738 - val_accuracy: 0.5814\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 858us/step - loss: 0.9694 - accuracy: 0.5975 - val_loss: 0.9540 - val_accuracy: 0.6233\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.9445 - accuracy: 0.6105 - val_loss: 0.9286 - val_accuracy: 0.6233\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 648us/step - loss: 0.9274 - accuracy: 0.6302 - val_loss: 0.9279 - val_accuracy: 0.5907\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.9138 - accuracy: 0.6219 - val_loss: 0.9386 - val_accuracy: 0.5721\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.8993 - accuracy: 0.6312 - val_loss: 0.9070 - val_accuracy: 0.5953\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 937us/step - loss: 0.8877 - accuracy: 0.6359 - val_loss: 0.8936 - val_accuracy: 0.5860\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.8795 - accuracy: 0.6338 - val_loss: 0.8811 - val_accuracy: 0.6140\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8670 - accuracy: 0.6447 - val_loss: 0.8987 - val_accuracy: 0.6186\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8770 - accuracy: 0.6426 - val_loss: 0.8625 - val_accuracy: 0.6186\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8582 - accuracy: 0.6473 - val_loss: 0.8684 - val_accuracy: 0.6186\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 649us/step - loss: 0.8542 - accuracy: 0.6494 - val_loss: 0.8642 - val_accuracy: 0.6140\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.8511 - accuracy: 0.6483 - val_loss: 0.8597 - val_accuracy: 0.6093\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.8505 - accuracy: 0.6421 - val_loss: 0.8614 - val_accuracy: 0.6140\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8442 - accuracy: 0.6489 - val_loss: 0.8542 - val_accuracy: 0.6093\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8422 - accuracy: 0.6520 - val_loss: 0.8576 - val_accuracy: 0.6140\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8408 - accuracy: 0.6561 - val_loss: 0.8586 - val_accuracy: 0.6140\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.8383 - accuracy: 0.6561 - val_loss: 0.8529 - val_accuracy: 0.6186\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8395 - accuracy: 0.6535 - val_loss: 0.8414 - val_accuracy: 0.6233\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8322 - accuracy: 0.6566 - val_loss: 0.8393 - val_accuracy: 0.6186\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 685us/step - loss: 0.8320 - accuracy: 0.6546 - val_loss: 0.8432 - val_accuracy: 0.6047\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.8273 - accuracy: 0.6655 - val_loss: 0.8351 - val_accuracy: 0.6186\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 727us/step - loss: 0.8253 - accuracy: 0.6572 - val_loss: 0.8457 - val_accuracy: 0.6140\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.8234 - accuracy: 0.6639 - val_loss: 0.8366 - val_accuracy: 0.6140\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.8245 - accuracy: 0.6499 - val_loss: 0.8426 - val_accuracy: 0.6140\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8235 - accuracy: 0.6556 - val_loss: 0.8525 - val_accuracy: 0.6047\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.8225 - accuracy: 0.6525 - val_loss: 0.8361 - val_accuracy: 0.6093\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.8165 - accuracy: 0.6592 - val_loss: 0.8371 - val_accuracy: 0.6093\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 691us/step - loss: 0.8119 - accuracy: 0.6644 - val_loss: 0.8392 - val_accuracy: 0.6093\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.8106 - accuracy: 0.6613 - val_loss: 0.8337 - val_accuracy: 0.6000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.8090 - accuracy: 0.6649 - val_loss: 0.8410 - val_accuracy: 0.6047\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.8109 - accuracy: 0.6644 - val_loss: 0.8213 - val_accuracy: 0.6047\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.8011 - accuracy: 0.6675 - val_loss: 0.8352 - val_accuracy: 0.6093\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.8029 - accuracy: 0.6665 - val_loss: 0.8225 - val_accuracy: 0.6000\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.8001 - accuracy: 0.6686 - val_loss: 0.8200 - val_accuracy: 0.6233\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7976 - accuracy: 0.6696 - val_loss: 0.8255 - val_accuracy: 0.6233\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.7942 - accuracy: 0.6748 - val_loss: 0.8190 - val_accuracy: 0.6233\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.7981 - accuracy: 0.6691 - val_loss: 0.8073 - val_accuracy: 0.6186\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.7914 - accuracy: 0.6732 - val_loss: 0.8078 - val_accuracy: 0.6186\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7857 - accuracy: 0.6748 - val_loss: 0.8104 - val_accuracy: 0.6326\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7849 - accuracy: 0.6758 - val_loss: 0.8028 - val_accuracy: 0.6233\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.7828 - accuracy: 0.6769 - val_loss: 0.8118 - val_accuracy: 0.6326\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.7781 - accuracy: 0.6789 - val_loss: 0.8101 - val_accuracy: 0.6233\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.7736 - accuracy: 0.6815 - val_loss: 0.8022 - val_accuracy: 0.6233\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7730 - accuracy: 0.6821 - val_loss: 0.8218 - val_accuracy: 0.6279\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.7811 - accuracy: 0.6738 - val_loss: 0.7962 - val_accuracy: 0.6326\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7700 - accuracy: 0.6893 - val_loss: 0.7928 - val_accuracy: 0.6279\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.7698 - accuracy: 0.6805 - val_loss: 0.7875 - val_accuracy: 0.6326\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 649us/step - loss: 0.7658 - accuracy: 0.6784 - val_loss: 0.8028 - val_accuracy: 0.6186\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7618 - accuracy: 0.6878 - val_loss: 0.7971 - val_accuracy: 0.6233\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7589 - accuracy: 0.6831 - val_loss: 0.7875 - val_accuracy: 0.6372\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7571 - accuracy: 0.6893 - val_loss: 0.7918 - val_accuracy: 0.6419\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 860us/step - loss: 0.7524 - accuracy: 0.6878 - val_loss: 0.7882 - val_accuracy: 0.6419\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.7520 - accuracy: 0.6852 - val_loss: 0.7910 - val_accuracy: 0.6326\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7534 - accuracy: 0.6914 - val_loss: 0.7914 - val_accuracy: 0.6233\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.7448 - accuracy: 0.6878 - val_loss: 0.7980 - val_accuracy: 0.6186\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7440 - accuracy: 0.6955 - val_loss: 0.7913 - val_accuracy: 0.6186\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7429 - accuracy: 0.6924 - val_loss: 0.7830 - val_accuracy: 0.6326\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.7439 - accuracy: 0.6924 - val_loss: 0.7819 - val_accuracy: 0.6233\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7378 - accuracy: 0.6909 - val_loss: 0.7833 - val_accuracy: 0.6419\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7370 - accuracy: 0.6971 - val_loss: 0.8004 - val_accuracy: 0.6419\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7383 - accuracy: 0.6976 - val_loss: 0.7805 - val_accuracy: 0.6279\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.7363 - accuracy: 0.6966 - val_loss: 0.8073 - val_accuracy: 0.6186\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.7366 - accuracy: 0.6904 - val_loss: 0.7796 - val_accuracy: 0.6512\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7281 - accuracy: 0.6966 - val_loss: 0.7735 - val_accuracy: 0.6372\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7302 - accuracy: 0.6966 - val_loss: 0.7792 - val_accuracy: 0.6326\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7237 - accuracy: 0.7002 - val_loss: 0.7720 - val_accuracy: 0.6186\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7233 - accuracy: 0.7002 - val_loss: 0.7693 - val_accuracy: 0.6233\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 747us/step - loss: 0.7216 - accuracy: 0.6976 - val_loss: 0.7735 - val_accuracy: 0.6233\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 884us/step - loss: 0.7206 - accuracy: 0.7012 - val_loss: 0.7779 - val_accuracy: 0.6326\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 759us/step - loss: 0.7168 - accuracy: 0.6976 - val_loss: 0.7715 - val_accuracy: 0.6326\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.7226 - accuracy: 0.7012 - val_loss: 0.7696 - val_accuracy: 0.6186\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 859us/step - loss: 0.7136 - accuracy: 0.7059 - val_loss: 0.7697 - val_accuracy: 0.6698\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 975us/step - loss: 0.7084 - accuracy: 0.7028 - val_loss: 0.7627 - val_accuracy: 0.6233\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7113 - accuracy: 0.7018 - val_loss: 0.7564 - val_accuracy: 0.6698\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 962us/step - loss: 0.7111 - accuracy: 0.7018 - val_loss: 0.7603 - val_accuracy: 0.6326\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.7089 - accuracy: 0.7018 - val_loss: 0.7554 - val_accuracy: 0.6512\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.7125 - accuracy: 0.7085 - val_loss: 0.7529 - val_accuracy: 0.6465\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.7121 - accuracy: 0.7101 - val_loss: 0.7649 - val_accuracy: 0.6558\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.7072 - accuracy: 0.7090 - val_loss: 0.7560 - val_accuracy: 0.6279\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7015 - accuracy: 0.7095 - val_loss: 0.7563 - val_accuracy: 0.6326\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.6949 - accuracy: 0.7168 - val_loss: 0.7515 - val_accuracy: 0.6651\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.7066 - accuracy: 0.7132 - val_loss: 0.7559 - val_accuracy: 0.6372\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 785us/step - loss: 0.7016 - accuracy: 0.7044 - val_loss: 0.7469 - val_accuracy: 0.6512\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6928 - accuracy: 0.7173 - val_loss: 0.7503 - val_accuracy: 0.6605\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.6994 - accuracy: 0.7064 - val_loss: 0.7467 - val_accuracy: 0.6465\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 666us/step - loss: 0.6930 - accuracy: 0.7070 - val_loss: 0.7632 - val_accuracy: 0.6372\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 770us/step - loss: 0.6932 - accuracy: 0.7142 - val_loss: 0.7409 - val_accuracy: 0.6605\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 703us/step - loss: 0.6918 - accuracy: 0.7163 - val_loss: 0.7510 - val_accuracy: 0.6326\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.6888 - accuracy: 0.7241 - val_loss: 0.7386 - val_accuracy: 0.6698\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.6845 - accuracy: 0.7158 - val_loss: 0.7604 - val_accuracy: 0.6279\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6932 - accuracy: 0.7121 - val_loss: 0.7488 - val_accuracy: 0.6698\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6844 - accuracy: 0.7189 - val_loss: 0.7378 - val_accuracy: 0.6558\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.6808 - accuracy: 0.7152 - val_loss: 0.7413 - val_accuracy: 0.6558\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6845 - accuracy: 0.7173 - val_loss: 0.7410 - val_accuracy: 0.6419\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6809 - accuracy: 0.7178 - val_loss: 0.7370 - val_accuracy: 0.6698\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6804 - accuracy: 0.7137 - val_loss: 0.7416 - val_accuracy: 0.6558\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.7152 - val_loss: 0.7270 - val_accuracy: 0.6837\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 864us/step - loss: 0.6740 - accuracy: 0.7210 - val_loss: 0.7424 - val_accuracy: 0.6512\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6744 - accuracy: 0.7241 - val_loss: 0.7335 - val_accuracy: 0.6558\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 668us/step - loss: 0.6764 - accuracy: 0.7230 - val_loss: 0.7340 - val_accuracy: 0.6558\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.6710 - accuracy: 0.7210 - val_loss: 0.7377 - val_accuracy: 0.6558\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 673us/step - loss: 0.6736 - accuracy: 0.7220 - val_loss: 0.7235 - val_accuracy: 0.6558\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 714us/step - loss: 0.6694 - accuracy: 0.7173 - val_loss: 0.7273 - val_accuracy: 0.6791\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 739us/step - loss: 0.6713 - accuracy: 0.7210 - val_loss: 0.7195 - val_accuracy: 0.6698\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6668 - accuracy: 0.7277 - val_loss: 0.7288 - val_accuracy: 0.6605\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6660 - accuracy: 0.7303 - val_loss: 0.7236 - val_accuracy: 0.6465\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6687 - accuracy: 0.7210 - val_loss: 0.7330 - val_accuracy: 0.6512\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.6670 - accuracy: 0.7220 - val_loss: 0.7279 - val_accuracy: 0.6605\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 784us/step - loss: 0.6630 - accuracy: 0.7225 - val_loss: 0.7384 - val_accuracy: 0.6651\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.6656 - accuracy: 0.7251 - val_loss: 0.7133 - val_accuracy: 0.6744\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.6596 - accuracy: 0.7277 - val_loss: 0.7234 - val_accuracy: 0.6558\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6604 - accuracy: 0.7235 - val_loss: 0.7106 - val_accuracy: 0.6698\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6612 - accuracy: 0.7235 - val_loss: 0.7043 - val_accuracy: 0.6744\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 998us/step - loss: 0.6555 - accuracy: 0.7308 - val_loss: 0.7134 - val_accuracy: 0.6884\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6605 - accuracy: 0.7241 - val_loss: 0.7107 - val_accuracy: 0.6558\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6566 - accuracy: 0.7303 - val_loss: 0.7197 - val_accuracy: 0.6605\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.6527 - accuracy: 0.7293 - val_loss: 0.7207 - val_accuracy: 0.6698\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6574 - accuracy: 0.7256 - val_loss: 0.7103 - val_accuracy: 0.6791\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6490 - accuracy: 0.7324 - val_loss: 0.7152 - val_accuracy: 0.6651\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6529 - accuracy: 0.7313 - val_loss: 0.6956 - val_accuracy: 0.6791\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6504 - accuracy: 0.7298 - val_loss: 0.7023 - val_accuracy: 0.6791\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6483 - accuracy: 0.7329 - val_loss: 0.7104 - val_accuracy: 0.6744\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6507 - accuracy: 0.7199 - val_loss: 0.6963 - val_accuracy: 0.6884\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6540 - accuracy: 0.7313 - val_loss: 0.6999 - val_accuracy: 0.6744\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6450 - accuracy: 0.7246 - val_loss: 0.7066 - val_accuracy: 0.6744\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6497 - accuracy: 0.7303 - val_loss: 0.6904 - val_accuracy: 0.6837\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6481 - accuracy: 0.7293 - val_loss: 0.6993 - val_accuracy: 0.6884\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.7329 - val_loss: 0.6926 - val_accuracy: 0.6930\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.6380 - accuracy: 0.7350 - val_loss: 0.7243 - val_accuracy: 0.6558\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6467 - accuracy: 0.7298 - val_loss: 0.7054 - val_accuracy: 0.6884\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6448 - accuracy: 0.7282 - val_loss: 0.6925 - val_accuracy: 0.6837\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6401 - accuracy: 0.7303 - val_loss: 0.6918 - val_accuracy: 0.6884\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6367 - accuracy: 0.7324 - val_loss: 0.7255 - val_accuracy: 0.6651\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.7287 - val_loss: 0.6904 - val_accuracy: 0.6977\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6340 - accuracy: 0.7313 - val_loss: 0.7010 - val_accuracy: 0.6744\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.7355 - val_loss: 0.6950 - val_accuracy: 0.7070\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.6409 - accuracy: 0.7277 - val_loss: 0.6802 - val_accuracy: 0.6884\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6332 - accuracy: 0.7329 - val_loss: 0.7181 - val_accuracy: 0.6558\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6313 - accuracy: 0.7396 - val_loss: 0.6911 - val_accuracy: 0.6930\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6337 - accuracy: 0.7370 - val_loss: 0.6912 - val_accuracy: 0.6837\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.7391 - val_loss: 0.6991 - val_accuracy: 0.7116\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6324 - accuracy: 0.7339 - val_loss: 0.6992 - val_accuracy: 0.6744\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.6331 - accuracy: 0.7381 - val_loss: 0.6973 - val_accuracy: 0.7116\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.7303 - val_loss: 0.6820 - val_accuracy: 0.7163\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6253 - accuracy: 0.7370 - val_loss: 0.6983 - val_accuracy: 0.6791\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6264 - accuracy: 0.7386 - val_loss: 0.6836 - val_accuracy: 0.7116\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6290 - accuracy: 0.7350 - val_loss: 0.6873 - val_accuracy: 0.7070\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.7407 - val_loss: 0.7017 - val_accuracy: 0.7302\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.6290 - accuracy: 0.7370 - val_loss: 0.6897 - val_accuracy: 0.7070\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6237 - accuracy: 0.7417 - val_loss: 0.6895 - val_accuracy: 0.6884\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6202 - accuracy: 0.7401 - val_loss: 0.6860 - val_accuracy: 0.6977\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6243 - accuracy: 0.7427 - val_loss: 0.6932 - val_accuracy: 0.7163\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 660us/step - loss: 0.6204 - accuracy: 0.7386 - val_loss: 0.6785 - val_accuracy: 0.7163\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6247 - accuracy: 0.7355 - val_loss: 0.6803 - val_accuracy: 0.7116\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6173 - accuracy: 0.7427 - val_loss: 0.6975 - val_accuracy: 0.6837\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6184 - accuracy: 0.7324 - val_loss: 0.6761 - val_accuracy: 0.7070\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6171 - accuracy: 0.7422 - val_loss: 0.6964 - val_accuracy: 0.6884\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6187 - accuracy: 0.7459 - val_loss: 0.6799 - val_accuracy: 0.6930\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6169 - accuracy: 0.7412 - val_loss: 0.6860 - val_accuracy: 0.6930\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.6138 - accuracy: 0.7438 - val_loss: 0.6761 - val_accuracy: 0.7070\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.6150 - accuracy: 0.7433 - val_loss: 0.6704 - val_accuracy: 0.7070\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6172 - accuracy: 0.7490 - val_loss: 0.6731 - val_accuracy: 0.7116\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6143 - accuracy: 0.7453 - val_loss: 0.6766 - val_accuracy: 0.6977\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 740us/step - loss: 0.6119 - accuracy: 0.7453 - val_loss: 0.6808 - val_accuracy: 0.7023\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 928us/step - loss: 0.6132 - accuracy: 0.7427 - val_loss: 0.6709 - val_accuracy: 0.7116\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6105 - accuracy: 0.7495 - val_loss: 0.6902 - val_accuracy: 0.6930\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 754us/step - loss: 0.6084 - accuracy: 0.7469 - val_loss: 0.6863 - val_accuracy: 0.6930\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.6097 - accuracy: 0.7464 - val_loss: 0.6672 - val_accuracy: 0.7070\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6108 - accuracy: 0.7448 - val_loss: 0.6737 - val_accuracy: 0.6977\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6087 - accuracy: 0.7474 - val_loss: 0.6834 - val_accuracy: 0.7116\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6086 - accuracy: 0.7453 - val_loss: 0.6774 - val_accuracy: 0.6977\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6147 - accuracy: 0.7396 - val_loss: 0.6858 - val_accuracy: 0.7116\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.6065 - accuracy: 0.7417 - val_loss: 0.6790 - val_accuracy: 0.6930\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 959us/step - loss: 0.6083 - accuracy: 0.7510 - val_loss: 0.6869 - val_accuracy: 0.7209\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6088 - accuracy: 0.7490 - val_loss: 0.6832 - val_accuracy: 0.7070\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6047 - accuracy: 0.7469 - val_loss: 0.6844 - val_accuracy: 0.6977\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6078 - accuracy: 0.7484 - val_loss: 0.6816 - val_accuracy: 0.7070\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6066 - accuracy: 0.7453 - val_loss: 0.6812 - val_accuracy: 0.6930\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6028 - accuracy: 0.7516 - val_loss: 0.6701 - val_accuracy: 0.7070\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.6003 - accuracy: 0.7500 - val_loss: 0.6727 - val_accuracy: 0.6930\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6042 - accuracy: 0.7443 - val_loss: 0.6815 - val_accuracy: 0.7302\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6038 - accuracy: 0.7505 - val_loss: 0.6662 - val_accuracy: 0.7163\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5993 - accuracy: 0.7469 - val_loss: 0.6646 - val_accuracy: 0.7116\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6003 - accuracy: 0.7510 - val_loss: 0.6687 - val_accuracy: 0.7116\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5979 - accuracy: 0.7484 - val_loss: 0.6798 - val_accuracy: 0.7302\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5986 - accuracy: 0.7484 - val_loss: 0.7003 - val_accuracy: 0.7209\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5971 - accuracy: 0.7479 - val_loss: 0.6833 - val_accuracy: 0.6977\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.7490 - val_loss: 0.6807 - val_accuracy: 0.7349\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 691us/step - loss: 0.5954 - accuracy: 0.7531 - val_loss: 0.6728 - val_accuracy: 0.6977\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 887us/step - loss: 0.5961 - accuracy: 0.7552 - val_loss: 0.6733 - val_accuracy: 0.7070\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.5945 - accuracy: 0.7552 - val_loss: 0.6655 - val_accuracy: 0.7023\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.6018 - accuracy: 0.7479 - val_loss: 0.6627 - val_accuracy: 0.7070\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5967 - accuracy: 0.7521 - val_loss: 0.6603 - val_accuracy: 0.7209\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5967 - accuracy: 0.7516 - val_loss: 0.6729 - val_accuracy: 0.7256\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5923 - accuracy: 0.7536 - val_loss: 0.6797 - val_accuracy: 0.7349\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 671us/step - loss: 0.5926 - accuracy: 0.7464 - val_loss: 0.6757 - val_accuracy: 0.7116\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.5934 - accuracy: 0.7541 - val_loss: 0.6648 - val_accuracy: 0.7070\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5895 - accuracy: 0.7562 - val_loss: 0.6837 - val_accuracy: 0.6977\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5902 - accuracy: 0.7484 - val_loss: 0.6864 - val_accuracy: 0.7023\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5933 - accuracy: 0.7547 - val_loss: 0.6692 - val_accuracy: 0.7302\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5909 - accuracy: 0.7516 - val_loss: 0.6687 - val_accuracy: 0.7070\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.5881 - accuracy: 0.7547 - val_loss: 0.6844 - val_accuracy: 0.7070\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5907 - accuracy: 0.7510 - val_loss: 0.6662 - val_accuracy: 0.7256\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.5887 - accuracy: 0.7573 - val_loss: 0.6659 - val_accuracy: 0.7302\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5868 - accuracy: 0.7583 - val_loss: 0.6725 - val_accuracy: 0.7116\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5863 - accuracy: 0.7578 - val_loss: 0.6564 - val_accuracy: 0.7163\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.5892 - accuracy: 0.7531 - val_loss: 0.6784 - val_accuracy: 0.7070\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.5873 - accuracy: 0.7588 - val_loss: 0.6966 - val_accuracy: 0.7070\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5891 - accuracy: 0.7459 - val_loss: 0.6610 - val_accuracy: 0.7209\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5872 - accuracy: 0.7531 - val_loss: 0.6743 - val_accuracy: 0.7209\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5860 - accuracy: 0.7583 - val_loss: 0.6995 - val_accuracy: 0.6930\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5856 - accuracy: 0.7557 - val_loss: 0.6651 - val_accuracy: 0.7163\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5948 - accuracy: 0.7521 - val_loss: 0.6622 - val_accuracy: 0.7256\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7578 - val_loss: 0.6617 - val_accuracy: 0.7442\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 842us/step - loss: 0.5831 - accuracy: 0.7588 - val_loss: 0.6591 - val_accuracy: 0.7163\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.5839 - accuracy: 0.7567 - val_loss: 0.6810 - val_accuracy: 0.7116\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5855 - accuracy: 0.7505 - val_loss: 0.6709 - val_accuracy: 0.7209\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5823 - accuracy: 0.7588 - val_loss: 0.6630 - val_accuracy: 0.7302\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.5859 - accuracy: 0.7526 - val_loss: 0.6776 - val_accuracy: 0.7070\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5828 - accuracy: 0.7573 - val_loss: 0.6763 - val_accuracy: 0.7023\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5828 - accuracy: 0.7547 - val_loss: 0.6760 - val_accuracy: 0.7116\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5800 - accuracy: 0.7578 - val_loss: 0.6715 - val_accuracy: 0.7116\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5783 - accuracy: 0.7604 - val_loss: 0.6735 - val_accuracy: 0.7256\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5839 - accuracy: 0.7599 - val_loss: 0.6647 - val_accuracy: 0.7163\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5826 - accuracy: 0.7557 - val_loss: 0.6816 - val_accuracy: 0.7442\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5800 - accuracy: 0.7578 - val_loss: 0.6763 - val_accuracy: 0.7209\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5816 - accuracy: 0.7505 - val_loss: 0.6716 - val_accuracy: 0.7209\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 982us/step - loss: 0.5816 - accuracy: 0.7573 - val_loss: 0.6670 - val_accuracy: 0.7209\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5808 - accuracy: 0.7567 - val_loss: 0.6678 - val_accuracy: 0.7256\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5776 - accuracy: 0.7609 - val_loss: 0.6612 - val_accuracy: 0.7116\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5788 - accuracy: 0.7567 - val_loss: 0.6766 - val_accuracy: 0.7116\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5826 - accuracy: 0.7573 - val_loss: 0.6687 - val_accuracy: 0.7256\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5763 - accuracy: 0.7531 - val_loss: 0.7063 - val_accuracy: 0.6977\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5867 - accuracy: 0.7547 - val_loss: 0.6618 - val_accuracy: 0.7256\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 783us/step - loss: 0.5763 - accuracy: 0.7578 - val_loss: 0.6727 - val_accuracy: 0.7302\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5752 - accuracy: 0.7614 - val_loss: 0.6853 - val_accuracy: 0.7395\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5762 - accuracy: 0.7573 - val_loss: 0.6592 - val_accuracy: 0.7209\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 678us/step - loss: 0.5780 - accuracy: 0.7573 - val_loss: 0.6544 - val_accuracy: 0.7302\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.5751 - accuracy: 0.7635 - val_loss: 0.6674 - val_accuracy: 0.7209\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5775 - accuracy: 0.7573 - val_loss: 0.6842 - val_accuracy: 0.7349\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5703 - accuracy: 0.7635 - val_loss: 0.6724 - val_accuracy: 0.7163\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5723 - accuracy: 0.7578 - val_loss: 0.6764 - val_accuracy: 0.7070\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5769 - accuracy: 0.7588 - val_loss: 0.6807 - val_accuracy: 0.7209\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5708 - accuracy: 0.7604 - val_loss: 0.6702 - val_accuracy: 0.7209\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5727 - accuracy: 0.7604 - val_loss: 0.6624 - val_accuracy: 0.7256\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5720 - accuracy: 0.7624 - val_loss: 0.6742 - val_accuracy: 0.7256\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5724 - accuracy: 0.7656 - val_loss: 0.6636 - val_accuracy: 0.7302\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5779 - accuracy: 0.7599 - val_loss: 0.6819 - val_accuracy: 0.7116\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.5722 - accuracy: 0.7573 - val_loss: 0.6657 - val_accuracy: 0.7209\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5730 - accuracy: 0.7573 - val_loss: 0.6613 - val_accuracy: 0.7209\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5695 - accuracy: 0.7630 - val_loss: 0.6682 - val_accuracy: 0.7256\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5760 - accuracy: 0.7557 - val_loss: 0.6540 - val_accuracy: 0.7349\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5705 - accuracy: 0.7604 - val_loss: 0.6990 - val_accuracy: 0.7395\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5727 - accuracy: 0.7578 - val_loss: 0.6642 - val_accuracy: 0.7209\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5754 - accuracy: 0.7573 - val_loss: 0.6657 - val_accuracy: 0.7395\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5689 - accuracy: 0.7630 - val_loss: 0.6659 - val_accuracy: 0.7209\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5701 - accuracy: 0.7573 - val_loss: 0.6844 - val_accuracy: 0.7070\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5674 - accuracy: 0.7635 - val_loss: 0.6731 - val_accuracy: 0.7349\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.5718 - accuracy: 0.7578 - val_loss: 0.6525 - val_accuracy: 0.7442\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5697 - accuracy: 0.7619 - val_loss: 0.6777 - val_accuracy: 0.7302\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5700 - accuracy: 0.7630 - val_loss: 0.6642 - val_accuracy: 0.7302\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5669 - accuracy: 0.7661 - val_loss: 0.6673 - val_accuracy: 0.7302\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5662 - accuracy: 0.7557 - val_loss: 0.6593 - val_accuracy: 0.7442\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5709 - accuracy: 0.7630 - val_loss: 0.6611 - val_accuracy: 0.7256\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5702 - accuracy: 0.7599 - val_loss: 0.6654 - val_accuracy: 0.7349\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5664 - accuracy: 0.7650 - val_loss: 0.6581 - val_accuracy: 0.7163\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5701 - accuracy: 0.7536 - val_loss: 0.6814 - val_accuracy: 0.7395\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5684 - accuracy: 0.7624 - val_loss: 0.6477 - val_accuracy: 0.7349\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5678 - accuracy: 0.7609 - val_loss: 0.6492 - val_accuracy: 0.7349\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5669 - accuracy: 0.7619 - val_loss: 0.6645 - val_accuracy: 0.7395\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5657 - accuracy: 0.7619 - val_loss: 0.6667 - val_accuracy: 0.7302\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 679us/step - loss: 0.5697 - accuracy: 0.7661 - val_loss: 0.6621 - val_accuracy: 0.7302\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.5654 - accuracy: 0.7682 - val_loss: 0.6703 - val_accuracy: 0.7256\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5694 - accuracy: 0.7614 - val_loss: 0.6761 - val_accuracy: 0.7349\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5635 - accuracy: 0.7599 - val_loss: 0.6596 - val_accuracy: 0.7209\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5668 - accuracy: 0.7588 - val_loss: 0.6551 - val_accuracy: 0.7209\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5662 - accuracy: 0.7645 - val_loss: 0.6533 - val_accuracy: 0.7349\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5633 - accuracy: 0.7645 - val_loss: 0.6657 - val_accuracy: 0.7349\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5646 - accuracy: 0.7624 - val_loss: 0.6895 - val_accuracy: 0.7256\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5645 - accuracy: 0.7640 - val_loss: 0.6485 - val_accuracy: 0.7349\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5639 - accuracy: 0.7588 - val_loss: 0.6547 - val_accuracy: 0.7302\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5665 - accuracy: 0.7640 - val_loss: 0.6654 - val_accuracy: 0.7442\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5630 - accuracy: 0.7656 - val_loss: 0.6513 - val_accuracy: 0.7442\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5669 - accuracy: 0.7624 - val_loss: 0.6844 - val_accuracy: 0.7070\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.5625 - accuracy: 0.7656 - val_loss: 0.6461 - val_accuracy: 0.7349\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5612 - accuracy: 0.7614 - val_loss: 0.6749 - val_accuracy: 0.7209\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.5648 - accuracy: 0.7676 - val_loss: 0.6657 - val_accuracy: 0.7163\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5591 - accuracy: 0.7697 - val_loss: 0.6684 - val_accuracy: 0.7442\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 832us/step - loss: 0.5604 - accuracy: 0.7609 - val_loss: 0.6545 - val_accuracy: 0.7302\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5593 - accuracy: 0.7599 - val_loss: 0.6530 - val_accuracy: 0.7395\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5599 - accuracy: 0.7547 - val_loss: 0.6686 - val_accuracy: 0.7302\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5657 - accuracy: 0.7578 - val_loss: 0.6585 - val_accuracy: 0.7349\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5600 - accuracy: 0.7666 - val_loss: 0.6407 - val_accuracy: 0.7442\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5623 - accuracy: 0.7640 - val_loss: 0.6619 - val_accuracy: 0.7256\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5572 - accuracy: 0.7692 - val_loss: 0.6776 - val_accuracy: 0.7116\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5626 - accuracy: 0.7619 - val_loss: 0.6630 - val_accuracy: 0.7256\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5606 - accuracy: 0.7661 - val_loss: 0.6842 - val_accuracy: 0.7116\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5615 - accuracy: 0.7697 - val_loss: 0.6556 - val_accuracy: 0.7349\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5569 - accuracy: 0.7666 - val_loss: 0.6624 - val_accuracy: 0.7349\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5581 - accuracy: 0.7624 - val_loss: 0.6557 - val_accuracy: 0.7442\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5566 - accuracy: 0.7650 - val_loss: 0.6752 - val_accuracy: 0.7116\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 773us/step - loss: 0.5586 - accuracy: 0.7687 - val_loss: 0.6587 - val_accuracy: 0.7442\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5582 - accuracy: 0.7588 - val_loss: 0.6572 - val_accuracy: 0.7302\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5579 - accuracy: 0.7624 - val_loss: 0.6616 - val_accuracy: 0.7302\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 765us/step - loss: 0.5568 - accuracy: 0.7661 - val_loss: 0.6701 - val_accuracy: 0.7209\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 893us/step - loss: 0.5570 - accuracy: 0.7624 - val_loss: 0.6864 - val_accuracy: 0.7395\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5583 - accuracy: 0.7573 - val_loss: 0.6506 - val_accuracy: 0.7302\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5576 - accuracy: 0.7630 - val_loss: 0.6592 - val_accuracy: 0.7349\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5593 - accuracy: 0.7640 - val_loss: 0.6712 - val_accuracy: 0.7302\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5569 - accuracy: 0.7609 - val_loss: 0.6593 - val_accuracy: 0.7256\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7614 - val_loss: 0.6438 - val_accuracy: 0.7535\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5544 - accuracy: 0.7630 - val_loss: 0.6467 - val_accuracy: 0.7349\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5588 - accuracy: 0.7661 - val_loss: 0.6498 - val_accuracy: 0.7302\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5524 - accuracy: 0.7682 - val_loss: 0.6781 - val_accuracy: 0.7349\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5586 - accuracy: 0.7593 - val_loss: 0.6648 - val_accuracy: 0.7302\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5566 - accuracy: 0.7604 - val_loss: 0.6591 - val_accuracy: 0.7395\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5555 - accuracy: 0.7599 - val_loss: 0.6563 - val_accuracy: 0.7442\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5533 - accuracy: 0.7645 - val_loss: 0.6579 - val_accuracy: 0.7442\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5556 - accuracy: 0.7650 - val_loss: 0.6761 - val_accuracy: 0.7163\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5587 - accuracy: 0.7640 - val_loss: 0.6709 - val_accuracy: 0.7395\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.5568 - accuracy: 0.7640 - val_loss: 0.6661 - val_accuracy: 0.7256\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5519 - accuracy: 0.7624 - val_loss: 0.6663 - val_accuracy: 0.7349\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5523 - accuracy: 0.7661 - val_loss: 0.6570 - val_accuracy: 0.7349\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5534 - accuracy: 0.7593 - val_loss: 0.6653 - val_accuracy: 0.7163\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5527 - accuracy: 0.7692 - val_loss: 0.6460 - val_accuracy: 0.7395\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5543 - accuracy: 0.7650 - val_loss: 0.6686 - val_accuracy: 0.7349\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5515 - accuracy: 0.7619 - val_loss: 0.6556 - val_accuracy: 0.7302\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.5519 - accuracy: 0.7671 - val_loss: 0.6608 - val_accuracy: 0.7302\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5553 - accuracy: 0.7640 - val_loss: 0.6601 - val_accuracy: 0.7209\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5550 - accuracy: 0.7650 - val_loss: 0.6438 - val_accuracy: 0.7256\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5524 - accuracy: 0.7671 - val_loss: 0.6727 - val_accuracy: 0.7302\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 960us/step - loss: 0.5524 - accuracy: 0.7609 - val_loss: 0.6657 - val_accuracy: 0.7209\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5541 - accuracy: 0.7707 - val_loss: 0.6765 - val_accuracy: 0.7209\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5544 - accuracy: 0.7624 - val_loss: 0.6784 - val_accuracy: 0.7116\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.5504 - accuracy: 0.7707 - val_loss: 0.6468 - val_accuracy: 0.7302\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 752us/step - loss: 0.5532 - accuracy: 0.7671 - val_loss: 0.6457 - val_accuracy: 0.7256\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.5489 - accuracy: 0.7744 - val_loss: 0.6840 - val_accuracy: 0.7395\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5560 - accuracy: 0.7640 - val_loss: 0.6443 - val_accuracy: 0.7395\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5496 - accuracy: 0.7630 - val_loss: 0.6588 - val_accuracy: 0.7349\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 754us/step - loss: 0.5514 - accuracy: 0.7630 - val_loss: 0.6539 - val_accuracy: 0.7302\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.5500 - accuracy: 0.7666 - val_loss: 0.6540 - val_accuracy: 0.7395\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5539 - accuracy: 0.7619 - val_loss: 0.6603 - val_accuracy: 0.7209\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.5499 - accuracy: 0.7656 - val_loss: 0.6523 - val_accuracy: 0.7395\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5517 - accuracy: 0.7640 - val_loss: 0.6605 - val_accuracy: 0.7302\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.5531 - accuracy: 0.7666 - val_loss: 0.6611 - val_accuracy: 0.7302\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5531 - accuracy: 0.7614 - val_loss: 0.6689 - val_accuracy: 0.7209\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5523 - accuracy: 0.7723 - val_loss: 0.6559 - val_accuracy: 0.7256\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - 0s 721us/step - loss: 0.5514 - accuracy: 0.7640 - val_loss: 0.6629 - val_accuracy: 0.7256\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5457 - accuracy: 0.7697 - val_loss: 0.6567 - val_accuracy: 0.7209\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5472 - accuracy: 0.7661 - val_loss: 0.6555 - val_accuracy: 0.7256\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5481 - accuracy: 0.7671 - val_loss: 0.6700 - val_accuracy: 0.7302\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5516 - accuracy: 0.7671 - val_loss: 0.6625 - val_accuracy: 0.7116\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5488 - accuracy: 0.7682 - val_loss: 0.6420 - val_accuracy: 0.7302\n",
      "Epoch 369/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5540 - accuracy: 0.7640 - val_loss: 0.6690 - val_accuracy: 0.7302\n",
      "Epoch 370/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5512 - accuracy: 0.7687 - val_loss: 0.6483 - val_accuracy: 0.7302\n",
      "Epoch 371/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5481 - accuracy: 0.7713 - val_loss: 0.6543 - val_accuracy: 0.7349\n",
      "Epoch 372/500\n",
      "72/72 [==============================] - 0s 831us/step - loss: 0.5504 - accuracy: 0.7697 - val_loss: 0.6628 - val_accuracy: 0.7256\n",
      "Epoch 373/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5548 - accuracy: 0.7687 - val_loss: 0.6607 - val_accuracy: 0.7209\n",
      "Epoch 374/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5514 - accuracy: 0.7650 - val_loss: 0.6704 - val_accuracy: 0.7163\n",
      "Epoch 375/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.5471 - accuracy: 0.7718 - val_loss: 0.6654 - val_accuracy: 0.7163\n",
      "Epoch 376/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5485 - accuracy: 0.7624 - val_loss: 0.6649 - val_accuracy: 0.7302\n",
      "Epoch 377/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5473 - accuracy: 0.7661 - val_loss: 0.6465 - val_accuracy: 0.7349\n",
      "Epoch 378/500\n",
      "72/72 [==============================] - 0s 798us/step - loss: 0.5486 - accuracy: 0.7713 - val_loss: 0.6559 - val_accuracy: 0.7349\n",
      "Epoch 379/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5544 - accuracy: 0.7661 - val_loss: 0.6621 - val_accuracy: 0.7256\n",
      "Epoch 380/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5458 - accuracy: 0.7650 - val_loss: 0.6938 - val_accuracy: 0.7023\n",
      "Epoch 381/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5464 - accuracy: 0.7650 - val_loss: 0.6506 - val_accuracy: 0.7256\n",
      "Epoch 382/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5447 - accuracy: 0.7671 - val_loss: 0.6795 - val_accuracy: 0.7070\n",
      "Epoch 383/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5531 - accuracy: 0.7692 - val_loss: 0.6624 - val_accuracy: 0.7256\n",
      "Epoch 384/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5446 - accuracy: 0.7676 - val_loss: 0.6606 - val_accuracy: 0.7256\n",
      "Epoch 385/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.5444 - accuracy: 0.7692 - val_loss: 0.6532 - val_accuracy: 0.7163\n",
      "Epoch 386/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5462 - accuracy: 0.7759 - val_loss: 0.6526 - val_accuracy: 0.7302\n",
      "Epoch 387/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.5458 - accuracy: 0.7718 - val_loss: 0.6773 - val_accuracy: 0.7209\n",
      "Epoch 388/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5470 - accuracy: 0.7645 - val_loss: 0.6738 - val_accuracy: 0.7209\n",
      "Epoch 389/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5437 - accuracy: 0.7744 - val_loss: 0.6468 - val_accuracy: 0.7256\n",
      "Epoch 390/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5452 - accuracy: 0.7687 - val_loss: 0.6675 - val_accuracy: 0.7163\n",
      "Epoch 391/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5485 - accuracy: 0.7687 - val_loss: 0.6665 - val_accuracy: 0.7302\n",
      "Epoch 392/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5430 - accuracy: 0.7759 - val_loss: 0.6641 - val_accuracy: 0.7163\n",
      "Epoch 393/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5445 - accuracy: 0.7682 - val_loss: 0.6680 - val_accuracy: 0.7302\n",
      "Epoch 394/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5441 - accuracy: 0.7671 - val_loss: 0.6526 - val_accuracy: 0.7209\n",
      "Epoch 395/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5467 - accuracy: 0.7656 - val_loss: 0.6755 - val_accuracy: 0.7209\n",
      "Epoch 396/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.5478 - accuracy: 0.7630 - val_loss: 0.6572 - val_accuracy: 0.7302\n",
      "Epoch 397/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.5450 - accuracy: 0.7656 - val_loss: 0.6615 - val_accuracy: 0.7302\n",
      "Epoch 398/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5454 - accuracy: 0.7666 - val_loss: 0.6583 - val_accuracy: 0.7256\n",
      "Epoch 399/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5438 - accuracy: 0.7609 - val_loss: 0.6618 - val_accuracy: 0.7209\n",
      "Epoch 400/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5438 - accuracy: 0.7671 - val_loss: 0.6535 - val_accuracy: 0.7302\n",
      "Epoch 401/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5450 - accuracy: 0.7671 - val_loss: 0.6495 - val_accuracy: 0.7395\n",
      "Epoch 402/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5449 - accuracy: 0.7692 - val_loss: 0.6508 - val_accuracy: 0.7442\n",
      "Epoch 403/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5426 - accuracy: 0.7749 - val_loss: 0.6529 - val_accuracy: 0.7163\n",
      "Epoch 404/500\n",
      "72/72 [==============================] - 0s 779us/step - loss: 0.5435 - accuracy: 0.7671 - val_loss: 0.6803 - val_accuracy: 0.6930\n",
      "Epoch 405/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.5438 - accuracy: 0.7697 - val_loss: 0.6737 - val_accuracy: 0.7256\n",
      "Epoch 406/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5483 - accuracy: 0.7645 - val_loss: 0.6690 - val_accuracy: 0.7209\n",
      "Epoch 407/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5430 - accuracy: 0.7713 - val_loss: 0.6477 - val_accuracy: 0.7209\n",
      "Epoch 408/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5474 - accuracy: 0.7702 - val_loss: 0.6548 - val_accuracy: 0.7116\n",
      "Epoch 409/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5475 - accuracy: 0.7687 - val_loss: 0.6763 - val_accuracy: 0.7209\n",
      "Epoch 410/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5420 - accuracy: 0.7749 - val_loss: 0.6590 - val_accuracy: 0.7116\n",
      "Epoch 411/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5393 - accuracy: 0.7733 - val_loss: 0.6588 - val_accuracy: 0.7209\n",
      "Epoch 412/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5412 - accuracy: 0.7744 - val_loss: 0.6594 - val_accuracy: 0.7209\n",
      "Epoch 413/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5472 - accuracy: 0.7733 - val_loss: 0.6503 - val_accuracy: 0.7302\n",
      "Epoch 414/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5442 - accuracy: 0.7702 - val_loss: 0.6522 - val_accuracy: 0.7256\n",
      "Epoch 415/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5393 - accuracy: 0.7749 - val_loss: 0.6740 - val_accuracy: 0.7070\n",
      "Epoch 416/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5410 - accuracy: 0.7765 - val_loss: 0.6646 - val_accuracy: 0.7209\n",
      "Epoch 417/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5429 - accuracy: 0.7744 - val_loss: 0.6493 - val_accuracy: 0.7395\n",
      "Epoch 418/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5418 - accuracy: 0.7671 - val_loss: 0.6953 - val_accuracy: 0.7023\n",
      "Epoch 419/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5431 - accuracy: 0.7728 - val_loss: 0.6589 - val_accuracy: 0.7256\n",
      "Epoch 420/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5404 - accuracy: 0.7713 - val_loss: 0.6488 - val_accuracy: 0.7209\n",
      "Epoch 421/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5401 - accuracy: 0.7718 - val_loss: 0.6674 - val_accuracy: 0.7209\n",
      "Epoch 422/500\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.5404 - accuracy: 0.7728 - val_loss: 0.6442 - val_accuracy: 0.7302\n",
      "Epoch 423/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5387 - accuracy: 0.7671 - val_loss: 0.6469 - val_accuracy: 0.7302\n",
      "Epoch 424/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5404 - accuracy: 0.7682 - val_loss: 0.6584 - val_accuracy: 0.7256\n",
      "Epoch 425/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5402 - accuracy: 0.7739 - val_loss: 0.6636 - val_accuracy: 0.7256\n",
      "Epoch 426/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5421 - accuracy: 0.7749 - val_loss: 0.6509 - val_accuracy: 0.7163\n",
      "Epoch 426: early stopping\n",
      "29/29 - 0s - loss: 0.5469 - accuracy: 0.7626 - 94ms/epoch - 3ms/step\n",
      "8\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5522 - accuracy: 0.2941 - val_loss: 1.4557 - val_accuracy: 0.4837\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 921us/step - loss: 1.4032 - accuracy: 0.4295 - val_loss: 1.3276 - val_accuracy: 0.4419\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 1.3004 - accuracy: 0.4450 - val_loss: 1.2708 - val_accuracy: 0.4093\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 1.2495 - accuracy: 0.4455 - val_loss: 1.2434 - val_accuracy: 0.4233\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 1.2157 - accuracy: 0.4652 - val_loss: 1.2051 - val_accuracy: 0.4791\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1910 - accuracy: 0.4803 - val_loss: 1.1729 - val_accuracy: 0.4930\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 859us/step - loss: 1.1672 - accuracy: 0.4886 - val_loss: 1.1536 - val_accuracy: 0.4884\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1423 - accuracy: 0.5073 - val_loss: 1.1353 - val_accuracy: 0.5023\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1217 - accuracy: 0.5244 - val_loss: 1.1017 - val_accuracy: 0.5209\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0958 - accuracy: 0.5290 - val_loss: 1.0838 - val_accuracy: 0.5349\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0734 - accuracy: 0.5451 - val_loss: 1.0663 - val_accuracy: 0.5628\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 903us/step - loss: 1.0521 - accuracy: 0.5539 - val_loss: 1.0556 - val_accuracy: 0.5442\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0297 - accuracy: 0.5690 - val_loss: 1.0234 - val_accuracy: 0.5814\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 883us/step - loss: 1.0133 - accuracy: 0.5705 - val_loss: 1.0113 - val_accuracy: 0.5721\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 691us/step - loss: 0.9889 - accuracy: 0.5877 - val_loss: 0.9923 - val_accuracy: 0.5814\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.9738 - accuracy: 0.5985 - val_loss: 0.9852 - val_accuracy: 0.5721\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9563 - accuracy: 0.6058 - val_loss: 0.9579 - val_accuracy: 0.6000\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9410 - accuracy: 0.6203 - val_loss: 0.9423 - val_accuracy: 0.6140\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.9210 - accuracy: 0.6317 - val_loss: 0.9412 - val_accuracy: 0.6140\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9080 - accuracy: 0.6291 - val_loss: 0.9042 - val_accuracy: 0.6372\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.8932 - accuracy: 0.6354 - val_loss: 0.9133 - val_accuracy: 0.6140\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8830 - accuracy: 0.6416 - val_loss: 0.8989 - val_accuracy: 0.6186\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.8722 - accuracy: 0.6504 - val_loss: 0.8896 - val_accuracy: 0.6326\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8606 - accuracy: 0.6483 - val_loss: 0.8847 - val_accuracy: 0.6233\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.8564 - accuracy: 0.6468 - val_loss: 0.8826 - val_accuracy: 0.6093\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.8467 - accuracy: 0.6540 - val_loss: 0.8564 - val_accuracy: 0.6326\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8392 - accuracy: 0.6582 - val_loss: 0.8620 - val_accuracy: 0.6186\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8347 - accuracy: 0.6551 - val_loss: 0.8566 - val_accuracy: 0.6186\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 758us/step - loss: 0.8274 - accuracy: 0.6577 - val_loss: 0.8621 - val_accuracy: 0.6000\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 929us/step - loss: 0.8262 - accuracy: 0.6556 - val_loss: 0.8375 - val_accuracy: 0.6233\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.8197 - accuracy: 0.6582 - val_loss: 0.8342 - val_accuracy: 0.6093\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.8146 - accuracy: 0.6670 - val_loss: 0.8261 - val_accuracy: 0.6233\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.8186 - accuracy: 0.6613 - val_loss: 0.8353 - val_accuracy: 0.6186\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.8086 - accuracy: 0.6680 - val_loss: 0.8356 - val_accuracy: 0.6233\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.8046 - accuracy: 0.6706 - val_loss: 0.8348 - val_accuracy: 0.6093\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.8051 - accuracy: 0.6727 - val_loss: 0.8428 - val_accuracy: 0.5907\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.7993 - accuracy: 0.6675 - val_loss: 0.8287 - val_accuracy: 0.6140\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7953 - accuracy: 0.6753 - val_loss: 0.8271 - val_accuracy: 0.6140\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.7949 - accuracy: 0.6789 - val_loss: 0.8148 - val_accuracy: 0.6186\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7896 - accuracy: 0.6660 - val_loss: 0.8077 - val_accuracy: 0.6186\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.7858 - accuracy: 0.6805 - val_loss: 0.8076 - val_accuracy: 0.6093\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.7858 - accuracy: 0.6800 - val_loss: 0.8066 - val_accuracy: 0.6186\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7805 - accuracy: 0.6805 - val_loss: 0.8172 - val_accuracy: 0.6186\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.7871 - accuracy: 0.6748 - val_loss: 0.7995 - val_accuracy: 0.6140\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.7734 - accuracy: 0.6831 - val_loss: 0.8095 - val_accuracy: 0.6047\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 733us/step - loss: 0.7747 - accuracy: 0.6784 - val_loss: 0.7954 - val_accuracy: 0.6186\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 945us/step - loss: 0.7730 - accuracy: 0.6784 - val_loss: 0.8087 - val_accuracy: 0.6186\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7634 - accuracy: 0.6841 - val_loss: 0.8020 - val_accuracy: 0.6279\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7621 - accuracy: 0.6862 - val_loss: 0.7821 - val_accuracy: 0.6419\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7612 - accuracy: 0.6795 - val_loss: 0.7803 - val_accuracy: 0.6558\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.7645 - accuracy: 0.6898 - val_loss: 0.7830 - val_accuracy: 0.6233\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7543 - accuracy: 0.6857 - val_loss: 0.7886 - val_accuracy: 0.6140\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 791us/step - loss: 0.7563 - accuracy: 0.6893 - val_loss: 0.7915 - val_accuracy: 0.6326\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7543 - accuracy: 0.6914 - val_loss: 0.7744 - val_accuracy: 0.6372\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7502 - accuracy: 0.6872 - val_loss: 0.7846 - val_accuracy: 0.6140\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 786us/step - loss: 0.7443 - accuracy: 0.6904 - val_loss: 0.7850 - val_accuracy: 0.6419\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.7425 - accuracy: 0.6929 - val_loss: 0.7867 - val_accuracy: 0.6326\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7428 - accuracy: 0.6929 - val_loss: 0.7687 - val_accuracy: 0.6512\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.7408 - accuracy: 0.6976 - val_loss: 0.7843 - val_accuracy: 0.6465\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7385 - accuracy: 0.6945 - val_loss: 0.7747 - val_accuracy: 0.6419\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6961 - val_loss: 0.7704 - val_accuracy: 0.6651\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 755us/step - loss: 0.7353 - accuracy: 0.6955 - val_loss: 0.7717 - val_accuracy: 0.6279\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 876us/step - loss: 0.7301 - accuracy: 0.6971 - val_loss: 0.7665 - val_accuracy: 0.6465\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.7298 - accuracy: 0.7018 - val_loss: 0.7708 - val_accuracy: 0.6512\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7298 - accuracy: 0.7012 - val_loss: 0.7730 - val_accuracy: 0.6558\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7325 - accuracy: 0.6929 - val_loss: 0.7619 - val_accuracy: 0.6605\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6981 - val_loss: 0.7499 - val_accuracy: 0.6837\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 858us/step - loss: 0.7287 - accuracy: 0.6961 - val_loss: 0.7702 - val_accuracy: 0.6372\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.7218 - accuracy: 0.7054 - val_loss: 0.7606 - val_accuracy: 0.6744\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7201 - accuracy: 0.7033 - val_loss: 0.7587 - val_accuracy: 0.6512\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.7160 - accuracy: 0.7080 - val_loss: 0.7634 - val_accuracy: 0.6512\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.7181 - accuracy: 0.7054 - val_loss: 0.7526 - val_accuracy: 0.6744\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7187 - accuracy: 0.7012 - val_loss: 0.7535 - val_accuracy: 0.6651\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7136 - accuracy: 0.6997 - val_loss: 0.7494 - val_accuracy: 0.6651\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.7118 - accuracy: 0.7085 - val_loss: 0.7689 - val_accuracy: 0.6698\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 874us/step - loss: 0.7119 - accuracy: 0.7080 - val_loss: 0.7668 - val_accuracy: 0.6837\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 957us/step - loss: 0.7103 - accuracy: 0.7101 - val_loss: 0.7676 - val_accuracy: 0.6930\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 953us/step - loss: 0.7126 - accuracy: 0.7033 - val_loss: 0.7468 - val_accuracy: 0.6698\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.7137 - val_loss: 0.7620 - val_accuracy: 0.6977\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.7092 - accuracy: 0.6997 - val_loss: 0.7444 - val_accuracy: 0.6512\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.7030 - accuracy: 0.7152 - val_loss: 0.7599 - val_accuracy: 0.6558\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7023 - accuracy: 0.7101 - val_loss: 0.7357 - val_accuracy: 0.6791\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.7024 - accuracy: 0.7095 - val_loss: 0.7376 - val_accuracy: 0.6698\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6965 - accuracy: 0.7152 - val_loss: 0.7406 - val_accuracy: 0.6698\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6983 - accuracy: 0.7085 - val_loss: 0.7345 - val_accuracy: 0.6744\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6960 - accuracy: 0.7080 - val_loss: 0.7339 - val_accuracy: 0.6977\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.6937 - accuracy: 0.7137 - val_loss: 0.7417 - val_accuracy: 0.6884\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6933 - accuracy: 0.7127 - val_loss: 0.7441 - val_accuracy: 0.6605\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6930 - accuracy: 0.7142 - val_loss: 0.7459 - val_accuracy: 0.6744\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6909 - accuracy: 0.7184 - val_loss: 0.7311 - val_accuracy: 0.6651\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6896 - accuracy: 0.7147 - val_loss: 0.7264 - val_accuracy: 0.6837\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6902 - accuracy: 0.7163 - val_loss: 0.7326 - val_accuracy: 0.6837\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6890 - accuracy: 0.7158 - val_loss: 0.7388 - val_accuracy: 0.6698\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 724us/step - loss: 0.6903 - accuracy: 0.7111 - val_loss: 0.7348 - val_accuracy: 0.6884\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.6866 - accuracy: 0.7142 - val_loss: 0.7336 - val_accuracy: 0.6744\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.7215 - val_loss: 0.7223 - val_accuracy: 0.7023\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 0.6843 - accuracy: 0.7132 - val_loss: 0.7300 - val_accuracy: 0.6930\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6833 - accuracy: 0.7189 - val_loss: 0.7202 - val_accuracy: 0.6977\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6807 - accuracy: 0.7184 - val_loss: 0.7410 - val_accuracy: 0.6651\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.6810 - accuracy: 0.7220 - val_loss: 0.7279 - val_accuracy: 0.6605\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6812 - accuracy: 0.7173 - val_loss: 0.7339 - val_accuracy: 0.6465\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.6785 - accuracy: 0.7178 - val_loss: 0.7238 - val_accuracy: 0.6977\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6842 - accuracy: 0.7127 - val_loss: 0.7258 - val_accuracy: 0.6884\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.7152 - val_loss: 0.7196 - val_accuracy: 0.7070\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6737 - accuracy: 0.7204 - val_loss: 0.7109 - val_accuracy: 0.6930\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6768 - accuracy: 0.7256 - val_loss: 0.7071 - val_accuracy: 0.6977\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6751 - accuracy: 0.7163 - val_loss: 0.7315 - val_accuracy: 0.6605\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 860us/step - loss: 0.6699 - accuracy: 0.7189 - val_loss: 0.7137 - val_accuracy: 0.6698\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 840us/step - loss: 0.6745 - accuracy: 0.7246 - val_loss: 0.7078 - val_accuracy: 0.7070\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6664 - accuracy: 0.7230 - val_loss: 0.7417 - val_accuracy: 0.6977\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6718 - accuracy: 0.7163 - val_loss: 0.7347 - val_accuracy: 0.6744\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6725 - accuracy: 0.7235 - val_loss: 0.7367 - val_accuracy: 0.6558\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6657 - accuracy: 0.7204 - val_loss: 0.7199 - val_accuracy: 0.6744\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 795us/step - loss: 0.6649 - accuracy: 0.7256 - val_loss: 0.7358 - val_accuracy: 0.6651\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.6674 - accuracy: 0.7225 - val_loss: 0.7155 - val_accuracy: 0.6930\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 838us/step - loss: 0.6668 - accuracy: 0.7189 - val_loss: 0.7242 - val_accuracy: 0.6977\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 868us/step - loss: 0.6650 - accuracy: 0.7241 - val_loss: 0.7016 - val_accuracy: 0.6977\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.7261 - val_loss: 0.7021 - val_accuracy: 0.7116\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6611 - accuracy: 0.7199 - val_loss: 0.7140 - val_accuracy: 0.6884\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.6599 - accuracy: 0.7210 - val_loss: 0.7163 - val_accuracy: 0.6884\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6583 - accuracy: 0.7220 - val_loss: 0.7065 - val_accuracy: 0.6837\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6602 - accuracy: 0.7272 - val_loss: 0.7396 - val_accuracy: 0.6884\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6578 - accuracy: 0.7267 - val_loss: 0.6956 - val_accuracy: 0.6977\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.6571 - accuracy: 0.7277 - val_loss: 0.6999 - val_accuracy: 0.6977\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6566 - accuracy: 0.7235 - val_loss: 0.6972 - val_accuracy: 0.7116\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6554 - accuracy: 0.7282 - val_loss: 0.7169 - val_accuracy: 0.6744\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 726us/step - loss: 0.6529 - accuracy: 0.7282 - val_loss: 0.6895 - val_accuracy: 0.7023\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.6576 - accuracy: 0.7272 - val_loss: 0.7013 - val_accuracy: 0.6744\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6524 - accuracy: 0.7287 - val_loss: 0.6974 - val_accuracy: 0.6977\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6530 - accuracy: 0.7277 - val_loss: 0.6949 - val_accuracy: 0.6837\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.6492 - accuracy: 0.7225 - val_loss: 0.7170 - val_accuracy: 0.6698\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6559 - accuracy: 0.7230 - val_loss: 0.6983 - val_accuracy: 0.6930\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6488 - accuracy: 0.7251 - val_loss: 0.7126 - val_accuracy: 0.6977\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6485 - accuracy: 0.7360 - val_loss: 0.7044 - val_accuracy: 0.7023\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6507 - accuracy: 0.7246 - val_loss: 0.7012 - val_accuracy: 0.6930\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6482 - accuracy: 0.7282 - val_loss: 0.7005 - val_accuracy: 0.7023\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6449 - accuracy: 0.7365 - val_loss: 0.6858 - val_accuracy: 0.7070\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6442 - accuracy: 0.7298 - val_loss: 0.6892 - val_accuracy: 0.6837\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6439 - accuracy: 0.7298 - val_loss: 0.6878 - val_accuracy: 0.7023\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6439 - accuracy: 0.7277 - val_loss: 0.6859 - val_accuracy: 0.6977\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6451 - accuracy: 0.7277 - val_loss: 0.7009 - val_accuracy: 0.6698\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6440 - accuracy: 0.7344 - val_loss: 0.6883 - val_accuracy: 0.7023\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6413 - accuracy: 0.7339 - val_loss: 0.6963 - val_accuracy: 0.6884\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.6383 - accuracy: 0.7355 - val_loss: 0.6966 - val_accuracy: 0.6837\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6371 - accuracy: 0.7313 - val_loss: 0.6854 - val_accuracy: 0.6977\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.6377 - accuracy: 0.7360 - val_loss: 0.6865 - val_accuracy: 0.7070\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6403 - accuracy: 0.7282 - val_loss: 0.6947 - val_accuracy: 0.6977\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6340 - accuracy: 0.7282 - val_loss: 0.6778 - val_accuracy: 0.7023\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 847us/step - loss: 0.6420 - accuracy: 0.7287 - val_loss: 0.6770 - val_accuracy: 0.7116\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.7313 - val_loss: 0.6804 - val_accuracy: 0.7163\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.7287 - val_loss: 0.6909 - val_accuracy: 0.7209\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.6351 - accuracy: 0.7344 - val_loss: 0.6877 - val_accuracy: 0.7070\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.7318 - val_loss: 0.6779 - val_accuracy: 0.7302\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6316 - accuracy: 0.7422 - val_loss: 0.6752 - val_accuracy: 0.7023\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6288 - accuracy: 0.7391 - val_loss: 0.6782 - val_accuracy: 0.7163\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6334 - accuracy: 0.7412 - val_loss: 0.6686 - val_accuracy: 0.7209\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6288 - accuracy: 0.7422 - val_loss: 0.6785 - val_accuracy: 0.7256\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6298 - accuracy: 0.7396 - val_loss: 0.6741 - val_accuracy: 0.7209\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6247 - accuracy: 0.7355 - val_loss: 0.6824 - val_accuracy: 0.7163\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.6280 - accuracy: 0.7381 - val_loss: 0.6682 - val_accuracy: 0.7116\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.6271 - accuracy: 0.7334 - val_loss: 0.6675 - val_accuracy: 0.7209\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6246 - accuracy: 0.7438 - val_loss: 0.6824 - val_accuracy: 0.7209\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6230 - accuracy: 0.7433 - val_loss: 0.6607 - val_accuracy: 0.7256\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.6268 - accuracy: 0.7350 - val_loss: 0.6721 - val_accuracy: 0.7116\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6266 - accuracy: 0.7334 - val_loss: 0.6765 - val_accuracy: 0.7256\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6254 - accuracy: 0.7293 - val_loss: 0.6775 - val_accuracy: 0.7302\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.6228 - accuracy: 0.7334 - val_loss: 0.6963 - val_accuracy: 0.7023\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6249 - accuracy: 0.7386 - val_loss: 0.6778 - val_accuracy: 0.7163\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6156 - accuracy: 0.7427 - val_loss: 0.6710 - val_accuracy: 0.7209\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6259 - accuracy: 0.7355 - val_loss: 0.6720 - val_accuracy: 0.7209\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6175 - accuracy: 0.7443 - val_loss: 0.6871 - val_accuracy: 0.6977\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6249 - accuracy: 0.7386 - val_loss: 0.6723 - val_accuracy: 0.7023\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6155 - accuracy: 0.7433 - val_loss: 0.6525 - val_accuracy: 0.7302\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6126 - accuracy: 0.7453 - val_loss: 0.6648 - val_accuracy: 0.7116\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.6156 - accuracy: 0.7448 - val_loss: 0.6491 - val_accuracy: 0.7302\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.7401 - val_loss: 0.6683 - val_accuracy: 0.7349\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 767us/step - loss: 0.6128 - accuracy: 0.7417 - val_loss: 0.6593 - val_accuracy: 0.7349\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 916us/step - loss: 0.6104 - accuracy: 0.7422 - val_loss: 0.6652 - val_accuracy: 0.7302\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.6144 - accuracy: 0.7401 - val_loss: 0.6548 - val_accuracy: 0.7256\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6142 - accuracy: 0.7339 - val_loss: 0.6636 - val_accuracy: 0.7209\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.6162 - accuracy: 0.7427 - val_loss: 0.6756 - val_accuracy: 0.6977\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6244 - accuracy: 0.7401 - val_loss: 0.6490 - val_accuracy: 0.7209\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6116 - accuracy: 0.7464 - val_loss: 0.6558 - val_accuracy: 0.7163\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6141 - accuracy: 0.7453 - val_loss: 0.6545 - val_accuracy: 0.7256\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6124 - accuracy: 0.7443 - val_loss: 0.6670 - val_accuracy: 0.7349\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6084 - accuracy: 0.7412 - val_loss: 0.6478 - val_accuracy: 0.7302\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6080 - accuracy: 0.7433 - val_loss: 0.6456 - val_accuracy: 0.7256\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 794us/step - loss: 0.6077 - accuracy: 0.7417 - val_loss: 0.6506 - val_accuracy: 0.7209\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.6107 - accuracy: 0.7386 - val_loss: 0.6670 - val_accuracy: 0.7116\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6088 - accuracy: 0.7448 - val_loss: 0.6548 - val_accuracy: 0.7256\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.6033 - accuracy: 0.7448 - val_loss: 0.6468 - val_accuracy: 0.7302\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6074 - accuracy: 0.7417 - val_loss: 0.6665 - val_accuracy: 0.7256\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6106 - accuracy: 0.7407 - val_loss: 0.6479 - val_accuracy: 0.7209\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6023 - accuracy: 0.7505 - val_loss: 0.6460 - val_accuracy: 0.7256\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6024 - accuracy: 0.7484 - val_loss: 0.6446 - val_accuracy: 0.7256\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.6028 - accuracy: 0.7500 - val_loss: 0.6450 - val_accuracy: 0.7256\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.6028 - accuracy: 0.7443 - val_loss: 0.6598 - val_accuracy: 0.7302\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6028 - accuracy: 0.7453 - val_loss: 0.6395 - val_accuracy: 0.7209\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6023 - accuracy: 0.7490 - val_loss: 0.6391 - val_accuracy: 0.7256\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 846us/step - loss: 0.6071 - accuracy: 0.7448 - val_loss: 0.6392 - val_accuracy: 0.7256\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5977 - accuracy: 0.7464 - val_loss: 0.6449 - val_accuracy: 0.7116\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5989 - accuracy: 0.7469 - val_loss: 0.6472 - val_accuracy: 0.7256\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5971 - accuracy: 0.7464 - val_loss: 0.6535 - val_accuracy: 0.7209\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5991 - accuracy: 0.7427 - val_loss: 0.6565 - val_accuracy: 0.7349\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.6004 - accuracy: 0.7453 - val_loss: 0.6392 - val_accuracy: 0.7209\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6000 - accuracy: 0.7407 - val_loss: 0.6357 - val_accuracy: 0.7256\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.7443 - val_loss: 0.6555 - val_accuracy: 0.7395\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.5982 - accuracy: 0.7484 - val_loss: 0.6419 - val_accuracy: 0.7349\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.5945 - accuracy: 0.7427 - val_loss: 0.6690 - val_accuracy: 0.7209\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5935 - accuracy: 0.7567 - val_loss: 0.6583 - val_accuracy: 0.7116\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5994 - accuracy: 0.7484 - val_loss: 0.6403 - val_accuracy: 0.7209\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5921 - accuracy: 0.7464 - val_loss: 0.6575 - val_accuracy: 0.7395\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5898 - accuracy: 0.7541 - val_loss: 0.6569 - val_accuracy: 0.7163\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5926 - accuracy: 0.7484 - val_loss: 0.6426 - val_accuracy: 0.7256\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5909 - accuracy: 0.7541 - val_loss: 0.6413 - val_accuracy: 0.7302\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5888 - accuracy: 0.7526 - val_loss: 0.6586 - val_accuracy: 0.7116\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5880 - accuracy: 0.7495 - val_loss: 0.6409 - val_accuracy: 0.7209\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5912 - accuracy: 0.7469 - val_loss: 0.6498 - val_accuracy: 0.7349\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.5897 - accuracy: 0.7552 - val_loss: 0.6470 - val_accuracy: 0.7116\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5882 - accuracy: 0.7536 - val_loss: 0.6465 - val_accuracy: 0.7302\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5896 - accuracy: 0.7557 - val_loss: 0.6554 - val_accuracy: 0.7209\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5841 - accuracy: 0.7593 - val_loss: 0.6523 - val_accuracy: 0.7302\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5880 - accuracy: 0.7469 - val_loss: 0.6349 - val_accuracy: 0.7256\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5849 - accuracy: 0.7552 - val_loss: 0.6702 - val_accuracy: 0.7349\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5886 - accuracy: 0.7500 - val_loss: 0.6379 - val_accuracy: 0.7349\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5850 - accuracy: 0.7531 - val_loss: 0.6359 - val_accuracy: 0.7256\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5857 - accuracy: 0.7531 - val_loss: 0.6499 - val_accuracy: 0.7209\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 788us/step - loss: 0.5848 - accuracy: 0.7630 - val_loss: 0.6567 - val_accuracy: 0.7023\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 860us/step - loss: 0.5841 - accuracy: 0.7552 - val_loss: 0.6408 - val_accuracy: 0.7163\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5825 - accuracy: 0.7547 - val_loss: 0.6445 - val_accuracy: 0.7209\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5873 - accuracy: 0.7593 - val_loss: 0.6402 - val_accuracy: 0.7163\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5835 - accuracy: 0.7552 - val_loss: 0.6598 - val_accuracy: 0.7209\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5814 - accuracy: 0.7583 - val_loss: 0.6467 - val_accuracy: 0.7209\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5800 - accuracy: 0.7573 - val_loss: 0.6436 - val_accuracy: 0.7209\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5844 - accuracy: 0.7547 - val_loss: 0.6466 - val_accuracy: 0.7209\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5830 - accuracy: 0.7521 - val_loss: 0.6778 - val_accuracy: 0.6977\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.5834 - accuracy: 0.7479 - val_loss: 0.6470 - val_accuracy: 0.7302\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5825 - accuracy: 0.7547 - val_loss: 0.6294 - val_accuracy: 0.7256\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5807 - accuracy: 0.7573 - val_loss: 0.6481 - val_accuracy: 0.7209\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.5806 - accuracy: 0.7567 - val_loss: 0.6389 - val_accuracy: 0.7302\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5781 - accuracy: 0.7599 - val_loss: 0.6521 - val_accuracy: 0.7349\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5777 - accuracy: 0.7609 - val_loss: 0.6435 - val_accuracy: 0.7395\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5761 - accuracy: 0.7588 - val_loss: 0.6330 - val_accuracy: 0.7302\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5806 - accuracy: 0.7573 - val_loss: 0.6622 - val_accuracy: 0.7256\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5780 - accuracy: 0.7557 - val_loss: 0.6840 - val_accuracy: 0.7395\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5787 - accuracy: 0.7599 - val_loss: 0.6435 - val_accuracy: 0.7349\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5760 - accuracy: 0.7583 - val_loss: 0.6315 - val_accuracy: 0.7302\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5761 - accuracy: 0.7562 - val_loss: 0.6309 - val_accuracy: 0.7209\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5772 - accuracy: 0.7516 - val_loss: 0.6426 - val_accuracy: 0.7256\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5788 - accuracy: 0.7619 - val_loss: 0.6256 - val_accuracy: 0.7209\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5773 - accuracy: 0.7645 - val_loss: 0.6654 - val_accuracy: 0.7302\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5791 - accuracy: 0.7614 - val_loss: 0.6393 - val_accuracy: 0.7349\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5727 - accuracy: 0.7588 - val_loss: 0.6362 - val_accuracy: 0.7256\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5729 - accuracy: 0.7562 - val_loss: 0.6418 - val_accuracy: 0.7349\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5715 - accuracy: 0.7635 - val_loss: 0.6340 - val_accuracy: 0.7256\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5707 - accuracy: 0.7630 - val_loss: 0.6377 - val_accuracy: 0.7395\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5712 - accuracy: 0.7593 - val_loss: 0.6385 - val_accuracy: 0.7395\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5727 - accuracy: 0.7578 - val_loss: 0.6625 - val_accuracy: 0.7302\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5676 - accuracy: 0.7635 - val_loss: 0.6391 - val_accuracy: 0.7256\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5710 - accuracy: 0.7656 - val_loss: 0.6400 - val_accuracy: 0.7163\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5713 - accuracy: 0.7567 - val_loss: 0.6462 - val_accuracy: 0.7302\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7614 - val_loss: 0.6475 - val_accuracy: 0.7488\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5674 - accuracy: 0.7640 - val_loss: 0.6644 - val_accuracy: 0.7209\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.5699 - accuracy: 0.7640 - val_loss: 0.6437 - val_accuracy: 0.7349\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5682 - accuracy: 0.7609 - val_loss: 0.6392 - val_accuracy: 0.7349\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5683 - accuracy: 0.7614 - val_loss: 0.6445 - val_accuracy: 0.7349\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5717 - accuracy: 0.7578 - val_loss: 0.6436 - val_accuracy: 0.7349\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5687 - accuracy: 0.7573 - val_loss: 0.6550 - val_accuracy: 0.7302\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5676 - accuracy: 0.7624 - val_loss: 0.6297 - val_accuracy: 0.7302\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5692 - accuracy: 0.7578 - val_loss: 0.6349 - val_accuracy: 0.7395\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5690 - accuracy: 0.7619 - val_loss: 0.6466 - val_accuracy: 0.7442\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5665 - accuracy: 0.7624 - val_loss: 0.6413 - val_accuracy: 0.7442\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5657 - accuracy: 0.7645 - val_loss: 0.6523 - val_accuracy: 0.7302\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5666 - accuracy: 0.7640 - val_loss: 0.6461 - val_accuracy: 0.7349\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5676 - accuracy: 0.7697 - val_loss: 0.6295 - val_accuracy: 0.7349\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5664 - accuracy: 0.7609 - val_loss: 0.6292 - val_accuracy: 0.7395\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.5655 - accuracy: 0.7661 - val_loss: 0.6322 - val_accuracy: 0.7349\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 864us/step - loss: 0.5675 - accuracy: 0.7609 - val_loss: 0.6388 - val_accuracy: 0.7395\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.5632 - accuracy: 0.7635 - val_loss: 0.6382 - val_accuracy: 0.7349\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.5625 - accuracy: 0.7666 - val_loss: 0.6433 - val_accuracy: 0.7302\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5648 - accuracy: 0.7630 - val_loss: 0.6684 - val_accuracy: 0.7209\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5630 - accuracy: 0.7557 - val_loss: 0.6368 - val_accuracy: 0.7349\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5633 - accuracy: 0.7630 - val_loss: 0.6389 - val_accuracy: 0.7442\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5594 - accuracy: 0.7661 - val_loss: 0.6495 - val_accuracy: 0.7256\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.5630 - accuracy: 0.7661 - val_loss: 0.6525 - val_accuracy: 0.7209\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5669 - accuracy: 0.7645 - val_loss: 0.6635 - val_accuracy: 0.7256\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5630 - accuracy: 0.7640 - val_loss: 0.6368 - val_accuracy: 0.7302\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5625 - accuracy: 0.7682 - val_loss: 0.6409 - val_accuracy: 0.7209\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5615 - accuracy: 0.7656 - val_loss: 0.6233 - val_accuracy: 0.7395\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5600 - accuracy: 0.7609 - val_loss: 0.6310 - val_accuracy: 0.7349\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7661 - val_loss: 0.6378 - val_accuracy: 0.7535\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5623 - accuracy: 0.7630 - val_loss: 0.6314 - val_accuracy: 0.7302\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5585 - accuracy: 0.7671 - val_loss: 0.6376 - val_accuracy: 0.7302\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.5659 - accuracy: 0.7604 - val_loss: 0.6266 - val_accuracy: 0.7395\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5599 - accuracy: 0.7614 - val_loss: 0.6277 - val_accuracy: 0.7209\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.5625 - accuracy: 0.7661 - val_loss: 0.6247 - val_accuracy: 0.7302\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5630 - accuracy: 0.7640 - val_loss: 0.6367 - val_accuracy: 0.7302\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 716us/step - loss: 0.5590 - accuracy: 0.7656 - val_loss: 0.6663 - val_accuracy: 0.7116\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 963us/step - loss: 0.5583 - accuracy: 0.7630 - val_loss: 0.6354 - val_accuracy: 0.7302\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5562 - accuracy: 0.7645 - val_loss: 0.6525 - val_accuracy: 0.7302\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5582 - accuracy: 0.7682 - val_loss: 0.6470 - val_accuracy: 0.7488\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5586 - accuracy: 0.7640 - val_loss: 0.6539 - val_accuracy: 0.7256\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5566 - accuracy: 0.7640 - val_loss: 0.6340 - val_accuracy: 0.7442\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5588 - accuracy: 0.7702 - val_loss: 0.6284 - val_accuracy: 0.7209\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5556 - accuracy: 0.7687 - val_loss: 0.6225 - val_accuracy: 0.7395\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.5595 - accuracy: 0.7635 - val_loss: 0.6253 - val_accuracy: 0.7442\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.5542 - accuracy: 0.7697 - val_loss: 0.6454 - val_accuracy: 0.7395\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.5546 - accuracy: 0.7718 - val_loss: 0.6200 - val_accuracy: 0.7349\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5581 - accuracy: 0.7687 - val_loss: 0.6393 - val_accuracy: 0.7209\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5568 - accuracy: 0.7666 - val_loss: 0.6334 - val_accuracy: 0.7302\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5537 - accuracy: 0.7666 - val_loss: 0.6487 - val_accuracy: 0.7116\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 859us/step - loss: 0.5563 - accuracy: 0.7614 - val_loss: 0.6365 - val_accuracy: 0.7442\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5567 - accuracy: 0.7624 - val_loss: 0.6393 - val_accuracy: 0.7395\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5594 - accuracy: 0.7624 - val_loss: 0.6412 - val_accuracy: 0.7349\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.5538 - accuracy: 0.7728 - val_loss: 0.6327 - val_accuracy: 0.7395\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5526 - accuracy: 0.7656 - val_loss: 0.6342 - val_accuracy: 0.7349\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5540 - accuracy: 0.7713 - val_loss: 0.6498 - val_accuracy: 0.7442\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5520 - accuracy: 0.7676 - val_loss: 0.6348 - val_accuracy: 0.7256\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5525 - accuracy: 0.7718 - val_loss: 0.6259 - val_accuracy: 0.7395\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5534 - accuracy: 0.7661 - val_loss: 0.6296 - val_accuracy: 0.7349\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5520 - accuracy: 0.7640 - val_loss: 0.6690 - val_accuracy: 0.7163\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5531 - accuracy: 0.7676 - val_loss: 0.6374 - val_accuracy: 0.7488\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5543 - accuracy: 0.7744 - val_loss: 0.6323 - val_accuracy: 0.7395\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5518 - accuracy: 0.7640 - val_loss: 0.6247 - val_accuracy: 0.7256\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5543 - accuracy: 0.7676 - val_loss: 0.6563 - val_accuracy: 0.7256\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5545 - accuracy: 0.7713 - val_loss: 0.6330 - val_accuracy: 0.7442\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.5508 - accuracy: 0.7718 - val_loss: 0.6353 - val_accuracy: 0.7395\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5512 - accuracy: 0.7682 - val_loss: 0.6475 - val_accuracy: 0.7395\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5517 - accuracy: 0.7682 - val_loss: 0.6298 - val_accuracy: 0.7488\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5496 - accuracy: 0.7650 - val_loss: 0.6489 - val_accuracy: 0.7256\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5547 - accuracy: 0.7749 - val_loss: 0.6453 - val_accuracy: 0.7302\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5527 - accuracy: 0.7666 - val_loss: 0.6349 - val_accuracy: 0.7395\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5499 - accuracy: 0.7676 - val_loss: 0.6425 - val_accuracy: 0.7395\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5546 - accuracy: 0.7702 - val_loss: 0.6438 - val_accuracy: 0.7302\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5512 - accuracy: 0.7749 - val_loss: 0.6550 - val_accuracy: 0.7116\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.5511 - accuracy: 0.7661 - val_loss: 0.6460 - val_accuracy: 0.7349\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5540 - accuracy: 0.7733 - val_loss: 0.6259 - val_accuracy: 0.7349\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5546 - accuracy: 0.7697 - val_loss: 0.6375 - val_accuracy: 0.7488\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.7650 - val_loss: 0.6504 - val_accuracy: 0.7674\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5512 - accuracy: 0.7687 - val_loss: 0.6436 - val_accuracy: 0.7395\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5480 - accuracy: 0.7682 - val_loss: 0.6269 - val_accuracy: 0.7256\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5525 - accuracy: 0.7733 - val_loss: 0.6285 - val_accuracy: 0.7349\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5502 - accuracy: 0.7728 - val_loss: 0.6272 - val_accuracy: 0.7302\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5500 - accuracy: 0.7692 - val_loss: 0.6358 - val_accuracy: 0.7163\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5483 - accuracy: 0.7707 - val_loss: 0.6322 - val_accuracy: 0.7442\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5467 - accuracy: 0.7707 - val_loss: 0.6321 - val_accuracy: 0.7442\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5486 - accuracy: 0.7702 - val_loss: 0.6323 - val_accuracy: 0.7349\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5516 - accuracy: 0.7687 - val_loss: 0.6372 - val_accuracy: 0.7395\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5431 - accuracy: 0.7728 - val_loss: 0.6422 - val_accuracy: 0.7256\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5449 - accuracy: 0.7749 - val_loss: 0.6486 - val_accuracy: 0.7163\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5471 - accuracy: 0.7692 - val_loss: 0.6418 - val_accuracy: 0.7349\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5437 - accuracy: 0.7811 - val_loss: 0.6379 - val_accuracy: 0.7256\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5486 - accuracy: 0.7775 - val_loss: 0.6281 - val_accuracy: 0.7395\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5474 - accuracy: 0.7733 - val_loss: 0.6272 - val_accuracy: 0.7349\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5451 - accuracy: 0.7785 - val_loss: 0.6277 - val_accuracy: 0.7442\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5493 - accuracy: 0.7707 - val_loss: 0.6486 - val_accuracy: 0.7116\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5477 - accuracy: 0.7676 - val_loss: 0.6448 - val_accuracy: 0.7442\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5480 - accuracy: 0.7713 - val_loss: 0.6206 - val_accuracy: 0.7256\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5458 - accuracy: 0.7707 - val_loss: 0.6272 - val_accuracy: 0.7302\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5480 - accuracy: 0.7650 - val_loss: 0.6264 - val_accuracy: 0.7302\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5464 - accuracy: 0.7676 - val_loss: 0.6197 - val_accuracy: 0.7209\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5476 - accuracy: 0.7661 - val_loss: 0.6338 - val_accuracy: 0.7442\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5438 - accuracy: 0.7733 - val_loss: 0.6315 - val_accuracy: 0.7395\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5465 - accuracy: 0.7723 - val_loss: 0.6552 - val_accuracy: 0.7395\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5479 - accuracy: 0.7697 - val_loss: 0.6642 - val_accuracy: 0.7163\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5441 - accuracy: 0.7770 - val_loss: 0.6471 - val_accuracy: 0.7302\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5415 - accuracy: 0.7687 - val_loss: 0.6346 - val_accuracy: 0.7302\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5480 - accuracy: 0.7697 - val_loss: 0.6546 - val_accuracy: 0.7302\n",
      "Epoch 369/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5427 - accuracy: 0.7728 - val_loss: 0.6320 - val_accuracy: 0.7442\n",
      "Epoch 370/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.5430 - accuracy: 0.7759 - val_loss: 0.6352 - val_accuracy: 0.7209\n",
      "Epoch 371/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5423 - accuracy: 0.7780 - val_loss: 0.6326 - val_accuracy: 0.7395\n",
      "Epoch 372/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5419 - accuracy: 0.7713 - val_loss: 0.6325 - val_accuracy: 0.7442\n",
      "Epoch 373/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5396 - accuracy: 0.7770 - val_loss: 0.6197 - val_accuracy: 0.7302\n",
      "Epoch 374/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5462 - accuracy: 0.7640 - val_loss: 0.6408 - val_accuracy: 0.7535\n",
      "Epoch 375/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5470 - accuracy: 0.7713 - val_loss: 0.6288 - val_accuracy: 0.7302\n",
      "Epoch 376/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5435 - accuracy: 0.7697 - val_loss: 0.6343 - val_accuracy: 0.7488\n",
      "Epoch 377/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5432 - accuracy: 0.7733 - val_loss: 0.6340 - val_accuracy: 0.7442\n",
      "Epoch 378/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5431 - accuracy: 0.7692 - val_loss: 0.6472 - val_accuracy: 0.7535\n",
      "Epoch 379/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5417 - accuracy: 0.7765 - val_loss: 0.6374 - val_accuracy: 0.7535\n",
      "Epoch 380/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5442 - accuracy: 0.7754 - val_loss: 0.6690 - val_accuracy: 0.7442\n",
      "Epoch 381/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5430 - accuracy: 0.7666 - val_loss: 0.6306 - val_accuracy: 0.7395\n",
      "Epoch 382/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5508 - accuracy: 0.7671 - val_loss: 0.6344 - val_accuracy: 0.7209\n",
      "Epoch 383/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5416 - accuracy: 0.7775 - val_loss: 0.6298 - val_accuracy: 0.7256\n",
      "Epoch 384/500\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.5424 - accuracy: 0.7749 - val_loss: 0.6460 - val_accuracy: 0.7488\n",
      "Epoch 385/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5425 - accuracy: 0.7733 - val_loss: 0.6376 - val_accuracy: 0.7488\n",
      "Epoch 386/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5467 - accuracy: 0.7749 - val_loss: 0.6396 - val_accuracy: 0.7442\n",
      "Epoch 387/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5390 - accuracy: 0.7707 - val_loss: 0.6460 - val_accuracy: 0.7256\n",
      "Epoch 388/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5409 - accuracy: 0.7733 - val_loss: 0.6354 - val_accuracy: 0.7349\n",
      "Epoch 389/500\n",
      "72/72 [==============================] - 0s 796us/step - loss: 0.5416 - accuracy: 0.7718 - val_loss: 0.6332 - val_accuracy: 0.7395\n",
      "Epoch 390/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5405 - accuracy: 0.7754 - val_loss: 0.6431 - val_accuracy: 0.7395\n",
      "Epoch 391/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5445 - accuracy: 0.7801 - val_loss: 0.6473 - val_accuracy: 0.7209\n",
      "Epoch 392/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5432 - accuracy: 0.7744 - val_loss: 0.6395 - val_accuracy: 0.7302\n",
      "Epoch 393/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5412 - accuracy: 0.7749 - val_loss: 0.6373 - val_accuracy: 0.7395\n",
      "Epoch 394/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5416 - accuracy: 0.7733 - val_loss: 0.6411 - val_accuracy: 0.7395\n",
      "Epoch 395/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5444 - accuracy: 0.7713 - val_loss: 0.6349 - val_accuracy: 0.7349\n",
      "Epoch 396/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5391 - accuracy: 0.7749 - val_loss: 0.6424 - val_accuracy: 0.7442\n",
      "Epoch 397/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5396 - accuracy: 0.7739 - val_loss: 0.6278 - val_accuracy: 0.7395\n",
      "Epoch 398/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5442 - accuracy: 0.7733 - val_loss: 0.6430 - val_accuracy: 0.7116\n",
      "Epoch 399/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5467 - accuracy: 0.7650 - val_loss: 0.6332 - val_accuracy: 0.7349\n",
      "Epoch 400/500\n",
      "72/72 [==============================] - 0s 697us/step - loss: 0.5393 - accuracy: 0.7785 - val_loss: 0.6275 - val_accuracy: 0.7256\n",
      "Epoch 401/500\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.5388 - accuracy: 0.7739 - val_loss: 0.6434 - val_accuracy: 0.7256\n",
      "Epoch 402/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5366 - accuracy: 0.7728 - val_loss: 0.6363 - val_accuracy: 0.7488\n",
      "Epoch 403/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5367 - accuracy: 0.7718 - val_loss: 0.6317 - val_accuracy: 0.7256\n",
      "Epoch 404/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5387 - accuracy: 0.7744 - val_loss: 0.6473 - val_accuracy: 0.7209\n",
      "Epoch 405/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5375 - accuracy: 0.7775 - val_loss: 0.6266 - val_accuracy: 0.7302\n",
      "Epoch 406/500\n",
      "72/72 [==============================] - 0s 799us/step - loss: 0.5389 - accuracy: 0.7728 - val_loss: 0.6292 - val_accuracy: 0.7302\n",
      "Epoch 407/500\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.5408 - accuracy: 0.7785 - val_loss: 0.6522 - val_accuracy: 0.7488\n",
      "Epoch 408/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5385 - accuracy: 0.7728 - val_loss: 0.6310 - val_accuracy: 0.7442\n",
      "Epoch 409/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5404 - accuracy: 0.7676 - val_loss: 0.6599 - val_accuracy: 0.7070\n",
      "Epoch 410/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.5403 - accuracy: 0.7775 - val_loss: 0.6291 - val_accuracy: 0.7349\n",
      "Epoch 411/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5360 - accuracy: 0.7739 - val_loss: 0.6461 - val_accuracy: 0.7349\n",
      "Epoch 412/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5360 - accuracy: 0.7718 - val_loss: 0.6486 - val_accuracy: 0.7256\n",
      "Epoch 413/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5374 - accuracy: 0.7811 - val_loss: 0.6537 - val_accuracy: 0.7163\n",
      "Epoch 414/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5380 - accuracy: 0.7749 - val_loss: 0.6323 - val_accuracy: 0.7395\n",
      "Epoch 415/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5361 - accuracy: 0.7749 - val_loss: 0.6389 - val_accuracy: 0.7488\n",
      "Epoch 416/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5360 - accuracy: 0.7744 - val_loss: 0.6419 - val_accuracy: 0.7581\n",
      "Epoch 417/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5365 - accuracy: 0.7785 - val_loss: 0.6276 - val_accuracy: 0.7395\n",
      "Epoch 418/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5350 - accuracy: 0.7718 - val_loss: 0.6354 - val_accuracy: 0.7442\n",
      "Epoch 419/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.5327 - accuracy: 0.7770 - val_loss: 0.6343 - val_accuracy: 0.7488\n",
      "Epoch 420/500\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.5347 - accuracy: 0.7811 - val_loss: 0.6469 - val_accuracy: 0.7256\n",
      "Epoch 421/500\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.5373 - accuracy: 0.7759 - val_loss: 0.6390 - val_accuracy: 0.7488\n",
      "Epoch 422/500\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.5383 - accuracy: 0.7749 - val_loss: 0.6423 - val_accuracy: 0.7442\n",
      "Epoch 423/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5373 - accuracy: 0.7744 - val_loss: 0.6264 - val_accuracy: 0.7442\n",
      "Epoch 424/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5365 - accuracy: 0.7749 - val_loss: 0.6385 - val_accuracy: 0.7395\n",
      "Epoch 425/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5354 - accuracy: 0.7785 - val_loss: 0.6318 - val_accuracy: 0.7256\n",
      "Epoch 426/500\n",
      "72/72 [==============================] - 0s 748us/step - loss: 0.5330 - accuracy: 0.7811 - val_loss: 0.6216 - val_accuracy: 0.7256\n",
      "Epoch 427/500\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.5351 - accuracy: 0.7707 - val_loss: 0.6467 - val_accuracy: 0.7256\n",
      "Epoch 428/500\n",
      "72/72 [==============================] - 0s 840us/step - loss: 0.5330 - accuracy: 0.7790 - val_loss: 0.6187 - val_accuracy: 0.7349\n",
      "Epoch 429/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5352 - accuracy: 0.7770 - val_loss: 0.6942 - val_accuracy: 0.7209\n",
      "Epoch 430/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.5433 - accuracy: 0.7765 - val_loss: 0.6416 - val_accuracy: 0.7395\n",
      "Epoch 431/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5326 - accuracy: 0.7775 - val_loss: 0.6551 - val_accuracy: 0.7488\n",
      "Epoch 432/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5341 - accuracy: 0.7796 - val_loss: 0.6437 - val_accuracy: 0.7488\n",
      "Epoch 433/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5346 - accuracy: 0.7749 - val_loss: 0.6534 - val_accuracy: 0.7674\n",
      "Epoch 434/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5313 - accuracy: 0.7759 - val_loss: 0.6746 - val_accuracy: 0.7070\n",
      "Epoch 435/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5352 - accuracy: 0.7775 - val_loss: 0.6243 - val_accuracy: 0.7302\n",
      "Epoch 436/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5339 - accuracy: 0.7796 - val_loss: 0.6363 - val_accuracy: 0.7488\n",
      "Epoch 437/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5336 - accuracy: 0.7759 - val_loss: 0.6431 - val_accuracy: 0.7209\n",
      "Epoch 438/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5334 - accuracy: 0.7702 - val_loss: 0.6569 - val_accuracy: 0.7535\n",
      "Epoch 439/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5350 - accuracy: 0.7806 - val_loss: 0.6286 - val_accuracy: 0.7302\n",
      "Epoch 439: early stopping\n",
      "29/29 - 0s - loss: 0.5395 - accuracy: 0.7713 - 112ms/epoch - 4ms/step\n",
      "9\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5621 - accuracy: 0.2925 - val_loss: 1.4655 - val_accuracy: 0.3953\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 999us/step - loss: 1.3950 - accuracy: 0.4072 - val_loss: 1.3389 - val_accuracy: 0.4698\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 1.2995 - accuracy: 0.4445 - val_loss: 1.2801 - val_accuracy: 0.4372\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 1.2493 - accuracy: 0.4647 - val_loss: 1.2426 - val_accuracy: 0.4605\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 1.2165 - accuracy: 0.4767 - val_loss: 1.2107 - val_accuracy: 0.4605\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1864 - accuracy: 0.4844 - val_loss: 1.1863 - val_accuracy: 0.4977\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1611 - accuracy: 0.4969 - val_loss: 1.1641 - val_accuracy: 0.5209\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 1.1372 - accuracy: 0.5176 - val_loss: 1.1324 - val_accuracy: 0.5209\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1135 - accuracy: 0.5316 - val_loss: 1.1111 - val_accuracy: 0.5349\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 834us/step - loss: 1.0854 - accuracy: 0.5436 - val_loss: 1.0941 - val_accuracy: 0.5302\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 1.0644 - accuracy: 0.5565 - val_loss: 1.0658 - val_accuracy: 0.5302\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 1.0409 - accuracy: 0.5529 - val_loss: 1.0523 - val_accuracy: 0.5302\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0158 - accuracy: 0.5799 - val_loss: 1.0154 - val_accuracy: 0.5628\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9900 - accuracy: 0.5908 - val_loss: 0.9914 - val_accuracy: 0.5674\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.9665 - accuracy: 0.5970 - val_loss: 0.9828 - val_accuracy: 0.5674\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.9447 - accuracy: 0.6126 - val_loss: 0.9672 - val_accuracy: 0.5628\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9323 - accuracy: 0.6151 - val_loss: 0.9384 - val_accuracy: 0.6093\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9123 - accuracy: 0.6302 - val_loss: 0.9251 - val_accuracy: 0.6279\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.8946 - accuracy: 0.6442 - val_loss: 0.9226 - val_accuracy: 0.5860\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.8903 - accuracy: 0.6390 - val_loss: 0.8961 - val_accuracy: 0.6186\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.8745 - accuracy: 0.6478 - val_loss: 0.8908 - val_accuracy: 0.6093\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.8683 - accuracy: 0.6395 - val_loss: 0.8862 - val_accuracy: 0.6093\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.8627 - accuracy: 0.6530 - val_loss: 0.8808 - val_accuracy: 0.6047\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.8613 - accuracy: 0.6489 - val_loss: 0.8672 - val_accuracy: 0.6047\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8492 - accuracy: 0.6489 - val_loss: 0.8621 - val_accuracy: 0.6140\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8480 - accuracy: 0.6520 - val_loss: 0.8739 - val_accuracy: 0.6047\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.8458 - accuracy: 0.6494 - val_loss: 0.8682 - val_accuracy: 0.6047\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.8441 - accuracy: 0.6499 - val_loss: 0.8616 - val_accuracy: 0.6047\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 860us/step - loss: 0.8383 - accuracy: 0.6587 - val_loss: 0.8598 - val_accuracy: 0.6140\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.8359 - accuracy: 0.6530 - val_loss: 0.8759 - val_accuracy: 0.6140\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.8275 - accuracy: 0.6618 - val_loss: 0.8474 - val_accuracy: 0.6186\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.8266 - accuracy: 0.6582 - val_loss: 0.8392 - val_accuracy: 0.6233\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.8234 - accuracy: 0.6618 - val_loss: 0.8362 - val_accuracy: 0.6326\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.8272 - accuracy: 0.6649 - val_loss: 0.8552 - val_accuracy: 0.6000\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.8191 - accuracy: 0.6649 - val_loss: 0.8433 - val_accuracy: 0.6326\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.8153 - accuracy: 0.6629 - val_loss: 0.8368 - val_accuracy: 0.6233\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 770us/step - loss: 0.8171 - accuracy: 0.6649 - val_loss: 0.8307 - val_accuracy: 0.6326\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.8108 - accuracy: 0.6717 - val_loss: 0.8294 - val_accuracy: 0.6233\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 749us/step - loss: 0.8079 - accuracy: 0.6696 - val_loss: 0.8367 - val_accuracy: 0.6326\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.8099 - accuracy: 0.6691 - val_loss: 0.8307 - val_accuracy: 0.6186\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.8054 - accuracy: 0.6675 - val_loss: 0.8424 - val_accuracy: 0.6186\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8029 - accuracy: 0.6691 - val_loss: 0.8245 - val_accuracy: 0.6372\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 916us/step - loss: 0.7994 - accuracy: 0.6769 - val_loss: 0.8274 - val_accuracy: 0.6233\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.8019 - accuracy: 0.6686 - val_loss: 0.8136 - val_accuracy: 0.6000\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 781us/step - loss: 0.7964 - accuracy: 0.6722 - val_loss: 0.8192 - val_accuracy: 0.6372\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 883us/step - loss: 0.7925 - accuracy: 0.6789 - val_loss: 0.8097 - val_accuracy: 0.6233\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7898 - accuracy: 0.6691 - val_loss: 0.8092 - val_accuracy: 0.6279\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7874 - accuracy: 0.6753 - val_loss: 0.8061 - val_accuracy: 0.6326\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7835 - accuracy: 0.6738 - val_loss: 0.8189 - val_accuracy: 0.6140\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.7892 - accuracy: 0.6779 - val_loss: 0.7985 - val_accuracy: 0.6279\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 803us/step - loss: 0.7820 - accuracy: 0.6758 - val_loss: 0.8236 - val_accuracy: 0.6186\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 782us/step - loss: 0.7765 - accuracy: 0.6831 - val_loss: 0.7938 - val_accuracy: 0.6372\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7785 - accuracy: 0.6821 - val_loss: 0.8031 - val_accuracy: 0.6186\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7752 - accuracy: 0.6805 - val_loss: 0.7977 - val_accuracy: 0.6465\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 847us/step - loss: 0.7734 - accuracy: 0.6815 - val_loss: 0.7863 - val_accuracy: 0.6465\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7709 - accuracy: 0.6789 - val_loss: 0.7868 - val_accuracy: 0.6465\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.7670 - accuracy: 0.6805 - val_loss: 0.7967 - val_accuracy: 0.6326\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7631 - accuracy: 0.6857 - val_loss: 0.7845 - val_accuracy: 0.6372\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7629 - accuracy: 0.6841 - val_loss: 0.7982 - val_accuracy: 0.6279\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7611 - accuracy: 0.6862 - val_loss: 0.7830 - val_accuracy: 0.6419\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7569 - accuracy: 0.6945 - val_loss: 0.7860 - val_accuracy: 0.6419\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7552 - accuracy: 0.6883 - val_loss: 0.7848 - val_accuracy: 0.6419\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 753us/step - loss: 0.7541 - accuracy: 0.6867 - val_loss: 0.7897 - val_accuracy: 0.6233\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 749us/step - loss: 0.7517 - accuracy: 0.6966 - val_loss: 0.7785 - val_accuracy: 0.6372\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.7474 - accuracy: 0.6955 - val_loss: 0.8002 - val_accuracy: 0.6279\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 864us/step - loss: 0.7475 - accuracy: 0.6909 - val_loss: 0.7890 - val_accuracy: 0.6326\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.7446 - accuracy: 0.6929 - val_loss: 0.7738 - val_accuracy: 0.6326\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7417 - accuracy: 0.6935 - val_loss: 0.7660 - val_accuracy: 0.6512\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.7378 - accuracy: 0.7018 - val_loss: 0.7711 - val_accuracy: 0.6372\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7380 - accuracy: 0.6935 - val_loss: 0.7879 - val_accuracy: 0.6326\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7359 - accuracy: 0.6992 - val_loss: 0.7696 - val_accuracy: 0.6279\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.7018 - val_loss: 0.7712 - val_accuracy: 0.6605\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.7322 - accuracy: 0.6862 - val_loss: 0.7728 - val_accuracy: 0.6558\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.7286 - accuracy: 0.6992 - val_loss: 0.7696 - val_accuracy: 0.6419\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 753us/step - loss: 0.7293 - accuracy: 0.7007 - val_loss: 0.7783 - val_accuracy: 0.6512\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.7272 - accuracy: 0.7012 - val_loss: 0.7564 - val_accuracy: 0.6512\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.7237 - accuracy: 0.6992 - val_loss: 0.7836 - val_accuracy: 0.6605\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7228 - accuracy: 0.7002 - val_loss: 0.7618 - val_accuracy: 0.6419\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.7297 - accuracy: 0.7007 - val_loss: 0.7590 - val_accuracy: 0.6605\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7221 - accuracy: 0.7002 - val_loss: 0.7577 - val_accuracy: 0.6465\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7139 - accuracy: 0.7049 - val_loss: 0.7644 - val_accuracy: 0.6372\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.7038 - val_loss: 0.7616 - val_accuracy: 0.6651\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 823us/step - loss: 0.7170 - accuracy: 0.6966 - val_loss: 0.7599 - val_accuracy: 0.6326\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7119 - accuracy: 0.7095 - val_loss: 0.7565 - val_accuracy: 0.6512\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7103 - accuracy: 0.7070 - val_loss: 0.7542 - val_accuracy: 0.6651\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7072 - accuracy: 0.7085 - val_loss: 0.7622 - val_accuracy: 0.6326\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.7074 - accuracy: 0.7070 - val_loss: 0.7523 - val_accuracy: 0.6651\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.7089 - accuracy: 0.6971 - val_loss: 0.7416 - val_accuracy: 0.6651\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.7032 - accuracy: 0.7142 - val_loss: 0.7374 - val_accuracy: 0.6651\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.7054 - val_loss: 0.7398 - val_accuracy: 0.6698\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.7049 - val_loss: 0.7490 - val_accuracy: 0.6744\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 978us/step - loss: 0.6988 - accuracy: 0.7075 - val_loss: 0.7643 - val_accuracy: 0.6419\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.7075 - val_loss: 0.7342 - val_accuracy: 0.6837\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.6989 - accuracy: 0.7132 - val_loss: 0.7418 - val_accuracy: 0.6605\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6914 - accuracy: 0.7173 - val_loss: 0.7562 - val_accuracy: 0.6558\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6900 - accuracy: 0.7158 - val_loss: 0.7467 - val_accuracy: 0.6465\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6930 - accuracy: 0.7085 - val_loss: 0.7420 - val_accuracy: 0.6465\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6905 - accuracy: 0.7152 - val_loss: 0.7368 - val_accuracy: 0.6651\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6917 - accuracy: 0.7173 - val_loss: 0.7438 - val_accuracy: 0.6558\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.7085 - val_loss: 0.7331 - val_accuracy: 0.6884\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6893 - accuracy: 0.7116 - val_loss: 0.7306 - val_accuracy: 0.6744\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6867 - accuracy: 0.7137 - val_loss: 0.7407 - val_accuracy: 0.6465\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6830 - accuracy: 0.7127 - val_loss: 0.7262 - val_accuracy: 0.6791\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6827 - accuracy: 0.7090 - val_loss: 0.7243 - val_accuracy: 0.6791\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 973us/step - loss: 0.6799 - accuracy: 0.7168 - val_loss: 0.7340 - val_accuracy: 0.6512\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.6817 - accuracy: 0.7111 - val_loss: 0.7218 - val_accuracy: 0.6744\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6806 - accuracy: 0.7101 - val_loss: 0.7227 - val_accuracy: 0.6837\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.7210 - val_loss: 0.7164 - val_accuracy: 0.6930\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6806 - accuracy: 0.7127 - val_loss: 0.7154 - val_accuracy: 0.6930\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.6800 - accuracy: 0.7173 - val_loss: 0.7326 - val_accuracy: 0.6791\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6712 - accuracy: 0.7210 - val_loss: 0.7164 - val_accuracy: 0.6651\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6739 - accuracy: 0.7225 - val_loss: 0.7162 - val_accuracy: 0.6791\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.6720 - accuracy: 0.7220 - val_loss: 0.7126 - val_accuracy: 0.6930\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6729 - accuracy: 0.7220 - val_loss: 0.7121 - val_accuracy: 0.6837\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6718 - accuracy: 0.7220 - val_loss: 0.7133 - val_accuracy: 0.6698\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6648 - accuracy: 0.7184 - val_loss: 0.7185 - val_accuracy: 0.6605\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.6649 - accuracy: 0.7173 - val_loss: 0.7231 - val_accuracy: 0.6698\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6645 - accuracy: 0.7184 - val_loss: 0.7368 - val_accuracy: 0.6558\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.6627 - accuracy: 0.7256 - val_loss: 0.7104 - val_accuracy: 0.6884\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6623 - accuracy: 0.7230 - val_loss: 0.7235 - val_accuracy: 0.6884\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.7313 - val_loss: 0.7069 - val_accuracy: 0.7116\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6625 - accuracy: 0.7230 - val_loss: 0.7044 - val_accuracy: 0.6744\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6595 - accuracy: 0.7230 - val_loss: 0.7214 - val_accuracy: 0.6744\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6632 - accuracy: 0.7246 - val_loss: 0.7084 - val_accuracy: 0.6930\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6577 - accuracy: 0.7246 - val_loss: 0.7071 - val_accuracy: 0.6791\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6581 - accuracy: 0.7194 - val_loss: 0.7146 - val_accuracy: 0.7116\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6580 - accuracy: 0.7272 - val_loss: 0.7092 - val_accuracy: 0.6977\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.6548 - accuracy: 0.7267 - val_loss: 0.6944 - val_accuracy: 0.6977\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6586 - accuracy: 0.7267 - val_loss: 0.7039 - val_accuracy: 0.6884\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6532 - accuracy: 0.7261 - val_loss: 0.7119 - val_accuracy: 0.6930\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6523 - accuracy: 0.7267 - val_loss: 0.6988 - val_accuracy: 0.6930\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.6587 - accuracy: 0.7282 - val_loss: 0.7094 - val_accuracy: 0.6791\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.7287 - val_loss: 0.7097 - val_accuracy: 0.6977\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.6495 - accuracy: 0.7293 - val_loss: 0.6989 - val_accuracy: 0.6977\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6491 - accuracy: 0.7282 - val_loss: 0.7201 - val_accuracy: 0.6605\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.6543 - accuracy: 0.7272 - val_loss: 0.7013 - val_accuracy: 0.6884\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.6455 - accuracy: 0.7324 - val_loss: 0.7049 - val_accuracy: 0.7023\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6494 - accuracy: 0.7334 - val_loss: 0.7026 - val_accuracy: 0.6744\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 769us/step - loss: 0.6483 - accuracy: 0.7277 - val_loss: 0.6940 - val_accuracy: 0.7023\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 841us/step - loss: 0.6469 - accuracy: 0.7339 - val_loss: 0.7130 - val_accuracy: 0.6698\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.6434 - accuracy: 0.7287 - val_loss: 0.6981 - val_accuracy: 0.6884\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.7334 - val_loss: 0.6963 - val_accuracy: 0.7209\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.6466 - accuracy: 0.7287 - val_loss: 0.7084 - val_accuracy: 0.6651\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6428 - accuracy: 0.7308 - val_loss: 0.6927 - val_accuracy: 0.7023\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.6417 - accuracy: 0.7355 - val_loss: 0.7121 - val_accuracy: 0.6651\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.6410 - accuracy: 0.7355 - val_loss: 0.6915 - val_accuracy: 0.6837\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 975us/step - loss: 0.6405 - accuracy: 0.7261 - val_loss: 0.7086 - val_accuracy: 0.6698\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 846us/step - loss: 0.6443 - accuracy: 0.7287 - val_loss: 0.7212 - val_accuracy: 0.6698\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 826us/step - loss: 0.6384 - accuracy: 0.7324 - val_loss: 0.7020 - val_accuracy: 0.6744\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6353 - accuracy: 0.7339 - val_loss: 0.7051 - val_accuracy: 0.6884\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6395 - accuracy: 0.7407 - val_loss: 0.6991 - val_accuracy: 0.7070\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6347 - accuracy: 0.7350 - val_loss: 0.6863 - val_accuracy: 0.6977\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.6320 - accuracy: 0.7396 - val_loss: 0.7005 - val_accuracy: 0.6977\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.7318 - val_loss: 0.6993 - val_accuracy: 0.7256\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6314 - accuracy: 0.7360 - val_loss: 0.7007 - val_accuracy: 0.6791\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6366 - accuracy: 0.7360 - val_loss: 0.7162 - val_accuracy: 0.6744\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6391 - accuracy: 0.7256 - val_loss: 0.6832 - val_accuracy: 0.7023\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 704us/step - loss: 0.6321 - accuracy: 0.7303 - val_loss: 0.6887 - val_accuracy: 0.6977\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6315 - accuracy: 0.7344 - val_loss: 0.6879 - val_accuracy: 0.6744\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6326 - accuracy: 0.7381 - val_loss: 0.6847 - val_accuracy: 0.7256\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 830us/step - loss: 0.6285 - accuracy: 0.7355 - val_loss: 0.7084 - val_accuracy: 0.6651\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.6286 - accuracy: 0.7344 - val_loss: 0.6863 - val_accuracy: 0.7070\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6290 - accuracy: 0.7318 - val_loss: 0.6842 - val_accuracy: 0.6977\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6288 - accuracy: 0.7360 - val_loss: 0.7009 - val_accuracy: 0.6930\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.6242 - accuracy: 0.7360 - val_loss: 0.6949 - val_accuracy: 0.7163\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 828us/step - loss: 0.6263 - accuracy: 0.7396 - val_loss: 0.6844 - val_accuracy: 0.7023\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.6264 - accuracy: 0.7339 - val_loss: 0.6910 - val_accuracy: 0.7256\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6221 - accuracy: 0.7438 - val_loss: 0.6922 - val_accuracy: 0.7070\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.7334 - val_loss: 0.6828 - val_accuracy: 0.7302\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6220 - accuracy: 0.7412 - val_loss: 0.6872 - val_accuracy: 0.6977\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6206 - accuracy: 0.7376 - val_loss: 0.6994 - val_accuracy: 0.7256\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6191 - accuracy: 0.7407 - val_loss: 0.6847 - val_accuracy: 0.7256\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6203 - accuracy: 0.7422 - val_loss: 0.6796 - val_accuracy: 0.7163\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.6182 - accuracy: 0.7474 - val_loss: 0.6907 - val_accuracy: 0.7116\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.6214 - accuracy: 0.7391 - val_loss: 0.6764 - val_accuracy: 0.6930\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - 0s 745us/step - loss: 0.6202 - accuracy: 0.7391 - val_loss: 0.7116 - val_accuracy: 0.6698\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.6209 - accuracy: 0.7401 - val_loss: 0.6924 - val_accuracy: 0.6884\n",
      "Epoch 178/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6179 - accuracy: 0.7401 - val_loss: 0.6801 - val_accuracy: 0.7163\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6178 - accuracy: 0.7427 - val_loss: 0.6960 - val_accuracy: 0.7302\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6144 - accuracy: 0.7412 - val_loss: 0.6870 - val_accuracy: 0.7163\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6171 - accuracy: 0.7459 - val_loss: 0.6962 - val_accuracy: 0.6977\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6222 - accuracy: 0.7401 - val_loss: 0.7004 - val_accuracy: 0.6930\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6124 - accuracy: 0.7417 - val_loss: 0.6851 - val_accuracy: 0.7302\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6148 - accuracy: 0.7484 - val_loss: 0.6855 - val_accuracy: 0.6884\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6154 - accuracy: 0.7448 - val_loss: 0.6797 - val_accuracy: 0.7163\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.7391 - val_loss: 0.6829 - val_accuracy: 0.7349\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6097 - accuracy: 0.7438 - val_loss: 0.6866 - val_accuracy: 0.6977\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.6131 - accuracy: 0.7422 - val_loss: 0.6753 - val_accuracy: 0.7116\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - 0s 689us/step - loss: 0.6154 - accuracy: 0.7438 - val_loss: 0.6780 - val_accuracy: 0.7023\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.6110 - accuracy: 0.7484 - val_loss: 0.6842 - val_accuracy: 0.7302\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.6197 - accuracy: 0.7422 - val_loss: 0.6869 - val_accuracy: 0.7256\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.6125 - accuracy: 0.7339 - val_loss: 0.6758 - val_accuracy: 0.7209\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6091 - accuracy: 0.7443 - val_loss: 0.6786 - val_accuracy: 0.7070\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6079 - accuracy: 0.7484 - val_loss: 0.6876 - val_accuracy: 0.7302\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6080 - accuracy: 0.7567 - val_loss: 0.6737 - val_accuracy: 0.6977\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - 0s 730us/step - loss: 0.6079 - accuracy: 0.7448 - val_loss: 0.6856 - val_accuracy: 0.7116\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - 0s 945us/step - loss: 0.6080 - accuracy: 0.7459 - val_loss: 0.6677 - val_accuracy: 0.7070\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6065 - accuracy: 0.7443 - val_loss: 0.6839 - val_accuracy: 0.7070\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6054 - accuracy: 0.7448 - val_loss: 0.6739 - val_accuracy: 0.7256\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.6057 - accuracy: 0.7484 - val_loss: 0.6968 - val_accuracy: 0.7256\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - 0s 810us/step - loss: 0.6113 - accuracy: 0.7401 - val_loss: 0.6838 - val_accuracy: 0.7163\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6035 - accuracy: 0.7479 - val_loss: 0.6780 - val_accuracy: 0.7302\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6050 - accuracy: 0.7469 - val_loss: 0.6785 - val_accuracy: 0.7070\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.6037 - accuracy: 0.7495 - val_loss: 0.6756 - val_accuracy: 0.7209\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - 0s 793us/step - loss: 0.6038 - accuracy: 0.7438 - val_loss: 0.6805 - val_accuracy: 0.7163\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.6027 - accuracy: 0.7469 - val_loss: 0.6885 - val_accuracy: 0.7116\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.6029 - accuracy: 0.7438 - val_loss: 0.6756 - val_accuracy: 0.7209\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.6009 - accuracy: 0.7443 - val_loss: 0.6718 - val_accuracy: 0.7023\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - 0s 874us/step - loss: 0.6008 - accuracy: 0.7438 - val_loss: 0.6761 - val_accuracy: 0.7209\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.6009 - accuracy: 0.7495 - val_loss: 0.6760 - val_accuracy: 0.7349\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5985 - accuracy: 0.7453 - val_loss: 0.6755 - val_accuracy: 0.7209\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5967 - accuracy: 0.7464 - val_loss: 0.6761 - val_accuracy: 0.7163\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5976 - accuracy: 0.7474 - val_loss: 0.7034 - val_accuracy: 0.6837\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5997 - accuracy: 0.7396 - val_loss: 0.6703 - val_accuracy: 0.7070\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5963 - accuracy: 0.7536 - val_loss: 0.6723 - val_accuracy: 0.7302\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.6015 - accuracy: 0.7438 - val_loss: 0.6821 - val_accuracy: 0.7070\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - 0s 736us/step - loss: 0.5954 - accuracy: 0.7557 - val_loss: 0.6672 - val_accuracy: 0.7163\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - 0s 928us/step - loss: 0.5979 - accuracy: 0.7484 - val_loss: 0.6705 - val_accuracy: 0.7209\n",
      "Epoch 219/500\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.5951 - accuracy: 0.7510 - val_loss: 0.6751 - val_accuracy: 0.7256\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5953 - accuracy: 0.7505 - val_loss: 0.6791 - val_accuracy: 0.7163\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5951 - accuracy: 0.7490 - val_loss: 0.6780 - val_accuracy: 0.7302\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5962 - accuracy: 0.7469 - val_loss: 0.6765 - val_accuracy: 0.6884\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - 0s 894us/step - loss: 0.5919 - accuracy: 0.7516 - val_loss: 0.6720 - val_accuracy: 0.6977\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5979 - accuracy: 0.7536 - val_loss: 0.6652 - val_accuracy: 0.7302\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5906 - accuracy: 0.7495 - val_loss: 0.6638 - val_accuracy: 0.7256\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5892 - accuracy: 0.7536 - val_loss: 0.6654 - val_accuracy: 0.7209\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5895 - accuracy: 0.7495 - val_loss: 0.6752 - val_accuracy: 0.7163\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5938 - accuracy: 0.7490 - val_loss: 0.6657 - val_accuracy: 0.7209\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.7541 - val_loss: 0.6632 - val_accuracy: 0.7442\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5882 - accuracy: 0.7541 - val_loss: 0.6688 - val_accuracy: 0.7302\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5897 - accuracy: 0.7552 - val_loss: 0.6648 - val_accuracy: 0.7163\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5904 - accuracy: 0.7583 - val_loss: 0.6701 - val_accuracy: 0.7256\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5934 - accuracy: 0.7521 - val_loss: 0.6682 - val_accuracy: 0.7302\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5883 - accuracy: 0.7541 - val_loss: 0.6661 - val_accuracy: 0.7256\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5880 - accuracy: 0.7490 - val_loss: 0.6633 - val_accuracy: 0.7349\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5901 - accuracy: 0.7453 - val_loss: 0.6619 - val_accuracy: 0.7116\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.5840 - accuracy: 0.7567 - val_loss: 0.6651 - val_accuracy: 0.7163\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.5862 - accuracy: 0.7547 - val_loss: 0.6659 - val_accuracy: 0.7209\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5928 - accuracy: 0.7510 - val_loss: 0.6739 - val_accuracy: 0.7209\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5929 - accuracy: 0.7490 - val_loss: 0.6783 - val_accuracy: 0.7023\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5839 - accuracy: 0.7552 - val_loss: 0.6749 - val_accuracy: 0.7116\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5900 - accuracy: 0.7500 - val_loss: 0.6634 - val_accuracy: 0.7256\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5861 - accuracy: 0.7547 - val_loss: 0.6790 - val_accuracy: 0.7070\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5842 - accuracy: 0.7526 - val_loss: 0.6636 - val_accuracy: 0.7395\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5844 - accuracy: 0.7516 - val_loss: 0.6829 - val_accuracy: 0.7209\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5848 - accuracy: 0.7521 - val_loss: 0.6729 - val_accuracy: 0.7302\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5818 - accuracy: 0.7536 - val_loss: 0.6649 - val_accuracy: 0.7209\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5857 - accuracy: 0.7531 - val_loss: 0.6849 - val_accuracy: 0.6977\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.5821 - accuracy: 0.7547 - val_loss: 0.6672 - val_accuracy: 0.7256\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5807 - accuracy: 0.7573 - val_loss: 0.6891 - val_accuracy: 0.7302\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5819 - accuracy: 0.7521 - val_loss: 0.6621 - val_accuracy: 0.7256\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5850 - accuracy: 0.7541 - val_loss: 0.6716 - val_accuracy: 0.7256\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.5801 - accuracy: 0.7547 - val_loss: 0.6581 - val_accuracy: 0.7256\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5778 - accuracy: 0.7578 - val_loss: 0.6598 - val_accuracy: 0.7163\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5853 - accuracy: 0.7583 - val_loss: 0.6653 - val_accuracy: 0.7395\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5775 - accuracy: 0.7536 - val_loss: 0.6722 - val_accuracy: 0.7163\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5803 - accuracy: 0.7624 - val_loss: 0.6552 - val_accuracy: 0.7302\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5767 - accuracy: 0.7567 - val_loss: 0.6634 - val_accuracy: 0.7163\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5765 - accuracy: 0.7562 - val_loss: 0.6567 - val_accuracy: 0.7209\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5776 - accuracy: 0.7552 - val_loss: 0.6743 - val_accuracy: 0.7256\n",
      "Epoch 261/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5775 - accuracy: 0.7583 - val_loss: 0.6615 - val_accuracy: 0.6977\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5762 - accuracy: 0.7536 - val_loss: 0.6612 - val_accuracy: 0.7349\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5785 - accuracy: 0.7562 - val_loss: 0.6756 - val_accuracy: 0.6977\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5788 - accuracy: 0.7573 - val_loss: 0.6615 - val_accuracy: 0.7209\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5760 - accuracy: 0.7567 - val_loss: 0.6540 - val_accuracy: 0.7209\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5789 - accuracy: 0.7599 - val_loss: 0.6673 - val_accuracy: 0.7302\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5786 - accuracy: 0.7531 - val_loss: 0.6879 - val_accuracy: 0.6837\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5770 - accuracy: 0.7604 - val_loss: 0.6648 - val_accuracy: 0.7163\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5769 - accuracy: 0.7599 - val_loss: 0.6740 - val_accuracy: 0.6977\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5754 - accuracy: 0.7599 - val_loss: 0.6591 - val_accuracy: 0.7209\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5734 - accuracy: 0.7557 - val_loss: 0.6567 - val_accuracy: 0.7395\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5723 - accuracy: 0.7578 - val_loss: 0.6652 - val_accuracy: 0.7209\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5756 - accuracy: 0.7573 - val_loss: 0.6531 - val_accuracy: 0.7209\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5733 - accuracy: 0.7562 - val_loss: 0.6621 - val_accuracy: 0.7070\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.5731 - accuracy: 0.7588 - val_loss: 0.6574 - val_accuracy: 0.7256\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5720 - accuracy: 0.7614 - val_loss: 0.7008 - val_accuracy: 0.7116\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5761 - accuracy: 0.7526 - val_loss: 0.6626 - val_accuracy: 0.7442\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5707 - accuracy: 0.7593 - val_loss: 0.6613 - val_accuracy: 0.7209\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5721 - accuracy: 0.7609 - val_loss: 0.6654 - val_accuracy: 0.7302\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5710 - accuracy: 0.7547 - val_loss: 0.6745 - val_accuracy: 0.7209\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5744 - accuracy: 0.7609 - val_loss: 0.6573 - val_accuracy: 0.7256\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.5713 - accuracy: 0.7588 - val_loss: 0.6716 - val_accuracy: 0.7256\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5752 - accuracy: 0.7562 - val_loss: 0.6545 - val_accuracy: 0.7209\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5690 - accuracy: 0.7588 - val_loss: 0.6622 - val_accuracy: 0.7209\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5736 - accuracy: 0.7588 - val_loss: 0.6559 - val_accuracy: 0.7395\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.5706 - accuracy: 0.7547 - val_loss: 0.6515 - val_accuracy: 0.7256\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5669 - accuracy: 0.7650 - val_loss: 0.6634 - val_accuracy: 0.7116\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5748 - accuracy: 0.7578 - val_loss: 0.6564 - val_accuracy: 0.7256\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5710 - accuracy: 0.7609 - val_loss: 0.6759 - val_accuracy: 0.7163\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5683 - accuracy: 0.7609 - val_loss: 0.6624 - val_accuracy: 0.7116\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - 0s 816us/step - loss: 0.5704 - accuracy: 0.7552 - val_loss: 0.6675 - val_accuracy: 0.7163\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5694 - accuracy: 0.7593 - val_loss: 0.6680 - val_accuracy: 0.7070\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5652 - accuracy: 0.7619 - val_loss: 0.6540 - val_accuracy: 0.7349\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5681 - accuracy: 0.7614 - val_loss: 0.6681 - val_accuracy: 0.7116\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5650 - accuracy: 0.7593 - val_loss: 0.6690 - val_accuracy: 0.7302\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.5692 - accuracy: 0.7593 - val_loss: 0.6546 - val_accuracy: 0.7349\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5651 - accuracy: 0.7593 - val_loss: 0.6580 - val_accuracy: 0.7209\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - 0s 848us/step - loss: 0.5705 - accuracy: 0.7593 - val_loss: 0.6662 - val_accuracy: 0.7302\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5685 - accuracy: 0.7588 - val_loss: 0.6538 - val_accuracy: 0.7116\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5724 - accuracy: 0.7650 - val_loss: 0.6711 - val_accuracy: 0.6977\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5657 - accuracy: 0.7661 - val_loss: 0.6635 - val_accuracy: 0.7302\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.5655 - accuracy: 0.7630 - val_loss: 0.6666 - val_accuracy: 0.6977\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5668 - accuracy: 0.7609 - val_loss: 0.6568 - val_accuracy: 0.7349\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5658 - accuracy: 0.7645 - val_loss: 0.6572 - val_accuracy: 0.7442\n",
      "Epoch 305/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5647 - accuracy: 0.7588 - val_loss: 0.6550 - val_accuracy: 0.7349\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5636 - accuracy: 0.7599 - val_loss: 0.6578 - val_accuracy: 0.7023\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5630 - accuracy: 0.7624 - val_loss: 0.6557 - val_accuracy: 0.7349\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5659 - accuracy: 0.7630 - val_loss: 0.6550 - val_accuracy: 0.7209\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5603 - accuracy: 0.7609 - val_loss: 0.6694 - val_accuracy: 0.7163\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5735 - accuracy: 0.7547 - val_loss: 0.6681 - val_accuracy: 0.7395\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5669 - accuracy: 0.7578 - val_loss: 0.6631 - val_accuracy: 0.7302\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5641 - accuracy: 0.7557 - val_loss: 0.6548 - val_accuracy: 0.7116\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5647 - accuracy: 0.7599 - val_loss: 0.6541 - val_accuracy: 0.7256\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5631 - accuracy: 0.7609 - val_loss: 0.6618 - val_accuracy: 0.7302\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.5604 - accuracy: 0.7650 - val_loss: 0.6548 - val_accuracy: 0.7442\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5608 - accuracy: 0.7671 - val_loss: 0.6688 - val_accuracy: 0.7070\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5648 - accuracy: 0.7624 - val_loss: 0.6643 - val_accuracy: 0.7256\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - 0s 839us/step - loss: 0.5639 - accuracy: 0.7588 - val_loss: 0.6524 - val_accuracy: 0.7256\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5610 - accuracy: 0.7619 - val_loss: 0.6829 - val_accuracy: 0.7116\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5623 - accuracy: 0.7593 - val_loss: 0.6547 - val_accuracy: 0.7163\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5613 - accuracy: 0.7614 - val_loss: 0.6578 - val_accuracy: 0.7256\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5646 - accuracy: 0.7630 - val_loss: 0.6515 - val_accuracy: 0.7302\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5602 - accuracy: 0.7635 - val_loss: 0.6670 - val_accuracy: 0.7349\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5628 - accuracy: 0.7604 - val_loss: 0.6519 - val_accuracy: 0.7209\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5605 - accuracy: 0.7614 - val_loss: 0.6639 - val_accuracy: 0.7442\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5636 - accuracy: 0.7619 - val_loss: 0.6724 - val_accuracy: 0.7442\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7609 - val_loss: 0.6673 - val_accuracy: 0.7488\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5613 - accuracy: 0.7619 - val_loss: 0.6550 - val_accuracy: 0.7116\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.5580 - accuracy: 0.7645 - val_loss: 0.6512 - val_accuracy: 0.7302\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5552 - accuracy: 0.7676 - val_loss: 0.6543 - val_accuracy: 0.7070\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5579 - accuracy: 0.7635 - val_loss: 0.6616 - val_accuracy: 0.7395\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5567 - accuracy: 0.7609 - val_loss: 0.6595 - val_accuracy: 0.7302\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5562 - accuracy: 0.7614 - val_loss: 0.6540 - val_accuracy: 0.7209\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - 0s 806us/step - loss: 0.5556 - accuracy: 0.7666 - val_loss: 0.6595 - val_accuracy: 0.7256\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5567 - accuracy: 0.7630 - val_loss: 0.6626 - val_accuracy: 0.7302\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5576 - accuracy: 0.7666 - val_loss: 0.6603 - val_accuracy: 0.7256\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5557 - accuracy: 0.7661 - val_loss: 0.6515 - val_accuracy: 0.7163\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5570 - accuracy: 0.7624 - val_loss: 0.6564 - val_accuracy: 0.7349\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5595 - accuracy: 0.7588 - val_loss: 0.6606 - val_accuracy: 0.7209\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5578 - accuracy: 0.7588 - val_loss: 0.6496 - val_accuracy: 0.7256\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5599 - accuracy: 0.7661 - val_loss: 0.6661 - val_accuracy: 0.7349\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5558 - accuracy: 0.7666 - val_loss: 0.6793 - val_accuracy: 0.7023\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.5599 - accuracy: 0.7609 - val_loss: 0.6589 - val_accuracy: 0.7395\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5564 - accuracy: 0.7619 - val_loss: 0.6608 - val_accuracy: 0.7395\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.5569 - accuracy: 0.7666 - val_loss: 0.6616 - val_accuracy: 0.7163\n",
      "Epoch 346/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5592 - accuracy: 0.7635 - val_loss: 0.6420 - val_accuracy: 0.7256\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5543 - accuracy: 0.7650 - val_loss: 0.6545 - val_accuracy: 0.7209\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5540 - accuracy: 0.7640 - val_loss: 0.7003 - val_accuracy: 0.7116\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5586 - accuracy: 0.7635 - val_loss: 0.6624 - val_accuracy: 0.7395\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5542 - accuracy: 0.7614 - val_loss: 0.6509 - val_accuracy: 0.7302\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5578 - accuracy: 0.7671 - val_loss: 0.6558 - val_accuracy: 0.7349\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.5583 - accuracy: 0.7619 - val_loss: 0.6505 - val_accuracy: 0.7302\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5538 - accuracy: 0.7656 - val_loss: 0.6641 - val_accuracy: 0.7395\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - 0s 822us/step - loss: 0.5543 - accuracy: 0.7614 - val_loss: 0.6476 - val_accuracy: 0.7349\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5523 - accuracy: 0.7656 - val_loss: 0.6667 - val_accuracy: 0.7395\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5529 - accuracy: 0.7682 - val_loss: 0.6615 - val_accuracy: 0.7023\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5506 - accuracy: 0.7645 - val_loss: 0.6404 - val_accuracy: 0.7209\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5525 - accuracy: 0.7604 - val_loss: 0.6581 - val_accuracy: 0.7302\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5527 - accuracy: 0.7671 - val_loss: 0.6644 - val_accuracy: 0.7256\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5561 - accuracy: 0.7702 - val_loss: 0.6573 - val_accuracy: 0.7256\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - 0s 855us/step - loss: 0.5612 - accuracy: 0.7635 - val_loss: 0.6461 - val_accuracy: 0.7163\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5529 - accuracy: 0.7656 - val_loss: 0.6571 - val_accuracy: 0.7349\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5506 - accuracy: 0.7650 - val_loss: 0.6421 - val_accuracy: 0.7349\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5493 - accuracy: 0.7707 - val_loss: 0.6844 - val_accuracy: 0.7116\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5537 - accuracy: 0.7697 - val_loss: 0.6581 - val_accuracy: 0.7302\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.5517 - accuracy: 0.7604 - val_loss: 0.6607 - val_accuracy: 0.7442\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5490 - accuracy: 0.7697 - val_loss: 0.6922 - val_accuracy: 0.6977\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5525 - accuracy: 0.7676 - val_loss: 0.6616 - val_accuracy: 0.7256\n",
      "Epoch 369/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5508 - accuracy: 0.7687 - val_loss: 0.6566 - val_accuracy: 0.7116\n",
      "Epoch 370/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5521 - accuracy: 0.7650 - val_loss: 0.6553 - val_accuracy: 0.7302\n",
      "Epoch 371/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5517 - accuracy: 0.7702 - val_loss: 0.6630 - val_accuracy: 0.7256\n",
      "Epoch 372/500\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.5501 - accuracy: 0.7682 - val_loss: 0.6459 - val_accuracy: 0.7395\n",
      "Epoch 373/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5487 - accuracy: 0.7713 - val_loss: 0.6504 - val_accuracy: 0.7163\n",
      "Epoch 374/500\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7676 - val_loss: 0.6654 - val_accuracy: 0.7535\n",
      "Epoch 375/500\n",
      "72/72 [==============================] - 0s 808us/step - loss: 0.5486 - accuracy: 0.7682 - val_loss: 0.6594 - val_accuracy: 0.7349\n",
      "Epoch 376/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5538 - accuracy: 0.7619 - val_loss: 0.6553 - val_accuracy: 0.7116\n",
      "Epoch 377/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5514 - accuracy: 0.7661 - val_loss: 0.6497 - val_accuracy: 0.7256\n",
      "Epoch 378/500\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5477 - accuracy: 0.7661 - val_loss: 0.6503 - val_accuracy: 0.7116\n",
      "Epoch 379/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5544 - accuracy: 0.7609 - val_loss: 0.6760 - val_accuracy: 0.7395\n",
      "Epoch 380/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5474 - accuracy: 0.7645 - val_loss: 0.6451 - val_accuracy: 0.7209\n",
      "Epoch 381/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5487 - accuracy: 0.7702 - val_loss: 0.6462 - val_accuracy: 0.7302\n",
      "Epoch 382/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5510 - accuracy: 0.7692 - val_loss: 0.6689 - val_accuracy: 0.7349\n",
      "Epoch 383/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5466 - accuracy: 0.7682 - val_loss: 0.6698 - val_accuracy: 0.7349\n",
      "Epoch 384/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5474 - accuracy: 0.7671 - val_loss: 0.6439 - val_accuracy: 0.7209\n",
      "Epoch 385/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5475 - accuracy: 0.7687 - val_loss: 0.6413 - val_accuracy: 0.7256\n",
      "Epoch 386/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5482 - accuracy: 0.7692 - val_loss: 0.6639 - val_accuracy: 0.7302\n",
      "Epoch 387/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5478 - accuracy: 0.7661 - val_loss: 0.6471 - val_accuracy: 0.7302\n",
      "Epoch 388/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5491 - accuracy: 0.7666 - val_loss: 0.6665 - val_accuracy: 0.7349\n",
      "Epoch 389/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5462 - accuracy: 0.7656 - val_loss: 0.6713 - val_accuracy: 0.7116\n",
      "Epoch 390/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5467 - accuracy: 0.7682 - val_loss: 0.6501 - val_accuracy: 0.7395\n",
      "Epoch 391/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5469 - accuracy: 0.7656 - val_loss: 0.6494 - val_accuracy: 0.7349\n",
      "Epoch 392/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5458 - accuracy: 0.7713 - val_loss: 0.6683 - val_accuracy: 0.7023\n",
      "Epoch 393/500\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.5455 - accuracy: 0.7749 - val_loss: 0.6539 - val_accuracy: 0.7349\n",
      "Epoch 394/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5452 - accuracy: 0.7692 - val_loss: 0.6660 - val_accuracy: 0.7349\n",
      "Epoch 395/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5439 - accuracy: 0.7697 - val_loss: 0.6468 - val_accuracy: 0.7302\n",
      "Epoch 396/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5462 - accuracy: 0.7676 - val_loss: 0.6524 - val_accuracy: 0.7395\n",
      "Epoch 397/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5437 - accuracy: 0.7682 - val_loss: 0.6630 - val_accuracy: 0.7163\n",
      "Epoch 398/500\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.5486 - accuracy: 0.7702 - val_loss: 0.6478 - val_accuracy: 0.7256\n",
      "Epoch 399/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5459 - accuracy: 0.7661 - val_loss: 0.6543 - val_accuracy: 0.7349\n",
      "Epoch 400/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5444 - accuracy: 0.7702 - val_loss: 0.6547 - val_accuracy: 0.7349\n",
      "Epoch 401/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5450 - accuracy: 0.7718 - val_loss: 0.6691 - val_accuracy: 0.7349\n",
      "Epoch 402/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5457 - accuracy: 0.7713 - val_loss: 0.6528 - val_accuracy: 0.7023\n",
      "Epoch 403/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5441 - accuracy: 0.7671 - val_loss: 0.6539 - val_accuracy: 0.7349\n",
      "Epoch 404/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5440 - accuracy: 0.7671 - val_loss: 0.6563 - val_accuracy: 0.7163\n",
      "Epoch 405/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5414 - accuracy: 0.7707 - val_loss: 0.6415 - val_accuracy: 0.7256\n",
      "Epoch 406/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5456 - accuracy: 0.7656 - val_loss: 0.6550 - val_accuracy: 0.7163\n",
      "Epoch 407/500\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.5449 - accuracy: 0.7718 - val_loss: 0.6539 - val_accuracy: 0.7349\n",
      "Epoch 408/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.5451 - accuracy: 0.7645 - val_loss: 0.6435 - val_accuracy: 0.7395\n",
      "Epoch 409/500\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.5433 - accuracy: 0.7692 - val_loss: 0.6458 - val_accuracy: 0.7209\n",
      "Epoch 410/500\n",
      "72/72 [==============================] - 0s 814us/step - loss: 0.5444 - accuracy: 0.7650 - val_loss: 0.6536 - val_accuracy: 0.7349\n",
      "Epoch 411/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5435 - accuracy: 0.7697 - val_loss: 0.6427 - val_accuracy: 0.7349\n",
      "Epoch 412/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5459 - accuracy: 0.7697 - val_loss: 0.6526 - val_accuracy: 0.7256\n",
      "Epoch 413/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5406 - accuracy: 0.7765 - val_loss: 0.6582 - val_accuracy: 0.7488\n",
      "Epoch 414/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5412 - accuracy: 0.7682 - val_loss: 0.6497 - val_accuracy: 0.7302\n",
      "Epoch 415/500\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.5453 - accuracy: 0.7697 - val_loss: 0.6642 - val_accuracy: 0.7209\n",
      "Epoch 416/500\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.5433 - accuracy: 0.7687 - val_loss: 0.6459 - val_accuracy: 0.7349\n",
      "Epoch 417/500\n",
      "72/72 [==============================] - 0s 852us/step - loss: 0.5426 - accuracy: 0.7718 - val_loss: 0.6534 - val_accuracy: 0.7302\n",
      "Epoch 418/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5460 - accuracy: 0.7713 - val_loss: 0.6637 - val_accuracy: 0.7256\n",
      "Epoch 419/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5406 - accuracy: 0.7744 - val_loss: 0.6724 - val_accuracy: 0.7163\n",
      "Epoch 420/500\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.5449 - accuracy: 0.7656 - val_loss: 0.6464 - val_accuracy: 0.7256\n",
      "Epoch 421/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5418 - accuracy: 0.7676 - val_loss: 0.6449 - val_accuracy: 0.7209\n",
      "Epoch 422/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5415 - accuracy: 0.7765 - val_loss: 0.6622 - val_accuracy: 0.7070\n",
      "Epoch 423/500\n",
      "72/72 [==============================] - 0s 811us/step - loss: 0.5435 - accuracy: 0.7759 - val_loss: 0.6679 - val_accuracy: 0.7256\n",
      "Epoch 424/500\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.5422 - accuracy: 0.7624 - val_loss: 0.6468 - val_accuracy: 0.7302\n",
      "Epoch 425/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5423 - accuracy: 0.7707 - val_loss: 0.6535 - val_accuracy: 0.7488\n",
      "Epoch 426/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5461 - accuracy: 0.7661 - val_loss: 0.6578 - val_accuracy: 0.7116\n",
      "Epoch 427/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5433 - accuracy: 0.7676 - val_loss: 0.6748 - val_accuracy: 0.7163\n",
      "Epoch 428/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5411 - accuracy: 0.7697 - val_loss: 0.6646 - val_accuracy: 0.7163\n",
      "Epoch 429/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5395 - accuracy: 0.7707 - val_loss: 0.6596 - val_accuracy: 0.7395\n",
      "Epoch 430/500\n",
      "72/72 [==============================] - 0s 827us/step - loss: 0.5407 - accuracy: 0.7718 - val_loss: 0.6588 - val_accuracy: 0.7395\n",
      "Epoch 431/500\n",
      "72/72 [==============================] - 0s 804us/step - loss: 0.5423 - accuracy: 0.7676 - val_loss: 0.6656 - val_accuracy: 0.7349\n",
      "Epoch 432/500\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.5399 - accuracy: 0.7733 - val_loss: 0.6769 - val_accuracy: 0.7395\n",
      "Epoch 433/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5430 - accuracy: 0.7687 - val_loss: 0.6491 - val_accuracy: 0.7256\n",
      "Epoch 434/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5428 - accuracy: 0.7728 - val_loss: 0.6614 - val_accuracy: 0.7395\n",
      "Epoch 435/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5384 - accuracy: 0.7765 - val_loss: 0.6467 - val_accuracy: 0.7256\n",
      "Epoch 436/500\n",
      "72/72 [==============================] - 0s 787us/step - loss: 0.5410 - accuracy: 0.7707 - val_loss: 0.6551 - val_accuracy: 0.7209\n",
      "Epoch 437/500\n",
      "72/72 [==============================] - 0s 807us/step - loss: 0.5419 - accuracy: 0.7728 - val_loss: 0.6392 - val_accuracy: 0.7256\n",
      "Epoch 438/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5431 - accuracy: 0.7624 - val_loss: 0.6554 - val_accuracy: 0.7302\n",
      "Epoch 439/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5395 - accuracy: 0.7702 - val_loss: 0.6466 - val_accuracy: 0.7302\n",
      "Epoch 440/500\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.5378 - accuracy: 0.7707 - val_loss: 0.6490 - val_accuracy: 0.7209\n",
      "Epoch 441/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5406 - accuracy: 0.7671 - val_loss: 0.6580 - val_accuracy: 0.7395\n",
      "Epoch 442/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5390 - accuracy: 0.7713 - val_loss: 0.6567 - val_accuracy: 0.7302\n",
      "Epoch 443/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5399 - accuracy: 0.7707 - val_loss: 0.6526 - val_accuracy: 0.7209\n",
      "Epoch 444/500\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.5437 - accuracy: 0.7682 - val_loss: 0.6574 - val_accuracy: 0.7395\n",
      "Epoch 445/500\n",
      "72/72 [==============================] - 0s 839us/step - loss: 0.5372 - accuracy: 0.7759 - val_loss: 0.6482 - val_accuracy: 0.7256\n",
      "Epoch 446/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5358 - accuracy: 0.7676 - val_loss: 0.6513 - val_accuracy: 0.7349\n",
      "Epoch 447/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5416 - accuracy: 0.7656 - val_loss: 0.6496 - val_accuracy: 0.7209\n",
      "Epoch 448/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5382 - accuracy: 0.7682 - val_loss: 0.6588 - val_accuracy: 0.7302\n",
      "Epoch 449/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5341 - accuracy: 0.7754 - val_loss: 0.6596 - val_accuracy: 0.7163\n",
      "Epoch 450/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5381 - accuracy: 0.7765 - val_loss: 0.6494 - val_accuracy: 0.7395\n",
      "Epoch 451/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5382 - accuracy: 0.7692 - val_loss: 0.6475 - val_accuracy: 0.7302\n",
      "Epoch 452/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5379 - accuracy: 0.7718 - val_loss: 0.6497 - val_accuracy: 0.7256\n",
      "Epoch 453/500\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.5374 - accuracy: 0.7744 - val_loss: 0.6592 - val_accuracy: 0.7163\n",
      "Epoch 454/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5359 - accuracy: 0.7790 - val_loss: 0.6688 - val_accuracy: 0.7349\n",
      "Epoch 455/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5377 - accuracy: 0.7728 - val_loss: 0.6753 - val_accuracy: 0.7023\n",
      "Epoch 456/500\n",
      "72/72 [==============================] - 0s 809us/step - loss: 0.5357 - accuracy: 0.7728 - val_loss: 0.6482 - val_accuracy: 0.7256\n",
      "Epoch 457/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5433 - accuracy: 0.7692 - val_loss: 0.6701 - val_accuracy: 0.7163\n",
      "Epoch 458/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5361 - accuracy: 0.7765 - val_loss: 0.6564 - val_accuracy: 0.7256\n",
      "Epoch 459/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5336 - accuracy: 0.7728 - val_loss: 0.6529 - val_accuracy: 0.7302\n",
      "Epoch 460/500\n",
      "72/72 [==============================] - 0s 829us/step - loss: 0.5390 - accuracy: 0.7676 - val_loss: 0.6411 - val_accuracy: 0.7209\n",
      "Epoch 461/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5401 - accuracy: 0.7656 - val_loss: 0.6482 - val_accuracy: 0.7349\n",
      "Epoch 462/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5363 - accuracy: 0.7723 - val_loss: 0.6611 - val_accuracy: 0.7349\n",
      "Epoch 463/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5341 - accuracy: 0.7723 - val_loss: 0.6456 - val_accuracy: 0.7256\n",
      "Epoch 464/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5378 - accuracy: 0.7739 - val_loss: 0.6734 - val_accuracy: 0.7023\n",
      "Epoch 465/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5345 - accuracy: 0.7749 - val_loss: 0.6522 - val_accuracy: 0.7349\n",
      "Epoch 466/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5341 - accuracy: 0.7759 - val_loss: 0.6640 - val_accuracy: 0.7302\n",
      "Epoch 467/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5363 - accuracy: 0.7682 - val_loss: 0.6532 - val_accuracy: 0.7209\n",
      "Epoch 468/500\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.5341 - accuracy: 0.7770 - val_loss: 0.6575 - val_accuracy: 0.7302\n",
      "Epoch 469/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5337 - accuracy: 0.7728 - val_loss: 0.6470 - val_accuracy: 0.7256\n",
      "Epoch 470/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5339 - accuracy: 0.7754 - val_loss: 0.6529 - val_accuracy: 0.7209\n",
      "Epoch 471/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5357 - accuracy: 0.7754 - val_loss: 0.6462 - val_accuracy: 0.7395\n",
      "Epoch 472/500\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.5368 - accuracy: 0.7676 - val_loss: 0.6720 - val_accuracy: 0.7116\n",
      "Epoch 473/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5345 - accuracy: 0.7692 - val_loss: 0.6668 - val_accuracy: 0.7302\n",
      "Epoch 474/500\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.5342 - accuracy: 0.7759 - val_loss: 0.6601 - val_accuracy: 0.7442\n",
      "Epoch 474: early stopping\n",
      "29/29 - 0s - loss: 0.5143 - accuracy: 0.7757 - 112ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import timeit\n",
    "# Buidling neural network model\n",
    "def build_my_model(numberOfClasses):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=10,  activation=\"tanh\"))\n",
    "    model.add(Dense(20,  activation=\"tanh\"))\n",
    "    model.add(Dense(numberOfClasses))\n",
    " \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-3 / 200)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "   # print(model.summary())\n",
    "    return model;\n",
    "\n",
    "\n",
    "tSTAT_NN=[]\n",
    "aSTAT_NN=[]\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    checkpoint_path='bestmodel_0_0_STAT_NN.h5'\n",
    "    keras_callbacks   = [EarlyStopping(monitor='val_accuracy', patience=100, verbose=1),\n",
    "                         ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "                        ]\n",
    "    model=build_my_model(myN);\n",
    "    \n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    history=model.fit(X_train, Y_train, epochs=500, batch_size=27, verbose=1, validation_split=0.1,callbacks=[keras_callbacks])\n",
    "    best_model = load_model(checkpoint_path)\n",
    "    model=best_model;\n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    \n",
    "    tSTAT_NN.append(stop - start)\n",
    "    test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2) \n",
    "    aSTAT_NN.append(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7683807432651519\n",
      "25.271336999999903\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(aSTAT_NN))\n",
    "print(np.mean(tSTAT_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC1\\AppData\\Local\\Temp\\ipykernel_14584\\3171291920.py:19: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  plt.grid(b=None)\n",
      "C:\\Users\\PC1\\AppData\\Local\\Temp\\ipykernel_14584\\3171291920.py:27: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  plt.grid(b=None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 489us/step\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.69      0.72      0.70       184\n",
      "       Inner       0.84      0.88      0.86       178\n",
      "       Outer       0.82      0.74      0.78       184\n",
      "        Ball       0.73      0.66      0.70       184\n",
      "        Comb       0.80      0.88      0.84       184\n",
      "\n",
      "    accuracy                           0.78       914\n",
      "   macro avg       0.78      0.78      0.77       914\n",
      "weighted avg       0.78      0.78      0.77       914\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Training and Validation Accuracy and  Training and Validation Loss\n",
    "plt.rc('axes',edgecolor='k')\n",
    "plt.rc('axes',linewidth='1')\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(history.history['loss']))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.subplot(121, facecolor='w')\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(b=None)\n",
    "\n",
    "plt.subplot(122, facecolor='w')\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.grid(b=None)\n",
    "plt.show()\n",
    "\n",
    "# Draw confusion matrix (It is only for the last trial)\n",
    "predictions=model.predict(X_test);\n",
    "confusion=confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(predictions,axis=1));\n",
    "\n",
    "dataset_labels=np.array(['Normal','Inner','Outer','Ball','Comb'])\n",
    "##\n",
    "df_cm = pd.DataFrame(confusion, \n",
    "              dataset_labels, \n",
    "              dataset_labels)\n",
    "\n",
    "sn.set(font_scale=1.2) # for label size\n",
    "plt.figure(figsize=(4,4))\n",
    "sn.heatmap(df_cm,annot=True,annot_kws={\"size\": 10},fmt = \"d\",linewidths=.5,cmap=\"YlGnBu\") \n",
    "plt.title('TDSIs')\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "\n",
    "# Print classification report\n",
    "print('CLASSIFICATION REPORT\\n',\n",
    "  classification_report(np.argmax(Y_test, axis=1), \n",
    "                        np.argmax(predictions, axis=1), \n",
    "                        target_names=dataset_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The end of TDSIs-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XfZ4ahDDV7QV",
    "MILEa3sq4Ewl",
    "CiLv18pzwyBk",
    "Psj_tDGCT_xr",
    "6WTT3OiUwXaA",
    "XdmzyxqlwmlD",
    "ikVFzxuEApxE",
    "TbRQNLIgmEOV"
   ],
   "name": "RELU HybridCNN+MLP (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
